v e r v e w bias artificial intelligence introductory survey eirini pavlos ujwal vasileios wolfgang salvatore franco symeon emmanouil ioannis katharina claudia fariba miriam harith bettina tina christian klaus gjergji thanassis steffen 1 research center faculty electrical engineering computer science leibniz university hannover hannover germany computer science foundation research heraklion greece leibniz information centre science tecnhnology hannover germany dipartimento di informatica università di pisa pisa italy technology institute centre research technology hellas certh thessaloniki greece leibniz institute social science cologne germany medium institute open university milton keynes uk electrical engineering computer science tu berlin berlin germany computer science ku leuven leuven belgium legal informatics leibniz university hanover hanover germany lab schufa holding ag wiesbaden germany computer science university southampton southampton uk parallel distributed system university stuttgart germany correspondence eirini ntoutsi research center faculty electrical engineering computer science leibniz university hannover hannover germany email ntoutsi funding information european commission number 860630 abstract artificial intelligence ai system widely employed nowadays make decision impact individual society sion might affect everyone everywhere anytime entailing concern potential human right issue therefore necessary move beyond tional ai algorithm optimized predictive performance embed ethical legal principle design training deployment ensure social good still benefiting huge potential ai technology goal survey provide broad multidisciplinary overview area bias ai system focusing technical challenge solution well suggest new research direction towards approach legal frame received 23 september 2019 revised 17 december 2019 accepted 31 december 2019 doi open access article term creative common attribution license permit use distribution reproduction any medium provided original work properly cited 2020 author wire data mining knowledge discovery published wiley periodical wire data mining knowl discov 2020 10 1 14 survey focus ai large part ai powered day big data powerful machine learning algorithm otherwise not specified use general term bias describe problem related ing processing data might result prejudiced decision base demographic feature race sex forth article categorized commercial legal ethical issue fairness data mining commercial legal ethical issue ethical consideration commercial legal ethical issue legal issue k e w r fairness ai machine learning interpretability responsible ai 1 introduction artificial intelligence ai algorithm widely employed business government organization order make decision impact individual society decision might influence everyone everywhere anytime offering solution problem faced different discipline daily life time entailing risk like denied job medical treatment discriminative impact certain population group ha already observed variety case instance pa system predicting risk wa found predict higher risk value black defendant lower white one actual risk angwin larson mattu kirchner 2016 another case google ad tool targeted advertising wa found serve significantly fewer ad high paid job woman men datta tschantz datta 2015 incident led ever increasing public concern impact ai life bias not new problem rather bias old human civilization human nature member dominant majority oblivious experience 1 however may nify bias evolve new classification criterion huge potential new type bias constantly increasing concern led reconsideration system towards new approach also address fairness decision paper survey recent technical approach bias fairness based system discus legal well open challenge direction towards solution societal good divide work three broad category understanding bias approach help understand bias created society enters technical system manifested data used ai algorithm modeled formally defined mitigating bias approach tackle bias different stage making namely preprocessing processing method focusing data input learning algorithm model output respectively accounting bias approach account bias proactively via data collection retroactively explaining human term figure 1 provides visual map topic discussed survey paper complement existing survey either strong focus machine ethic yu et al 2018 study specific subproblem explaining black box model atzmueller 2017 guidotti et 2019 focus specific context web 2018 providing broad categorization technical challenge solution comprehensive coverage different line research well legal ground aware problem bias discrimination not limited ai technology deployed consciously unconsciously way reflect amplify distort real world perception status quo therefore root problem not only technological also naive believe technological tions suffice rather technical solution required including socially acceptable definition fairness meaningful intervention ensure group challenge require 2 14 ntoutsi et al 19424795 2020 3 downloaded test wiley online library see term condition wiley online library rule use oa article governed applicable creative common license multidisciplinary perspective constant dialogue society bias fairness multifaceted tile nevertheless ai technology penetrates life extremely important technology creator aware bias discrimination ensure responsible usage technology keeping mind cal approach not panacea sort bias ai problem 2 understanding bias bias old concept machine learning ml traditionally referring assumption made specific model inductive bias mitchell 1997 classical example occam razor preference simplest hypothesis respect human bias many facet studied many discipline including psychology ethnography law forth survey consider bias inclination prejudice decision made ai system one person group especially way considered unfair given definition focus bias enters ai system manifested data comprising input ai algorithm tackling bias entail answering question define fairness considered ai system discus different fairness notion employed existing solution finally close section legal implication data collection bias definition cause bias ai relies heavily data generated human content collected via system created human therefore whatever bias exist human enter system even worse amplified due complex sociotechnical system result algorithm may reproduce even increase existing inequality discrimination karimi génois wagner singer strohmaier 2018 within society certain social group may disadvantaged usually result institutional bias tendency procedure practice particular institution operate way some social group advantaged others disadvantaged need not result conscious discrimination rather majority following existing norm institutional racism sexism common example chandler munday 2011 algorithm part ting biased institution structure may also amplify introduce bias favor phenomenon aspect human behavior easily quantifiable hard even impossible measure problem exacerbated fact certain data may easier access analyze others ha caused example role twitter various societal phenomenon overemphasized tufekci 2014 introduced algorithmic system encourage creation specific data collection infrastructure policy understanding bias data generation cause bias data collection institutional bias sensitive feature causal inference bias manifestation data data representativeness data modality causal reasoning predicted outcome predicted actual outcome predicted probability actual outcome fairness definition instance class modification mitigating bias instance selection instance weighting classification model adaptation regularization loss function constraint latent fair class score correction boundary decision wrapping fair classifier top baselearner accounting bias bias elicitation individual assessor mathematical data collection crowdsourcing pooling group elicitation consensus building description causal logic describing modelling bias ontological formalism reasoning model explanation approximation explaining ai decision inherently interpretable model local behaviour explanation legal issue data accuracy gdpr regulation provision equality prohibition intellectual property issue discrimination data modification legal legal basis modification applicability algorithmic application existing rule limited scope discrimination law indirect discrimination figure 1 overview topic discussed survey ntoutsi et al 3 14 19424795 2020 3 downloaded test wiley online library see term condition wiley online library rule use oa article governed applicable creative common license example may suggest tracking surveillance introna wood 2004 change amplify power tions algorithm thus shape societal institution potential intervention vice versa currently not entirely clear complex interaction algorithm structure play society scholar thus called algorithmic accountability improve understanding power structure bias influence algorithm exercise society diakopoulos 2015 bias manifested data bias manifested multimodal data sensitive feature causal influence certain group sensitive feature causal influence data encode number people characteristic form feature value sensitive characteristic identify unds discrimination bias may present not removing ignoring sensitive feature doe not prevent learning biased model correlated feature also known redundant encoding may used proxy example neighborhood city highly correlated race fact ha used tematic denial service bank loan purchase rather including sensitive feature data may beneficial design fair model zliobaite custer 2016 sensitive feature may also correlated target feature classification model want predict example minority preference red car may induce bias minority predicting accident rate red car also preferred aggressive driver higher insurance premium may set red car owner disproportionately impact minority member simple correlation apparently neutral feature lead biased decision discovering understanding causal influence among variable fundamental tool dealing bias recognized legal circle foster 2004 medical research grime schulz 2002 interested reader referred recent survey causal approach fairness classification model loftus russell kusner silva 2018 representativeness data statistical including ml inference require data model wa learned representative data applied however data collection often suffers bias lead representation certain group especially big data many data set not created rigor statistical study activity different often operational goal barocas selbst 2016 frequently occurring bias include selection bias certain individual likely selected study often bias reverse exclusion bias reporting bias observation certain kind likely reported lead sort selection bias observation detection bias phenomenon likely observed particular set subject analogous bias lead property individual example boyd crawford 2012 group coincide social group already exists social bias prejudice discrimination even unbiased computational process lead discriminative decision procedure calder zliobaite 2013 data lead vicious cycle perpetuate discrimination disadvantage barocas selbst 2016 pernicious feedback loop 2016 occur historically disadvantaged group example woman people color developer community image datasets buolamwini gebru 2018 example black people arrest lum isaac 2016 data modality bias data come different modality numerical textual image etc well multimodal representation content ml approach refer structured data represented some 4 14 ntoutsi et al 19424795 2020 3 downloaded test wiley online library see term condition wiley online library rule use oa article governed applicable creative common license fixed feature space data approach also exist especially textual data image bias guage ha attracted lot recent interest many study exposing large number offensive association related gender race publicly available word embeddings bolukbasi chang zou saligrama kalai 2016 well association evolved time kutuzov øvrelid szymanski velldal 2018 similarly computer vision community standard image collection like mnist exploited ing pretrained model used feature extractor assuming collection comprise tive sample real world reality though collection biased many recent study indicated instance buolamwini gebru 2018 found commercial facial recognition service form much better lighter male subject darker female one overall additional layer feature tion typically used within multimodal analysis system make even challenging trace source bias system fairness defined 20 different definition fairness appeared thus far computer science literature verma rubin 2018 zliobaite 2017 some definition others proposed investigated work malizing fairness discipline education past 50 year hutchinson mitchell 2019 ting fairness definition categorized predicted outcome b predicted actual outcome c predicted probability actual outcome similarity based e causal reasoning verma rubin 2018 predicted outcome definition solely rely model prediction demographic parity check age protected group positive class predicted actual outcome combine model diction true label equalized odds requires false positive negative rate similar among protected group predicted probability actual outcome employ predicted probability instead predicted outcome good calibration requires true positive probability protected group contrary definition c only consider sensitive attribute ity based definition also employ attribute fairness awareness state similar uals must treated equally finally causal reasoning definition based directed acyclic graph capture relation feature impact outcome structural equation counterfactual fairness kusner loftus russell silva 2017 construct graph verifies whether attribute defining outcome correlated sensitive attribute despite many formal mathematical definition fairness proposed last year problem ing fairness still open well discussion merit demerit different measure missing goel 2018 show statistical limitation prevailing mathematical definition fairness negative effect enforcing group urge community explicitly focus consequence potential intervention legal issue bias fairness ai taking account variety bias creation ai system impact society question arises whether law provide regulation decision making generally speaking existing eu lation come play discriminatory decision taken provision tackling quality selected data rare earlier control discriminatory decision principle equality tion discrimination art 20 21 eu charter fundamental right art 4 directive directive apply however provision only address discrimination basis specific criterion require prima facie evidence le favorable treatment ground prohibited criterion often difficult establish hacker 2018 latter control quality selected data respect personal data art 5 1 stipulates principle data accuracy however doe not hinder wrongful disproportionate selection respect automated art 22 gdpr recital 71 only point appropriate ematical statistical procedure shall used discriminatory effect shall prevented ness art 22 gdpr uncertain zuiderveen borgesius 2018 provides some safeguard restriction use automated used right transparency obtain human intervention ntoutsi et al 5 14 19424795 2020 3 downloaded test wiley online library see term condition wiley online library rule use oa article governed applicable creative common license contest decision finally some provision legislation found example art 12 regulation ec no european statistic 3 mitigating bias approach bias mitigation categorized preprocessing method focusing data b processing method focusing ml algorithm c method focusing ml model conclude section discussion legal issue bias mitigation preprocessing approach approach category focus data primary source bias aiming produce balanced dataset fed any learning algorithm intuition behind approach fairer training data le discriminative resulting model method modify original data distribution altering class label carefully selected instance close decision boundary kamiran calder 2009 local borhoods luong ruggieri turini 2011 assigning different weight instance based group ship calder kamiran pechenizkiy 2009 carefully sampling group method use heuristic aiming balance protected unprotected group training set however impact not well controlled despite effort minimal data intervention recently calmon wei vinzamuri ramamurthy varshney 2017 proposed probabilistic framework alters data distribution towards fairness trolling distortion preserving data utility learning approach approach reformulate classification problem explicitly incorporating model discrimination behavior objective function regularization constraint training latent target label ple kamiran calder pechenizkiy 2010 modify splitting criterion decision tree also consider impact split protected attribute kamishima akaho asoh sakuma 2012 integrate regularizer reduce effect indirect prejudice mutual information sensitive feature class label dwork hardt pitassi reingold zemel 2012 redefine classification problem minimizing arbitrary loss function subject individual similar individual treated similarly zafar valera gummadi 2017 propose approach disparate mistreatment defined term misclassification rate incorporated svms different direction krasanakis xioufis papadopoulos kompatsiaris 2018 assume existence latent fair class propose iterative training approach towards class alters weight instance iosifidis ntoutsi 2019 pose sequential fair ensemble adafair extends weighted distribution approach adaboost also ing cumulative fairness learner current boosting round moreover optimizes balanced error instead overall error account class imbalance approach refer classification approach unsupervised case also emerged recently example approach samadi tantipongpipat morgenstern singh vempala 2018 force equal reconstruction error protected unprotected group chierichetti kumar lattanzi vassilvitskii 2017 formulate problem fair clustering approximately equal representation protected group every cluster define classical algorithm approach third strategy postprocess classification model ha learned data consists altering model internals approach prediction approach example approach consist correcting confidence cpar classification rule pedreschi ruggieri turini 2009 6 14 ntoutsi et al 19424795 2020 3 downloaded test wiley online library see term condition wiley online library rule use oa article governed applicable creative common license probability naïve bayes model calder verwer 2010 class label leaf decision tree kamiran et 2010 approach not developed recent year superseded method example approach aim keeping proportionality decision among protected versus unprotected group promoting demoting prediction close decision boundary kamiran mansha karim zhang 2018 differentiating decision boundary group hardt price srebro 2016 wrapping fair classifier top base classifier agarwal beygelzimer dudík langford wallach 2018 ysis postprocess calibrated classifier fairness constraint given canetti et 2019 majority approach concerned classification model bias ha deemed relevant interpreting clustering model well lorimer held stoop 2017 legal issue mitigating bias pertinent legal question involve whether modification data envisaged approach well altering model approach could considered lawful besides intellectual property issue might occur no general legal provision dealing way data collected selected even modified provision place mainly training data would still personal data modification well any processing would need legal basis however legitimation could derive informed consent provided specific safeguard met could rely contract legitimate interest besides data quality could relevant term warranty data provider sell data specific issue arises debiasing involves sensitive data art 9 gdpr special category data ethnicity often requires explicit consent kilbertus et 2018 sible solution could art 9 2 g gdpr permit processing reason substantial public interest arguably could seen debiasing ground legitimation apply altering model however trary data modification data protection law would arguably not applicable model would not contain personal data unless model vulnerable confidentiality attack model inversion membership ence veale binns edward 2018 4 accounting bias algorithmic accountability refers assignment responsibility algorithm created impact society kaplan donovan hanson matthew 2019 case ai algorithm problem aggravated not codify solution rather solution inferred via ml algorithm complex data ai accountability ha many facet focus prominent one account bias either proactively via data tion retroactively explaining ai decision human term furthermore discus importance describing documenting bias mean formalism like ontology proactively data collection variety method adopted data acquisition serve diverse need may prone introducing bias data collection stage example morstatter pfeffer liu 2014 proposal made tured approach bias elicitation evidence synthesis including bias checklist elicitation task formed either individual assessor mathematical pooling group elicitation consensus building hybrid approach turner spiegelhalter smith thompson 2009 however bias elicitation found biased even high quality assessor involved remedy proposed manzi forster 2019 among method crowdsourcing popular approach relies acquisition human input dealing data label scarcity ml crowdsourced data label may subject bias different stage process task design experimental setup task decomposition result aggregation selection worker entailing human factor hube fetahu gadiraju 2019 kamar kapoor horvitz 2015 karger oh shah 2011 mitigating bias crowdsourced data becomes harder subjective task presence varying ideological cultural background worker mean possible observe biased label complete ment among worker ntoutsi et al 7 14 19424795 2020 3 downloaded test wiley online library see term condition wiley online library rule use oa article governed applicable creative common license describing modeling bias using ontology accounting bias not only requires understanding different source data knowledge base rithms importantly demand interpretation description meaning potential side effect enance context bias usually unbalanced category understood bias considered source negative side effect nevertheless skewed distribution may simply hide feature domain characteristic removed would hinder discovery relevant insight situation observed instance population lung cer patient highlighted diverse scientific report example garrido et 2019 lung cancer woman men ha significant difference etiology pathophysiology histology risk factor may impact cer occurrence treatment outcome survival furthermore specific organization collaborate lung cancer prevention battle smoking some campaign oriented particular focus group effect initiative observed certain population fact impact gender distribution population could interpreted bias however context imbalance reveals domain specific fact need preserved population formal description uneven distribution provided avoid misinterpretation moreover any type data source knowledge base ontology also suffer various type bias knowledge imbalance example description existing mutation gene knowledge base like property associated gene gene may biased amount research ha conducted disease associated gene expressive formal model demanded order describe explain characteristic data source condition context data source biased formalism like description causal logic example besnard cordier moinard 2014 dehaspe raedt 1996 krötzsch marx ozaki thost 2018 leblanc balduccini vennekens 2019 allow measuring detecting bias data collection diverse type example online data set pitoura et 2017 tion system serbos qi mamoulis pitoura tsaparas 2017 also enable annotation statement trustworthiness son pontelli gelfond balduccini 2016 temporality ozaki krötzsch rudolph 2019 well causation relationship leblanc et 2019 ontology also play relevant role knowledge representation model describing universe discourse term concept class property sumption relationship well contextual statement concept ndfluents mann maret 2017 context ontology language cool strang frank 2003 represent exemplar ontology formal model able express combine diverse contextual dimension interrelation locality vicinity albeit expressive existing ontological formalism not tailored resenting contextual bias differentiating unbalanced category consistently correspond instance world domain therefore expressive ontological formalism demanded represent contextual dimension various type source example data collection knowledge base ontology well annotation denoting causality provenance represented knowledge formalism equip bias detection algorithm reasoning mechanism not only enhance accuracy also enable explainability meaning condition origin context bias thus domain modeling using ontology support bias description interpretability retroactively explaining ai decision explainability refers extent internal mechanic learning model explained human term often used interchangeably interpretability although latter refers whether one predict happen given change model input parameter although attempt tackle interpretable ml existed some time hoffman klein 2017 ha exceptional growth research literature last year ing keywords explainable ai adadi berrada 2018 black box explanation guidotti et 2019 many paper propose approach understanding global logic model building interpretable classifier able mimic obscure decision system generally method designed explaining specific model example deep neural network montavon samek müller 2018 only agnostic black box model henelius puolamäki boström asker papapetrou 2014 difficulty explaining black box complex model ex post motivated proposal transparent classifier interpretable exhibit predictive accuracy close obscure model include bayesian model li huan 2017 generalized additive 8 14 ntoutsi et al 19424795 2020 3 downloaded test wiley online library see term condition wiley online library rule use oa article governed applicable creative common license model lou caruana gehrke hooker 2013 supersparse linear model ustun rudin 2016 decision set lakkaraju bach leskovec 2016 optimal classification tree bertsimas dunn 2017 model tree broelemann kasneci 2019 neural network interpretable layer zhang wu zhu 2018 different stream approach focus local behavior model searching explanation sion made specific instance guidotti et 2019 approach either example lor approximation kasneci gottron 2016 saliency mask image region mainly responsible decision neural network decision yu yue 2015 attention model recurrent network choi et 2016 started lime method ribeiro singh guestrin 2016 main idea derive local explanation decision outcome specific instance learning interpretable model randomly generated neighborhood instance third stream aim bridging local global one defining strategy combining local model incremental way pedreschi et 2019 recent work ha asked fundamental question explanation mittelstadt russell wachter 2019 reject usage term explanation criticizing might appropriate modeling expert not lay man example humanity philosophy entirely different understanding explanation speculate computational method allow u find some middle ground instance some approach ml statistical relational learning particular raedt kersting natarajan poole 2016 take perspective knowledge representation reasoning account developing ml model formal logical statistical ground ai knowledge representation ha developing rich theory argumentation last 25 year dung 1995 recent approach cocarascu toni 2016 try leverage generalizing reasoning aspect ml towards use computational model argumentation outcome model ments counterargument towards certain classification inspected human user might used formal ground explanation manner mittelstadt et al 2019 called legal issue accounting bias data protection rule affect input data output automated decision level ai ing law well consumer competition rule address discriminatory policy primarily perspective automated decision action based however application rule based decision largely unclear present law principle private autonomy decision private party normally not include reason explanation therefore first issue existing rule applied algorithmic given decision often not reasoned hence reason unknown difficult establish wa made basis biased process mittelstadt et 2019 even bias proven second issue limited scope law present law only certain transaction private party fall eu directive liddell 2018 moreover case ai instrument not directly use unlawful criterion gender basis decision rather neutral one residence practice lead le favorable ment certain group raise difficult concept indirect discrimination scenario ently neutral rule disadvantage person group sharing characteristic liddell 2018 finally form differential treatment justified pursues legitimate aim mean pursue aim appropriate necessary unclear whether argument decision making tems produce decision economically sound sufficient justification 5 future direction conclusion several direction impact field going forward first despite large number method igating bias still no conclusive result regarding state art method category intervention perform best whether intervention perform better comparing holistic approach tackle bias stage analysis process believe systematic evaluation existing approach necessary understand capability limitation also vital part proposing new solution difficulty evaluation lie fact different method work different fairness notion ntoutsi et al 9 14 19424795 2020 3 downloaded test wiley online library see term condition wiley online library rule use oa article governed applicable creative common license applicable different ai model end benchmark datasets made available cover ent application area manifest challenge finally standard evaluation procedure measure ing model performance aspect followed accordance international standard like bias working second recognize fairness not reduced simple mathematical definition ness dynamic social not statistical 9 also fair not fair everywhere schäfer haun tomasello 2015 meaning notion fairness varies across country culture application domain fore important realistic applicable fairness definition different context well specific datasets method development evaluation moreover important move beyond typical evaluation setup consider consequence potential intervention ensure wellbeing different group finally given temporal change fairness perception question whether one train model historical data use current problem becomes ingly pressing third related work thus far focus mainly supervised learning many case however direct feedback data label not available therefore alternative learning task considered like unsupervised learning reinforcement learning rl only intermediate feedback provided model recent work emerged direction example jabbari joseph kearns morgenstern roth 2017 examine fairness rl context one need reconsider effect action reward fourth general trend ml community recently generating plausible data existing data using generative adversarial network attempt cover high data demand modern method especially dnns recently approach used also context fairness xu yuan zhang wu 2018 generate synthetic fair data similar real data still however problem representativeness training data impact representativeness generated data might aggravate issue fairness discrimination topic recent work revealed dnns vulnerable adversarial attack tional perturbation input example therefore need method enhance resilience song et 2018 fifth ai scientist everyone involved decision making process aware issue effect design choice assumption instance study show bias creep development process development team not aware importance distinguishing certain category buolamwini gebru 2018 member privileged group may not even aware existence racial category sense often perceive people interpretation unconscious default requires voice individual underprivileged group persistently perceive two strategy appear promising addressing cognitive bias try improve diversity ment team subject algorithm outside scrutiny example permitting certain form reverse engineering algorithmic accountability finally legal point view apart data protection law general provision respect data quality selection still missing recently iso standard data quality iso 8000 wa published though not binding not regard technique moreover first important step made example draft ethic guideline trustworthy ai european commission expert group ai european parliament resolution containing recommendation commission civil law rule robotics however resolution still generic interdisciplinary research needed define specifically needed meet balance fundamental right freedom citizen mitigating bias time ering technical challenge economical need therefore any legislative procedure require close ration legal technical expert already mentioned legal discussion paper refers eu despite many recent effort still no consensus algorithmic fairness regulation across country therefore still lot work done analyzing legal standard regulation national national level support globally legal ai design conclude problem bias discrimination system ha attracted lot attention recently science industry society policy maker ongoing debate ai nities risk life civilization paper survey technical challenge solution well legal ground order advance field direction exploit tremendous power ai solving real world problem also considers societal implication solution final note want stress bias deeply embedded society illusion believe ai bias problem 10 14 ntoutsi et al 19424795 2020 3 downloaded test wiley online library see term condition wiley online library rule use oa article governed applicable creative common license eliminated only technical solution nevertheless technology reflects project bias future key responsibility technology creator understand limit propose safeguard avoid pitfall equal importance also technology creator realize technical solution without any social legal und not thrive therefore multidisciplinary approach required acknowledgment work supported project nobias artificial intelligence without bias ha received funding european union horizon 2020 research innovation programme marie innovative training network grant agreement no conflict interest author declared no conflict interest article author contribution eirini ntoutsi conceptualization investigation methodology resource validation draft review editing pavlos fafalios conceptualization project administration draft editing ujwal gadiraju investigation resource draft vasileios iosifidis investigation resource draft wolfgang nejdl conceptualization vidal resource original draft salvatore ruggieri conceptualization investigation methodology resource draft editing franco turini conceptualization methodology resource draft review editing symeon papadopoulos conceptualization methodology resource visualization draft editing emmanouil krasanakis draft ioannis kompatsiaris alization katharina methodology resource draft claudia wagner resource draft fariba karimi resource draft miriam fernandez resource original draft harith alani resource draft editing bettina berendt tualization methodology resource draft editing tina kruegel investigation resource draft editing christian heinze resource draft editing klaus broelemann methodology resource draft editing gjergji kasneci methodology resource draft editing thanassis tiropanis methodology resource draft editing steffen staab tion methodology resource draft editing orcid eirini ntoutsi pavlos fafalios salvatore ruggieri franco turini symeon papadopoulos emmanouil krasanakis ioannis kompatsiaris katharina miriam fernandez bettina berendt endnotes 1 li ai google professor stanford 2 legal discussion paper refers primarily eu situation acknowledge difficulty mapping territory ai law well extra complexity legislation brings upon therefore believe one tant area future work 3 web science web scientist building web science better world 4 amazon doe not consider race customer 5 general data protection regulation eu gdpr ntoutsi et al 11 14 19424795 2020 3 downloaded test wiley online library see term condition wiley online library rule use oa article governed applicable creative common license 6 7 8 9 related wire article causability explainability artificial intelligence medicine reference adadi berrada 2018 peeking inside survey explainable artificial intelligence xai ieee access 6 agarwal beygelzimer dudík langford wallach 2018 reduction approach fair classification icml 80 angwin larson mattu kirchner 2016 may 23 machine bias propublica atzmueller 2017 declarative aspect explicative data mining computational sensemaking declarative programming knowledge management pp springer 2018 bias web communication acm 61 6 barocas selbst 2016 big data disparate impact california law review 104 bertsimas dunn j 2017 optimal classification tree machine learning 106 7 besnard cordier moinard 2014 argument using ontological causal knowledge foiks lecture note computer ence vol 8367 pp springer bolukbasi chang zou saligrama kalai 2016 man computer programmer woman homemaker debiasing word embeddings nip pp boyd crawford 2012 critical question big data provocation cultural technological scholarly phenomenon mation communication society 15 5 broelemann kasneci 2019 split criterion highly accurate transparent model tree ijcai pp aaai press buolamwini gebru 2018 gender shade intersectional accuracy disparity commercial gender classification fat ings machine learning research vol 81 pp pmlr calder kamiran pechenizkiy 2009 building classifier independency constraint icdm workshop pp ieee computer society calder verwer 2010 three naive bayes approach classification data mining knowledge discovery 21 2 calder zliobaite 2013 unbiased computational process lead discriminative decision procedure discrimination privacy information society study applied philosophy epistemology rational ethic vol 3 pp springer calmon wei vinzamuri ramamurthy varshney 2017 optimized discrimination prevention nip pp canetti cohen dikkala ramnarayan scheffler smith 2019 soft classifier hard decision fair fat pp acm chandler munday 2011 dictionary medium communication oup oxford chierichetti kumar lattanzi vassilvitskii 2017 fair clustering fairlets nip pp choi bahadori sun kulas schuetz stewart 2016 retain interpretable predictive model healthcare using reverse time attention mechanism nip pp cocarascu toni 2016 argumentation machine learning survey comma frontier artificial intelligence tions vol 287 pp io press goel 2018 measure mismeasure fairness critical review fair machine learning arxiv preprint arxiv datta tschantz datta 2015 automated experiment ad privacy setting privacy enhancing technology 2015 1 dehaspe raedt 1996 dlab declarative language bias formalism ismis lecture note computer science vol 1079 pp springer diakopoulos 2015 algorithmic accountability journalistic investigation computational power structure digital journalism 3 3 dung 1995 acceptability argument fundamental role nonmonotonic reasoning logic programming person game artificial intelligence 77 2 dwork hardt pitassi reingold zemel 2012 fairness awareness itcs pp acm foster 2004 causation antidiscrimination law beyond intent versus impact houston law review 41 5 1469 12 14 ntoutsi et al 19424795 2020 3 downloaded test wiley online library see term condition wiley online library rule use oa article governed applicable creative common license garrido viñolas isla provencio majem rotl felip 2019 lung cancer spanish woman ject european journal cancer care 28 1 zimmermann maret 2017 ndfluents ontology annotated statement inference preservation eswc 1 lecture note computer science vol 10249 pp grime schulz 2002 bias causal association observational research lancet 359 guidotti monreale ruggieri turini giannotti pedreschi 2019 survey method explaining black box model acm computing survey 51 5 hacker 2018 teaching fairness artificial intelligence existing novel strategy algorithmic discrimination eu law common market law review 55 4 hardt price srebro 2016 equality opportunity supervised learning nip pp henelius puolamäki boström asker papapetrou 2014 peek black box exploring classifier tion data mining knowledge discovery 28 hoffman klein 2017 explaining explanation part 1 theoretical foundation ieee intelligent system 32 3 hube fetahu gadiraju u 2019 understanding mitigating worker bias crowdsourced collection subjective ments chi 407 acm hutchinson mitchell 2019 50 year test un fairness lesson machine learning fat pp acm introna wood 2004 picturing algorithmic surveillance politics facial recognition system surveillance society 2 iosifidis ntoutsi 2019 adafair cumulative fairness adaptive boosting cikm acm jabbari joseph kearns morgenstern roth 2017 fairness reinforcement learning icml proceeding machine learning research vol 70 pp pmlr kamar kapoor horvitz 2015 identifying accounting bias crowdsourcing hcomp pp aaai press kamiran calder 2009 classifying without discriminating computer control communication pp ieee computer society kamiran calder pechenizkiy 2010 discrimination aware decision tree learning icdm pp ieee computer society kamiran mansha karim zhang x 2018 exploiting reject option classification social discrimination control tion science 425 kamishima akaho asoh sakuma j 2012 classifier prejudice remover regularizer 2 lecture note computer science vol 7524 pp springer kaplan donovan hanson matthew j 2019 algorithmic accountability primer retrieved karger oh shah 2011 iterative learning reliable crowdsourcing system nip pp karimi génois wagner singer strohmaier 2018 homophily influence ranking minority social network entific report kasneci gottron 2016 licon linear weighting scheme contribution input variable deep artificial neural work cikm pp acm kilbertus gascon kusner veale gummadi weller 2018 blind justice fairness encrypted sensitive butes icml pp pmlr krasanakis xioufis papadopoulos kompatsiaris 2018 adaptive sensitive reweighting mitigate bias classification www pp acm krötzsch marx ozaki thost 2018 attributed description logic reasoning knowledge graph ijcai pp aaai press kusner loftus russell silva 2017 counterfactual fairness nip pp kutuzov øvrelid szymanski velldal 2018 diachronic word embeddings semantic shift survey coling pp acl lakkaraju bach leskovec j 2016 interpretable decision set joint framework description prediction kdd pp acm leblanc balduccini vennekens j 2019 explaining actual causation via reasoning action change jelia lecture note computer science vol 11468 pp springer li huan j 2017 constructivism learning learning paradigm transparent predictive analytics kdd pp acm liddell 2018 handbook european law european union agency fundamental right fra loftus russell kusner silva 2018 causal reasoning algorithmic fairness corr lorimer held stoop 2017 clustering much bias need philosophical transaction royal society 375 lou caruana gehrke hooker 2013 accurate intelligible model pairwise interaction kdd pp acm lum isaac 2016 predict serve significance 13 5 ntoutsi et al 13 14 19424795 2020 3 downloaded test wiley online library see term condition wiley online library rule use oa article governed applicable creative common license luong ruggieri turini 2011 implementation situation testing discrimination discovery prevention kdd pp acm yu yue x 2015 survey image saliency detection method cyberc pp ieee computer society manzi forster 2019 bias bias elicitation communication statistic theory method 48 18 mitchell 1997 machine learning new york ny mittelstadt russell wachter 2019 explaining explanation ai fat pp acm montavon samek müller 2018 method interpreting understanding deep neural network digital signal processing 73 morstatter pfeffer liu 2014 biased assessing representativeness twitter streaming api www ion volume pp acm 2016 weapon math destruction big data increase inequality threatens democracy crown publishing group ozaki krötzsch rudolph 2019 temporally attributed description logic description logic theory combination lecture note computer science vol 11560 pp springer pedreschi giannotti guidotti monreale ruggieri turini 2019 meaningful explanation black box ai decision system aaai pp aaai press pedreschi ruggieri turini 2009 measuring discrimination decision record sdm pp siam pitoura tsaparas flouris fundulaki papadakos abiteboul weikum 2017 measuring bias online tion sigmod record 46 4 raedt kersting natarajan poole 2016 statistical relational artificial intelligence logic probability computation synthesis lecture artificial intelligence machine learning 10 2 ribeiro singh guestrin 2016 trust explaining prediction any classifier kdd pp acm samadi tantipongpipat morgenstern singh vempala 2018 price fair pca one extra dimension rip pp schäfer haun tomasello 2015 fair not fair everywhere psychological science 26 8 serbos qi mamoulis pitoura tsaparas 2017 fairness recommendation www pp acm son pontelli gelfond balduccini 2016 reasoning truthfulness agent using answer set programming kr pp aaai press song cheng yang li wu wu li 2018 mat adversarial training method mitigate sarial attack isvlsi pp ieee computer society strang frank 2003 cool context ontology language enable contextual interoperability dais lecture note computer science vol 2893 pp springer tufekci z 2014 big question social medium big data representativeness validity methodological pitfall icwsm aaai press turner spiegelhalter smith thompson 2009 bias modelling evidence synthesis journal royal statistical society 172 1 ustun rudin 2016 supersparse linear integer model optimized medical scoring system machine learning 102 3 veale binns edward 2018 algorithm remember model inversion attack data protection law philosophical action royal society mathematical physical engineering science 376 2133 verma rubin j 2018 fairness definition explained fairware icse pp acm xu yuan zhang wu x 2018 fairgan generative adversarial network bigdata pp ieee yu shen miao leung lesser yang q 2018 building ethic artificial intelligence ijcai pp aaai press zafar valera gummadi 2017 fairness beyond disparate treatment disparate impact learning classification without disparate mistreatment www pp acm zhang wu zhu 2018 interpretable convolutional neural network cvpr pp ieee computer society zliobaite 2017 measuring discrimination algorithmic decision making data mining knowledge discovery 31 4 zliobaite custer b 2016 using sensitive personal data may necessary avoiding discrimination decision model artifical intelligence law 24 2 zuiderveen borgesius 2018 discrimination artificial intelligence algorithmic cite article ntoutsi e fafalios p gadiraju u et al bias artificial intelligence introductory survey wire data mining knowl discov 2020 10 14 14 ntoutsi et al 19424795 2020 3 downloaded test wiley online library see term condition wiley online library rule use oa article governed applicable creative common license