comment vol 2 may 2020 ethical limitation algorithmic fairness solution health care machine learning artificial intelligence ha exposed pernicious bias within health data constitutes substantial ethical threat use machine learning solution algorithmic fairness developed create neutral model model designed produce discriminatory prediction constraining bias respect predicted outcome protected identity race solution omit variable model widely regarded ineffective increase discrimination constrain ensure equal error rate across group derive outcome independent one identity controlling estimated risk outcome mathematically balance benefit harm group temptation engineer ethic algorithm design immense industry increasingly pushing solution space stake could higher clinician integrate model care trusting issue bias ha sufficiently managed within model however even well recognised technical challenge set framing fairness purely technical problem solvable inclusion data accurate computation ethically problematic highlight challenge ethical empirical efficacy solution algorithmic fairness show risk relying heavily called veneer technical could exacerbate harm vulnerable group historically algorithmic fairness ha not accounted complex causal relationship biological environmental social factor give rise difference medical condition across protected identity social determinant health play important role particularly risk model social structural factor affect health across multiple intersecting mechanism social determinant affect health outcome not always well understood additional complication flow reality difference doe not always entail inequity some instance appropriate incorporate difference identity reasonable presumption causation example biological difference gender affect efficacy pharmacological compound incorporating difference prescribing practice doe not make prescription unjust however incorporating causative factor recommendation propagate unequal treatment reifying extant inequity exacerbating effect not allow model promote different standard care according protected identity not causative association outcome nevertheless many case difficult distinguish acknowledging difference propagating discrimination given epistemic uncertainty surrounding association protected identity health outcome use fairness solution create empirical challenge consider case heart attack symptom among woman particularly woman colour research heart health well recognised problematic directly affected uneven improvement treatment heart attack woman men tailoring health solution majority ie referent group inevitably fall short helping patient many algorithmic fairness solution effect replicate problem trying fit group ignoring heterogeneity assuming latter represents true underlying pattern another concern disconnection patient clinical trajectory fair prediction consider implication model corrected fairness predict patient respond treatment patient referent class would happens patient doe not predicted response difference idealised model behaviour affect metric model performance eg specificity sensitivity clinical utility practice moreover model ha made ineffective recommendation could obscured relevant intervention help patient clinician patient believe mode ha rendered neutral any discrepancy model prediction patient true clinical state might impossible interpret result would camouflage persistent comment vol 2 may 2020 health inequality fairness operationalised output metric alone insufficient consequence carefully considered bias ineffective solution algorithmic fairness threaten ethical obligation avoid minimise harm patient panel maleficence demand any new clinical tool assessed patient safety machine learning safety include awareness model limitation respect protected identity social determinant health consideration justice requires implemented model not exacerbate pernicious bias movement toward developing guideline standardised reporting machine learning model health prospective appraisal clinical appraisal particularly important determining implication vulnerable patient machine learning model integrated clinical decision making clinical trial essential providing sense model performance clinician make informed decision awareness related model limitation some computation promote justice revealing unfairness refining problem formulation obermeyer show calibration reveal unfairness seemingly neutral task choice label dictate heavily bias incorporated prediction might no way exists define purely neutral problem some clinical prediction task might susceptible bias others transparency multiple point pipeline machine learning including development testing implementation stage support interpretation model output relevant stakeholder eg researcher clinician patient auditor combined adequate documentation output ensuing decision step support strong accountability framework machine learning tool respect safety fairness patient problem formulation respect bias often ethically charged ethical decision making highlight importance converging knowledge source inform given choice important stakeholder could include affected community cultural anthropologist social scientist race gender theorist computation alone clearly not solve bias problem could offered place within broader approach addressing fairness aim healthcare algorithmic fairness could necessary fix statistical limitation reflective perniciously biased data encourage work worry suggesting solution risk unintended bias not new however machine learning ha potential reveal bias motivate change support panel recommendation ethical approach issue bias health model machine learning relying neutral algorithm problematic challenge cast doubt whether any solution adequately facilitate ethical goal resisting tendency view machine learning solution objective essential remaining preventing unintended harm problem formulation support improved model changing way problem conceptualised operationalised reduce effect pernicious bias clinician key role identifying actionable clinical problem effect bias minimized causal knowledge exists support algorithmic fairness solution clinician science might epistemic advantage support formulation transparency required surrounding model development statistical validation standardisation reporting model machine learning promote transparency training data statistical validation help clinician decision maker determine transferability model served population large discrepancy increase risk patient performance metric eg stratification ethnicity gender socioeconomic status inform consideration patient safety implementing given model initiating transparency field explainable interpretable machine learning evolves suggest sensitive attribute used problem formulation could affect prediction accompanied visibility top predictive feature prediction affected sensitive variable prediction rationale documented ensuing clinical decision promote fair transparent medical decision making communication patient rationale essential shared decision making transparency prediction level robust auditing process increasingly viewed essential proper oversight machine learning tool bias considered auditing promote reflexive understanding tool machine learning affect care management vulnerable patient discrepancy systematic prediction become evident used evidence need beneficial intervention highlight large structural barrier affect health inequality ethical decision making suggests engaging diverse knowledge source ethical analysis consider consequence affected group weigh benefit risk various approach engage stakeholder come supportable conclusion therefore analysis need focus downstream effect patient rather adopting presumption fairness accomplished solely metric system comment vol 2 may 2020 ethical analysis bringing crucial conversation new audience watershed moment health care ethical consideration rarely integral essential maximising success technology empirically clinically time right partake thoughtful collaborative engagement challenge bias bring lasting change declare no competing interest copyright 2020 author published elsevier open access article cc license melissa mccradden shalmali joshi mjaye mazwi james anderson department bioethics mdm jaa department critical care medicine mm hospital sick child toronto canada vector institute artificial intelligence toronto canada sj 1 char shah nh magnus implementing machine learning health ethical challenge n engl j med 2018 378 2 obermeyer z power b vogeli c mullainathan dissecting racial bias algorithm used manage health population science 2019 366 3 goel measure mismeasure fairness critical review fair machine learning accessed march 16 2020 4 marmot social determinant health inequality lancet 2005 365 5 benjamin assessing risk automating racism science 2019 366 6 wenger nk cardiovascular disease female heart vulnerable call action report clin cardiol 2012 35 7 friedler sa scheidegger c venkatasubramanian im possibility fairness sept 23 2019 accessed march 16 2020 8 barocas hardt narayanan fairness machine learning limitation opportunity 2019 9 collins g reitsma jb altman dg moon kgm tripod group transparent reporting multivariable prediction model individual prognosis diagnosis tripod tripod statement ann intern med 2015 162 10 steering group reporting guideline clinical trial evaluating artificial intelligence intervention needed nat med 2019 25