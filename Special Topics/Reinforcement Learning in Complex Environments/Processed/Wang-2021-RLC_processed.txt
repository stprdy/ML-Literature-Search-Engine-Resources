expert system applic avail onlin april elsevi right reserv multirobot coordin deep reinforc learn complex environ di wang hongbin deng school mechatron engin beij institut technolog beij china r c l e n f keyword multirobot coordin reinforc learn deep learn visual percept b r c multipl autonom robot system veri import complet path plan coordin effect process interfer avoid resourc alloc inform share tradit multirobot coordin algorithm solut known environ target posit robot need move robot prioriti set limit autonomi robot onli use visual inform solv problem multirobot coordin still less thi paper propos cooper algorithm base deep reinforc learn make robot autonom process select target posit move use approach use onli top view top view view imag inform collect perspect robot input propos algorithm includ duel neural network structur solv task alloc path plan call algorithm tfduel percept derstand environ robot reach target posit without collis robot move ani target posit compar propos algorithm tfduel differ input structur algorithm tduel fduel differ neural network structur tfdqn tfddqn experi show propos tfduel algorithm ha highest accuraci robust introduct field robot matur enough perform divers plex task recent year multirobot becom popular applic survey monitor search rescu applic robot need establish coordin interact achiev individu group goal key problem make individu decis whole system achiev greatest reward thi problem often call coordin farinelli zanotto pagello howev multirobot coordin caus problem robot complet path plan coordin effect process interfer avoid resourc alloc inform share reliabl coordin method import part multipl autonom robot system present research multirobot coordin algorithm ha achiev posit result includ central method azarm schmidt decoupl method cirillo ura koenig reinforc learn method wang silva multirobot coordin autonom mobil robot need identifi team member consid path robot path plan robot handl complex task easili sever autonom robot multipl coordin robot accomplish given task faster effici singl robot spaan gonalv sequeira propos multirobot nation algorithm base auction algorithm markov sion model auction provid flexibl method assign task robot combin observ markov decis model framework calcul execut strategi agent task bid valu obtain directli correspond valu function howev auction algorithm solv problem task assign begin doe make differ decis base state multipl robot azarm schmidt propos method dynam assign robot prioriti negoti process solv coordin problem two robot space method separ assign task path plan set prioriti robot work precis grid world limit autonomi robot correspond author address denghongbin deng content list avail sciencedirect expert system applic journal homepag http receiv februari receiv revis form januari accept april expert system applic mani method multirobot path plan find optim path problem adler halperin solovey demonstr move disk simpl polygon problem disk allow move ani target posit long target posit eventu occupi known problem difficult move sever object start configur target configur find coordin trajectori contrast gener path plan problem requir robot move fix target posit simul environ allow multipl robot move random initi posit ani target posit distribut artifici intellig dai subfield artifici tellig dai focus system consist multipl independ entiti interact domain tradit dai divid two subdisciplin distribut problem solut dp focus inform manag system multipl compon work toward common goal multiag system deal behavior sever independ entiti agent stone veloso simul environ design multirobot system propos algorithm differ heurist cap leader vrohidi vlanti bechliouli kyriakopoulo method equival solv task assign path plan among multipl leader robot prioriti fulli achiev autonomi vrohidi et al propos distribut multirobot system multirobot path plan problem solv workspac reinforc learn use solv problem less commun maze problem uwano tateb tajima eaqr zhang wang reinforc learn algorithm solv distribut sensor network problem mrcdrl wang deng pan solv problem multirobot coordin reli vision scene complex scene rel multirobot coordin algorithm reli vision highli dynam environ multirobot coordin need solv problem effect environment percept task ment path plan environ robot often doe know target posit need determin target posit perceiv understand scene highli dynam environ includ dynam static obstacl complex background tive path plan without collis also import robot earn differ reward differ state final move path determin begin robot need complet task assign path plan problem accord state simul environ design top view contain multipl control agent isomorph agent center imag preprocess top view imag captur agent perspect use input neural network therefor deep neural network design multiinput structur train process necessari consid action robot process coordin achiev greater reward thi paper propos multirobot coordin algorithm base deep ment learn dynam environ solv problem task assign path plan effect algorithm verifi simul contribut rize follow dynam environ start tabula rasa onli two part imag data use input top view robot centric top view view imag inform collect perspect robot doe need know distanc robot surround obstacl distanc robot target posit imag annot requir train correspond action current state robot obtain method base deep reinforc learn propos solv multirobot task assign path plan problem process train necessari specifi target posit robot go repeat experi reward weight automat updat final multipl robot reach target posit without collis multipl robot reach target posit rest thi paper organ follow section provid review relat work literatur section contain descript experiment enviro approach describ section section contain neural network structur neural network train neural network test final conclus summar section relat work challeng design appropri coordin strategi multirobot environ robot oper effect complex environ yan jouandeau cherif mani studi central control method still use consid singl robot part coupl system use singl central plan unit calcul path algorithm use obtain singl robot version includ method spaan et artifici potenti field method schultz parker schneider nazarahari khanmirza doosti spatial decomposit method koo et approach make use principl market economi enabl robot coordin essenc trade task resourc robot maxim wealth improv overal effect kalra zlot dia stentz murdoch gerkey matar task alloc system base principl publish subscrib commun model artifici potenti field method map everi point space real valu use deriv function simpl case robot must simpli follow gradient reach target posit yamashita et al propos path plan method multimobil robot port larg object base artifici potenti field method algorithm known environ problem multirobot cooper start area target area wa solv spatial decomposit method divid space stacl small area use group adjac area repres path multipl robot tri enter area area subdivid assign differ robot koo et al propos multirobot coordin framework base regular tessel thi framework regular tessel use divid space interest union disjoint region equal cell occupi onli robot obstacl robot model hybrid automata captur limit mode oper maintain within current unit reach adjac unit spond cell task survey supervis search rescu robot often work complex environ make accur divis space imposs although exist method effect calcul trajectori singl robot effect method dinat multirobot movement avoid deadlock multirobot path plan problem decoupl subproblem avoid deadlock cirillo et al van snoeyink lin manocha although research multirobot system ha made substanti progress multirobot coordin still difficult particular deal spatial task distribut exponenti explos due wang deng expert system applic connect action state central control multipl robot come imposs applic heurist method also better solut gorithm prioriti plan algorithm solv multirobot coordin known environ cap propos modifi prioriti plan algorithm adjust execut asynchron decentr manner robot search set global coordin trajectori start posit target posit exchang messag use heurist estim algorithm mean bid price alway exactli correct accur bid result give greatest reward effect robot kalra et also sever differ coordin approach includ graph theori method hernndez barriento cerro reactiv behavior method matar swarm method aler tuyl clae weiss leader method mouriki roumelioti focu reactiv behavior avoid collis use highli reactiv behavior simplifi plan avoid conflict shortli befor conflict occur swarm method doe consid everi robot reach target posit robot swarm exhibit behavior aler et al propos collabor algorithm base forag behavior bee ant solv problem maxim environment coverag multirobot system leader approach one leader follow robot form mani uncertain resourc unstructur dynam environ veri difficult design control control need guarante perform local percept li chen tee li studi coordin control multirobot base reinforc learn solv problem path plan process move object wang silva propos learn algorithm solv conflict caus multirobot transport task dynam environ simul environ pixel wa establish dure train process accur locat inform obstacl wa use state input path plan reinforc learn sutton barto adapt flexibl method automat updat weight repeat experi correspond reward obtain spond action current state howev increas system complex learn cost reinforc learn increas exponenti deep neural network lecun bengio hinton appli visual path predict huang et deep understand imag learn train combin deep neural network reinforc learn strategi success obtain perceptu input mnih kavukcuoglu silver use solv exponenti growth learn cost reinforc learn deep reinforc learn li perform better human singl agent video game atari mnih et guo singh lee lewi wang virtual environ mnih et jaderberg et deep reinforc learn ha wide use field game strategi path plan singl robot levin finn darrel abbeel propos train method base depth reinforc learn train ceptron control learn robot motor torqu strategi origin imag monocular output imag mirowski pascanu viola propos use deep reinforc learn solv igat problem complex environ mnih et al propos deep q network dqn use onli imag score input learn strategi success singl agent scenario dimension perceptu input doubl dqn ddqn hasselt guez silver base dqn algorithm onli reduc overestim problem also achiev higher effici game wang et al propos new neural network structur duel network chitectur duel base dqn network structur express two part one estim state valu function advantag function thi duel structur also improv formanc dqn appli duel neural network structur multirobot coordin experiment environ verifi effect propos multirobot coordin algorithm complex environ use uniti juliani et design experiment environ shown fig experiment environ includ robot static cle ground stain target locat static obstacl includ rock heap differ shape surround rock wall differ plant robot repres black vehicl target posit resent white cube number robot target posit fig b c e imag collect fig experiment environ experiment environ contain dynam static obstacl ground stain target posit b c e imag collect perspect robot wang deng expert system applic person perspect robot experiment environ algorithm connect juliani et easili obtain state reward experiment ment action given algorithm appli experiment environ propos algorithm use deep reinforc learn solv problem multipl robot reach target posit without collis train process onli current status spond reward robot use input human anc requir robot move path target posit robot perform current action set differ reward rh depend whether robot collid robot doe collid doe reach target tion set reward rh robot collid static obstacl set reward rh robot collid robot set reward rh robot reach target posit differ reward rh rp set accord distanc h center robot target posit shown fig rp rv half target posit robot length respect reward rh robot robot consid reach target posit larger reward rh rh set multirobot coordin algorithm thi section introduc multirobot coordin algorithm base deep reinforc learn complex environ fig distanc robot target posit robot contact target posit distanc h center calcul maximum distanc set rp rv regardless longest distanc form obliqu diagon robot target posit rp rv half target locat robot length respect fig overview multirobot coordin algorithm top view view robot time step preprocess combin form empir data set neural network use train sampl randomli select empir dataset obtain ing action fig preprocess top view rectangl center robot segment rectangl width w slightli larger top view simul environ wang deng expert system applic includ data preprocess experi replay train tfduel neural network shown fig data preprocess simul environ two piec imag inform return top view simul environ imag f collect perspect robot need preprocess top view ensur differ robot correspond differ state take robot side exampl fig take robot center top view segment squar size process segment posit beyond top view fill gray robot process way state st robot correspond top view obtain shown fig imag f directli use state sf correspond perspect robot use continu state algorithm input robot better understand current scene mnih et algorithm use four continu frame input frame consist st sf reduc quantiti data input neural network perform grayscal process shown top view view fig current input state algorithm sj sj sj sj sj sj f sj f sj f sj f j number robot time step j n n number robot deep q network dqn main advantag dqn obtain possibl action calcul q valu accord input state network mnih et process train use experi replay mnih et improv stabil weight updat neural network experi ej sj aj rj sj end gener time step ad data set ej ej aj action correspond state robot time step end indic whether current state last current episod episod number collis robot consid end neural network use size train sampl randomli select empir data target valu yq onlin defin yq rj γmax aj q sj aj θi γ discount factor use discount factor γ sj state correspond time step aj action correspond state sj θi weight ith time step neural network rj rh p rt p compos reward introduc simul environ chapter gener distanc robot target locat reward rt rt gener time step episod tmax averag time step robot random initi posit target posit episod target network improv stabil learn updat process mnih et paramet target network copi onlin network ramet everi time step target valu ydqn dqn defin ydqn rj γmax aj q sj aj doubl dqn ddqn standard dqn valu use select evalu action valu lead overoptimist valu estim hasselt et ddqn use onlin network target network reduc overestim target valu yddqn ddqn defin yddqn rj γq sj argmaxaj sj aj θi argmaxaj sj aj θi use paramet θi onlin network obtain action correspond state sj stream network tfduel base dqn duel neural network wang et timiz fulli connect layer neural network structur two part state valu function action fig tfduel neural network structur top view stream use convolut neural network extract featur top view view stream use convolut network extract featur view duel stream combin two featur output correspond action wang deng expert system applic advantag function atari domain duel neural network obtain better strategi estim repres mani action state valu advantag valu use convolut featur merg duel stream fig q sj aj θi αi βi v sj θi βi sj aj θi αi sj aj θi αi v sj θi βi valu function βi paramet valu function sj aj θi αi advantag function αi paramet advantag function sj aj θi αi mean advantag function train process tfduel neural network shown tfduel algorithm consist three part name top view stream view stream duel stream shown fig combin ddqn duel network structur duel stream target valu ytfduel j tfduel defin ytfduel rj γq sj argmaxaj sj aj θi αi βi paramet target network advantag function valu function respect reward function often decept onli reward mize mechan encourag intellig detect function fall local optimum caus agent unabl learn correctli propos algorithm agent explor new area environ tfduel free directli use sampl input simul solv reinforc learn task learn greedi strategi also tfduel network train initi replay memori initi time step initi onlin network random weight θ α β initi target network weight θ α β episod initi state sequenc sj sj sj sj sj sj sj sj sj dead probabl ε select random action aj otherwis select aj argmaxaj q sj aj θi αi βi execut action aj observ reward rj next state sj save experi ej sj aj rj sj end sampl random ej k sj k aj k rj k sj end k subscript sampl randomli select set ytfduel k rj k end rj k γq sj argmaxaj q sj aj θi αi βi end perform gradient descent step ytfduel k sj k aj k θi αi βi respect network paramet θi αi βi everi c time step copi θi αi βi end end experi valid propos multirobot coordin algorithm tfduel experi simul platform use ubuntu nvidia gtx ti graphic card thi chapter compar number differ robot structur differ neural network illustr effect propos algorithm fig score number success train process differ number robot score number success two robot b e result three robot c f result four robot wang deng expert system applic neural network structur structur neural network use propos algorithm shown fig input layer neural network process imag top view view size first hidden layer top view stream volut layer convolv filter stride activ function rectifi nonlinear nair hinton pool layer size ad first hidden layer shown pictur second hidden layer convolut layer filter stride appli rectifi next two convolut layer convolv filter filter size stride rectifi appli first hidden layer view stream convolut layer convolv filter stride appli rectifi follow pool layer size also shown pictur next two convolut layer convolv filter filter size stride rectifi appli first layer duel stream compos featur top view stream view stream output second layer fulli connect layer unit last hidden layer fulli connect valu stream one output advantag size output layer size output layer consist forward left right neural network train dure train process robot move random initi posit without human interfer satisfi number store experi experi replay wa larger batch divers train wa start number perienc store experi replay wa greater thousand experi replay storag space wa thousand polici ε wa reduc first thousand time step remain use three differ neural network structur tfduel tfdqn stream network tfddqn stream network train simul environ differ number robot experiment result shown fig fig b c train score two three four robot differ neural network structur given respect line light color score episod averag score adjac one thousand episod repres dark line score tend stabil fig e f show number success two three four robot differ neural network structur respect accord fig e f late maximum max averag avg varianc var one thousand episod near max shown tabl case two robot max avg var number success three neural network algorithm similar case three robot tfduel algorithm better two algorithm case four robot onli var tfduel algorithm slightli larger tfddqn algorithm max avg better two algorithm valid use top view view input effect use top view view alon illustr fig tduel use onli top view stream duel stream fduel use onli view stream duel stream case three robot use tfduel tduel fduel neural network structur train number cess differ neural network structur shown fig use top view view input number success ele much higher tduel fduel neural network structur show tfduel effect solv multirobot coordin problem complex environ algorithm propos differ singl agent algorithm ha propos use top view get global percept scene view get local percept scene process train agent get reward togeth tabl statist neural network train type tfdqn tfddqn tfduel max avg var max avg var max avg var fig number success gener neural network differ input structur train part neural network structur tduel fduel hyperparamet tfduel fig number success gener differ neural network structur dure test process case four robot success episod first episod count wang deng expert system applic neural network test process test adjust polici ε reduc impact explor use neural network shown fig f set initi posit randomli count number success end episod cumul shown fig propos tfduel algorithm also ha best perform test process case four robot effect diagram multirobot ation tfduel algorithm shown fig ball differ color repres trajectori robot fig b show robot learn reach target posit accord distanc c e show multipl robot reach target posit avoid near target posit f g show multipl robot directli reach target posit h show robot encount protuber rock cours detour lead failur experiment condit design strict collis occur caus failur onli imag data use perceiv understand scene robot arriv target posit random initi posit without collis effect complet path plan multirobot doe need specifi target posit robot need go complet task assign multirobot autonom conclus complex environ propos robot coordin algorithm base deep reinforc learn onli top view top view person view imag collect perspect robot use input solv task alloc path plan problem multiautonom robot robot start random initi posit train time step creas multirobot learn multipl robot begin occupi target locat mutual final predict target locat robot ha reach begin train robot run randomli environ increas train time robot begin move target posit thi time multipl robot move target posit final robot predict target posit go without collis compar propos algorithm tfduel differ neural network structur tduel fduel tfdqn tfddqn ment show tfduel algorithm effect robustli solv problem multirobot coordin complex dimension environ futur research improv curaci algorithm follow two aspect creas train time step state store experi databas close target locat accuraci improv veri slow accuraci improv balanc state experi databas howev due limit visual percept percept rang imposs accur mine distanc local obstacl state improv raci improv local percept robot current consid improv accuraci algorithm consider increas train time credit authorship contribut statement di wang conceptu methodolog softwar valid formal analysi investig data curat write origin draft write review edit visual hongbin deng resourc supervis project administr fund acquisit declar compet interest author declar known compet financi interest person relationship could appear influenc work report thi paper acknowledg would like thank anonym review zhenhua pan whose insight comment greatli improv qualiti thi paper work describ thi paper wa support part nation natur scienc foundat china grant refer adler halperin solovey effici motion plan unlabel disc simpl polygon algorithm foundat robot xi pp fig result multirobot collabor base tfduel algorithm ball differ color repres trajectori robot wang deng expert system applic aler tuyl clae weiss robot coordin forag coverag artifici life confer proceed pp azarm schmidt decentr approach motion multipl mobil robot advanc robot cap algorithm trajectori plan infrastructur associ advanc artifici intellig pp cirillo ura koenig approach motion plan vehicl intellig robot system iro pp van snoeyink lin manocha central path plan multipl robot optim decoupl sequenti plan robot scienc system farinelli zanotto pagello advanc approach coordin logist scenario robot autonom system gerkey matar j sold auction method multirobot coordin ieee transact robot autom guo singh lee lewi wang x deep learn atari game play use offlin tree search plan intern confer neural inform process system pp hasselt guez silver deep reinforc learn doubl learn aaai hernndez barriento cerro select smooth fictiti play approach base game theori patrol infrastructur system expert system applic huang li wu liu tang zhuang deep learn driven visual path predict singl imag ieee transact imag process jaderberg mnih czarnecki schaul leibo silver kavukcuoglu reinforc learn unsupervis auxiliari task arxiv preprint juliani berg vckay gao henri mattar lang uniti gener platform intellig agent arxiv preprint kalra zlot dia stentz multirobot coordin comprehens survey analysi univ pittsburgh pa robot inst koo li quottrup clifton bak framework motion plan tempor logic specif pp scienc china inform scienc lecun bengio hinton deep learn natur levin finn darrel abbeel train deep visuomotor polici journal machin learn research li deep reinforc learn overview arxiv preprint arxiv li chen tee li q reinforc learn control coordin manipul neurocomput matar j design emerg behavior local interact collect intellig proceed second intern confer simul adapt behavior pp mirowski pascanu viola et al learn navig complex environ arxiv preprint mnih badia mirza grave lillicrap harley silver kavukcuoglu asynchron method deep reinforc learn intern confer machin learn pp mnih kavukcuoglu silver et al control deep reinforc learn natur mouriki roumelioti optim sensor schedul constrain local mobil robot format ieee transact robot nair hinton rectifi linear unit improv restrict boltzmann machin proc int conf mach pp nazarahari khanmirza doosti path plan continu environ use enhanc genet algorithm expert system applic pp schultz parker schneider system swarm intellig automata springer spaan gonalv sequeira j multirobot coordin auction pomdp robot autom icra pp stone veloso multiag system survey machin learn perspect autonom robot sutton barto reinforc learn introduct mit press uwano tateb tajima et al cooper base reinforc learn intern reward maze problem sice journal control measur system integr vrohidi vlanti bechliouli kyriakopoulo j reconfigur coordin guarante converg obstacl clutter environ local commun autonom robot wang deng pan z mrcdrl coordin deep reinforc learn neurocomput wang silva approach coordin engin applic artifici intellig wang schaul hessel hasselt lanctot freita duel network architectur deep reinforc learn arxiv preprint arxiv yamashita arai asama motion plan multipl mobil robot cooper manipul transport ieee transact robot autom yan jouandeau cherif survey analysi coordin intern journal advanc robot system zhang wang eaqr multiag algorithm coordin multipl agent complex di wang receiv degre comput scienc technolog lin yi univers linyi china degre beij union univers beij china current work toward degre beij institut technolog hi current research interest includ machin learn robot hongbin deng receiv degre beij institut technolog beij china respect associ professor beij institut technolog hi current research interest includ robot control wang deng