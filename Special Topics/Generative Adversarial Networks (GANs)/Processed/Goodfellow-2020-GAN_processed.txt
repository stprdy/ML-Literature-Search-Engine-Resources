novemb vol commun acm gener adversari network ian goodfellow jean mehdi mirza bing xu david sherjil ozair aaron courvil yoshua bengio abstract gener adversari network kind artifici ligenc algorithm design solv gener ing problem goal gener model studi collect train exampl learn probabl distribut gener gener adversari network gan abl gener exampl estim probabl distribut gener model base deep learn common gan among success gener model cialli term abil gener realist resolut imag gan success appli wide varieti task mostli research set continu present uniqu challeng research opportun becaus base game theori approach gener model base optim introduct current approach develop artifici genc base primarili machin learn wide use success form machin learn date supervis learn supervis learn algorithm given dataset pair exampl input exampl put learn associ input output thu learn map input output ple input exampl typic complic data object like imag natur languag sentenc audio waveform output exampl often rel simpl common kind supervis learn classif output integ code tifi specif categori photo might recogn come categori contain cat categori tain dog supervis learn often abl achiev greater human accuraci train process complet thu ha integr mani product servic unfortun learn process still fall far short human abil supervis learn definit reli human supervisor provid output exampl input exampl wors exist approach vise learn often requir million train exampl exceed human perform human might abl learn perform task accept veri small number exampl order reduc amount human sion requir learn number exampl requir learn mani research today studi unsupervis learn often use gener model thi overview paper describ one particular approach unsupervis learn via gener model call gener adversari network briefli review origin version thi paper entitl gener adversari network wa publish advanc neural inform process system nip applic gan identifi core research problem relat converg game necessari make gan reliabl technolog gener model goal supervis learn rel straightforward specifi supervis learn algorithm essenti goal learn accur associ new input exampl correct output instanc object recognit algorithm may associ photo dog kind dog categori identifi unsupervis learn less clearli defin branch machin learn mani differ unsupervis ing algorithm pursu mani differ goal broadli speak goal unsupervis learn learn thing use examin dataset contain unlabel input exampl cluster dimension reduct common exampl unsupervis learn anoth approach unsupervis learn gener model gener model train exampl x drawn unknown distribut pdata x goal gener model algorithm learn pmodel x approxim pdata x close possibl straightforward way learn approxim pdata explicitli write function pmodel x θ control eter θ search valu paramet make pdata pmodel similar possibl particular popular approach gener model probabl mum likelihood estim consist minim diverg pdata pmodel common approach estim mean paramet gaussian distribut take mean set tion one exampl maximum likelihood estim thi approach base explicit densiti function trate figur explicit densiti model ha work well tradit statist use simpl function form probabl tribut usual appli small number variabl recent rise machin learn gener deep learn particular research becom interest learn model make use rel complic function form deep neural work use gener data correspond densiti function may comput intract tradit two domin approach confront thi intract problem care design model tractabl densiti function design learn algorithm base research highlight commun acm novemb vol comput tractabl approxim intract densiti function kingma approach prove difficult mani applic erat realist high resolut imag research remain unsatisfi result far thi motiv research improv two path also suggest third path could use besid take point x input return mate probabl gener point gener model use abl gener sampl distribut pmodel thi illustr figur mani model repres densiti function also gener sampl densiti function case ing sampl veri expens onli approxim method gener sampl tractabl gener model avoid entir issu ing tractabl densiti function learn onli tractabl sampl gener process call implicit tive model gan fall thi categori prior duction gan state art deep implicit gener model wa gener stochast ble approxim gener sampl via increment process base markov chain gan introduc order creat deep implicit gener model wa abl gener true sampl model distribut singl gener step without need tal gener process approxim natur sampl markov chain today popular approach gener ele probabl gan variat belief net none approach reli markov chain reason interest gan today succeed origin goal gener model without markov chain rather succed gener iti imag proven use sever task straightforward gener describ section gener adversari network gener adversari network base game sens game theori two machin learn model typic implement use neural network one network call gener defin pmodel x itli gener necessarili abl evalu siti function pmodel variant gan evalu densiti function possibl ani tractabl densiti model sampl tractabl differnti could train gan gener done danihelka learn model train data gener sampl figur goal mani gener model illustr studi collect train exampl learn gener exampl come probabl distribut gan learn thi without use explicit represent densiti function one advantag gan framework may appli model densiti function comput intract sampl shown sampl imagenet includ one label model use actual imagenet data illustr goal hypothet perfect model would attain x p x figur mani approach gener model base densiti estim observ sever train exampl random variabl x infer densiti function p x gener train data thi approach illustr sever data point real number line use fit gaussian densiti function explain observ sampl contrast thi common approach gan implicit model infer probabl distribut p x without necessarili repres densiti function explicitli novemb vol commun acm et thi requir instead gener abl draw sampl distribut pmodel erat defin prior distribut p z vector z serv input gener function g z θ g θ g set learnabl paramet defin gener strategi game input vector z thought sourc random otherwis determinist tem analog seed pseudorandom number erat prior distribut p z typic rel unstructur distribut gaussian distribut uniform distribut hypercub sampl z thi distribut nois main role gener learn tion g z transform unstructur nois z realist sampl player thi game discrimin discrimin examin sampl x return mate x θ whether x real drawn train distribut fake drawn pmodel run erat origin formul gan thi estim consist probabl input real rather fake assum real distribut fake tion sampl equal often formul arjovski et exist gener speak level verbal intuit descript discrimin tri dict whether input wa real fake player incur cost j g θ g θ gener j θ g θ discrimin player attempt minim cost roughli speak tor cost encourag correctli classifi data real fake gener cost encourag gener sampl discrimin incorrectli classifi real veri mani differ specif formul cost possibl far popular formul seem form roughli origin version gan j wa defin neg discrimin assign label given input discrimin word discrimin train like regular binari classifi origin work gan offer two version cost ator one version today call minimax gan defin cost j g yield minimax game straightforward analyz theoret defin cost gener flip sign tor cost anoth approach gan gener cost defin ping discrimin label word tor tri minim neg discrimin assign wrong label later help avoid gradient satur train model think gan bit like counterfeit polic counterfeit make fake money polic tri arrest counterfeit continu allow spend legitim money competit counterfeit polic lead realist counterfeit money eventu counterfeit duce perfect fake polic tell differ real fake money one complic thi analog gener learn via discrimin real data fake data dataset gener random latent variabl random index dataset discrimin discrimin figur train gan involv train gener network discrimin network process involv real data drawn dataset fake data creat continu gener throughout train process discrimin train much like ani classifi defin deep neural network shown left discrimin shown data train set thi case discrimin train assign data real class shown right train process also involv fake data fake data construct first sampl random vector z prior distribut latent variabl model gener use produc sampl x g z function g simpli function repres neural network transform random unstructur z vector structur data intend statist indistinguish train data discrimin classifi thi fake data discrimin train assign thi data fake class backpropag algorithm make possibl use deriv discrimin output respect discrimin input train gener gener train fool discrimin word make discrimin assign input real class train process discrimin thu much ani binari classifi except data fake class come distribut chang constantli gener learn rather fix distribut learn process gener somewhat uniqu becaus given specif target output rather simpli given reward produc output fool constantli chang oppon gradient counterfeit mole among polic report specif method polic use detect fake thi process illustr figur figur show cartoon give intut process work research highlight commun acm novemb vol demonstr metz et argmin oper difficult work thi way popular approach regard thi situat game two player much game theori literatur concern game discret finit action space convex loss properti simplifi gan requir use game theori set yet cost action polici continu regardless whether consid action choos specif paramet vector θ g whether consid action gener sampl x goal machin learn algorithm thi context find local nash point local minimum player cost respect player paramet local move player reduc cost assum player paramet chang common train algorithm simpli use optim repeatedli take simultan step player increment minim er cost respect player paramet end train process gan often abl produc realist sampl even veri complic et contain imag exampl shown figur high level one reason gan framework ces may involv veri littl approxim mani approach gener model must approxim intract densiti function gan involv ani situat straightforward model mizat problem becaus player cost function player paramet player may control onli paramet possibl reduc tion optim goal minim x z x z c b x z x z figur illustr basic intuit behind gan train process illustr fit gaussian distribut thi exampl understand goal gener learn simpl scale invers cumul distribut function data gener distribut gan train simultan updat discrimin function blue dash line discrimin sampl data gener distribut black dot line px gener distribut pmodel green solid line lower horizont line domain z sampl thi case uniformli horizont line abov part domain upward arrow show map x g z impos distribut pmodel transform sampl g contract region high densiti expand region low densiti pmodel consid pair adversari network initi pmodel initi unit gaussian thi exampl defin randomli initi deep neural network b suppos train converg g held fix practic train simultan purpos build intuit see g fix would converg c suppos gradual train g sampl x gener g flow direct increas order arriv region like classifi data meanwhil estim updat respons thi updat nash equilibrium neither player improv payoff becaus pmodel pdata discrimin unabl differenti two distribut thi constant function show point equal like come either distribut practic g typic optim simultan gradient step necessari optim everi step shown thi intuit cartoon see ref fedu et nagarajan realist discuss gan equilibr process figur thi imag sampl progress depict person doe exist wa imagin gan train photo celebr novemb vol commun acm spuriou nash equilibria whether learn rithm converg nash doe mani case practic interest theoret question open best learn algorithm seem empir often fail converg theoret work answer question ongo work design ter cost model train algorithm better vergenc properti gan topic thi articl focus summari core design sider algorithm properti gan mani topic potenti interest ere due space consider thi articl discuss use gan approxim distribut p x also extend condit erat sampl correspond input draw ple condit distribut p x gan relat moment optim quirk gan made especi clear connect mmd optim transport may use train gener model pmodel ha port onli thin manifold may actual assign zero likelihood train data gan struggl gener discret data becaus algorithm need propag gradient discrimin output gener thi problem gradual like gener model gan use fill gap miss gan proven veri effect learn classifi data use veri label train evalu perform gener model includ gan difficult research area gan seen way machin learn learn cost function rather minim cost function gan seen way supervis machin learn ask approxim true underli task onli real error statist error sampl finit amount train data rather measur true underli distribut failur learn algorithm converg exactli optim paramet mani gener model strategi would introduc sourc error also sourc approxim error base markov chain optim bound true cost rather cost etc difficult give much specif guidanc ing detail gan becaus gan activ research area specif advic quickli becom date figur show quickli capabl gan progress year sinc introduct converg gan central theoret result present origin gan space densiti function pmodel tor function onli one local nash rium pmodel pdata possibl optim directli siti function algorithm consist mize converg inner loop make small gradient step pmodel outer loop converg thi nash equilibrium howev theoret model local move directli densiti function space may veri relev gan train practic use local move paramet space gener function among set function represent neural network finit number paramet paramet repres finit number bit mani differ theoret model interest studi whether nash equilibrium whether ani figur illustr progress gan capabl cours approxim three year follow introduct gan gan rapidli becom capabl due chang gan algorithm improv underli deep learn algorithm improv underli deep learn softwar hardwar infrastructur thi rapid progress mean infeas ani singl document summar gan capabl ani specif set best practic continu evolv rapidli enough ani comprehens survey quickli becom date figur reproduc permiss brundag et individu result ref karra et liu radford et respect research highlight commun acm novemb vol produc ani output machin learn algorithm recogn accept rather ask produc specif exampl output gan thu great learn situat mani possibl correct answer predict mani possibl futur happen video gan el use learn transform data one domain data anoth domain even without ani label pair exampl domain zhu et exampl studi collect photo zebra collect photo hors gan turn photo hors photo gan use enc simul experi would costli run even tradit softwar gan use creat fake data train machin learn model either real data would hard would privaci concern associ real model call network use domain gan use varieti interact digit media effect end goal produc compel gan even use solv variat infer problem use approach gener gan learn use embed vector discov concept like gender human face without conclus gan kind gener model base game theori great practic success term gener realist data especi imag current still difficult train gan becom reliabl ogi necessari design model cost train algorithm possibl find good nash ria consist refer arjovski chintala bottou wasserstein gan arxiv preprint arora ge liang zhang gener equilibrium gener adversari net gan arxiv preprint wu william green preserv gener deep neural network support clinic data share biorxiv bengio alain yosinski deep gener stochast network trainabl backprop icml brundag avin clark toner eckersley garfinkel dafo scharr zeitzoff filar anderson roff allen steinhardt flynn héigeartaigh beard belfield farquhar lyle crootof evan page bryson yampolskiy amodei malici use artifici intellig forecast prevent mitig arxiv danihelka lakshminarayanan uria wierstra dayan comparison maximum likelihood train real nvp arxiv preprint de oliveira paganini nachman learn particl physic exampl gener adversari network physic synthesi comput softwar big scienc deng dong socher li li imagenet hierarch imag databas fedu goodfellow dai maskgan better text gener via fill intern confer learn represent fedu rosca lakshminarayanan dai moham goodfellow mani path equilibrium gan need decreas diverg everi step intern confer learn represent frey graphic model machin learn digit commun mit press boston ganin lempitski unsupervis domain adapt backpropag intern confer machin learn goodfellow mirza xu ozair courvil bengio gener adversari net ghahramani well cort lawrenc weinberg ed advanc neural inform process system curran associ boston karra aila lain lehtinen progress grow gan improv qualiti stabil variat corr kingma well encod variat bay proceed intern confer learn represent iclr li swerski zemel gener moment match network corr liu tuzel coupl gener adversari network lee sugiyama luxburg guyon garnett ed advanc neural inform process system curran associ boston lucic kurach michalski gelli bousquet gan creat equal studi arxiv preprint mathieu coupri lecun deep video predict beyond mean squar error arxiv preprint mesched nowozin geiger adversari variat bay unifi variat autoencod gener adversari network arxiv preprint mesched nowozin geiger numer gan advanc neural inform process system metz pool pfau unrol gener adversari network arxiv preprint mirza osindero condit gener adversari net arxiv preprint nagarajan kolter gradient descent gan optim local stabl guyon luxburg bengio wallach fergu vishwanathan garnett ed advanc neural inform process system curran associ boston odena olah shlen condit imag synthesi auxiliari classifi gan arxiv preprint oord li babuschkin simonyan vinyal kavukcuoglu driessch lockhart cobo stimberg et al parallel wavenet fast speech synthesi arxiv preprint radford metz chintala unsupervis represent learn deep convolut gener adversari network arxiv preprint ratliff burden sastri character comput local nash equilibria continu game commun control comput allerton annual allerton confer ieee saliman goodfellow zaremba cheung radford chen improv techniqu train gan advanc neural inform process system shrivastava pfister tuzel susskind wang webb learn simul unsupervis imag adversari train thei van den oord bethg note evalu gener model nov unterthin nessler klambauer heusel ramsauer hochreit coulomb gan provabl optim nash equilibria via potenti field arxiv preprint wu burda salakhutdinov gross quantit analysi gener model arxiv preprint yeh chen lim johnson semant imag inpaint perceptu contextu loss arxiv preprint zhu park isola efro unpair translat use adversari network arxiv preprint ian goodfellow written googl brain jean mehdi mirza bing xu david sherjil ozair aaron courvil yoshua bengio université de montréal final submit copyright held public right licens acm