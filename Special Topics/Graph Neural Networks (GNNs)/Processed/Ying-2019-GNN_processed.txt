gnnexplain gener explan graph neural network rex dylan jiaxuan marinka jure comput scienc stanford univers rexi dtsbourg jiaxuan marinka jure abstract graph neural network gnn power tool machin learn graph gnn combin node featur inform graph structur recurs pass neural messag along edg input graph howev corpor graph structur featur inform lead complex model explain predict made gnn remain unsolv propos gnnexplain ﬁrst gener approach provid pretabl explan predict ani model ani machin learn task given instanc gnnexplain identiﬁ compact subgraph structur small subset node featur crucial role gnn predict gnnexplain gener consist concis explan entir class instanc formul gnnexplain optim task maxim mutual inform gnn tion distribut possibl subgraph structur experi synthet graph show approach identifi import graph structur well node featur outperform altern baselin approach explan accuraci gnnexplain provid varieti beneﬁt abil visual semant relev structur interpret give insight error faulti gnn introduct mani applic includ social inform chemic biolog domain data natur model graph graph power data represent challeng work becaus requir model rich relat inform well node featur inform address thi challeng graph neural network gnn emerg machin learn graph due abil recurs incorpor inform neighbor node graph natur captur graph structur node featur despit strength gnn lack transpar easili allow explan predict yet abil understand gnn predict import use sever reason increas trust gnn model ii improv model transpar grow number applic pertain fair privaci safeti challeng iii allow practition get understand network characterist identifi correct systemat pattern mistak made model befor deploy real world current method explain gnn recent approach explain type neural network taken one two main rout one line work local approxim confer neural inform process system neurip vancouv canada gnn model train predict explan gnn predict gnnexplain figur gnnexplain provid interpret explan predict made ani gnn model ani machin learn task shown hypothet node classiﬁc task gnn model φ train social interact graph predict futur sport activ given train gnn φ predict ˆ yi basketbal person vi gnnexplain gener explan identifi small subgraph input graph togeth small subset node featur shown right inﬂuenti ˆ yi examin explan ˆ yi see mani friend one part vi social circl enjoy ball game gnn predict vi like basketbal similarli examin explan ˆ yj see vj friend friend hi friend enjoy water beach sport gnn predict ˆ yj model simpler surrog model probe explan method care examin model relev featur ﬁnd good qualit interpret high level featur identifi inﬂuenti input instanc howev approach fall short abil incorpor relat inform essenc graph sinc thi aspect crucial success machin learn graph ani explan gnn predict leverag rich relat inform provid graph well node featur propos gnnexplain approach explain predict made gnn plainer take train gnn predict return explan form small subgraph input graph togeth small subset node featur inﬂuenti predict figur approach explain predict ani gnn ani machin learn task graph includ node classiﬁc link predict graph classiﬁc handl well explan case explan gnnexplain explain gnn predict one particular instanc node label new link label case explan gnnexplain provid explan consist explain set instanc node given class gnnexplain speciﬁ explan rich subgraph entir graph gnn wa train subgraph maxim mutual inform gnn predict thi achiev formul mean ﬁeld variat approxim learn graph mask select import subgraph gnn comput graph simultan gnnexplain also learn featur mask mask unimport node featur figur evalu gnnexplain synthet well graph experi show gnnexplain provid consist concis explan gnn predict synthet graph plant network motif play role determin node label show gnnexplain accur identiﬁ well node featur determin node label outperform altern baselin approach explan accuraci use two dataset show gnnexplain provid import domain insight robustli identifi import graph structur node featur inﬂuenc gnn predict speciﬁc use molecular graph social interact network show gnnexplain identifi import graph structur chemic group ring structur molecul star structur reddit thread overal experi demonstr gnnexplain provid consist concis explan model differ machin learn task graph relat work although problem explain gnn relat problem interpret neural debug receiv substanti attent machin learn high level group interpret method neural network two main famili b figur gnn comput graph gc green orang make predict ˆ node edg gc form import neural pathway green allow use node inform propag across gc aggreg v predict edg orang howev gnn need aggreg import well unimport messag form predict node v dilut signal accumul v neighborhood goal gnnexplain identifi small set import featur pathway green crucial predict addit gs green gnnexplain identiﬁ featur dimens gs node import predict learn node featur mask method ﬁrst famili formul simpl proxi model full neural network thi done way usual learn local faith approxim around predict exampl linear model set rule repres sufﬁcient condit predict method second famili identifi import aspect comput exampl featur gradient backpropag neuron contribut input featur counterfactu reason howev salienc map produc method shown mislead instanc prone issu like gradient satur issu exacerb discret input graph adjac matric sinc gradient valu veri larg onli veri small interv becaus approach suitabl explain predict made neural network graph instead creat new inher interpret model interpret method consid model black box probe relev inform howev work ha done leverag relat structur like graph lack method explain predict data problemat mani case predict graph induc complex combin node path edg exampl task edg import onli anoth altern path exist graph form cycl two featur onli consid togeth accur predict node label joint contribut thu model simpl linear combin individu contribut final recent gnn model augment interpret via attent mechan howev although learn edg attent valu indic import graph structur valu predict across node thu thi contradict mani applic edg essenti predict label one node label anoth node furthermor approach either limit speciﬁc gnn architectur explain predict jointli consid graph structur node featur inform formul explan graph neural network let g denot graph edg e node v associ node featur x xn xi without loss gener consid problem explain node classiﬁc task see section task let f denot label function node f v c map everi node v one c class gnn model φ optim node train set use predict approxim f new node background graph neural network layer l updat gnn model φ involv three key comput first model comput neural messag everi pair node messag node pair vi vj function msg vi vj represent j previou layer relat rij node ml ij msg j rij second node vi gnn aggreg messag vi neighborhood nvi calcul aggreg messag mi via aggreg method agg l agg ml nvi neighborhood node vi whose deﬁnit depend particular gnn variant final gnn take aggreg messag l along vi represent previou layer transform obtain vi represent hl layer l hl updat l ﬁnal embed node vi l layer comput zi hl gnnexplain provid explan ani gnn formul term msg agg updat comput gnnexplain problem formul key insight observ comput graph node v deﬁn gnn aggreg figur fulli determin inform gnn use gener predict ˆ node particular v comput graph tell gnn gener v embed let us denot comput graph gc v associ binari adjac matrix ac v associ featur set xc v v gnn model φ learn condit distribut pφ xc random variabl repres label c indic probabl node belong c class gnn predict given ˆ φ gc v xc v mean fulli determin model φ graph structur inform gc v node featur inform xc v effect thi observ impli onli need consid graph structur gc v node featur xc v explain ˆ figur formal gnnexplain gener explan predict ˆ gs xf gs small subgraph comput graph xs associ featur gs xf small subset node featur mask mask f xf xf j gs import explain ˆ figur gnnexplain next describ approach gnnexplain given train gnn model φ predict explan section set predict explan section gnnexplain gener explan identifi subgraph comput graph subset node featur inﬂuenti model φ predict case explain set predict gnnexplain aggreg individu explan set automat summar prototyp conclud thi section discuss gnnexplain use ani machin learn task graph includ link predict graph classiﬁc section explan given node v goal identifi subgraph gs associ featur xs import gnn predict ˆ assum xs small subset node featur later discuss automat determin dimens node featur need includ explan section formal notion import use mutual inform mi formul gnnexplain follow optim framework max gs mi gs xs h gs x xs node v mi quantiﬁ chang probabl predict ˆ φ gc xc v comput graph limit explan subgraph gs node featur limit xs exampl consid situat vj vi vj vi remov vj gc vi strongli decreas probabl predict ˆ yi node vj good counterfactu explan predict vi similarli consid situat vj vk vi vj vk vi remov edg vj vk strongli decreas probabl predict ˆ yi absenc edg good counterfactu explan predict vi examin eq see entropi term h constant becaus φ ﬁxed train gnn result maxim mutual inform predict label distribut explan gs xs equival minim condit entropi h gs x xs express follow h x xs log pφ x explan predict ˆ thu subgraph gs minim uncertainti φ gnn comput limit gs effect gs maxim probabl ˆ figur obtain compact explan impos constraint gs size gs ha km node effect thi impli gnnexplain aim denois gc take km edg give highest mutual inform predict gnnexplain optim framework direct optim gnnexplain object tractabl gc ha exponenti mani subgraph gs candid explan ˆ thu consid fraction adjac subgraph gs enforc subgraph constraint j k j k j thi continu relax interpret variat approxim distribut subgraph gc particular treat gs random graph variabl object eq becom min g gs x xs convex assumpt jensen inequ give follow upper bound min g h eg gs x xs practic due complex neural network convex assumpt doe hold howev experiment found minim thi object regular often lead local minimum correspond explan tractabl estim eg use variat approxim decompos g multivari bernoulli distribut pg gs q j k j k thi allow us estim expect respect approxim therebi obtain j k entri repres expect whether edg vj vk exist observ empir thi approxim togeth regular promot discret converg good local minima despit gnn condit entropi equat optim replac eg gs optim mask comput graph adjac matrix ac denot mask need learn multipl σ denot sigmoid map mask applic instead ﬁnding explan term model conﬁdenc user care whi doe train model predict certain class label make train model predict desir class label modifi condit entropi object equat cross entropi object label class model answer queri comput efﬁcient version gnnexplain object optim use gradient descent follow min c x c log pφ ac x xc mask approach also found neural relat infer albeit differ motiv object lastli comput multipl σ ac remov low valu threshold arriv explan gs gnn model predict ˆ node joint learn graph structur node featur inform identifi node featur import predict ˆ gnnexplain learn featur selector f node explan gs instead deﬁn xs consist node featur type edg deﬁn gs ce number edg type label class predict label class gnn model explain answer whi doe train model predict certain class label make train model predict desir class label answer use label class xs gnnexplain consid xf subset featur node gs deﬁn binari featur selector f figur xf xf j xf j xj xj tk fti xf j ha node featur mask explan gs xs jointli optim maxim mutual inform object max gs f mi gs f h gs x xf repres modiﬁ object function eq consid structur node featur inform gener explan predict ˆ learn binari featur selector specifi xf xs f act featur mask need learn intuit particular featur import correspond weight gnn weight matrix take valu close zero effect thi impli mask featur doe decreas predict probabl ˆ convers featur import mask would decreas predict probabl howev case thi approach ignor featur import predict take valu close zero address thi issu margin featur subset use mont carlo estim sampl empir margin distribut node xs dure train use reparametr trick backpropag gradient eq featur mask particular backpropag random variabl x reparametr x x z xs p j fj z random variabl sampl empir distribut kf paramet repres maximum number featur kept explan integr addit constraint explan impos properti tion extend gnnexplain object function eq regular term exampl use entropi encourag structur node featur mask discret gnnexplain encod constraint techniqu like lagrang multipli constraint addit regular term includ number regular term produc explan desir properti penal larg size explan ad sum element mask paramt regular term final import note explan must valid comput graph particular explan gs xs need allow gnn neural messag ﬂow toward node v gnn make predict ˆ importantli gnnexplain automat provid explan repres valid comput graph becaus optim structur mask across entir comput graph even disconnect edg import neural select explan inﬂuenc gnn predict effect thi impli explan gs tend small connect subgraph explan graph prototyp output explan section small subgraph input graph small subset associ node featur inﬂuenti singl predict answer question like gnn predict given set node label c need obtain global explan class goal provid insight identiﬁ subgraph particular node relat graph structur explain entir class gnnexplain provid explan base graph align prototyp approach ha two stage first given class c ani set predict want explain ﬁrst choos refer node vc exampl comput mean embed node assign take explan gs vc refer vc align explan node assign class find optim match larg graph challeng practic howev instanc gnnexplain gener small graph section thu pairwis graph match efﬁcient comput second aggreg align adjac matric graph prototyp aproto use exampl robust approach prototyp aproto give insight graph pattern share node belong class one studi predict particular node compar explan node predict return explan approach prototyp see appendix inform gnnexplain model extens ani machin learn task graph addit explain node classiﬁc plainer provid explan link predict graph classiﬁc chang optim algorithm predict link vj vk gnnexplain learn two mask xs vj xs vk endpoint link classifi graph adjac matrix eq union adjac matric node graph whose label want explain howev note graph classiﬁc unlik node classiﬁc due aggreg node ding longer true explan gs necessarili connect subgraph depend applic scenario chemistri explan function group connect one extract largest connect compon explan ani gnn model modern gnn base messag pass architectur input graph messag pass comput graph compos mani differ way gnnexplain account thu gnnexplain appli graph convolut network gate graph sequenc neural network jump knowledg network attent network graph network gnn variou node aggreg scheme nn gnn mani gnn architectur comput complex number paramet gnnexplain optim depend size comput graph gc node v whose predict aim explain particular gc v adjac matrix ac v equal size mask need learn gnnexplain howev sinc comput graph typic rel small compar size exhaust neighborhood hop neighborhood neighborhood neighborhood attent gnnexplain effect gener explan even input graph larg experi begin describ graph altern baselin approach experiment setup present experi explain gnn node classiﬁc graph classiﬁc task qualit quantit analysi demonstr gnnexplain accur effect identifi explan term graph structur node featur synthet dataset construct four kind node classiﬁc dataset tabl shape start base ba graph node set hous network motif attach randomli select node base graph result graph perturb ad random edg node assign class base structur role motif type role top middl bottom node hous therefor differ class correspond node top middl bottom hous node belong hous dataset union two graph node normal distribut featur vector assign one class base structur role commun membership start base balanc binari tree cycl motif attach random node base graph except grid motif attach base tree graph place cycl motif dataset consid two graph classiﬁc dataset mutag dataset molecul graph label accord mutagen effect bacterium typhimurium dataset graph repres onlin discuss thread reddit graph node user particip thread edg indic one user repli anoth user comment graph label accord type user interact thread contain interact contain interact altern baselin approach mani explain method directli appli graph section nevertheless consid follow altern approach provid insight predict made gnn grad method comput gradient gnn loss function respect adjac matrix associ node featur similar salienc map approach att graph attent gnn gat learn attent weight edg comput graph use proxi measur edg import att doe consid graph structur doe explain use node featur onli explain gat model furthermor att obviou attent weight need use edg base motif node featur none none commun id graph structur graph structur node featur inform explan content explan accuraci att grad gnnexplain commun commun none graph structur graph structur tabl illustr synthet dataset refer synthet dataset detail togeth perform evalu gnnexplain altern baselin explain approach b b comput graph grad ground truth att comput graph grad att ground truth gnnexplain gnnexplain figur evalu explan shown exemplar explan subgraph node classiﬁc task four synthet dataset method provid explan red node predict import sinc neighbor node also neighbor node due cycl edg import thu comput averag attent weight across layer setup implement detail dataset ﬁrst train singl gnn dataset use grad gnnexplain explain predict made gnn note att baselin requir use graph attent architectur like gat thu train separ gat model dataset use learn edg attent weight explan hyperparamet km kf control size subgraph featur explan respect inform prior knowledg dataset synthet dataset set km size ground truth dataset set km set kf dataset ﬁx weight regular hyperparamet across node graph classiﬁc experi refer reader appendix train detail code dataset avail http result investig question doe gnnexplain provid sensibl explan explan compar knowledg doe gnnexplain perform variou predict task explain predict made differ gnn quantit analys result node classiﬁc dataset shown tabl explan synthet dataset use calcul explan accuraci explan method speciﬁc formal explan problem binari classiﬁc task edg explan treat label import weight given explain method view predict score better explain method predict mutag mutag comput graph grad ground truth att comput graph grad att ground truth gnnexplain gnnexplain b topic reaction ring structur group expert answer multipl question figur evalu explan shown exemplar explan subgraph graph classiﬁc task two dataset mutag graph classif node classif b c cl h n f br p nak lica applic applic molecular graph node featur comput graph red node node featur input gnn node structur role molecul mutagen gnn predict ground truth featur import gnnexplain grad att figur visual featur import gnn predict shown repres molecular graph mutag dataset top tanc associ graph featur visual heatmap bottom contrast baselin gnnexplain correctli identiﬁ featur import predict molecul mutagen c h n atom shown comput graph red node dataset top gnnexplain success identiﬁ node featur import predict structur role node baselin method fail high score edg explan thu achiev higher explan accuraci result show gnnexplain outperform altern approach averag gnnexplain achiev higher accuraci hardest dataset qualit analys result shown figur predict task node featur gnnexplain correctli identiﬁ network motif explain node label structur label figur illustr ﬁgure hous cycl tree motif identiﬁ gnnexplain baselin method figur investig explan graph classiﬁc task mutag exampl color indic node featur repres atom hydrogen h carbon c etc gnnexplain correctli identiﬁ carbon ring well chemic group known mutagen exampl see graph row figur high degre node simultan connect mani low degre node make sens becaus qa thread reddit typic expert answer mani differ question convers observ discuss pattern commonli exhibit pattern row figur sinc thread reddit usual reaction singl topic hand grad att method give incorrect incomplet explan exampl baselin method miss cycl motif mutag dataset complex grid motif dataset furthermor although edg attent weight att interpret import score messag pass weight share across node input graph att fail provid high qualiti explan essenti criterion explan must interpret provid qualit understand relationship input node predict requir impli explan easi understand remain exhaust thi mean gnn explain take account structur underli graph well associ featur avail figur show result experi gnnexplain jointli consid structur inform well inform small number featur gnnexplain inde highlight compact featur represent figur approach struggl cope ad nois give high import score irrelev featur dimens conclus present gnnexplain novel method explain predict ani gnn ani base machin learn task without requir modiﬁc underli gnn architectur show gnnexplain leverag recurs scheme graph neural network identifi import graph pathway well highlight relev node featur inform pass along edg pathway problem explain predict ha receiv substanti attent recent literatur work uniqu sens present approach oper relat rich node provid straightforward interfac make sens gnn predict debug gnn model identifi systemat pattern mistak explan shown two dataset node featur mutag acknowledg jure leskovec chan zuckerberg biohub investig grate acknowledg support darpa ase msc nih mobil aro muri iarpa hfc nsf cine hdr stanford data scienc initi chan zuckerberg biohub amazon boe docomo huawei hitachi observ siemen ust global govern author reproduc distribut reprint government purpos notwithstand ani copyright notat thereon ani opinion ﬁnding conclus ommend express thi materi author necessarili reﬂect view polici endors either express impli darpa nih onr govern refer adadi berrada peek insid survey explain artiﬁci intellig xai ieee access adebayo gilmer muelli goodfellow hardt kim saniti check salienc map neurip gethsiy augasta kathirvalavakumar revers engin neural network rule extract classiﬁc problem neural process letter april peter w battaglia jessica b hamrick victor bapst alvaro viniciu baldi mateusz malinowski andrea tacchetti david raposo adam santoro ryan faulkner et al relat induct bias deep learn graph network chen zhu song stochast train graph convolut network varianc reduct icml jianbo chen le song martin j wainwright michael jordan learn explain perspect model interpret arxiv preprint jie chen tengfei cao xiao fastgcn fast learn graph convolut network via import sampl iclr chen li bruna supervis commun detect line graph neural network iclr cho myer leskovec friendship mobil user movement social network kdd debnath et al relationship mutagen aromat heteroaromat nitro compound correl molecular orbit energi hydrophob journal medicin chemistri kim toward rigor scienc interpret machin learn arxiv duvenaud et al convolut network graph learn molecular ﬁngerprint nip erhan bengio courvil vincent visual featur deep network univers montreal fisher rudin dominici model wrong mani use variabl import proprietari misspeciﬁ predict model use model class relianc januari arxiv guidotti et al survey method explain black box model acm comput hamilton ying leskovec induct represent learn larg graph nip hooker discov addit structur black box function kdd huang zhang rong huang adapt sampl toward fast graph tation learn neurip bo kang jefrey lijfﬁjt tijl de bie explain approach explain network link predict diederik p kingma max well variat bay neurip kipf well classiﬁc graph convolut network iclr thoma kipf ethan fetaya wang max well richard zemel neural relat infer interact system icml koh liang understand predict via inﬂuenc function icml srijan kumar william l hamilton jure leskovec dan jurafski commun interact conﬂict web www page lakkaraju kamar caruana leskovec interpret explor tion black box model li tarlow brockschmidt zemel gate graph sequenc neural network lundberg lee uniﬁ approach interpret model predict nip neil et al interpret graph convolut neural network infer noisi knowledg graph workshop neurip ribeiro singh guestrin whi trust explain predict ani classiﬁ kdd schmitz aldrich gouw algorithm extract decis tree artiﬁci neural network ieee transact neural network shrikumar greensid kundaj learn import featur propag activ differ icml sundararajan tali yan axiomat attribut deep network icml velickov cucurul casanova romero li bengio graph attent network iclr xie grossman crystal graph convolut neural network accur interpret predict materi properti phi rev xu hu leskovec jegelka power graph neural network icrl xu li tian sonob kawarabayashi jegelka represent learn graph jump knowledg network icml pinar yanardag svn vishwanathan deep graph kernel kdd page acm yeh kim yen ravikumar represent point select explain deep neural network neurip ying chen eksombatchai hamilton leskovec graph convolut neural network recommend system kdd ying morri ren hamilton leskovec hierarch graph represent learn differenti pool neurip liu ying pand leskovec graph convolut polici network molecular graph gener rex ying leskovec graph neural network icml zeiler fergu visual understand convolut network eccv zhang chen link predict base graph neural network nip zhang peng zhu deep learn graph survey zhou cui zhang yang liu sun graph neural network review method applic zilk loza mencia janssen deepr rule extract deep neural network discoveri scienc springer intern publish zintgraf cohen adel well visual deep neural network decis predict differ analysi iclr zitnik agraw leskovec model polypharmaci side effect graph convolut network bioinformat