articl power data quantum machin learn michael masoud ryan sergio boixo hartmut jarrod mcclean use quantum comput machin learn among excit prospect applic quantum technolog howev machin learn task data vide consider differ commonli studi comput task thi work show problem classic hard comput easili predict classic machin learn data use rigor predict error bound tion develop methodolog assess potenti quantum advantag learn task bound tight asymptot empir predict wide rang learn model construct explain numer result show help data classic machin learn model competit quantum model even tailor quantum problem propos project quantum model provid simpl rigor quantum learn problem regim implement demonstr signiﬁc predict advantag classic model engin data set design demonstr maxim quantum advantag one largest numer test quantum machin learn date qubit http open googl quantum ai venic ca usa institut quantum inform matter caltech pasadena ca usa depart comput mathemat scienc caltech pasadena ca usa jmcclean natur commun http quantum technolog continu rapidli advanc becom increasingli import understand applic beneﬁt power devic time machin learn classic comput ha made great stride revolution applic imag nition text translat even physic applic comput power lead ever increas quantum comput could acceler machin learn potenti impact enorm least two path toward quantum enhanc machin learn consid first motiv quantum applic power quantum ing could principl use help improv train process exist classic enhanc infer graphic thi could includ ﬁnding better optima train landscap ﬁnding optima fewer queri ever without structur known problem tage along line may limit quadrat small polynomi second vein interest possibl use quantum model gener correl variabl ﬁcient repres classic comput recent success theoret experiment demonstr quantum comput beyond classic tractabl taken evid quantum comput sampl probabl distribut exponenti difﬁcult sampl distribut coincid world distribut thi would suggest potenti niﬁcant advantag thi typic type advantag ha sought recent work quantum neural seek parameter distribut set adjust paramet quantum kernel use quantum comput deﬁn featur map map classic data quantum hilbert space justiﬁc capabl method exceed classic model often follow similar line ref quantum simul result model leverag quantum circuit hard sampl result classic potenti quantum advantag thi work show quantit thi pictur incomplet machin learn ml problem train data provid provid data elev classic model rival quantum model even quantum circuit gener data hard comput classic begin motiv exampl argument show classic algorithm data match quantum output follow thi provid rigor predict error bound train classic quantum ml method base kernel learn quantum mechan model focu kernel method onli provid provabl guarante also veri ﬂexibl function learn exampl recent advanc theoret machin learn show train neural network larg hidden layer equival train ml model particular kernel known neural tangent throughout refer classic ml model relat theoret develop refer ml model easili associ kernel either explicitli kernel method implicitli neural tangent kernel howev numer section also includ perform comparison method direct associ kernel challeng random forest method quantum case also show quantum ml base kernel made equival train inﬁnit depth quantum neural network use predict error bound devis ﬂowchart test potenti quantum predict advantag separ predict error quantum classic ml model ﬁxed amount train data import test geometr differ kernel function deﬁn classic quantum ml formal geometr differ deﬁn closest efﬁcient classic ml model practic one consid geometr differ respect suit optim classic ml model geometr differ small classic ml method guarante provid similar better perform predict dataset independ function valu label henc thi sent power function independ prescreen allow one evalu ani possibl better perform hand geometri differ greatli show exist dataset exhibit larg predict advantag use quantum ml model one construct efﬁcient tool develop could use compar construct hard classic model like hash function enforc restrict allow us say someth quantum separ particular featur map white box quantum circuit speciﬁc avail ideal featur map featur map made tional hard evalu classic construct exampl thi discret log featur map provabl separ kernel given supplementari section addit minimum classic model mean classic hash tion reproduc formal deﬁnit moreov applic tool exist model literatur rule mani immedi provid power siev focus develop new data encod follow construct numer experi ﬁnd varieti common quantum model literatur perform similarli wors classic ml classic quantum dataset due small geometr differ small geometr differ consequ exponenti larg hilbert space employ exist quantum model input far apart circumv setback propos improv enlarg geometr differ project quantum state embed classic data back approxim classic larg metric differ endow project quantum model abl construct engin dataset demonstr larg predict advantag common classic ml model numer experi qubit despit construct base method associ kernel ﬁnd empir predict advantag remain robust across test classic method includ without easili determin kernel thi open possibl use small quantum comput gener efﬁcient veriﬁ machin learn problem could challeng classic ml model result setup motiv exampl begin set problem method interest classic quantum model provid simpl motiv exampl studi data increas power classic model quantum data focu supervis learn task collect n train exampl xi yi xi input data yi associ label valu assum xi sampl independ data distribut theoret analysi consid yi r gener quantum model particular consid articl natur commun http natur commun http continu encod unitari map classic input data xi quantum state xi uencðxiþ j refer correspond densiti matrix ρ xi express power embed investig function analysi point howev set data provid requir special attent encod unitari follow unitari uqnn θ measur observ quantum neural network thi produc input xi given yi f ðxiþ xi qnnouqnn xi quantum model consid also refer quantum neural network qnn goal understand easi predict function f x train machin learn model notat place turn simpl motiv exampl understand avail data machin learn task chang comput hard consid data point fxign classic vector use amplitud encod data state xi xk k j xk individu coordin vector xi uqnn hamiltonian function f ðxþ x h juy qnnouqnn x j gener hard comput even singl input state particular follow proposit show classic algorithm comput f x efﬁcient quantum comput power classic comput see supplementari section proof proposit classic algorithm without train data comput f x efﬁcient ani uqnn bpp bqp nevertheless incorrect conclud train classic model data learn thi evolut hard see thi write expect valu f ðxiþ p k h j uy qnnouqnn p xl l j p p xl quadrat function coefﬁcient bkl k h juy qnnouqnn l j use theori develop later thi work show ani uqnn train speciﬁc classic ml model collect n train exampl xi yi f xi would give rise predict model h xi f ðxþj ﬃﬃﬃﬃ ﬃ n r constant c refer supplementari section proof thi result henc n train data one train classic ml model predict function f x addit predict error thi elev classic model train sampl illustr power data supplementari section give rigor theoret argument comput power provid data cartoon depict complex separ induc data provid fig thi simpl exampl make basic point sufﬁcient data chang complex consider perhap open question answer exampl use rather weak encod amplitud assum one ha access amount data par dimens model interest case occur strengthen data encod includ modern classic ml model consid number data n much less dimens model interest case one quantit answer fig illustr relat complex class ﬂowchart understand prescreen potenti quantum advantag cartoon separ problem complex creat addit data problem classic algorithm learn data deﬁn complex class solv problem beyond classic comput bpp still expect quantum comput efﬁcient solv problem classic ml algorithm data rigor deﬁnit proof separ classic algorithm learn data given supplementari section b ﬂowchart develop understand potenti quantum predict advantag n sampl data potenti inﬁnit depth qnn made encod function circuit uenc uqnn provid input along quantum classic method associ kernel test given function n emphas role data possibl predict advantag one ﬁrst evalu geometr quantiti gcq measur possibl advantag predict separ without yet consid actual function learn show one efﬁcient construct adversari function satur thi limit test pass otherwis classic approach guarante match perform ani function data subsequ consid actual function provid test may run use model complex sc sq one speciﬁc use quantum kernel qk method red dash arrow evalu possibl choic uqnn lead easi classic function chosen encod data natur commun http articl natur commun http primari interest ml algorithm much stronger ﬁtting quadrat function input data provid interest way amplitud encod thi work focu classic quantum ml model base kernel function k xi xj high level kernel function seen measur similar k xi xj larg xi xj close consid ﬁnite input data kernel function may repres matrix kij k xi xj condit requir kernel method satisﬁ matrix represent hermitian posit given kernel function correspond nonlinear featur map ϕ x map x possibl featur space kðxi xjþ ϕðxiþyϕðxjþ thi basi kernel trick intric power map ϕ xi implement evalu rel simpl kernel function simpl case exampl abov use kernel k xi xj correspond featur map ϕðxiþ xl k j l j capabl learn quadrat function amplitud kernel base ml algorithm train model alway written h x x w vector featur space deﬁn kernel exampl train convolut neural network larg hidden equival use correspond neural tangent kernel kcnn featur map ϕcnn kernel kcnn nonlinear map extract local properti quantum mechan similarli kernel function deﬁn use nativ geometri quantum state space x j exampl deﬁn kernel function use output thi kernel method like classic support vector deﬁn quantum kernel method wide class function learn sufﬁcient larg amount data use right kernel function exampl contrast perhap natur kernel quantum kernel kq xi xj tr ρ xi ρ xj learn arbitrarili deep quantum neural network uqnn measur ani observ shown supplementari section gaussian kernel kγðxi xjþ hyperparamet γ learn ani continu function compact includ learn ani qnn theless requir amount data n achiev small predict error could veri larg worst case although work kernel deﬁn quantum space due thi express properti terminolog past work refer kqðxi xjþ tr ρðxiþρðxjþ quantum kernel method throughout thi work also deﬁnit given test quantum advantag construct gener framework assess potenti quantum predict advantag machin learn task begin gener result build intuit practic test base metri learn space thi framework summar fig foundat gener predict error bound train ml model predict quantum model deﬁn f x tr ouρ x deriv concentr iti ou uy qnnouqnn suppos obtain n train exampl xi yi f xi train thi data exist ml algorithm output h x x use kernel kðxi xjþ kij ϕðxiþyϕðxjþ ha simpliﬁ predict error bound f ðxþj ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃ skðnþ n r constant c n independ sampl data distribut note thi subsequ bound key depend quantiti data n reﬂect role data improv predict perform due scale freedom αϕ x assum ϕðxiþyϕðxiþ tr ðkþ deriv thi result given supplementari section given thi core predict error bound seek understand implic main quantiti determin predict error skðnþ n n tr ðouρðxiþþ tr ðouρðxjþþ quantiti sk n equal model complex train function h x x sk n train smaller valu sk n impli better gener new data x sampl distribut intuit sk n measur whether close xi xj deﬁn kernel function k xi xj match well close observ expect quantum state ρ xi ρ xj recal larger kernel valu indic two point closer comput sk n perform efﬁcient classic comput invert n n matrix k obtain n valu tr ouρ xi perform order n experi physic quantum devic time complex scale order due connect model complex regular term often ad optim problem dure train h x x see ref regular prevent sk n becom larg expens complet ﬁtting train data detail discuss proof tion given supplementari section predict error upper bound often shown asymptot tight prove match lower bound exampl k xi xj quantum kernel tr ρ xi ρ xj deduc sk n henc one would need number data n scale tr supplementari section give match lower bound show scale tr unavoid assum larg hilbert space dimens thi lower bound hold ani learn algorithm onli quantum kernel method lower bound proof use mutual inform analysi could easili extend kernel thi proof strategi also employ extens devis upper lower bound classic quantum ml learn quantum model furthermor onli bound asymptot tight numer experi given supplementari section ﬁnd predict error bound also captur perform classic ml model base kernel constant factor observ quit modest given set data sk n found small rel n train classic ml model thi quantum model f x predict accur even f x hard comput classic ani given order formal evalu potenti quantum predict advantag gener one must take sk n minim efﬁcient classic model howev focus minim attain valu reason set classic method tune meter thi prescrib effect method evalu potenti quantum advantag practic alreadi rule consider number exampl literatur bound see potenti advantag one ml algorithm deﬁn predict better anoth ml algorithm deﬁn depend largest possibl separ dataset separ character deﬁn asymmetr geometr differ articl natur commun http natur commun http depend dataset independ function valu label henc evalu thi quantiti good ﬁrst step understand potenti quantum advantag shown fig thi quantiti deﬁn ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ jj ﬃﬃﬃﬃﬃﬃ p ﬃﬃﬃﬃﬃﬃ p q spectral norm result matrix assum tr tr one show impli predict error bound c ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ p ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ p detail deriv given supplementari section c illustr found fig geometr differ g comput classic comput perform singular valu tion n n matric standard numer analysi provid highli efﬁcient comput singular valu decomposit time order intuit xi xj xi xj larg geometr differ small valu grow kernel deviat see explicitli geometr differ allow one make statement possibl one ml model make differ predict anoth consid geometr differ gcq g classic ml model kernel kc xi xj quantum ml model kq xi xj tr ρ xi ρ xj gcq small becaus sc cqsq classic ml model alway similar better model complex sk n compar quantum ml model thi impli predict perform classic ml like competit better quantum ml model one like prefer use classic model thi captur ﬁrst step ﬂowchart fig contrast gcq larg show exist dataset sc cqsq quantum model exhibit superior predict perform efﬁcient method explicitli construct maxim diverg dataset given supplementari section numer demonstr stabil thi separ provid next section formal statement classic method gener requir deﬁn overal efﬁcient classic method practic consid gcq minimum geometr differ among suit optim classic ml model engin approach minim thi valu hyperparamet search ﬁnd best classic adversari show remark robust across classic method includ without associ kernel random speciﬁc case quantum kernel method kq ij kqðxi xjþ tr ðρðxiþρðxjþþ gain addit insight model complex sk sometim make conclus classic learnabl possibl uqnn given encod data let us deﬁn vec x hermitian matrix x vector contain real imaginari part entri thi case ﬁnd sq vecðouþ tpqvecðouþ pq projector onto subspac form vec ρ vec ρ xn highlight dim ðpqþ rank ðkqþ deﬁn effect dimens quantum state space span train data illustr dimens found fig becaus pq projector ha eigenvalu sq vecðouþ tvecðouþþ minðd tr assum henc case quantum kernel method predict error bound may written f ðxþj ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ minðd tr n r detail deriv given supplementari section also consid approxim dimens small lue kq truncat incur small train error fig cartoon geometri kernel function deﬁn classic quantum ml model letter b repres data point xi differ space arrow repres similar measur kernel function data geometr differ g differ similar measur arrow differ ml model effect dimens dataset quantum hilbert space natur commun http articl natur commun http obtain kq quantum devic dimens comput efﬁcient classic machin perform singular valu decomposit n n matrix kq estim tr perform sampl random state ψ quantum measur ψ perform statist analysi measur thi predict error bound show quantum kernel method learn ani uqnn dimens train set space squar frobeniu norm observ tr much smaller amount data supplementari section show quantum kernel method optim learn quantum model bound tr satur fundament lower bound howev practic observ pauli oper exponenti larg tr central quantiti dimens use predict error bound quantum kernel method gcq minðd tr small classic ml would also abl learn ani uqnn case one must conclud given encod data classic easi thi affect arbitrarili deep uqnn thi constitut bottom left part ﬂowchart fig ultim see predict advantag particular dataset speciﬁc function need larg separ sc sq thi happen input xi xj consid close quantum ml model actual close target function f x far classic ml thi repres ﬁnal test fig methodolog outlin thi result achiev term essenti compon project quantum kernel addit analyz exist quantum model analysi approach introduc also provid suggest new quantum model improv properti address exampl start origin quantum kernel effect dimens larg kernel tr ρ xi ρ xj base metric regard data far kernel matrix kq close ident thi result small geometr enc gcq lead classic ml model competit outperform quantum kernel method supplementari section present simpl quantum model requir exponenti amount sampl learn use quantum kernel tr ρ xi ρ xj onli need linear number sampl learn use classic ml model circumv thi setback propos famili project quantum kernel solut kernel work project quantum state approxim classic represent use reduc physic observ classic even train set space ha larg dimens n project allow us reduc dimension classic space gener better go exponenti larg quantum hilbert space project quantum kernel challeng evalu without quantum comput numer experi ﬁnd classic project increas rather decreas geometr differ classic ml model construct foundat best perform quantum method later one simplest form project quantum kernel measur reduc densiti matrix qubit encod state ρk xi ρ xi deﬁn kernel kpqðxi xjþ exp k jjρkðxiþ f thi kernel deﬁn featur map function space capabl express arbitrari function power quantum state nonintuit result densiti function theori know even one bodi densiti sufﬁcient determin exact ground properti system modest assumpt supplementari section provid exampl project quantum kernel thi includ efﬁcient method comput kernel function contain order rdm use local random measur formal classic classic shadow formal allow efﬁcient construct rdm veri ment supplementari section show project version quantum kernel lead simpl rigor quantum recent propos learn problem base discret numer studi provid numer evid qubit support theori relat dimens geometr differ g predict formanc use project quantum kernel geometr differ g much larger see strongest empir advantag scalabl quantum model quantum dataset date largest combin simul analysi digit quantum machin learn awar make use tensorflow reach peak throughput quadrillion ﬂoat point oper per second trend quantum simul classic analysi observ maximum experi size overal ﬂoat point oper across experi total quintillion exaﬂop order mimic data distribut pertain data conduct experi around imag classiﬁc distinguish cloth item challeng origin base mnist preprocess data use princip compon transform imag vector data provid quantum classic model classic case data input vector quantum case use given circuit emb vector space n qubit quantum embed explor three option separ rotat embed hamiltonian evolut circuit explicit construct supplementari section classic ml task c goal correctli identifi imag shirt dress origin dataset quantum ml task use sourc data embed abov take function valu expect valu local observ ha evolv quantum neural network resembl trotter evolut model random coupl case embed taken part ground truth result function differ depend quantum embed ml task compar best perform model list standard classic ml algorithm properli tune hyperparamet see supplementari tion detail fig give comparison predict perform classic quantum ml model one see onli classic ml model perform best origin classic dataset predict perform classic method quantum dataset also veri competit even outperform exist quantum ml model despit quantum ml model access train embed articl natur commun http natur commun http classic method perform classic ml model especi strong dataset q dataset q thi elev classic perform evid power data moreov thi intrigu behavior lack quantum advantag may explain consid effect dimens geometr differ g follow theoret construct fig see dimens origin quantum state space grow rather quickli geometr differ g becom small dimens becom larg standard quantum kernel satur dimens coincid decreas statist ﬂuctuat perform seen fig moreov given poor ml perform natur instinct throw resourc problem qubit demonstr thi naïv quantum kernel method like lead tini inner product even wors perform contrast project quantum space ha low dimens even grow yield higher geometr differ g embed system size methodolog predict g small classic ml model competit outperform quantum ml model thi veriﬁ fig origin project quantum kernel small geometr differ g lead veri good perform classic ml model larg quantum advantag seen onli geometr differ g larg project kernel method embed see mild advantag best classic method thi result hold disregard ani detail quantum evolut tri learn even one hard simul classic fig relat dimens geometr differ g predict perform shade region standard deviat independ run n number qubit quantum encod dimens input classic encod approxim dimens geometr differ g classic ml model quantum kernel q project quantum kernel pq differ embed system size b predict error lower better quantum kernel method q project quantum kernel method pq classic ml model classic c quantum q dataset number data n grow larg geometr differ g quantum kernel becom small see small geometr differ g alway result classic ml competit outperform quantum ml model g larg potenti improv classic ml exampl project quantum kernel improv upon best classic ml dataset q fig predict accuraci higher better engin dataset label function engin match geometr differ g project quantum kernel classic approach demonstr signiﬁc gap quantum best classic model qubit g larg consid best perform classic ml model among gaussian svm linear svm adaboost random forest neural network gradient boost onli report accuraci quantum kernel method system size n due high simul cost inferior perform natur commun http articl natur commun http order push limit separ quantum classic approach learn set consid set engin dataset function valu design satur geometr inequ sc classic ml model associ kernel project quantum kernel method particular design dataset spq sc gðkcjjkpqþ recal eq thi dataset henc show largest separ predict error bound ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ p engin dataset construct via simpl eigenvalu problem exact procedur describ supplementari section result shown fig quantum natur encod increas correspond increas g perform best classic method origin quantum kernel declin precipit advantag project quantum kernel close follow geometr differ g reach larg size despit optim g onli possibl classic method associ kernel perform advantag remain stabl across common classic method note also construct engin dataset satur geometr inequ classic ml origin quantum kernel small geometr differ g present empir advantag larg system size see supplementari section keep argument role data increas number train data n method improv advantag gradual diminish thi dataset engin show strongest empir separ largest system size date conjectur thi procedur could use quantum comput creat challeng dataset easi learn quantum devic hard learn classic still easi verifi classic given correct label moreov size margin impli thi separ may even persist moder amount nois quantum devic discuss use quantum comput machin learn remain excit prospect quantifi quantum advantag applic ha subtl issu one must approach care construct foundat understand opportun quantum advantag learn set show quantit classic ml algorithm data becom comput power predict advantag quantum model guarante even data come quantum process challeng dentli simul motiv test introduc project quantum kernel engin dataset project quantum kernel outperform test classic model predict error author knowledg thi ﬁrst empir stration larg separ quantum classic ml model thi work suggest simpl guidebook gener ml problem give larg separ quantum classic model even modest number qubit size thi separ trend qubit suggest exist learn task may easi verifi hard model classic requir modest number qubit allow devic nois claim true advantag quantum machin learn set requir onli benchmark classic machin learn model also classic approxim quantum model addit work need identifi embed satisfi sometim conﬂict requir hard approxim classic exhibit meaning signal local observ veri larg number qubit research requir ﬁnd use case dataset closer practic interest evalu potenti claim advantag believ tool develop thi work help pave way thi excit frontier data avail data support plot within thi paper ﬁnding thi studi avail upon reason request sourc data provid thi paper code avail tutori reproduc smaller numer experi avail http receiv novemb accept march refer halevi norvig pereira unreason effect data ieee intel syst grover fast quantum mechan algorithm databas search proc annual acm symposium theori comput durr hoyer quantum algorithm ﬁnding minimum http farhi et al quantum adiabat evolut algorithm appli random instanc problem scienc neven denchev rose macreadi train larg scale classiﬁ quantum adiabat algorithm http rebentrost mohseni lloyd quantum support vector machin big data classiﬁc phi rev lett leifer poulin quantum graphic model belief propag ann phi aaronson ambaini need structur quantum speedup http mcclean et al low depth mechan quantum optim http boixo et al character quantum supremaci devic nat phi arut et al quantum supremaci use programm superconduct processor natur peruzzo et al variat eigenvalu solver photon quantum processor nat commun mcclean romero babbush theori variat hybrid algorithm phi farhi neven classiﬁc quantum neural network near term processor arxiv preprint http havlíček et al supervis learn featur space natur cort vapnik network mach learn schölkopf et al learn kernel support vector machin regular optim beyond http mohri rostamizadeh talwalkar foundat machin learn http jacot gabriel hongler neural tangent kernel converg gener neural network nip proceed intern confer neural inform process system http pp novak et al neural tangent fast easi inﬁnit neural network python arxiv preprint http arora et al exact comput inﬁnit wide neural net advanc neural inform process system blank park rhee petruccion quantum classiﬁ tailor quantum kernel npj quantum inf bartkiewicz experiment quantum machin learn ﬁnite featur space sci articl natur commun http natur commun http liu arunachalam temm rigor robust quantum supervis machin learn arxiv preprint http huang kueng preskil predict mani properti quantum system veri measur nat phi http cotler j wilczek quantum overlap tomographi phi rev lett paini kalev approxim descript quantum state arxiv preprint http lloyd schuld ijaz izaac j killoran quantum embed machin learn arxiv preprint http schuld sweke meyer effect data encod express power variat quantum machin learn model phi rev mcclean boixo smelyanskiy babbush neven barren plateau quantum neural network train landscap nat commun grant wossnig ostaszewski benedetti initi strategi address barren plateau parametr quantum circuit quantum schuld bocharov svore wieb quantum classiﬁ phi rev laros coyl robust data encod quantum classiﬁ phi rev harrow montanaro quantum comput supremaci natur li et al enhanc convolut neural tangent kernel arxiv preprint http micchelli xu zhang univers kernel mach learn krogh hertz simpl weight decay improv gener adv neural inf process syst suyken vandewal least squar support vector machin classiﬁ neural process lett huang kueng preskil bound quantum advantag machin learn arxiv preprint http anderson et al lapack user guid edn societi industri appli mathemat breiman random forest mach learn gosset smolin compress classic descript quantum state arxiv preprint http aaronson shadow tomographi quantum state siam comput http aaronson rothblum gentl measur quantum state differenti privaci proc annual acm sigact symposium theori comput hohenberg kohn inhomogen electron ga phi rev rung gross theori system phi rev lett broughton et al tensorﬂow quantum softwar framework quantum machin learn arxiv preprint http xiao rasul vollgraf novel imag dataset benchmark machin learn algorithm arxiv preprint http lecun cort burg mnist handwritten digit databas http jolliff princip compon analysi springer schuld killoran quantum machin learn featur hilbert space phi rev lett skolik mcclean mohseni van der smagt leib layerwis learn quantum neural network quantum machin intellig acknowledg want thank richard kueng john platt john preskil thoma vidick nathan wieb wu valuabl input inspir discuss thank bálint pató crucial contribut set simul author contribut develop theoret aspect thi work conduct numer experi wrote open sourc code contribut technic discuss write manuscript compet interest author declar compet interest addit inform supplementari inform onlin version contain supplementari materi avail http correspond request materi address peer review inform natur commun thank nana liu anonym review contribut peer review thi work reprint permiss inform avail http publish note springer natur remain neutral regard jurisdict claim publish map institut afﬁliat open access thi articl licens creativ common attribut intern licens permit use share adapt distribut reproduct ani medium format long give appropri credit origin author sourc provid link creativ common licens indic chang made imag third parti materi thi articl includ articl creativ common licens unless indic otherwis credit line materi materi includ articl creativ common licens intend use permit statutori regul exce permit use need obtain permiss directli copyright holder view copi thi licens visit http author natur commun http articl natur commun http