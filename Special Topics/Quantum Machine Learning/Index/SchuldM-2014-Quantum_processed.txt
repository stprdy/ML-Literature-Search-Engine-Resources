introduction quantum machine learning maria schulda ilya sinayskiya b francesco petruccionea b aquantum research group school chemistry physic university durban 4001 south africa bnational institute theoretical physic nithep 4001 south africa september 11 2014 abstract machine learning algorithm learn desired relation example order interpret new input important task image speech recognition strategy optimisation growing application industry last couple year researcher investigated quantum computing help improve classical machine learning algorithm idea range running computationally costly algorithm subroutine eﬃciently quantum computer translation stochastic method language quantum theory contribution give systematic overview emerging ﬁeld quantum machine learning present approach well technical detail accessable way discus potential future theory quantum learning keywords quantum machine learning quantum computing artiﬁcial intelligence machine learning 1 introduction machine learning refers area computer ence pattern derived learned data goal make sense previously known input part artiﬁcial intelligence statistic machine learning algorithm process large amount information task come naturally human brain image speech recognition pattern identiﬁcation strategy optimisation problem gain signiﬁcant tance digital age illustrative example google pagerank machine learning algorithm search engine wa patented larry page 19971 led rise today one biggest company world important application machine learning spam last accessed mail ﬁlters iris recognition security system evaluation consumer behaviour assessing risk ﬁnancial sector developing strategy computer game short machine learning come play wherever need computer interpret data based experience usually involves huge amount previously collected data pair machine learning algorithm eﬃcient order deal called big data since volume globally stored data growing around 20 every year currently ranging order several hundred exabyte 1 pressure ﬁnd innovative approach machine learning rising promising idea currently investigated academia well research lab leading company exploit potential quantum computing order optimise classical machine learning algorithm last decade 1 10 sep 2014 physicist already demonstrated impressive power quantum system information ing contrast conventional computer built physical implementation two state 0 1 quantum computer make use qubit superposition two quantum state encoded two distinct energy level atom order follow many diﬀerent path computation time law quantum mechanic also restrict access information stored quantum system coming quantum algorithm outperform classical counterpart diﬃcult however toolbox quantum algorithm fairly established contains number impressive example speed best known classical method 2 technological implementation quantum computing emerging 3 many believe only matter time numerous theoretical proposal tested real machine background new research ﬁeld quantum machine learning might oﬀer potential revolutionise future way intelligent data processing number recent academic contribution plore idea using advantage quantum computing order improve machine learning algorithm example some eﬀort ha put development quantum version 4 5 6 artiﬁcial neural network widely used machine learning often based biological perspective major ha not accomplished yet 7 some author try develop entire quantum algorithm solve problem pattern recognition 8 9 10 proposal suggest simply run subroutine classical machine learning algorithm quantum computer hoping gain speed 11 12 13 interesting approach adiabatic quantum machine learning seems especially ﬁt some class optimisation problem 14 15 16 stochastic model bayesian decision theory hidden markov model ﬁnd elegant translation language open quantum system 17 18 despite growing level interest ﬁeld neighbour clustering support vector machine neural network decision tree bayesian theory hidden markov model machine learning method efficient calculation classical distance quantum computer reformulation language open quantum system first exploration quantum model quantum approach figure 1 overview method machine learning approach quantum information tive presented paper comprehensive theory quantum learning quantum information principle applied intelligent form computing only ﬁrst stage development contribution give systematic overview emerging ﬁeld quantum machine learning focus method pattern classiﬁcation brief discussion concept classical tum learning section 2 paper divided seven section presenting standard method machine learning namely neighbour od support vector machine clustering neural network decision tree bayesian theory hidden markov model various approach relate method quantum physic structure mirror still rather fragmented ﬁeld allows reader select speciﬁc area interest summarised figure 1 neighbour method support vector machine tering author mainly concerned ﬁnd eﬃcient calculation classical distance potential tum computer probabilistic method bayesian theory hidden markov model ﬁnd analogy formalism open quantum system neural network decision tree still waiting convincing quantum version although especially former ha relatively active ﬁeld 2 search last decade finally section 4 brieﬂy discus need future work quantum machine learning concentrate actual learning part machine learning method improved using power quantum information processing 2 classical quantum ing classical machine learning theory machine learning important discipline artiﬁcial intelligence statistic root traced back beginning artiﬁcial neural network artiﬁcial intelligence search 1950 19 20 1959 arthur samuel gave famous deﬁnition machine learning ﬁeld study give computer ability learn without explicitly programmed 2 fact misleading since algorithm doe not adapt learning process function encodes formal language mean relation computer program derived set training data often big method gain importance puters increasingly interact human become ﬂexible adapt speciﬁc need prominent example spam mail ﬁlter learns user behaviour external database classify new spam mail correctly however only one many diﬀerent case machine learning intersects life theory machine learning term ing usually divided three type see figure 2 help illustrate spectrum ﬁeld supervised unsupervised reinforcement learning supervised learning computer given example interesting note although quoted ous introduction machine learning original reference machine learning pioneer famous statement diﬃcult ﬁnd author either refer secondary publication falsely cite samuel seminal paper 1959 21 unsupervised learning supervised learning reinforcement learning figure 2 three type classical learning vised learning derives pattern training data ﬁnds application pattern recognition task pervised learning infers information ture input important data ing reinforcement learning optimises strategy due feedback reward function usually applies intelligent agent game correct relation ha infer mapping therefrom probably important task pattern classiﬁcation vector input data assigned diﬀerent class might sound like rather technical problem fact something human continuously example recognise face diﬀerent angle light condition belonging one person classify signal sensory organ dangerous not could even go far say pattern classiﬁcation abstract description interpreting input coming sens no surprise big share machine learning research try imitate remarkable ability human computer entire zoo algorithm generalise large training data set classify new input second category unsupervised learning ha not part machine learning long time describes process ﬁnding pattern data without prior experience example prominent 3 task data clustering forming subgroup given dataset order summarize large amount information only stereotype example important problem sociological study market research note task closely related classiﬁcation since clustering mean eﬀectively assign class vector given set without goal treating new input finally reinforcement learning closest might associate expression learning given framework rule goal agent usually computer program act player game get rewarded punished depending strategy us order win reward reinforces current strategy punishment lead adaptation policy 22 23 reinforcement learning central anism development study intelligent agent however not focus paper diﬀers many regard two type learning investigation quantum game quantum intelligent agent diverse numerous see example 24 25 26 27 28 shall treated elsewhere even within category expression learning relate diﬀerent procedure example may refer training phase optimal parameter algorithm weight initial state obtained done senting example correct task adapting parameter reproduce example training set discarded 29 illustrative case close human learning weight adjustment process artiﬁcial neural network backpropagation deep learning 30 31 training phase often costly part machine learning algorithm eﬃcient training method become especially important dealing called big data besides learning parameter optimisation problem large number machine learning algorithm not explicit learning phase example presented unclassiﬁed input vector pattern classiﬁcation us training data decide upon classiﬁcation case learning not parameter optimisation problem rather decision function inferred example reinforcement learning decision function becomes full strategy learning refers adaptation strategy increase chance future reward whatever type procedure learning sen optimal machine learning algorithm run minimum resource minimum error rate related task indicated misclassiﬁcation input poor division cluster little reward strategy challenge lie problem ﬁnding parameter initial value lead optimal solution come scheme reduce complexity class quantum computing promise help quantum machine learning quantum computing refers manipulation quantum system order process information ability quantum state tion thereby lead substantial speedup computation term complexity since operation executed many state time basic unit quantum computation qubit α β α β hilbert space absolute square amplitude probability measure qubit 0 1 state quantum dynamic always maintain property probability conservation given mathematical language mean tions map quantum state onto quantum state called quantum gate unitary single qubit quantum gate able manipulate basis state amplitude phase qubit example called respectively put qubit β 0 α 0 equal superposition complexity problem tell u factor computational resource needed solve problem grow increase input problem digit number one 4 h 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 xor x 0 1 1 0 1 1 1 1 1 2 x hadamard 0 1 1 0 measurement qubit state 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 swap x x figure 3 representation qubit state unitary gate measurement quantum circuit model matrix formalism α β 2 α 2 β 2 hadamard gate often based controlled operation execute single qubit operation only another ancilla control qubit certain state one important gate two qubit ﬂips basis state second qubit case ﬁrst qubit state gate mentioned later exchanging state two qubits quantum gate usually expressed unitary matrix see also figure 3 matrix operate vector contain amplitude basis state quantum system example working quantum state 2 would look like 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 2 1 0 0 1 1 2 1 0 1 0 produce 2 art developing algorithm potential quantum computer use elementary gate order create quantum state ha relatively high amplitude state represent solution given problem measurement computational basis produce desired result relatively high probability quantum algorithm usually repeated number time since result always probabilistic comprehensive introduction quantum computing refer standard textbook nielsen chuang 2 quantum machine learning quantum algorithm developed solve typical problem machine learning using eﬃciency quantum computing usually done adapting classical algorithm expensive subroutine run potential quantum computer expectation near future machine commonly available application help process growing amount global information emerging ﬁeld also includes approach vice versa namely method machine learning help extend improve quantum information theory mentioned no comprehensive theory quantum learning yet discussion ments theory found 32 33 34 following remark theory quantum learning would refer method quantum mation processing learn relation training input either optimisation system parameter example unitary operator see 35 ﬁnd quantum decision function quantum strategy many open question eﬃcient quantum learning procedure could look like example eﬃciently implement optimisation problem usually solved iterative dissipative method gradient descent coherent thus reversible quantum computer translate process important structural information distance metric using quantum state formulate decision strategy term quantum physic overall question general way quantum physic principle speed 5 certain problem machine learning underlying question also tion classical data quantum system common approach quantum computing represent classical information binary string xn xi 0 1 1 n directly translated quantum state hilbert space basis read formation measurement however isting machine learning algorithm often based internal structure data example euclidean distance similarity measure two example feature alternative data tations proposed seth lloyd encode classical information norm quantum state leading deﬁnition 11 12 x 1 order use strength quantum ic without conﬁned classical idea data encoding ﬁnding genuinely quantum way resenting extracting information could become vital future quantum machine learning 3 quantum version machine learning algorithm proceeding discussion classical machine learning algorithm quantum counterpart take look actual problem method intend solve well introduce formalism used throughout article probably important application task pattern classiﬁcation many diﬀerent classical algorithm tackling problem based set training example consisting feature respective class attribute computer ha correctly classify unknown feature vector example feature vector feature vector ha entry refer information speciﬁc case word datapoint could contain preprocessed information patient correctly diagnosed disease machine learning algorithm ha ﬁnd correct disease new patient precisely given training set vp cp n n feature vector v respective class cp well new input vector x ﬁnd class cx vector closely related pattern classiﬁcation task pattern completion adding missing information incomplete input associative memory retrieving one number stored memory vector upon input pattern recognition including ﬁnding examining shape pattern term often used synonym pattern classiﬁcation central problem unsupervised learning clustering data given set feature vector vp goal assign vector one k ferent cluster similar input share assignment problem machine learning cern optimal strategy term unknown ward function given set consecutive observation choice consequence stated not concentrate learning strategy quantum version neighbour method popular simple standard textbook method pattern classiﬁcation neighbour algorithm given training set feature vector respective classiﬁcation well unclassiﬁed input vector x idea choose class cx new input appears often amongst k nearest neighbour see figure 4 based assumption close feature vector encode similar example true many application common distance measure thereby inner product euclidian hamming choosing k not always easy inﬂuence result signiﬁcantly k chosen big loose hamming distance two binary string number ﬂips needed turn one 36 6 figure 4 colour online illustration knn method pattern classiﬁcation new tor black cross get assigned class majority k closest neighbour case would orange circle shape b variation method closest mean vector class vector deﬁnes cation new input understood neighbour method preprocessed data k locality information end simple majority vote entire training set small k lead result variation algorithm suggests not run training set calculate mean centroid nc p p vp nc vector belonging one class c beforehand select class nearest centroid call algorithm another variation weight inﬂuence neighbour distance gaining independence parameter k weighted nearest neighbour algorithm 37 method neighbour obviously based distance metric evaluate similarity two feature vector eﬀorts translate algorithm quantum version therefore focus eﬃcient evaluation classical distance quantum algorithm ımeur brassard gambs 38 introduce idea using overlap ﬁdelity two quantum state similarity sure ﬁdelity obtained ple quantum routine sometimes referred swap test 39 see figure 5 given quantum state b two wavefunctions well ancilla register initially set 0 hadamard h h figure 5 quantum circuit representation swap test routine transformation set ancilla superposition 2 followed controlled b swap two state condition ancilla state ond hadamard gate ancilla result state 1 2 1 2 probability measuring ground state given p 1 2 1 2 2 probability 2 consequently show two quantum state not overlap word orthogonal bility 1 indicates maximum overlap based swap test lloyd mohseni rebentrost 11 recently proposed way retrieve distance two vector b quantum measurement precisely author calculate inner uct ancilla state 1 2 state 1 z z evaluating part swap test look complicated ﬁrst inexpensive procedure since state eﬃciently prepared 11 trick lie clever deﬁnition quantum state given eq 1 encodes classical length vector x scalar product quantum state deﬁnition identity z hold true classical distance two vector b consequently retrieved simple quantum swap test carefully constructed state lloyd mohseni rebentrost use procedure 7 quantum version algorithm x b 1 nc p p vp propose calculate classical distance new input given centroid x 1 nc p p described procedure author claim even considering operation construct quantum state involved quantum method eﬃcient polynomial runtime needed calculate value classical computer wiebe kapoor svore 13 also use swap test order calculate inner product two vector another distance measure feature vector however use alternative sentation classical information quantum state given classical vector b entry aj bj j 1 n well upper bound rmax try training vector upper bound number zero vector sparsity idea write parameter amplitude quantum state 1 p j q 1 max aj rmax 1 p j q 1 max bj rmax perform swap test cording eq 2 probability measuring ancilla ground state p 1 2 1 1 max p inner product b consequently evaluated p max altogether independent dimension n vector author fact claim quadratic compared classical algorithm contribution wiebe kapoor svore also give scheme weighted rithm based euclidian distance evaluated algorithm toolbox quantum information amplitude estimation algorithm 40 urr høyer ﬁnd minimum subroutine 41 full quantum pattern recognition algorithm binary feature wa presented trugenberger 9 expands quantum associative memory circuit 42 purpose centre tine measure hamming distance two binary quantum state construct quantum superposition containing state quantum training set writes hamming distance binary input vector xi 0 1 amplitude training vector state done following useful routine based tary quantum operation given two binary string entry ai bi 0 1 construct initial state 1 2 consisting two register qubits b respectively well extra ancilla register superposition inverse hamming distance qubit ﬁrst second register dk 0 1 else replaces respective qubit second register done applying xora writes second entry bk 0 ak bk else 1 well not gate result state dn 2 write total hamming distance dh b ﬁrst phase amplitude berger us unitary operator u exp π h 1 k 1 2 σz 1 dk working three register note add negative sign case ancilla qubit hadamard formation ancilla state hanc 1 consequently result co h π dh b dn 0 sin h π dh b dn 1 measuring ancilla state amplitude scale hamming distance course power routine only becomes visible applied large superposition training state ﬁrst register p clever measurement 8 retrieves state close input state high probability quantum computing support vector machine support vector machine used linear crimination subcategory pattern classiﬁcation task linear discrimination problem ﬁnd hyperplane best discrimination two class region serf decision boundary future classiﬁcation task trivial example data only two class would ask point x lie exactly member class 1 2 value left x belong one class value right x higher dimension boundary given hyperplane see figure 6 two dimension seems like severe restriction method linear discrimination require problem linearly separable mean hyperplane divide datapoints vector either class one side hyperplane word region class disjunct however problem mapped onto linearly separable problem increasing dimension 22 support vector machine try ﬁnd mal separating hyperplane best discriminating hyperplane ha maximum distance closest datapoints called support vector mathematical optimisation problem ﬁnding maximum margin v w b plane support vector 29 see figure 6 case boundary condition vi b ci 1 vi b ci 3 support vector vi training data set classiﬁcation ci 1 mean ﬁnding maximum margin hyperplane must still separate training vector two class correctly optimisation problem w v w v figure 6 support vector machine ﬁnds plane line maximum margin est vector image illustrates geometry optimisation problem based 29 formulated using langrangian method 22 dual space 43 without going complex mathematical detail support vector machine important note mathematical formulation optimisation problem contains kernel k matrix containing inner product feature vector k pk vp vk p k 1 n basis vector composed entry support vector machine fact part larger class called kernel method 29 detail see 22 suﬀer fact calculating kernel get expensive term computational resource precisely quadratic programming problem form complexity nn 3 29 nn number variable involved computational resource therefore grow signiﬁcantly size training data thus crucial support vector machine ﬁnd method evaluating inner product eﬃciently quantum computing come play rebentrost mohseni lloyd 12 claim general evaluation inner product done faster quantum computer given quantum p nχ xi initial state constructed using quantum random access memory oracle described 44 accessing 9 nχ xi si training vector space every ing vector represented superposition p αi xi similar author tance measurement given eq 1 quantum evaluation classical inner product relies fact quantum state normalised xi xj xi xj kernel matrix inner product basis vector k k j xi xj lated taking partial trace corresponding density matrix state xi trx 1 nχ x xi xj z xj ˆ k tr k rebentrost mohseni lloyd propose inner product evaluation not only used kernel matrix also pattern ha classiﬁed invokes evaluation inner product parameter vector w new input see eq 3 quantum algorithm ing clustering describes task dividing set unclassiﬁed feature vector k subset cluster prominent problem unsupervised learning doe not use training set prior example generalisation rather extract information structural characteristic data set clustering usually based distance superposition memory state log nm paper rebentrost mohseni lloyd 12 also present another quantum support vector machine us reformulation optimisation problem appears system linear equation following 45 solved quantum matrix sion algorithm some condition depending matrix output information required eﬃcient classical method classiﬁcation posed done swap test measure squared euclidean distance b 2 b standard textbook example clustering algorithm alternately feature vector datapoint assigned closest current centroid vector form cluster centroid centroid vector get calculated cluster previous step see figure 7 course ﬁrst iteration requires initial choice centroid vector free parameter number k cluster formed procedure eventually converges stable centroid position however may represent local minimum only position initial centroid deﬁnes whether global minimum reached 46 problem clustering choose parameter k without prior knowledge data deal cluster visibly not grouped according distance measure concentric circle still work well many simple application reducing many datapoints only group example data compression task variation algorithm clustering role centroid taken datapoint cluster ha smallest total distance point besides version quantum clustering merely inspired quantum mechanic 47 use quantum mechanical ﬁdelity fid distance measure otherwise classical gorithm 38 several full quantum routine clustering proposed example ımeur brassard gilles gambs 48 use two subroutine quantum algorithm first help oracle calculates distance two quantum state total distance state state one cluster calculated based ﬁnd minimum subroutine 41 author describe routine ﬁnd smallest value distance function select according quantum state new median cluster unfortunately 10 step 1 step 2 figure 7 alternating step rithm step 1 cluster diﬀerent shape colour deﬁned attributing vector closest centroid vector larger darker shape step 2 centroid cluster deﬁned previous cycle recalculated deﬁne new tering oracle not described detail quantum machine learning proposal largely depends resource implemented contribution discussed earlier lloyd mohseni rebentrost 11 present pervised quantum learning algorithm clustering based adiabatic quantum computing adiabatic quantum computing alternative introduced method plementing unitary gate try continuously adjust quantum system parameter adiabatic process order transfer ground state easy prepare ground state encodes result computation although not focus quantum adiabatic computing seems interesting candidate quantum machine learning method 15 want sketch idea use adiabatic quantum computing clustering 11 goal clustering step output quantum superposition p c usual n set n feature vector datapoints expressed quantum state cluster set vj nc assigned ing step author essentially propose abatically transform initial hamiltonian 1 k p c hamiltonian x j vp encoding distance vector vp troid closest cluster vc give reﬁned version also mention adiabatic method applied solve optimisation problem ﬁnding good initial seed centroid tor searching quantum neural network model artiﬁcial neural network graph node xm called neuron connection weighted parameter wml representing synaptic strength neuron l 1 n activation function deﬁnes value neuron depending current value neuron weighted parameter wml dynamic neural network given successively updating value neuron activation function artiﬁcial neural network thus understood computational device input initial value neuron output either stable state entire network state speciﬁc subset neuron programming neural network done selecting weight parameter wml activation function encoding certain relation power artiﬁcial neural network lie fact learn weight training data fact neuroscientist believe basic principle brain process information 49 pattern classiﬁcation usually consider called neural network neuron arranged layer layer feed value next layer input presented neural network initialising input layer layer successively update node output example encoding 11 figure 8 illustration neural work sigmoid activation function ron classiﬁcation input read last layer see figure 8 neural network often use sigmoid tivation function xl sgm n x wmlxm κ deﬁned sgm κ 1 ate set weight parameter given neural network able classify input pattern extremely well evoke desired generalisation network initialised training vector output compared correct output weight adjusted gradient descent order minimise classiﬁcation error procedure called backpropagation 50 challenge pattern classiﬁcation neural network tional cost backpropagation algorithm even consider improved training method deep learning 30 number proposal quantum sion neural network however consider another class called hopﬁeld network powerful related task tive memory derived neuroscience rather machine learning large share ture quantum neural network try ﬁnd ciﬁc quantum circuit integrate mechanism neural network some way 6 51 52 53 trying use power neural computing quantum computation practical implementation given elizabeth behrman 54 55 56 us ing quantum dot simulate neural network quantum system interesting approach also use fuzzy neural network inspired quantum mechanic 57 allow ron also worth mentioning pattern tion scheme implemented adiabatic ing nuclear magnetic resonance 16 despite rich body idea no quantum neural network proposal delivers fully ing eﬃcient quantum pattern classiﬁcation method author know however ing open challenge translate nonlinear tion function meaningful quantum mechanical framework 7 ﬁnd learning scheme based quantum superposition parallelism towards quantum decision tree decision tree classiﬁers probably intuitive human depending answer question feature one follows certain branch leading next question ﬁnal class found see figure 9 precisely mathematical tree undirected graph any two node connected exactly one edge decision tree particular one starting node root node outgoing no incoming edge several end point leaf node incoming no outgoing edge node except leaf contains decision function decides branch input vector follows next layer word partition set data make leaf represent ﬁnal classiﬁcation example figure 9 procedure could used classify email spam no spam unsure decision tree classiﬁers machine ing constructed using training data set feature vector art decision tree design lie selection decision function node popular method ﬁnd function split given dataset organised 12 email sender address book no spam yes no email contains indicated word combination no yes spam unsure sender manually marked spam figure 9 simple example decision tree classiﬁcation email geometric shape symbolise feature vector diﬀerent class devided according decision function along tree structure measured term shannon entropy 22 assume decision function node split set p feature vector vp p 1 n subset containing nm vector respectively pm ni n without information calculate probability any vector vp attributed subset 1 word proceed ith node next layer ρi ni n entropy caused decision function partition consequently ρilog ρi example binary tree node two outgoing edge best partition would split original set two subset size obviously only possible one feature allows split depending application optimal decision tree would small number node branch level lu brainstein 58 propose quantum version decision tree classifying process follows classical algorithm only diﬀerence use quantum feature state 1 vp coding n feature state quantum tem node tree set training quantum state divided subset ment author call estimating attribute vi 1 n lu brainstein not give clear account division set node take place remain enigmatic tial part classifying algorithm contribute interesting idea using von neumann tropy design graph partition although ﬁrst step ha made potential quantum decision tree still established quantum state classiﬁcation bayesian method stochastic method bayesian decision theory play important role discipline machine learning also used pattern cation idea analyse existing information represented training data set der calculate probability new input certain class illustrative example risk class evaluation new customer bank nothing else conditional probability calculated using famous bayes formula p x p c p p x p c p x probability data class c getting input x respectively p x conditional probability assigning c upon getting x p class likelihood getting x look class obviously assign class highest conditional probability bayes classiﬁer p x input 22 value interest risk function calculated accordingly bayesian theory interesting candidate translation quantum physic since approach probabilistic opposed eﬀorts improve machine learning algorithm quantum computing bayesian method used important task quantum information called quantum state siﬁcation problem stem quantum formation theory goal use chine learning based bayesian theory order discriminate two quantum state produced unknown partly unknown source 13 classiﬁcation problem since learn discrimination function two class example two unknown quantum state represented density matrix ρ basic idea use positive measurement povm binary outcome corresponding two class bayesian classiﬁer word learn calculate measurement tum state able discriminate 59 process training set consisting amples two state respective cation ρ σ ρ imenter allowed perform any operation training set gut kot lowski 59 ﬁnd optimal qubit classiﬁcation strategy sasaki carlini 60 concerned related template ing solving optimisation problem measurement operator sentis et al 17 give variation training data stored classical information proposal far oretical nature await experimental veriﬁcation usefulness scheme hidden quantum markov model last couple year hidden markov model another important method machine learning ha investigated perspective quantum information 61 18 hidden markov model markov process state system only accessible observation see figure 10 readable introduction see 62 ﬁrst order discrete static markov model system ha countable set state sm transition state governed stochastic process way given set transition probability aml system state time only depends previous state time hidden model state system only accessible observation time ot take one set symbol observation ha certain probability invoked speciﬁc state matching task assign similar training vector training set input vector hidden markov model thus doubly embedded stochastic process use common application pattern recognition example 29 consider recorded speech speech realisation markov process called markov chain successive word recording observation shall imagine way translate signal discrete symbol markov model deﬁned transition probability word certain language model learned example speech hidden markov model also includes conditional probability given certain signal observation certain word ha said goal model ﬁnd sequence word likely recording predict next word only given recording infer optimal hidden markov model would encode hidden markov model play important role many application dna analysis online handwriting recognition 29 monras beige wiesner 61 ﬁrst introduced hidden quantum markov model contrast previous paper 63 observation represented quantum basis state tion process given von neumann projective measurement evolving quantum system thor consider much general formalism open quantum system introduction open quantum system see 64 state system given density matrix ρ transition state governed completely positive nonincreasing superoperators ai acting trice operation always represented set kraus operator 64 ki 1 ki q fulﬁlling probability conservation condition p q q ki q aiρ x k ki k probability obtaining state ρs p ρs given p ρs tr asρ 61 advantage hidden quantum markov model contain classical hidden markov model 14 figure 10 colour online hidden markov model stochastic process state transition sketch three state connected line symbolising transition probability ministic realisation sequence state transition give rise observation task hidden markov model guess likely state sequence given observation sequence therefore generalisation oﬀering richer dynamic original process 61 future might also possibility calculating outcome classical model via quantum simulation would especially interesting quantum setting could learn model given example problem nontrivial 62 clark et al 18 add notion hidden quantum markov model implemented using open quantum system instantaneous feedback information obtained environment used inﬂuence system however rigorous treatment idea still outstanding power hidden quantum markov model solve problem classical model developed yet shown interesting sibling hidden quantum markov model quantum observable markov decision ce 65 use similar idea classical observable markov decision process stood hidden markov model step agent take decision certain action leading next state system state system only accessible tions deliver probabilistic information goal ﬁnd strategy deﬁning action take upon observation maximises reward given reward function problem reinforcement learning intelligent agent not focus contribution however also ﬁnd striking analogy kraus operation open quantum system representing action nipulate density matrix stochastic description system 4 conclusion introduction quantum machine learning gave overview existing idea approach quantum machine learning focus wa thereby supervised unsupervised method pattern classiﬁcation clustering task therefore no mean complete review summary two main approach quantum machine learning many author try ﬁnd quantum algorithm take place classical machine learning algorithm solve problem show improvement term complexity gained dominantly true nearest neighbour kernel clustering method expensive distance calculation sped quantum computation another approach use probabilistic description quantum theory order describe stochastic process case hidden quantum markov model served generalise model bayesian theory wa also used genuinely quantum information task like quantum state discrimination great deal contribution still phase exploring possibility combine formalism quantum theory method machine learning seen area quantum neural network quantum decision tree previously remarked quantum theory learning yet outstanding although working quantum machine learning algorithm only 15 contribution actually answer question strength deﬁning feature machine ing learning process actually simulated quantum system especially learning method parameter optimisation not yet accessed quantum perspective diﬀerent approach quantum computing investigated pose quantum computing based unitary tum gate challenge would parameterise gradually adapt unitary transformation deﬁne algorithm several idea tion investigated already 66 67 35 important tool could quantum feedback control 68 quantum hamiltonian learning 69 tioned adiabatic quantum computing might lend learning optimisation problem 15 alternative quantum computation dissipative 70 tum computing 71 might also oﬀer interesting framowork quantum learning summary even though still lot work quantum machine learning remains promising emerging ﬁeld research many potential application great theoretical variety acknowledgement work based upon research supported south african research chair initiative partment science technology national research foundation reference 1 martin hilbert priscila opez world technological capacity store municate compute information science 332 6025 2011 2 michael nielsen isaac l chuang tum computation quantum information cambridge university press 2010 3 georgescu ashhab franco nori quantum simulation review modern physic 2014 4 gerasimos g rigatos spyros g tzafestas neurodynamics attractor quantum sociative memory integrated engineering 14 3 2007 5 elizabeth c behrman james e steck quantum neural network computes ative phase arxiv preprint 2013 6 sanjay gupta rkp zia quantum neural network journal computer system ences 63 3 2001 7 maria schuld ilya sinayskiy francesco petruccione quest quantum neural network quantum information processing doi 2014 8 dan ventura tony martinez tum associative memory information science 124 1 2000 9 carlo trugenberger quantum pattern recognition quantum information processing 1 6 2002 10 ralf utzhold pattern recognition tum computer physical review 2003 11 seth lloyd masoud mohseni patrick rebentrost quantum algorithm vised unsupervised machine learning arxiv preprint 2013 12 patrick rebentrost masoud mohseni seth lloyd quantum support vector machine big feature big data classiﬁcation arxiv preprint 2013 13 nathan wiebe ashish kapoor krysta svore quantum rithms machine learning arxiv preprint 2014 16 14 hartmut neven vasil denchev geordie rose william g macready training large scale classiﬁer quantum adiabatic algorithm arxiv preprint 2009 15 kristen l pudenz daniel lidar quantum adiabatic machine learning quantum tion processing 12 5 2013 16 rodion neigovzen jorge l neve rudolf lacher steﬀen j glaser quantum pattern recognition nuclear magnetic resonance physical review 79 4 2009 17 g ıs j calsamiglia e bagan quantum learning without tum memory scientiﬁc report 2 708 2012 18 lewis clark wei huang thomas low almut beige hidden quantum markov model open quantum system instantaneous feedback arxiv preprint 2014 19 stuart jonathan russell peter norvig john f canny jitendra malik douglas ward artiﬁcial intelligence modern proach volume prentice hall englewood cliﬀs 2010 20 frank rosenblatt perceptron bilistic model information storage ganization brain psychological review 65 6 1958 21 arthur l samuel some study machine learning using game checker ibm nal research development 44 226 2000 22 ethem alpaydin introduction machine ing mit press 2004 23 richard duda peter e hart david g stork pattern classiﬁcation john wiley son 2012 24 steven e landsburg quantum game theory wiley encyclopedia operation research management science 2011 25 jens eisert martin wilkens maciej stein quantum game quantum strategy physical review letter 83 15 1999 26 han j briegel gemma de la cuevas jective simulation artiﬁcial intelligence entiﬁc report 2 2012 27 jiangfeng du hui li xiaodong xu mingjun shi jihui wu xianyi zhou rongdian han experimental realization quantum game quantum computer physical review letter 88 13 2002 28 edward w piotrowski jan ladkowski invitation quantum game theory ternational journal theoretical physic 42 5 2003 29 christopher bishop et al pattern recognition machine learning volume springer new york 2006 30 geoﬀrey hinton simon osindero whye teh fast learning algorithm deep lief net neural computation 18 7 2006 31 david e rumelhart geoﬀrey e hinton ronald j williams learning representation error cognitive modeling 1988 32 masahide sasaki alberto carlini quantum learning universal quantum matching chine physical review 66 2 2002 33 esma ımeur gilles brassard ebastien gambs quantum unsupervised learning machine learning 90 2 2013 34 markus hunziker david meyer jihun park james pommersheim mitch rothstein geometry quantum learning arxiv preprint 2003 17 35 alessandro bisio giulio chiribella como mauro dariano stefano facchini paolo perinotti optimal quantum learning unitary transformation physical review 81 3 2010 36 richard w hamming error detecting error correcting code bell system technical journal 29 2 1950 37 klaus hechenbichler klaus schliep weighted technique ordinal classiﬁcation 2004 38 esma ımeur gilles brassard ebastien gambs machine learning quantum world advance artiﬁcial intelligence page springer 2006 39 harry buhrman richard cleve john watrous ronald de wolf quantum ﬁngerprinting physical review letter 87 16 2001 40 gilles brassard peter høyer michele mosca alain tapp quantum amplitude ﬁcation estimation arxiv preprint 2000 41 christoph urr peter høyer quantum gorithm ﬁnding minimum arxiv preprint 1996 42 carlo trugenberger probabilistic quantum memory physical review letter jul 2001 43 bernhard e boser isabelle guyon vladimir n vapnik training algorithm timal margin classiﬁers proceeding ﬁfth annual workshop computational learning ory page 1992 44 vittorio giovannetti seth lloyd lorenzo maccone quantum random access memory physical review letter 100 16 2008 45 aram w harrow avinatan hassid seth lloyd quantum algorithm linear tems equation physical review letter 103 15 2009 46 simon rogers mark girolami ﬁrst course machine learning crc press 2012 47 david horn assaf gottlieb algorithm data clustering pattern recognition problem based quantum mechanic physical review letter 88 1 2002 48 esma ımeur gilles brassard ebastien gambs quantum clustering algorithm ceedings international conference machine learning page 2007 49 peter dayan laurence f abbott ical neuroscience volume mit press bridge 2001 50 john hertz anders krogh richard g palmer introduction theory neural computation volume westview press 1991 51 w oliveira adenilton j silva teresa b ermir amanda leonel wilson r galindo jeﬀerson cc pereira quantum logical neural network brazilian symposium ral network 2008 sbrn page 2008 52 adenilton j da silva wilson r de oliveira teresa b ludermir classical posed learning quantum weightless neural network neurocomputing 75 1 60 2012 53 massimo panella giuseppe martinelli ral network quantum architecture quantum learning international journal cuit theory application 39 1 2011 54 elizabeth c behrman james e steck steven r skinner spatial quantum neural computer international joint conference neural network 1999 ijcnn 1999 55 eza oth craig lent p douglas tougaw yuriy brazhnik weiwen weng wolfgang porod liu huang quantum cellular neural network arxiv preprint 2000 18 56 jean faber gilson giraldi quantum model artiﬁcial neural network tronically available lncc pdf 2002 57 purushothaman karayiannis quantum neural network qnns inherently fuzzy feedforward neural network neural work ieee transaction 8 3 1997 58 songfeng lu samuel l braunstein tum decision tree classiﬁer quantum tion processing 13 3 2014 59 alin gut wojciech kot lowski tum learning asymptotically optimal tion qubit state new journal physic 12 12 2010 60 masahide sasaki alberto carlini richard jozsa quantum template matching physical review 64 2 2001 61 alex monras almut beige karoline ner hidden quantum markov model adaptive state applied mathematical computational science 2010 62 lawrence r rabbiner tutorial den markov model selected application speech recognition proceeding ieee 77 2 1989 63 karoline wiesner james p crutchﬁeld computation ﬁnitary stochastic quantum process physica nonlinear phenomenon 237 9 2008 64 heinz peter breuer francesco petruccione theory open quantum system oxford university press 2002 65 jennifer barry daniel barry scott aaronson quantum pomdps arxiv preprint 2014 66 søren gammelmark klaus mølmer tum learning measurement feedback new journal physic 11 3 2009 67 søren gammelmark klaus mølmer bayesian parameter inference continuously monitored quantum system physical review 87 3 2013 68 alexander hentschel barry c sander chine learning precise quantum ment physical review letter 104 6 2010 69 nathan wiebe christopher granade pher ferrie david cory quantum tonian learning using imperfect quantum source physical review 89 4 2014 70 frank verstraete michael wolf j cio cirac quantum computation state engineering driven dissipation nature physic 5 9 2009 71 hj briegel de browne w ur r raussendorf van den nest tum computation nature physic 5 1 2009 19