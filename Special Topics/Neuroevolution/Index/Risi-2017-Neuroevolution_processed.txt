ieee transaction computational intelligence ai game vol 9 no 1 march 2017 25 neuroevolution game state art open challenge sebastian risi julian togelius paper survey research applying tion ne game neuroevolution artiﬁcial neural network trained evolutionary algorithm taking inspiration way biological brain evolved analyze application ne game along ﬁve different ax role ne chosen play game different type neural network used way network evolved ﬁtness mined type input network receives paper also highlight important open research challenge ﬁeld index algorithm neural network roevolution introduction ﬁeld artiﬁcial computational intelligence game established research ﬁeld still growing rapidly ﬁeld researcher study automate playing design understanding tation game using wide variety method drawn computational intelligence ci artiﬁcial intelligence ai 17 76 78 one common technique applicable wide range problem within research ﬁeld neuroevolution ne 30 147 neuroevolution refers generation artiﬁcial neural network connection weight topology using evolutionary algorithm technique ha used successfully task diverse robot control 83 music generation 51 modelling biological phenomenon 21 chip resource allocation 43 among many others paper survey use neuroevolution game fig 1 main motivation writing neuroevolution important method ha seen continued popularity manuscript received november 04 2014 revised april 09 2015 august 24 2015 october 12 2015 accepted october 15 date publication october 26 2015 date current version march 15 risi university copenhagen copenhagen denmark sebr togelius department computer science engineering new york university new york 11201 usa julian color version one ﬁgures paper available online digital object identiﬁer two dedicated conference ieee conference tional intelligence game cig aaai conference artiﬁcial ligence interactive digital entertainment aiide well dedicated journal ieee transaction computational intelligence ai game furthermore work ﬁeld published number conference journal neighbouring ﬁelds fig neuroevolution game overview important distinction ne approach role ne play game tightly coupled input evolved neural network receives angle sensor type output produce request turn ne role also directly inﬂuences type ﬁtness evaluation different evolutionary algorithm support different network type some method le appropriate different type input representation since inception around two decade ago numerous existing application game even potential application researcher practitioner seeking apply neuroevolution game application could therefore use guide state art another main motivation game excellent testbeds neuroevolution research ai research many advantage existing testbeds mobile robotics paper therefore meant also useful neuroevolution researcher seeking use game testbed scope paper writing paper sought broad tive coverage kind neuroevolution kind game not possible exhaustive attempt cover main direction ﬁeld important paper only cover work neuroevolution ha some way applied game problem roevolution mean technique evolutionary tion similar stochastic rithms applied artiﬁcial neural network anns take inclusive view neural network including weighted sum map perceptrons not 2015 ieee personal use permitted requires ieee permission see information authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply 26 ieee transaction computational intelligence ai game vol 9 no 1 march 2017 expression tree evolved genetic programming game refer game people commonly play game includes game board game card game digital game arcade game racing game strategy game not purely abstract game dilemma robotics task benchmark ment learning pole balancing acknowledge bound some gray area no delineation absolutely sharp several survey available cover larger topic topic intersect topic paper cludes several survey game general 77 144 survey use evolutionary computation 72 machine learning 36 81 survey approach particular search area within ﬁeld pathﬁnding 4 player elling 146 procedural content generation 111 structure paper next section give overview neuroevolution main idea behind main motivation employing ne approach game section iii detail ﬁrst ax along analyse role neuroevolution game namely type role ne method chosen play ferent neural network type found ne game erature reviewed section iv v explains evolved different way ﬁtness ated game detailed section vi followed review different ann input representation section vii finally section viii highlight important open challenge ﬁeld ii neuroevolution reason wide applicability lasting popularity neuroevolution include many ai control lem cast optimization problem mized general function approximator neural work another important reason attractiveness paradigm method grounded biological metaphor evolutionary theory section introduces basic cepts idea behind neuroevolution ne motivated evolution biological nervous system applies abstraction natural evolution evolutionary algorithm generate artiﬁcial neural network anns generally represented network composed interconnected node neuron able compute value based external input provided network behavior ann typically determined based architecture network strength weight connection neuron training ann solve computational problem involves ﬁnding suitable network parameter topology weight synaptic connection basic idea behind roevolution train network evolutionary rithm class stochastic search method inspired darwinian evolution important design choice ne genetic representation genotype neural network combination mutation operator nipulate example one earliest ward way encode ann ﬁxed topology topology network determined user based concatenation numerical network weight value vector real number basic algorithm basic ne algorithm work follows population genotype encode anns evolved ﬁnd network weight topology solve computational problem typically genotype encoded neural network tested speciﬁc task certain amount time performance ﬁtness network recorded ﬁtness value genotype current population determined new population generated slightly changing genotype mutation combining multiple genotype general genotype higher ﬁtness higher chance selected reproduction offspring replaces genotype lower ﬁtness value thereby forming new generation generational loop typically repeated dreds thousand time hope ﬁnding better better performing network complete review ne see floreano et al 30 neuroevolution task described paper method could potentially used game gy could learned algorithm temporal ence learning family player model could learned port vector machine game content could represented straint model created answer set programming however number reason lution good general method apply many task interesting method study case fig 2 show lected example ne existing game highlight some unique beneﬁts 1 performance some problem neuroevolution simply provides best performance petition learning method performance course deﬁned differently different problem go example various version pole balancing classic reinforcement learning problem cosyne lution method convincingly beat method problem parameter 42 particular found solution problem using fewer try any algorithm best performance keepaway soccer problem another popular reinforcement learning benchmark also exhibited neuroevolution method 137 neuroevolution also form well supervised learning task demonstrated performance evolino several sequence prediction problem 104 combination neuroevolution simple linear ﬁtting could predict complex tions lower error any method game domain winner several ai competition partly based example winner recent 2 k botprize 107 108 simulated car racing championship 9 2 broad applicability another beneﬁt ne used supervised unsupervised reinforcement authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply risi togelius ne game state art open challenge 27 fig neuroevolution existing game ne able discover controller racing game torcs 11 b ne ha also successfully applied commercial game creature 44 additionally ne enables new type game gar c player interactively evolve particular weapon 46 nero player able evolve team robot battle player 119 learning task neuroevolution only requires some sort meric evaluation quality candidate network respect neuroevolution similar kind ment learning rl algorithm temporal difference td family 121 however dataset labelled target value provided ne used supervised learning algorithm similarly backpropagation used 3 scalability compared many type ment learning especially algorithm td family roevolution seems handle large space well especially used direct action selection 29 48 85 86 4 diversity neuroevolution draw rich family method niching objective method developed within tionary computation community enables neuroevolution method achieve several form diversity among result deliver set meaningfully different strategy troller model content 2 136 5 learning ne used rl way one might argue could go beyond relatively narrow formulation reinforcement learning particular case topology work evolved well neuroevolution could principle port evolution behavior arbitrary plexity sophistication could emerge concretely lution algorithm often search larger space algorithm 6 enables new kind game new video game galactic arm race gar 46 player actively evolve particular weapon nero 119 allows player evolve team robot battle player petalz video game 95 97 player breed unlimited variety virtual ﬂowers would difﬁcult realize traditional learning method tionary computation provides unique affordances game design some design rely speciﬁcally neuroevolution case game like petalz gar game rely continuous complexiﬁcation produced content naturally supported integral part certain ne method additionally game like petalz whose core game mechanic breeding new ﬂower type employing evolutionary method natural choice important example mercial game series offer novel gameplay based ne creature 44 ﬁrst creature game wa created player breed raise virtual pet called norn teach survive environment trast game adaptive anns controlling pet actually allow learn new behavior guided player fact neuroevolution method facilitate learning incorporating greater element exploration highlighted previous section also make ne directly plicable support new kind game not neuroevolution neuroevolution ha multiple attractive property not panacea several reason method might suitable particular problem portant one evolved neural network tend black box characteristic meaning human not easily work looking problem game development particular quality assurance come hard debug learned behavior problem using neuroevolution online hard predict actly kind behavior learned something clash traditional design principle commercial game iii role neuroevolution role neuroevolution chosen play ﬁrst several ax along ne usage analysed paper according survey literature vast majority case neuroevolution used learn play game trol npc game neural network one two role evaluate value state action some algorithm choose action take rectly select action take given state also us neuroevolution procedural content generation pcg active area research game ai able neural network used represent content finally neuroevolution also predict experience preference player table summarizes usage ne variety different game section survey use neuroevolution game role section ordered according game genre evaluation historically earliest possibly widespread use neuroevolution game estimate value board authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply 28 ieee transaction computational intelligence ai game vol 9 no 1 march 2017 table role neuroevolution selected game input not tied specific frame reference number edible ghost tions agent playing classical board game ples tree search algorithm some kind minimax pruning modiﬁcations used search space future move role evolved neural network evaluate quality hypothetical future board state node search tree assign numerical value quality value supposed related close winning game rational course action agent choose action would lead board state higher value case neural network evolved using ﬁtness tion based win rate game some opponent also example ﬁtness function based something else human playing style game history ai probably chess however relatively researcher attempted apply neuroevolution problem fogel et al devised architecture wa able learn play master level solely playing 32 ha also plenty work done evolving board evaluator related though somewhat simpler board game checker wa focus popular science book fogel 2001 31 chronicled several year work evolving checker player 16 18 evolved player called managed learn play human master level however interest checker benchmark game waned game wa solved 2007 101 ha shown even simple network evolved play checker well 54 another classic board game ha used testbed neuroevolution othello also called reversi moriarty miikkulainen used cooperative coevolution evolve board evaluator othello 79 80 chong et al evolved board evaluator based convolutional neural network captured aspect board geometry 19 contrast lucas runarsson later used evolution strategy learn position evaluator remarkably effective though simply weighted piece counter 73 also compared evolution temporal difference learning problem topic return section later work author showed network evolvable neural network based sampling combination board position could learn good state evaluator 70 network also shown perform better neural architecture playing checker 3 go ha recent year become focus much research ai ancient asian board game despite simple rule hard puters play proﬁciently year ago best player barely reached intermediate human play level combination tree search board state evaluation ha worked well game chess checker othello largely break applied go partly go ha much higher branching factor game partly cause hard calculate good estimate value go board early attempt evolve go board state evaluator used fairly standard neural network architecture 69 90 seems method well go 5 5 fail scale larger board size 100 gauci et al attempted address using hyperneat see section v neural network architecture specially designed exploit geometric regularity learn play go 38 schaul schmidhuber tried address issue using current convolutional network 103 noted neuroevolution not currently competitive state art domain state art go monte carlo tree authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply risi togelius ne game state art open challenge 29 search mcts statistical tree search technique ha nally allowed ai reach advanced human level 6 use neural network state value evaluator go beyond board game fact any game played using state value evaluation function given possible dict future state action lead reasonably small number action principle board game search tree possible future action evaluate resulting state choosing action lead state general method work even case game typical arcade game case building rather sometimes good result achieved shallow search search only resulting state taking single action uated good example lucas work evolving state evaluator 71 ha inspired number study 15 106 never ha four possible action make possible search one ply seen example work borg cardona et al 15 possible evolve evaluator not only state also future action neural network would case take current state potential future action input return value action control happens enumerating action choosing one highest value lucas togelius compared number way neuroevolution could used control car simple car racing game discrete action space including evolving state evaluator evolving action evaluator 74 wa found evolving state evaluator led signiﬁcantly higher performance evolving action evaluator direct action selection not always possible play game control game npc evaluating potential future state action example might many action any given state effectively game like civilization ha astronomical number possible action even search would computationally prohibitively sive though see branavan et al work learning action evaluator civilization ii hybrid method 5 case not even reliable method predicting state future action would lead learning player game not source code forward model calculating state would computationally expensive forward model stochastic case neural network still play game trol npc direct action selection mean neural network receives description current state some observation state input output action take output could take different form ample neural network might one output action continuous output deﬁne some action space many case output dimension network mirror ilar button stick game controller would used human play game note state tor action evaluator discussed previous section also perform action selection indirect way number experiment simple car racing game togelius lucas evolved network drove car using number sensor input output steering 123 124 126 wa shown network could drive least well human player incrementally evolved proﬁciently drive wide variety track using competitive coevolution variety ingly different playing style could generated however wa also shown version problem evolving network evaluate state gave superior driving performance compared evolving network directly select action 74 work evolving car racing controller spawned series competition simulated car racing ﬁrst year tition built simple racing game 128 wa exchanged sophisticated racing game torcs remaining year 67 68 several submission based neuroevolution usually role action selector 11 sometimes auxiliary role 9 another genre evolved neural network used role action selector shooter fps game work parker bryant evolving bot popular 90 fps quake ii good example 85 86 case neural network different output turning moving shooting fps game ha used frequently experimentation probably unreal tournament ha accessible interface called pogamut 39 ha used popular competition 2 k botprize 50 van hoorn et al evolved layered controller consisting several neural network implemented different component good behavior path following exploration shooting 135 different network output direct control signal corresponding movement direction shooting able override according ﬁxed hierarchy schrum et al evolved neural network behave manner using testbed 107 another game strong similarity shooter term capability agent though completely different focus gameplay experimental game nero see agent controlled neural network evolved version popular ne method neat 119 neat explained detail section platform game number action possible take any given moment typically limited partly go back iconic platform game nintendo super mario bros invented time common game platform limited input possibility super mario bros action space any combination button original nintendo controller left right togelius et al evolved neural network play inﬁnite mario bros clone super mario bros using network simply one output button 130 objective met only limited success wa simply get far possible number level study authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply 30 ieee transaction computational intelligence ai game vol 9 no 1 march 2017 ortega et al subsequently used neuroevolution role different objective evolving network mimic behavior human player 84 whereas might seem using neural network playing board game network used state action evaluator experiment using roevolution direct action selection role board game might mean one network output board position action taken possible action associated output case network gauci et al 37 exotic variant stanley miikkulainen roving eye play go traversing board ping think next stone placed 118 attempt generally not competitive architecture neural network evaluates state done order test new network type controller concept finally ha work developing architecture neural network evolved play any large number game one example togelius neural network learning play any series discrete game space deﬁned simple game description language 125 work later inspired general video game playing competition see section recently hausknecht et al evolved neural network different type play original atari 2600 game using atari learning environment 47 48 network output simply mapped atari controller performance varied greatly different game evolved network learning play some game master level many others barely selection strategy some game make no sense control primitive action player character rather choose one several strategy played short time span longer single time step example keepaway soccer task reinforcement learning benchmark strongly quality extracted robocup robot ball tournament every time agent ha ball selects one three static played next ball possession 142 143 whiteson et al evolved neural network task using neat good result found hybridising form reinforcement learning worked even better 142 modelling opponent strategy many case player need able predict ponent act order play well neuroevolution used speciﬁc role predicting opponent strategy part player whose part might might not based roevolution lockett miikkulainen evolved network could predict player strategy texas poker increasing win rate agent used model 66 content generation recently interest ha increased ﬁeld called procedural content generation pcg 111 part game created algorithmically rather pecially stochastic search method evolutionary rithms shown promise generating various type tent game level weapon even rule game evolutionary approach pcg go name pcg 132 several application content ha represented neural network application output characteristic decision surface network some way interpreted shape hull characteristic content artifact capacity neural network encode smooth surface essentially inﬁnite resolution make suitable compactly encoding structure continuous shape ticular type neural network called compositional pattern producing network cppn 115 interest cppns variation anns differ type activation function contain also way applied cppns scribed detail section example cppns used content generation include galactic arm race video game gar 46 player evolve weapon petalz video game 95 97 80 player interactively evolve ﬂowers another demonstration liapis et al 64 evolved cppns erate visually pleasing spaceship used space shooter game recent work author augmented system allow autonomous creation spaceship based evolving interestingness criterion 65 modelling player experience many type neural network including standard layer perceptron general function approximators approximate any function given accuracy given ﬁciently large number neuron reason neural network popular supervised learning application various type often neural network used vised learning trained some version tion however some case neuroevolution provides superior performance even supervised learning task ticular case preference learning task learn predict ordering instance data set one prominent use preference learning particular erence learning neuroevolution player experience modeling pedersen et al trained neural network predict level player would prefer clone super mario bros 87 dataset wa collected letting hundred player play pair different level recording playing session player well player choice level pair wa challenging frustrating gaging standard multilayer perceptron wa given mation player playing style feature level input output wa two level wa preferred training network neuroevolution wa found player preference could predicted 91 accuracy shaker et al later used model evolve personalised level super mario bros game simply searching parameter space level maximise particular aspect player experience 110 authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply risi togelius ne game state art open challenge 31 iv neural network type variety different neural network type found literature important note type ann signiﬁcantly inﬂuence learning ability simplest neural network feedforward mean information travel directly input node hidden node output node feedforward network no synaptic connection form loop cycle simplest feedforward network perceptron ann without any hidden node only direct connection input output activation function either simple step function identity function latter case perceptron simply weighted sum input 98 classic perceptron without hidden node only learn rectly solve linearly separable problem limiting use pattern classiﬁcation control complex multilayer perceptron mlp architecture hidden node typically sigmoid activation function also learn problem not linearly separable fact approximate any function given accuracy given suitable large number hidden neuron 53 capability mostly theoretical greater resentational capacity mlps standard perceptrons readily seen applying neuroevolution npc control game example lucas 71 compared performance single perceptrons simpliﬁed version game showed mlp reached niﬁcantly higher performance recurrent network network form loop cles allows information also propagated later layer back earlier layer directed cycle network create maintain internal state allows exhibit dynamic temporal property keep memory past event applied control problem simply put current network memory whereas static feedforward network live eternal present able base tions past well present ha obvious beneﬁts particular issue sensory aliasing arises agent ha imperfect information true any game not game world screen time different state different look agent 150 domain property also called task meaning state environment not fully observable agent 114 recurrent current network shown perform similarly domain platform game playing 130 recurrent network shown consistently outperform ward car racing task 136 ne approach game focus evolving monolithic neural network modular network recently shown superior performance some domain 106 modular network composed number individual neural network module module normally responsible speciﬁc overall system example schrum ha recently shown domain modular network extension neat performs better standard version evolves monolithic network likely explanation easier evolve multimodal behavior modular architecture 106 experiment featured module initially entiated whose role wa chosen evolution explicitly functionally differentiated module also work well task lends easy functional decomposition van hoorn et al evolved separate neural module lowing shooting exploration module arranged hierarchical architecture arrangement wa shown perform much better monolithic network 135 side game ha research way encouraging neural network evolve modular structure 21 also evolving ensemble neural network 148 different network complementary ﬁtness function 1 type neural network not change nection weight initial training plastic neural network change connection weight any time response activation pattern network enables form learning practically possible using current network plastic network evolved solve robot task unpredictable environment controller doe not initially know characteristic 28 however not yet applied game best knowledge seems plastic network would promising avenue learning controller play multiple game multiple version game another adaptive architecture ha shown promising result learning experience term memory lstm network 40 instead changing connection weight lstm network learn membering value arbitrary amount time turn topic learning discus important open challenge section viii evolving neural network large number different evolutionary algorithm applied ne including genetic algorithm evolution strategy evolutionary programming 147 addition stochastic method like particle swarm optimisation also used 26 method evolving neural network tightly coupled genotypic representation earliest ne method only evolved weight network ﬁxed topology simplest direct representation connection encoded single real value encoding sometimes called ventional neuroevolution cne allows whole network described concatenation value vector real number example cardona et al 15 lucas 71 directly evolved weight mlp pac man able represent whole network vector real number allows use any evolutionary algorithm work vector real number including highly efﬁcient algorithm like covariance matrix adaptation evolution strategy 45 55 signiﬁcant drawback ﬁxed topology approach user ha choose appropriate topology number hidden node priori topology network signiﬁcantly affect performance 55 126 129 130 sophisticated approach evolve network topology gether weight example method roevolution augmenting topology neat 116 authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply 32 ieee transaction computational intelligence ai game vol 9 no 1 march 2017 ha shown also evolving topology together connection weight often outperforms approach evolve weight alone neat similar method also allow evolution recurrent network solve difﬁcult markovian control problem example outside game clude pole balancing 42 tying knot 75 neat applied successfully variety ferent game domain controlling simulated car open car racing simulator torcs 10 team robot nero game 119 playing 106 unreal tournament 107 particular interest context paper extension neat ha oped increase performance making problem 61 kohl miikkulainen 61 demonstrate adding new topological mutation add neuron local ﬁelds network node mutation bias network architecture cascade type structure approach able easily solve tured task keepaway soccer fracture deﬁned author highly discontinuous mapping state optimal action within ann likely complex game tured decision space approach use direct encoding meaning connection encoded separately real number direct encoding proaches employ mapping parameter value network weight neuron genetic representation one disadvantage approach part solution similar must discovered separately evolution therefore interest ha increased recent year indirect encoding allow reuse information encode ﬁnal network thus compact genetic representation high number synaptic tions encoded considerably fewer parameter corresponding genotype promising indirect encoding ha employed cessfully variety game cppns 115 see section cppns variation anns differ type activation function contain also way applied anns traditionally employed troller cppns often function shown promise context procedurally generated tent additionally anns typically only contain sigmoid activation function cppns include also variety activation function like sine create repeating tern gaussian create symmetric pattern importantly cppns variation anns also evolved neat algorithm 120 cppns initially designed produce sional pattern image also extended evolve indirectly encoded anns main idea proach called hyperneat 120 exploit geometric domain property compactly describe connectivity pattern also run unity game engine complete list neat implementation found ann example board game like chess checker adjacency relationship symmetry play tant role understanding regularity enable gorithm learn general tactic instead speciﬁc action ciated single board piece hausknecht et al 48 recently showed ability encode large scale anns enables directly learn atari 2600 game raw game screen data outperforming human high score three game advance exciting game perspective since take step towards general game playing independent game speciﬁc input tation return topic section vii another form indirect encoding developmental proaches promising demonstration approach 60 evolved single developing complex neuron wa able play checker beat program contrast aforementioned indirect encoding like cppns neuron khan miller work grows develops new synaptic connection game played growth process based evolved genetic program ce input board vi fitness evaluation ﬁtness board value estimator ann controlled npc traditionally determined based performance particular domain might translate score achieves single player game many level manages plete many opponent beat ranking achieve competitive multiplayer game many game leading noisy ﬁtness evaluation meaning controller score differently evaluated several time problem evaluating performance controller multiple independent play averaging resulting score beneﬁcial 100 123 many case possible evolve good behaviour using straightforward ﬁtness function like score game ha advantage ﬁtness function cally not exploited way composite ﬁtness function sometimes only way achieve high score play game well however problem becomes complex ﬁcult evolve necessary behavior directly case helpful learn incrementally ﬁrst starting simpler task gradually making complex usually called staging incremental evolution 41 example togelius lucas 124 evolved controller simulated car racing incremental evolution proach setup car ﬁrst evaluated one track time population reach sufﬁciently high ﬁtness challenging track added evaluation ﬁtness averaged author showed following cremental evolutionary approach neurocontrollers general driving skill evolve no general driving skill served controller wa evaluated track ously incremental evolution also combined ularisation neural network time new ﬁtness function added new neural network module added authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply risi togelius ne game state art open challenge 33 mix could allow evolution solve problem quisition new competence conﬂicts existing petence 135 form training viewed radical version incremental evolution transfer learning goal transfer learning accelerate learning target task knowledge gained learning different lated source task example taylor et al 122 showed transfer learning signiﬁcantly speed learning neat 3 2 4 3 robot soccer keepaway demonstration applying transfer learning two different related game cardamone et al 14 transferred car racing controller evolved torcs another racing game called vdrift exploiting knowledge gained torcs evolution wa able adapt model new game quicker author tried evolve controller vdrift scratch incremental evolutionary approach allow ne solve complex problem designing good ﬁtness function challenging problem especially task become complex particular case competitive game good reliable opponent ai not available game evolutionary algorithm easily ﬁnds strategy exploit weakness game opponent strategy method potentially circumvent problem competitive coevolution 15 99 117 ﬁtness one ai controlled player depends performance competing another player drawn population another population idea evolutionary process supply worthy opponent beginning evolutionary run player tested equally bad player better player develop play player similar skill thus competitive coevolution said perform kind automated incrementalisation problem ideally would lead lution sophistication performance evolved agent would continue increasing indeﬁnitely due arm race 82 99 evolution ha never achieved due number phenomenon cycling loss gradient competitive coevolution sometimes effective one earliest example coevolution game wa performed lubberts miikkulainen 69 author coevolve network playing simpliﬁed version go show coevolution speed evolutionary search result since corroborated author 100 powerful demonstration coevolution 31 reached only playing khan miller 59 work author showed high performing anns evolve quicker coevolution evaluation agent checker player another example cardona et al 15 applied tionary method coevolve controller pac man ghost team controller interestingly author discovered wa signiﬁcantly easier coevolve controller team ghost indicating success coevolutionary approach much pendent chosen domain ﬁtness transitivity much solution performance one opponent correlate performance opponent competitive coevolution opponent drawn population one several population wa investigated series experiment evolving car racing controller wa found using multiple ulations improved result notably 126 coevolution doe not vanquishing also cooperative coevolution whereas competitive coevolution ﬁtness negatively affected success individual cooperative coevolution positively effected generally individual ﬁtness deﬁned performance collaboration individual implemented neuronal level every individual single neuron synapse ﬁtness average performance several network participates cosyne neuroevolution algorithm based idea wa shown outperform method variant pole balancing problem classic reinforcement learning benchmark 42 another example cardamone et al 12 demonstrated cosyne also able create competitive racing controller torcs endurance world championship conceptually closely related algorithm esp sane used evolve strategy othello 80 strategy game legion ii 7 another example whiteson et al 140 showed coevolution successfully discover complex control task soccer keepaway player vided adequate task decomposition however problem made complex correct task tion not given coevolution fails discover high performing solution some problem one ﬁtness dimension need taken account could case no single performance criterion example game no scoring several different score good performance indicator evolution helped taking factor account well example want encourage exploration environment performance might one criterion evolving agent towards might equally interested likeness believability variety agent behavior several approach taken towards existence multiple ﬁtness criterion simplest approach summing different ﬁtness function one ha drawback practice lead unequal selection pressure ﬁtness dimension another approach cascading elitism generation contains separate selection event ﬁtness function ensuring equal selection sure 127 principled solution existence need multiple ﬁtness function use multiobjective evolutionary algorithm moea 22 24 33 algorithm try satisfy given objective ﬁtness function case partially conﬂict map conﬂicts objective map used ﬁnd solution make appealing tradeoff authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply 34 ieee transaction computational intelligence ai game vol 9 no 1 march 2017 agent solution none objective improved without reducing performance one objective said pareto front multiobjective evolution ha used balance pure performance objective several way example van hoorn et al 136 used moea balance driving well driving manner similar recorded playtraces human driver racing game agapitos et al 2 working different racing game used multiobjective evolution several different characteristic driving style evolve set npc driver visibly different driving style retaining high driving skill schrum miikkulainen 105 used popular evolutionary algorithm sorting genetic algorithm 24 simply increase performance rewarding various component good behavior separately another promising ne approach might actually able new kind game allow human player interact evolution explicitly setting objective tionary process even act ﬁtness function self approach known interactive evolution nero video game 119 player train team npc military combat designing evolutionary curriculum curriculum consists sequence training exercise become increasingly difﬁcult example train team perform general maze navigation player design creasingly complex wall conﬁgurations training agent complete loaded battle tested team trained player recently karpov et al 58 investigated three different way assisting neuroevolution human input nero platform based original nero one approach wa advice method user write short example code automatically converted partial ann network spliced evolving ulation approach wa shaping user inﬂuence training modifying environment similar setup nero 119 last approach wa tion user control agent manually recorded data used train evolving network pervised fashion author showed three way ne outperform unassisted ne different task demonstrating promise combining ne human expertise another example interactive evolution game galactic arm race gar 46 player discover unique particle system weapon evolved neat ﬁtness weapon gar determined based number time wa ﬁred allowing player implicitly drive evolution towards content prefer petalz 95 97 casual social game facebook core game mechanic breeding different ﬂowers player interact evolution deciding ﬂowers pollinate mutation crossover ﬂowers interactive evolution approach ronments include evolution picture picbreeder 109 form 20 musical composition 52 even dance move 25 vii input representation far discussed role neuroevolution game type neural network ne algorithm ﬁtness uation another interesting dimension differentiate different us neuroevolution game sort input network get represented choosing right representation signiﬁcantly inﬂuence ability gorithm learn autonomously particularly important role neural network control npc some way example fps game world could resented ann raw sensory data nates various character distance angle player object simulated sensor data input could example shortest distance ghost feature likely path ghost 8 additionally representation appropriate depends some extent type role neural network controlling agent see section iii some representation might appropriate game direct action tion representation preferable board strategy game state evaluation general type input representation signiﬁcantly bias evolutionary search dictate strategy behavior ultimately discovered section cover number way information game state conveyed neural network straight line slice sensor pathﬁnding sensor data raw sensory data regardless representation used number important consideration one important input need scaled within range preferably within range adding irrelevant input actively harmful performance principle neuroevolution pable sorting useful useless input drastic performance increase sometimes noted removing information input vector 129 straight line sensor pie slice sensor good domain exemplify effect different input resentation simple car racing game studied togelius lucas 123 124 togelius et al 126 togelius lucas 123 investigated various sensor input representation showed best result achieved using centric information rangeﬁnder sensor return distance nearest object given direction stead information car position track frame reference author suggest mapping spatial information appropriate action likely thus making harder lution discover controller result might also explained underlying fractured decision space mapping 61 see section v addition evolving appropriate control policy ne proaches also support automatic feature selection whiteson et al 141 evolved anns car racing domain showed extension neat allows algorithm automatically authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply risi togelius ne game state art open challenge 35 determine appropriate set straight line sensor eliminating redundant input rangeﬁnder sensor also popular domain like fps game nero 119 agent ha rangeﬁnder sensor determine distance object wall tion rangeﬁnder sensor agent nero also pie slice sensor enemy sensor divide 360 degree around agent predetermined number slice ann ha input slice tion input proportional distance enemy unit within slice multiple unit contained one slice activation summed similar sensor found van hoorn et al 135 pie slice sensor useful detect discrete object like enemy team member rangeﬁnder sensor useful detect long contiguous object like wall angle sensor relative position sensor another kind egocentric sensor angle sensor simply report angle particular object nearest some class object previously discussed car racing experiment sensor used sensing waypoints regularly spaced track 123 124 126 experiment evolving combat bot quake iii zanetti rhalibi 149 used angle sensor position enemy weapon related relative position sensor report tances some object along some ax ample yannakakis hallam 145 evolved anns control behaviour cooperating ghost clone setup ann receives relative position input relative position closest ghost speciﬁed distance along pathﬁnding sensor type sensor still considered egocentric doe not take orientation controlled agent eration instead take topology environment consideration pathﬁnding sensor pathﬁnding sensor port distance closest some type entity along shortest path found distance typically not always longer distance along straight line commonly used game take another example lucas evolved neural network play using distance along shortest path ghost nearest pill power pill 71 case controller wa used state evaluator actual action selection wa done using search different input representation also highly bias tionary search type strategy discovered example approach learning pac man make distinction edible threat ghost cally one sensor indicating distance next edible ghost accompanied similar sensor closest threat ghost idea behind separation make easier ann evolve separate strategy dealing threatening edible ghost division make easier ditional approach learn game require domain ciﬁc knowledge might not available domain edible ghost good threat ghost bad might prevent certain strategy emerging example schrum ikkulainen 106 used sensor unbiased sors edible threat ghost showed modular tecture see section iv allowed evolution ﬁnd unexpected behavioral division example particular teresting behavior wa luring ghost near power pill would harder evolve biased sensor ample show important relation lutionary method type sensor support input many game evolved controller receives additional input beyond ﬁrst person sensor not tied speciﬁc frame reference example game like pac man controller typically receives number remaining normal power pill number ghost 106 another example including current level damage car car racing game controller 11 67 68 board game ann doe not directly trol agent section neural network typically only receives input could include quantity piece difference type piece occupying square board game like chess 31 checker 18 go 69 important aspect context etry particular domain example understanding concept adjacency game like checker ponent piece captured jumping cupied ﬁeld controller learn general strategy rather action tied speciﬁc position board earlier attempt evolving state evaluator not directly take ometry account representing board position two separate neuron game go 69 fogel et al 31 showed learning geometry critical generalization true checker well node ﬁrst hidden layer ann receives input different square checker board ﬁrst hidden node ceives input 3 3 subsquare board evolutionary algorithm evolves connection weight board input actual subsquares also put ﬁnal output node idea behind representing board state series overlapping subsquares make easier ann discover independent local relationship within subsquare combined higher level network geometry also represented convolutional recurrent network scan board 103 learning raw sensory data exciting promise ne approach learn directly raw sensory data instead cessed information interesting several reason one might help u understand aspect visual space actually important cessed form ludic computational cognitive science authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply 36 ieee transaction computational intelligence ai game vol 9 no 1 march 2017 another forcing game only rely formation human player get make fair parison human player might lead agent behaviour speculatively forcing controller use representation independent game might enable general game playing skill develop early step towards learning le processed data performed gallagher ledwich 35 simpliﬁed sion approach world wa represented square centered around direct encoded weight network optimized evolutionary strategy result demonstrated possible learn raw data evolved controller performed worse experiment lucas 71 shortest path distance current location ghost nearest maze junction nearest power pill given controller similar setup game super mario wa chosen gelius et al 130 setup author used two sensor detect environmental obstacle another one enemy obstacle enemy occupies one sors corresponding input ann would set togelius et al 130 compared setup sensor author compared proach controller showed based controller performs best smallest sensory setup 21 input total larger setup potentially vide information environment direct encoding apparently not deal increased dimensionality search space approach hand performs equally well regardless size input window scale 101 input take regularity environment description account result lucas 71 togelius et al 130 suggest intricate relationship method number sensor type game applied hyperneat ha also shown promise learning le processed data simpliﬁed version robocup soccer game called keepaway 137 using eye view representation game author showed approach wa able hold ball longer any ously reported result method like sarsa ne method like neat additionally author showed introduced bird eye view representation allows changing number player without changing underlying sentation enabling task transfer 3 2 4 3 away without training recently hausknecht et al 48 compared different ne method neat hyperneat deal different input representation general atari 2600 game playing highest level least general representation wa called object representation algorithm would automatically identify game object runtime based object image manually identiﬁed priori location tie wa directly provided evolving neural network similar work togelius et al 130 result hausknecht et al 48 also indicate direct network encoding work best compact object state representation like hyperneat capable learning directly raw input data learning raw sensory data challenging dimensional game becomes even challenging dimension one reason need some kind depth perception distance estimation perception whole change look around one early experiment learn raw sory data setting floreano et al 29 used direct encoding evolve neural network lated car racing task setup neural network receives visual input driving simulator called world network able perform active vision two output neuron allow determine visual focus olution next time step actual input ann wa limited 5 5 pixel visual ﬁeld evolved work wa able drive better equal human driver active vision approach also successfully applied board game like go roving eye traverse board stop think next stone placed 118 recently koutník et al 62 evolved indirectly encoded recurrent controller car driving torcs learned drive based raw 64 64 pixel image experiment featured rect encoding weight analogous jpeg compression image parker bryant 85 86 evolved ann shoot moving enemy quake ii only using raw sensory mation setup bot wa restricted ﬂat world only band 14 2 pixel center screen wa used input network however though network learned attack enemy evolved bot shooting constantly spinning around circle slowing minimally enemy appeared view ﬁeld promising result still far level human player indeed one ha received processed information angle distance viii open challenge paper ha presented categorized large body work ne ha applied mostly not exclusively role controlling game agent representing strategy many success ne already technique applied le box some problem also some domain problem not yet reached satisfactory performance task not attempted also various ne approach only superﬁcially explored following list consider currently promising future research tions ne plenty basic research question evolutionary computation ne important application technique game section mostly focus applied research sense research vated use game reaching performance seen throughout paper ne performs well many domain especially involving some kind authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply risi togelius ne game state art open challenge 37 continuous control some problem see section ne currently best known method extending range problem domain ne performs well tant research direction right recent year monte carlo tree search mcts ha provided mance many game domain 6 likely many clue taken new family algorithm order improve ne probably also hybridisation sible course performance measured many ferent way game task often though not always playing well measure good playing within some given computation time limit comparing combining evolution learning method ne easily applicable often sometimes best approach available some problem almost never only type algorithm applied problem always evolvable representation expression tree used genetic programming player modeling supervised learning algorithm based gradient descent often applied reinforcement learning problem one could choose apply algorithm temporal difference learning family td 0 relative performance alternative method compared differs drastically sometimes ne really best thing use sometimes not outstanding research question one use ne published comparative study ne kind reinforcement learning algorithm learn many case algorithm learn faster brittle ne eventually reach higher performance 74 100 142 sometimes performs well well tuned 73 sometimes ne completely dominates algorithm 42 needed some sort general theory problem characteristic advantage vantage ne need parameterizable benchmark help u chart problem space vantage point algorithm performance 131 some attempt constructing benchmark previously 57 general video game playing competition characterizes game according game design characteristic problem feature allowing another way comparing performance problem class 88 mapping relative strength algorithm really ﬁrst step know ne work better worse algorithm start inventing hybrid algorithm combine strength neuroevolution alternative particular gp previous research whiteson stone combining neat ha shown promising result 138 139 method applied some success shooter 89 racing game 13 learning data discussed section learning raw image similar unprocessed data hard challenge considerable scientiﬁc interest several application paucity experiment evolving neural network control game agent based raw data puzzling given tility topic however see published result also hard make work stand reason best result achieved using drastically scaled image feed direct shallow approach seem unable deal dimensionality signal formation necessary extracting information feed however recent advance tional network deep learning architecture one hand indirect encoding like hyperneat promise signiﬁcantly improved performance seems like interesting work would result sustained application technique visual input quake ii kind task might also catalyst development new evolvable indirect neural network encoding general video game playing one strength ne generic gorithm relatively tweak applied large number different task yet almost paper cited paper use only single game testbed problem construct ne solution learn play any number game seriously understudied one exception recent work learning play arbitrary atari game 47 48 ne performed admirably work clearly scope improvement apart atari ggp benchmark another relevant mark general video game playing competition us game encoded video game description guage vgdl 27 102 mean unlike atari ggp benchmark competition associated mark software feature generated game thus ically unbounded set video game controller architecture could evolved play any game large set would step towards generic ai capability ﬁrst edition competition wa controller based variation monte carlo tree search future edition feature learning track allows controller considerable time train game 88 method likely itive combining ne learning even larger step would evolve single neural work could learn adapt lifetime ically without evolution play one set game ha far know never attempted would highly impressive evolution learning two form biological adaptation operate different timescales learning allow organism adapt much faster environmental change modifying behavior lifetime one way ne create adaptive anns not only evolve weight ann also local synaptic plasticity parameter determine weight work change lifetime agent based incoming activation 30 113 133 134 resembles way brain organism nature cope changing predictable situation 49 authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply 38 ieee transaction computational intelligence ai game vol 9 no 1 march 2017 ha progress ﬁeld adaptive anns far mostly applied relatively simple toy lem however novel combination recent advance advanced form local plasticity neuromodulation 113 hypothesis testing distal reward learning 112 larger adaptive network 91 93 method avoid deception inherent evolving learning architecture 63 94 learning large behavioral repertoire 23 could allow creating learning network complex main game adaptive network could overcome many lenges applying ne game adjusting ﬂy difﬁculty opponent incrementally learning new skill without forgetting current one ultimately allow eral video game playing anns however preventing work potentially learning undesired behavior tion reliable controllable important future search direction especially context commercial game section competitive cooperative coevolution discussion ﬁtness function section vi cuss competitive cooperative coevolution some length approach bear exceptional promise competitive coevolution could theory enable evolution arm race cooperative coevolution could help ﬁnd solution complex problem automatically decomposing problem evaluating partial solution well ﬁt together unfortunately various problem beset approach prevent achieving full potential cooperative coevolution problem select appropriate level modularisation unit cooperatively coevolved itive coevolution ha several pathology cycling loss gradient however suspect problem much benchmark algorithm example evolution might not achievable scenario used previous research no room sophisticated strategy modern game might provide kind environment would allow evolution take place fast reliable method commercial game paper ha overview academic literature ne game rather us ne game industry simple reason not know many example ne part published commercial game exception commercial game creature 44 indie title gar 46 petalz 95 96 therefore one key research problem identify aspect neural network evolutionary algorithm combination hindered uptake commercial game ai try remedy example anns mostly found way commercial game data mining purpose tions usage npc control game black white car racing game colin mcrae rally game developer often cite lack control clarity issue working neural network especially ann learn game played section make sure doe not suddenly kill npc character vital game story additionally npc change behavior game balancing challenging new type debugging tool might become necessary future important address challenge encourage wider adoption promising ne technique game industry acknowledgment author thank numerous colleague ciously read commented version paper including stanley miller taylor nelson chong whiteson bentley clune lucas stone delalleau reference 1 abbass pareto constructing ensemble neural network using optimization proc 2003 ieee congr evol computation 2003 vol 3 pp 2 agapitos togelius lucas schmidhuber tinidis generating diverse opponent multiobjective evolution proc ieee symp computational intell game 2008 2008 pp 3 investigating evolutionary checker rating individual social learning system round robin tournament dissertation university nottingham nottingham 2011 4 botea bouzy buro bauckhage nau pathﬁnding game dagstuhl vol 6 2013 5 branavan silver barzilay search civilization ii proc int joint conf artiﬁcial 2011 pp aaai press 6 browne powley whitehouse lucas cowling rohlfshagen tavener perez samothrakis colton survey monte carlo tree search method ieee trans tational intell ai game vol 4 no 1 pp 2012 7 bryant miikkulainen neuroevolution adaptive team proc 2003 congr evol computation cec 2003 vol 3 pp 8 burrow lucas evolution versus temporal difference learning learning play proc ieee symp putational intell game cig 2009 2009 pp 9 butz lonneker optimized coupling plus strategy extension torcs car racing challenge proc ieee symp computational intell game 2009 pp 10 cardamone loiacono lanzi evolving competitive car controller racing game neuroevolution proc annu conf genetic evol computation 2009 pp acm 11 cardamone loiacono lanzi neuroevolution applied open racing car simulator proc ieee congr evol computation 2009 2009 pp 12 cardamone loiacono lanzi applying cooperative coevolution compete 2009 torcs endurance world onship proc 2010 ieee congr evol computation cec 2010 pp 13 cardamone loiacono lanzi learning drive open racing car simulator using online neuroevolution ieee trans comput intell ai game vol 2 no 3 pp 2010 14 cardamone caiazzo loiacono lanzi transfer driving behavior across different racing game proc ieee conf computational intell game cig 2011 pp 15 cardona togelius nelson competitive coevolution proc ieee congr evol computation cec 2013 pp 16 chellapilla fogel evolving neural network play checker without relying expert knowledge ieee trans neural vol 10 no 6 pp authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply risi togelius ne game state art open challenge 39 17 chellapilla fogel evolution neural network game intelligence proc ieee vol 87 no 9 pp 1999 18 chellapilla fogel evolving expert checker playing program without using human expertise ieee trans evol vol 5 no 4 pp 2001 19 chong tan white observing evolution neural network learning play game othello ieee trans evol vol 9 no 3 pp 2005 20 clune lipson evolving object generative encoding inspired developmental biology proc eur conf artiﬁcial life acm new york 2011 vol 5 pp 21 clune mouret lipson evolutionary origin modularity proc roy soc london b biol vol 280 no 1755 20122863 2013 22 coello van veldhuizen lamont lutionary algorithm solving problem new york springer 2002 vol 242 23 cully clune tarapore mouret robot adapt like animal nature vol 521 no 7553 pp 2015 24 deb pratap agarwal meyarivan fast elitist multiobjective genetic algorithm ieee trans evol vol 6 no 2 pp 2002 25 dubbin stanley learning dance interactive evolution applicant evol computation new york springer 2010 pp 26 eberhart shi particle swarm optimization ments application resource proc 2001 ieee congr evol 2001 vol 1 pp 27 ebner levine lucas schaul thompson togelius towards video game description language dagstuhl vol 6 2013 28 floreano mondada evolution plastic neurocontrollers situated agent animal animats 4 proc int conf simulation adaptive behavior sab 1996 1996 pp 29 floreano kato marocco sauser coevolution tive vision feature selection biolog vol 90 no 3 pp 2004 30 floreano dürr mattiussi neuroevolution tectures learning evol vol 1 no 1 pp 2008 31 fogel playing edge ai san mateo ca morgan kaufmann 2001 32 fogel hay hahn quon tionary chess program proc ieee vol 92 no 12 pp 2004 33 fonseca et genetic algorithm multiobjective tion formulation discussion generalization proc icga 1993 vol 93 pp 34 fullmer miikkulainen evolving ﬁnite state behavior using genetic encoding neural network proc eur conf artiﬁcial life 1992 35 gallagher ledwich evolving player learn raw input proc ieee symp computational intell game cig 2007 pp 36 galway charles black machine learning digital game survey artif intell vol 29 no 2 pp 2008 37 gauci stanley autonomous evolution topographic regularity artiﬁcial neural network neur vol 22 no 7 pp 2010 38 gauci stanley indirect encoding neural network scalable go parallel prob solv nature ppsn xi new york springer 2010 pp 39 gemrot et pogamut 3 assist developer building ai not only videogame agent agent game tions new york springer 2009 pp 40 gers schmidhuber lstm recurrent network learn simple language ieee trans neural vol 12 no 6 pp 2001 41 gomez miikkulainen incremental evolution complex general behavior adapt vol 5 no pp 1997 42 gomez schmidhuber miikkulainen accelerated neural evolution cooperatively coevolved synapsis mach learn vol 9 pp 2008 43 gomez burger miikkulainen method dynamic resource allocation chip multiprocessor proc int joint conf ieee neural network 2001 vol 4 pp 44 grand cliff malhotra creature artiﬁcial life tonomous software agent home entertainment proc int conf autonomous agent 1997 pp 45 hansen ostermeier completely derandomized tion evolution strategy evol vol 9 no 2 pp 2001 46 hastings guha stanley automatic content generation galactic arm race video game ieee trans comput intell ai game vol 1 no 4 pp 2009 47 hausknecht khandelwal miikkulainen stone atari general game player proc genetic evol computation conf gecco 2012 2012 48 hausknecht lehman miikkulainen stone roevolution approach general atari game playing ieee trans comput intell ai game 2013 49 hebb organization behavior neuropsychological theory new york wiley 1949 50 hingston new design turing test bot proc ieee symp computational intell game cig 2010 pp 51 hoover szerlip norton brindle merritt stanley generating complete multipart musical sition single monophonic melody functional scaffolding proc int conf computational creativity 2012 111 52 hoover szerlip stanley maher hammond pea perez ventura wiggins generating complete multipart musical composition single monophonic melody functional scaffolding proc int conf computational creativity 2012 53 hornik stinchcombe white multilayer feedforward network universal approximators neural vol 2 no 5 pp 1989 54 hughes piece difference simple evolve proc 2003 ieee congr evol computation cec 03 2003 vol 4 pp 55 igel neuroevolution reinforcement learning using evolution strategy proc 2003 congr evol computation 2003 vol 4 pp 56 jallov risi togelius evocommander 2015 online available 57 kalyanakrishnan stone characterizing reinforcement learning method parameterized learning problem mach vol 84 no pp 2011 58 karpov valsalam miikkulainen neuroevolution shaping advice example proc annu genetic evol computation conf gecco 2011 dublin ireland jul 2011 59 khan miller evolution cartesian genetic program capable learning proc annu acm conf genetic evol computation 2009 pp 60 khan miller search intelligence evolving developmental neuron capable learning connect vol 26 no 4 pp 2014 61 kohl miikkulainen evolving neural network strategic problem neur vol 22 no 3 pp 2009 62 koutník cuccu schmidhuber gomez evolving neural network reinforcement learning proc annu acm conf genetic evol computation 2013 pp 63 lehman miikkulainen overcoming deception evolution cognitive behavior proc genetic evol computation conf gecco 2014 vancouver bc canada jul 2014 64 liapis yannakakis togelius adapting model visual aesthetic personalized content creation ieee trans comput intell ai game vol 4 no 3 pp 2012 65 liapis martínez togelius yannakakis forming exploratory creativity delenox proc int conf computational creativity 2013 pp 66 lockett miikkulainen evolving opponent model texas hold proc 2008 ieee conf computational intell game 2008 67 loiacono togelius lanzi lucas simmerson perez reynolds saez wcci 2008 simulated car racing competition proc ieee symp computational intell game 2008 pp 68 loiacono et 2009 simulated car racing championship ieee trans computational intell ai game vol 2 no 2 pp authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply 40 ieee transaction computational intelligence ai game vol 9 no 1 march 2017 69 lubberts miikkulainen neural network coevolution turning adaptive algorithm upon self workshop genetic evol computation conf 2001 6 70 lucas runarsson preference learning move prediction evaluation function approximation othello ieee trans comput intell ai game vol 6 no 3 pp 2014 71 lucas kendall lucas evolving neural network location evaluator play proc 2005 ieee symp computational intell game cig 2005 2005 pp 72 lucas kendall evolutionary computation game ieee comput intell vol 1 no 1 pp 2006 73 lucas runarsson temporal difference learning versus acquiring othello position evaluation proc ieee symp computational intell game 2006 2006 pp 74 lucas togelius car initial study evolution versus temporal difference learning proc ieee symp computational intell game 2007 75 mayer gomez wierstra nagy knoll huber system robotic heart surgery learns tie knot using recurrent neural network advanc vol 22 no pp 2008 76 miikkulainen creating intelligent agent game bridge pp 2006 77 miikkulainen bryant cornelius karpov stanley yong computational intelligence game comput intell princ pp 2006 78 miikkulainen bryant cornelius karpov stanley yong computational intelligence game computational intell principle practice yen fogel ed piscataway nj ieee computational intelligence society 2006 79 moriarty miikkulainen evolving neural network focus minimax search aaai 1994 pp 80 moriarty miikkulainen discovering complex othello strategy evolutionary neural network connection vol 7 no pp 1995 81 bauckhage bida congdon kendall learning game ai dagstuhl vol 6 2013 82 nolﬁand floreano coevolving predator prey robot arm race arise artiﬁcial evolution artiﬁcial life vol 4 no 4 pp 1998 83 nolﬁand floreano evolutionary robotics biology ligence technology machine cambridge mit press 2000 84 ortega shaker togelius yannakakis imitating human playing style super mario bros entertain vol 4 no 2 pp 2013 85 parker bryant control quake ii game engine proc ieee int joint conf comput intell neural network 2008 ijcnn 2008 2008 pp 86 parker bryant neurovisual control quake ii vironment ieee trans comput intell ai game vol 4 no 1 pp 2012 87 pedersen togelius yannakakis modeling player experience content creation ieee trans comput intell ai game vol 2 no 1 pp 2010 88 perez samothrakis togelius schaul lucas toux lee lim thompson 2014 general video game playing competition ieee trans comput intell ai game published 89 reeder miguez spark georgiopoulos topoulos interactively evolved modular neural network game agent control proc ieee symp computational intell game 2008 2008 pp 90 richards moriarty miikkulainen b ack evolving neural network play go proc int conf genetic algorithm east lansing mi 1998 pp 91 risi stanley indirectly encoding neural plasticity pattern local rule animal animats new york springer 2010 pp 92 risi stanley uniﬁed approach evolving plasticity neural geometry proc ieee int joint conf neural network ijcnn 2012 pp 93 risi stanley guided indirectly coded evolving topographic map proc genetic evol computation conf new york 2014 8 94 risi hughes stanley evolving plastic neural work novelty search adapt vol 18 no 6 pp 2010 95 risi lehman hall stanley combining procedural content generation social gaming petalz video game artiﬁc intell interact digital ent conf aiide 2012 96 risi lehman stanley matically categorizing procedurally generated content collecting game proc workshop procedural content generation game pcg int conf foundation digital game new york 2014 97 risi lehman hall stanley petalz procedural content generation casual gamer ieee trans comput intell ai game published 98 rosenblatt perceptron probabilistic model information storage organization brain psychol vol 65 no 6 386 1958 99 rosin belew new method competitive tion evol computation vol 5 no 1 pp 1997 100 runarsson lucas coevolution versus poral difference learning acquiring position evaluation board go ieee trans evol vol 9 no 6 pp 2005 101 schaeffer burch björnsson kishimoto müller lake lu sutphen checker solved vol 317 no 5844 pp 2007 102 schaul video game description language interactive learning proc ieee conf computational intell game cig 2013 pp 103 schaul schmidhuber scalable neural network board game artiﬁcial neural new york springer 2009 pp 104 schmidhuber wierstra gagliolo gomez training recurrent network evolino neur computation vol 19 no 3 pp 2007 105 schrum miikkulainen constructing complex npc behavior via neuroevolution proc artiﬁc intell interact dig ent conf aiide vol 8 pp 2008 106 schrum miikkulainen evolving multimodal behavior modular neural network proc genetic evol computation conf gecco 2014 vancouver bc canada jul 2014 107 schrum karpov miikkulainen havior via neuroevolution combat behavior replay human trace proc ieee conf computational intell game cig 2011 ieee seoul south korea 2011 pp 108 schrum karpov miikkulainen combat behaviour via multiobjective neuroevolution believable bot new york springer 2012 pp 109 secretan beato rodriguez bell stanley picbreeder case study collaborative evolutionary exploration design space evol vol 19 no 3 pp 2011 110 shaker yannakakis togelius towards automatic sonalized content generation platform game proc artiﬁc tell interact dig ent conf aiide stanford ca 2010 pp 111 shaker togelius nelson procedural content generation game textbook overview current research 2015 112 soltoggio plasticity hypothesis testing distal reward learning biolog vol 109 no 1 pp 2015 113 soltoggio dürr mattiussi floreano evolving romodulatory topology reinforcement problem proc ieee congr evol computation cec 2007 2007 114 sondik optimal control partially observable markov ce inﬁnite horizon discounted cost oper vol 26 no 2 pp 1978 115 stanley compositional pattern producing network novel abstraction development genetic programm evolv vol 8 no 2 pp 2007 116 stanley miikkulainen evolving neural network augmenting topology evol vol 10 no 2 pp authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply risi togelius ne game state art open challenge 41 117 stanley miikkulainen competitive coevolution evolutionary complexiﬁcation artif intell jair vol 21 pp 2004 118 stanley miikkulainen evolving roving eye go proc genetic evol computation conf 2004 119 stanley bryant miikkulainen roevolution nero video game ieee trans evol vol 9 no 6 pp 2005 120 stanley gauci encoding evolving neural network artif life vol 15 no 2 pp 2009 121 sutton barto introduction reinforcement learning cambridge mit press 1998 122 taylor whiteson stone transfer via ping policy search reinforcement learning proc int joint conf autonomous agent multiagent syst aamas may 2007 pp 123 togelius lucas evolving controller simulated car racing proc 2005 ieee congr evol computation 2005 vol 2 pp 124 togelius lucas evolving robust specialized car racing skill proc 2006 ieee congr evol computation cec 2006 2006 pp 125 togelius schmidhuber experiment automatic game sign proc 2008 symp computational intell game 2008 pp 126 togelius et competitive car racing controller proc ieee congr evol computation 2007 pp 127 togelius de nardi lucas towards automatic sonalised content creation racing game proc computational intell game 2007 2007 pp 128 togelius et 2007 ieee cec simulated car racing tition genetic programm evolvable vol 9 no 4 pp 2008 129 togelius schaul schmidhuber gomez countering poisonous input memetic neuroevolution parallel problem solving new york springer 2008 pp 130 togelius karakovskiy koutník schmidhuber super mario evolution proc ieee symp computational intell game cig 2009 2009 pp 131 togelius schaul wierstra igel gomez huber ontogenetic phylogenetic reinforcement learning stliche intelligenz vol 23 no 3 pp 2009 132 togelius yannakakis stanley browne based procedural content generation taxonomy survey ieee trans comput intell ai game vol 3 pp 2011 133 tonelli mouret relationship generative encoding regularity learning ability evolving plastic artiﬁcial neural network plo one vol 8 no 11 2013 134 urzelai floreano evolution adaptive synapsis robot fast adaptive behavior new environment evol vol 9 no 4 pp 2001 135 van hoorn togelius schmidhuber hierarchical controller learning shooter proc 2009 ieee symp tational intell game cig 2009 pp 136 van hoorn togelius wierstra schmidhuber robust player imitation using multiobjective evolution proc ieee congr evol computation 2009 pp 137 verbancsics stanley evolving static representation task transfer mach learn vol 11 pp 2010 138 whiteson stone evolutionary computation inforcement learning stochastic domain proc annu conf genetic evol 2006 pp 139 whiteson stone evolutionary function approximation reinforcement learning mach learn vol 7 pp may 2006 140 whiteson kohl miikkulainen stone evolving away soccer player task decomposition mach vol 59 no 1 pp may 2005 141 whiteson stone stanley miikkulainen kohl automatic feature selection neuroevolution proc 2005 conf genetic evol computation 2005 pp 142 whiteson taylor stone empirical study action selection reinforcement learning adapt vol 15 no 1 pp 2007 143 whiteson taylor stone critical factor ical performance temporal difference evolutionary method reinforcement learning auton agent vol 21 no 1 pp 2010 144 yannakakis togelius panorama artiﬁcial tional intelligence game ieee trans comput intell ai game vol 7 no 4 pp 2014 145 yannakakis hallam evolving opponent interesting interactive computer game animal animats vol 8 pp 2004 146 yannakakis spronck loiacono andré player modeling dagstuhl vol 6 2013 147 yao evolving artiﬁcial neural network proc ieee vol 87 no 9 pp 1999 148 yao islam evolving artiﬁcial neural network sembles computational intell ieee vol 3 no 1 pp 2008 149 zanetti rhalibi machine learning technique fps proc 2004 acm sigchi int conf advance comput entertainment technol ace new york 2004 pp 150 ziemke remembering behave recurrent neural network adaptive robot behavior recurrent neur netw design pp sebastian risi received degree puter science university central florida orlando associate professor university copenhagen robotics evolution art lab real interest include computational intelligence game tion evolutionary robotics design automation also finchbeak company creates casual educational social game enabled gd technology risi ha several best paper award gecco ijcnn work adaptive system hyperneat algorithm evolving complex artiﬁcial neural network julian togelius received degree lund university lund sweden degree university sussex brighton degree university essex colchester associate professor department computer science engineering new york university work aspect tational intelligence game selected topic evolutionary computation evolutionary reinforcement learning current main research direction involve procedural content generation game eral video game playing player modeling fair relevant benchmarking game ai competition previously wa idsia lugano switzerland university copenhagen togelius past chair ieee ci technical committee game associate editor ieee transaction computational intelligence game authorized licensed use limited queen mary university london downloaded march utc ieee xplore restriction apply