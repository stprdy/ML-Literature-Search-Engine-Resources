arxiv 1 mar 2007 reinforcement learning recurrent neural network temporal coding daichi kimura yoshinori abstract study reinforcement learning temporal coding ral network consisting stochastic spiking neuron neural work information coded characteristic timing neuronal ﬁring including order ﬁring relative phase diﬀerences ﬁring derive learning rule network show network consisting neuron dynamical synaptic kinetics learn appropriate timing neuronal ﬁring also investigate system size dependence learning eﬃciency 1 introduction many study assumed neuron transmit information ﬁring rate unit typical model network unit investigated hand recent experiment suggest timing neuronal ﬁring may also contribute information representation function brain synaptic modiﬁcation gray onig engel singer 1989 bi poo 1999 varela lachaux rodriguez martinerie 2001 reyes 2003 example seems local global synchronization play signiﬁcant role integration information distributed across brain another example show order timing neuronal ﬁrings encode information stimulus ﬁngertips encoding sequence transmit information faster coding ﬁring rate directly johansson birznieks 2004 capture dynamical aspect neural network network consisting various model neuron unit physic tohoku university sendai japan 1 investigated unit not describe temporal behavior neuron short time scale context associative memory neural network oscillator neuron spiking neuron ha studied aoyagi 1995 yoshioka shiino 1998 hoppensteadt izhikevich 1999 kanamaru okabe 2000 hasegawa 2001 lee farhat 2001 2002 system relative phase diﬀerences timing ﬁrings used represent memory study learning pulse neuron model consisting hh neuron diﬃculty deriving learning rule although several study made learning network consist model neuron seung 2003 xie seung 2004 cio swiercz jackson 2004 study focus only coding term ﬁring rate however would useful combine temporal coding learning ha shown temporal coding deal mation process faster coding ﬁring rate thorpe delorme rullen 2001 example delorme et al 2001 show neural network consisting neuron learn identify human face using rank order coding coding order timing neuronal ﬁring neuron allowed spike only paper study reinforcement learning temporal coding neural network consisting stochastic spiking neuron deﬁning network coupled stochastic hh neuron some quantity sec ii train network learn xor operation output information coded order ﬁring sec iii sec iv investigate result performance learning depends system size strength noise conclusion follow 2 model illustrate example learning process spiking neuron sider neural network consisting hh neuron since hh neuron show excitability code information timing ﬁring complete 2 dynamic network coupled hh neuron may expressed cm dvi dt hi vna vk gl vl x j wijis j ξi 1 dmi dt αm vi 1 vi mi 2 dhi dt αh vi 1 vi hi 3 dni dt αn vi 1 vi ni 4 vi membrane potential neuron cm membrane itance vr r na k l equilibrium potential gr r na k l conductance mi hi ni voltage dependent activating inactivating ables αx βx x h n function voltage vi hodgkin huxley 1952 wij synaptic weight neuron j wij wji general j synaptic current ξi gaussian white noise obeys ξi 0 5 ξi ξj qδijδ 6 average time q variance noise synaptic current j given j rj vsyn 7 vsyn synaptic reversal potential rj fraction bound receptor destexhe mainen seijnowski 1994 described drj dt αt 1 8 1 j j τ 0 otherwise 9 α β j time presynaptic neuron j ﬁres membrane potential 27 mv τ andez huerta corbacho uenza 2000 fig 1 show behavior vi ri single neuron added external current whose amplitude 10 used forth order method time step solve eq 1 4 3 0 20 40 60 v mv 0 1 0 2 4 6 8 10 r time figure 1 behavior vi rj single hh neuron added external current neuron ﬁres 2 value ri start increase lapse τ ri turn decline 4 train neural network use reinforcement learning algorithm let u consider time sequence state neuron σ v 0 v 1 v 2 v v denotes vector vn assign scalar value reward time sequence σ according signal network sutton barto 1998 give high reward r desirable time quence σ episode consider episodic learning since eq 1 includes gaussian white noise calculate expected value reward average possible time sequence goal learning maximize adjusting wij use ascending gradient strategy wnew ij wold ij δwij 10 δwij 11 ǫ learning coeﬃcient calculate gradient respect wij hayakawa 2001 fiete seung 2006 1 q r σ z 0 dtξi j 12 detail derivation see appendix 3 learning procedure temporal coding present learning rule eq 10 12 eﬀective any information coding including order coding show example consider neural network consisting 2 input neuron 15 output neuron hidden neuron divide set output neuron three disjoint subset containing 5 output neuron assume information coded temporal order group activity subset learning goal chose xor operation term order coding subset ﬁre order input pattern 1 1 reverse order input pattern 1 1 train neural network learn suitable timing tk p ﬁring subset op given input pattern k 1 1 1 1 respectively described table right column table 1 show desirable order group activity subset input pattern learning goal reduction rms 5 table 1 order collective ﬁring learning goal respectively input tk p desirable pattern order 1 1 1 1 error ek input pattern k given ek 1 no 3 x x p 13 time neuron ﬁres no number output neuron deﬁne episode transient dynamic network last 0 accompanied external input evaluate reward r depending resulting error ek episode given input pattern r 1 ek ek th 0 ek th 14 ek th threshold error change threshold ek th gradually learning proceeds following simulation calculate age error ek ave 100 episode input pattern update threshold next 100 episode ek th ek ek th ek ave almost identical sometimes happens ek ave increase learning since update wij decrease ek aﬀect value k thus ek th also sometimes increase not decrease monotonically episode input signal ﬁxed value corresponding input pattern 10 learning coeﬃcient variance noise period one episode ǫ q 10000 respectively assume output hidden neuron excitatory wij j take only positive value set input neuron wij j take positive negative value ﬁrst set synaptic weight wij j using uniformly distributed 6 random number j n n n number neuron due normalization factor 1 n magnitude error ek doe not depend section number hidden neuron wa fig 2 show behavior output neuron initial state upper episode input pattern episode total elapsed lower ﬁnd neuron ﬁre order input pattern 1 1 reverse order pattern 1 1 learning fact fig 3 show average error ek ave decrease gradually learning ﬁgures indicate learning term order ﬁring applying present learning rule successful fig 4 show wij matrix form representing connection color learning seen connection result learning interpreted consequence no direct correlation output time sequence connection understood way 4 system size dependence learning eﬃciency since realistic biological system consist many neuron interesting important eﬃcient learning rule larger system size section discus system size dependence performance learning ﬁrst train network various number hidden neuron nh following simulation parameter nh given previous section sum average error p k ek ave shown fig 5 investigate property learning assumed exponential decay error function number episode showed λ inset fig 5 shown fig 5 speed learning becomes slower extra hidden neuron added decay rate λ also ha tendency however error signiﬁcantly reduced episode proceed case turned network nh 5 showed best result simulation added neuron redundant not contribute learnability next examine case learning speed various number output neuron no subset op consist number hidden neuron nh fig 5 b show error p k ek ave decay rate λ inset ﬁrst stage learning process decay rate approximately given λ δ however λ evaluated 7 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 5 10 time 0 5 10 time 0 5 10 time 1 0 5 10 time 15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 5 10 time 0 5 10 time 0 5 10 time 1 0 5 10 time figure 2 action potential output neuron initial state upper 5 104 episode input pattern 2 105 episode total elapsed lower index output neuron shown vertical axis neuron index index others ﬁre order input pattern reverse order 1 see also table 1 8 0 1 2 3 4 0 1 2 3 4 5 average ek average ek episode episode 1 1 10 0 1 2 3 4 5 figure 3 ek ave input pattern function episode ing inset data plot typical value ek learning approximately 3 0 1 hidden j input hidden figure 4 wij matrix form representing connection color learning neuron j presynaptic postsynaptic 9 1 10 100 0 1 2 3 4 5 sum ek episode 0 5 15 32 50 100 1 10 100 λ number hidden neuron 1 10 100 0 1 2 3 4 5 sum ek episode b 15 24 39 60 99 10 100 λ number output neuron figure 5 p k ek ave function episode learning nh no b inset decay constant λ p k ek ave 0 104 ﬁlled circle 4 104 5 104 open square number episode slope dotted line inset b approximately 10 1 10 100 0 1 2 3 4 5 sum ek episode 1250 2500 5000 10000 20000 40000 80000 103 104 105 λ q figure 6 p k ek ave function episode learning inset λ p k ek ave 0 104 ﬁlled circle 4 104 5 104 open square interval 4 104 5 104 no dependence λ seems weaken behavior learning process need investigated discus asymptotics would like mention eﬀects noise learning noise strength may aﬀect result performance learning random search process weight space essential part learning rithm tested dependence learning performance variance noise q eq 6 no 15 nh 5 parameter given previous section fig 6 show learning error decay rate since amount update order magnitude q directly aﬀect stability learning however fig 6 indicates learning rule robust change q long gradient ascending process assumed eq 11 hold 5 conclusion proposed concrete method encode temporal information network stochastic spiking neuron utilizing reinforcement learning 11 method show learning rule eﬀective order coding since derivation eq 11 doe not depend form diﬀerential equation action potential like eq 1 learning rule eq 11 generally applicable network type model neuron example neuron following fhn model random ﬂuctuation fact checked network consisting fhn neuron also learn order coding task learning rule eq 11 omit detail paper present learning rule applied not only order coding also any information coding general one design appropriate reward r deﬁning error group activity reference signal learning process given straightforward manner described sec iii example conﬁrmed present method also worked xor task term phase coding relative phase diﬀerence code information way oscillator neuron aoyagi 1995 simulation neural network consisted 2 input neuron hidden neuron 10 output neuron divided two disjoint subset containing 5 output element learning goal wa group activity become phase input pattern 1 1 phase 1 1 general convergence reinforcement learning slow present model not exception several factor need investigated improve speed convergence although assumed gaussian white noise study real neuronal system likely noise may obey statistical property example fiete et al 2006 discus learning rule using arbitrary noise furthermore learning speed depends great extent design cost function reward design reward not suitable learning process drop local minimum easily present study empirically employed sliding threshold method changing learning goal ek th eq 14 started easier one although strategy applied any learning task performance result learning sensitive deﬁne ek th paper deﬁned ek th ek ave severe learn speed learning becomes slower cause overestimated reward learning process drop local minimum point ek th doe not monotonically decrease also important since update wij decrease ek aﬀect value k therefore decrease ek th monotonically ek ave increase inﬂuence update wij task becomes harder learn well conventional back propagation learning decide number hidden neuron assign initial value wij also important problem 12 xor task order coding convergence speed learning process signiﬁcantly aﬀected number hidden output neuron larger size system seems require learning step intend examine relationship future research assumed fully connected network assigned random value initial state wij may not appropriate learning watt strogatz proposed network structure watt strogatz 1998 network ha investigated context network some improvement performance made simard nadeau oger 2005 also propagation velocity coherent oscillation neuron depend topology network includes network andez et 2000 roxin riecke solla 2004 result may indicate some suitable topology network temporal coding well since present learning rule eq 12 includes only local relation neuron j learning rule may applied network arbitrary topology finding suitable network topology facilitate learning also problem future investigation acknowledgment would like thank toshihiro kawakatsu tsuyoshi hondou helpful comment appendix estimation gradient let u introduce stochastic processing element model neuron value action potential neuron discrete time 0 1 2 represented vi vi internal state mi successive time step 1 determined vi 1 g vi mi n x j wijf vj ξi 15 mi 1 h vi mi 16 wij synaptic weight neuron j f vi signal neuron emits according vi n total number neuron g vi mi h vi mi function neuronal state ξi gaussian white noise obeys eq 5 eq 6 consider f vi g vi mi h vi mi arbitrary function 13 continuous time representation employ langevin equation neuronal update dvi dt g vi mi n x j wijf vj ξi 17 dmi dt h vi mi 18 although treat mi scalar variable following discussion method also applied mi multivariate consider time sequence state neuron 0 σ v 0 v 1 v 2 v v denotes vector vn mn assign reward r time sequence σ calculate gradient respect wij hayakawa 2001 fiete seung 2006 probability density tσ time sequence deﬁned tσ p v v 1 0 19 p transition probability state b since mi deterministic only vi includes gaussian noise described eq 5 6 transition probability eq 19 may expressed p v 1 1 exp h vi mi 1 exp x ηi δmi h vi mi 20 ηi vi 1 vi mi n x j wijf mj 2 21 δm n kronecker delta average quantity σ possible time sequence described 1 z x σ σ tσ 1 z x σ σ exp x x ηi 22 14 z normalization factor therefore gradient σ may obtained 1 z x σ tσy σ 1 q x ξi f vj 1 q σ x ξi f vj 23 continuous case 17 sum σ eq 22 becomes path integral 1 z z σ σ exp z 0 dt x ηi path 24 ηi dvi dt vi mi n x j wijf vj 2 25 using r σ σ obtain derivative eq 11 1 q r σ z 0 dtξi f vj 26 network consisting hh neuron 1 4 derive eq 12 instituting eq 7 eq 26 thus result indicates calculation gradient depends only ξi f vj r σ linear summation synaptic neuronal activity additive independent noise eq 15 eq 17 essential present learning algorithm learning rule includes only local relation neuron j propagation rumelhart hinton williams 1986 rtrl williams zipser 1989 requires information neuron addition j order calculate δwij reference aoyagi 1995 network neural oscillator retrieving phase mation phys rev 74 bi poo 1999 distributed synaptic modiﬁcation neural network induced patterned stimulation nature 401 792 15 cio swiercz jackson 2004 network spiking neuron modeling problem solving neurocomputing 61 delorme thorpe 2001 face identiﬁcation using one spike per neuron resistance image degradation neural network 14 destexhe mainen seijnowski 1994 eﬃcient method computing synaptic conductance based kinetic model receptor binding neural computation 6 andez huerta corbacho uenza 2000 fast response temporal coherent oscillation network phys rev 84 fiete seung 2006 gradient learning spiking neural network dynamic perturbation conductance phys rev 97 gray onig engel singer 1989 oscillatory response cat exhibit synchronization reﬂects global stimulus property nature 338 hasegawa 2001 associative memory hodgkin huxley neuron network synaptic coupling phys soc 70 hayakawa 2001 reinforcement learning stochastic neural network proceeding 2001 international symposium nonlinear theory application 2 hodgkin huxley 1952 quantitative description membrane current application conduction excitation nerve j physiol london 117 hoppensteadt izhikevich 1999 oscillatory neurocomputers dynamic connectivity phys rev 82 johansson birznieks 2004 first spike ensemble human tactile aﬀerents code complex spatial ﬁngertip event 7 kanamaru okabe 2000 associative memory retrieval induced ﬂuctuations pulsed neural network phys rev e 62 lee farhat 2001 bifurcating neuron network neural network 14 lee farhat 2002 bifurcating neuron network 2 analog associative memory neural network 15 reyes 2003 propagation ﬁring rate tively constructed network vitro 6 roxin riecke solla 2004 activity world network excitable neuron phys rev 92 rumelhart hinton williams 1986 learning representation error nature 323 533 16 seung 2003 learning spiking neural network reinforcement stochastic synaptic transmission neuron 40 simard nadeau oger 2005 fastest learning neural network physic letter 336 sutton barto 1998 reinforcement learning introduction cambridge mit press thorpe delorme rullen 2001 strategy rapid processing neural network 14 varela lachaux rodriguez martinerie j 2001 brainweb phase synchronization integration 2 watt strogatz 1998 collective dynamic work nature 393 williams zipser 1989 learning algorithm continually running fully recurrent neural network neural computation 1 xie seung 2004 learning neural network reinforcement irregular spiking phys rev e 69 yoshioka shiino 1998 associative memory based nized ﬁring spiking neuron interaction phys rev e 58 3628 17