received march 23 2017 accepted april 10 2017 date publication april 24 2017 date current version june 7 digital object identifier machine learning big data challenge approach alexandra l graduate student member ieee katarina member ieee hany member ieee miriam senior member ieee electrical computer engineering western university london canada science department faculty computer informatics suez canal university ismailia 41522 egypt corresponding author katarina grolinger kgroling work wa partially supported nserc crd western university grant crd abstract big data revolution promise transform live work think enabling process optimization empowering insight discovery improving decision making realization grand potential relies ability extract value massive data data analytics machine learning core ability learn data provide data driven insight decision prediction however traditional machine learning approach developed different era thus based upon multiple assumption data set ﬁtting entirely memory unfortunately no longer hold true new context broken assumption together big data characteristic creating obstacle traditional technique consequently paper compiles summarizes organizes machine learning challenge big data contrast research discus challenge work highlight relationship organizing challenge according big data v dimension instigated issue volume velocity variety veracity moreover emerging machine learning approach technique discussed term capable handling various challenge ultimate objective helping practitioner select appropriate solution use case finally matrix relating challenge approach presented process paper provides perspective domain identiﬁes research gap opportunity provides strong foundation encouragement research ﬁeld machine learning big data index term big data big data v data analysis data analytics deep learning distributed computing machine learning neural network table acronym acronym definition fpga gate array gpu graphic processing unit iot internet thing independent identically distributed lle locally linear embedding ml machine learning mllib machine learning library mlp perceptron moa massive online analysis pca principal component analysis ramp reduce map provenance rdd resilient distributed datasets svm support vector machine svr support vector regression introduction today amount data exploding unprecedented rate result development web technology social medium mobile sensing device example twitter process tweet per day thereby generating daily 1 abi research estimate 2020 30 billion connected device 2 big data posse tremendous potential term business value variety ﬁelds health care biology transportation online advertising energy management ﬁnancial service 3 4 however traditional approach struggling faced massive data concept big data deﬁned gartner 5 high volume high velocity high variety data require new processing paradigm enable insight ery improved decision making process optimization according deﬁnition big data not characterized 7776 2017 ieee translation content mining permitted academic research only personal use also permitted requires ieee permission see information volume 5 2017 l heureux et al machine learning big data challenge approach speciﬁc size metric rather fact traditional approach struggling process due size velocity variety potential big data highlighted deﬁnition however realization potential depends improving traditional approach developing new one capable handling data potential big data referred revolution transform live work think 6 main purpose revolution make use large amount data enable knowledge discovery better decision making 6 ability extract value big data depends data analytics jagadish et al 7 consider analytics core big data revolution data analytics involves various approach technology tool text analytics business gence data visualization statistical analysis paper focus machine learning ml fundamental ponent data analytics mckinsey global institute ha stated ml one main driver big data revolution 8 reason ability learn data provide data driven insight decision prediction 9 based statistic similarly tical analysis extract trend data however doe not require explicit use statistical proof according nature available data two main category learning task supervised learning input desired output label known system learns map input output unsupervised learning desired output not known system discovers structure within data classiﬁcation regression example supervised learning classiﬁcation output take discrete value class label sion output continuous example classiﬁcation algorithm neighbour logistic regression support vector machine svm regression example include support vector regression svr linear regression polynomial regression some algorithm neural network used classiﬁcation sion unsupervised learning includes clustering group object based established similarity criterion example algorithm predictive analytics relies machine learning develop model built using past data attempt predict future 10 numerous algorithm including svr neural network naïve bayes used purpose common ml presumption algorithm learn better data consequently provide rate result 11 however massive datasets impose ety challenge traditional algorithm not designed meet requirement example several ml algorithm designed smaller datasets assumption entire dataset ﬁt memory another assumption entire dataset available processing time training big data break assumption rendering traditional algorithm unusable greatly impeding performance number technique developed adapt machine learning algorithm work large datasets example new processing paradigm mapreduce 12 distributed processing framework hadoop 13 branch machine learning including deep online learning also adapted effort overcome challenge machine learning big data paper ﬁrst compiles summarizes organizes machine learning challenge big data contrast research 7 11 14 15 focus linking identiﬁed challenge big data v dimension volume velocity variety veracity highlight relationship next emerging machine learning approach reviewed emphasis address identiﬁed challenge process study provides perspective domain identiﬁes research gap opportunity area machine ing big data although security privacy tant consideration application perspective not impede execution machine learning fore considered outside scope paper remainder paper organized follows section ii review related work section iii present machine learning challenge classiﬁed according big data dimension overview emerging machine learning approach discussion challenge address provided section iv section v aggregate ﬁndings identiﬁes future research direction finally section vi concludes paper ii related work paper highlight challenge speciﬁc highly evant machine learning context big data associate v dimension provides overview emerging approach responding existing literature some researcher described general machine learning challenge big data 4 14 16 17 whereas others discussed context speciﬁc methodology 14 18 najafabadi et al 14 focused deep learning noted following general obstacle machine learning big data unstructured data format fast moving streaming data data input noisy data high dimensionality scalability algorithm imbalanced distribution input data unlabelled data limited labeled data similarly sukumar 16 identiﬁed three main ments designing ﬂexible highly scalable architecture understanding statistical data characteristic applying algorithm ﬁnally developing ability work larger datasets study najafabadi et al 14 sukumar 16 reviewed aspect machine learning big data however not attempt associate tiﬁed challenge cause moreover discussion high level without presenting related solution contrast work includes thorough discussion challenge establishes relation big data volume 5 2017 7777 l heureux et al machine learning big data challenge approach dimension present overview solution gate qiu et al 17 presented survey machine learning big data focused ﬁeld signal processing study identiﬁed ﬁve critical issue large scale different data type high speed data uncertain incomplete data data low value density related big data dimension study includes comprehensive view challenge similarly relates v dimension furthermore qiu et al 17 also identiﬁed various learning technique discussed representative work signal cessing big data although great work tifying existing problem possible solution lack categorization direct relationship approach challenge make difﬁcult make informed sion term learning paradigm solution would best speciﬁc use case scenario consequently work emphasis establishing correlation solution challenge et al 4 reviewed machine learning big data focussing efﬁciency system new algorithmic approach reduced memory footprint although mentioned various big data hurdle not present systematic view done work et al interested analytical aspect method reducing computational complexity tributed environment not considered work hand considers analytical aspect tational complexity distributed environment existing study effectively discussed obstacle encountered speciﬁc technique deep ing 14 18 however study focussed narrow aspect machine learning comprehensive view challenge approach big data context needed similar work gandomi haider categorized challenge accordance big data v 19 however characterization general not term machine learning survey platform big data analytics also presented 20 21 singh reddy 20 considered vertical horizontal scaling platform discussed advantage disadvantage different platform term attribute scalability performance fault ance processing iterative task support larly de almeida bernardino 21 reviewed open source platform including apache mahout massive online si moa r project vowpal pegasos graphlab study reviewed compared existing platform present study relates platform lenges address moreover work big data form one category reviewed solution challenge data mining big data explored literature 22 23 fan bifet 22 focused challenge data mining big data opposed work not classify challenge provide possible solution work wu et al 23 categorized challenge categorization ing three tier tier big data mining platform tier ii semantics application knowledge tier iii big data mining algorithm contrast categorization paper according v dimension whereas wu et al considered data mining study deal machine learning moreover present study relates big data solution challenge address understand origin machine learning challenge present work categorizes using big data nition addition various machine learning approach reviewed approach capable ing known challenge discussed enables researcher make better informed decision regarding learning paradigm solution use based speciﬁc big data scenario also make possible identify research gap opportunity domain machine learning big data consequently work serf comprehensive foundation facilitator future research figure big data characteristic associated challenge iii machine learning challenge originating big data definition big data often described dimension referred earlier deﬁnitions big data focussed three v 24 volume velocity variety however commonly accepted deﬁnition relies upon following four v 25 volume velocity variety veracity important note v also found literature example value often added v 22 26 however value deﬁned desired outcome big data processing 27 not deﬁning characteristic big data reason paper considers only four dimension characterize big data 28 provides opportunity relate challenge directly deﬁning characteristic big data rendering origin cause explicitly section identiﬁes machine learning challenge associate challenge speciﬁc dimension big data fig 1 illustrates dimension big data along associated lenges discussed following 7778 volume 5 2017 l heureux et al machine learning big data challenge approach volume ﬁrst talked characteristic big data volume amount size scale data machine learning context size deﬁned either vertically number record sample dataset zontally number feature attribute contains furthermore volume relative type data smaller number complex data point may considered equivalent larger quantity simple data 19 perhaps easiest dimension big data deﬁne time cause numerous challenge following discus machine learning challenge caused volume 1 processing performance one main challenge encountered tions big data come simple principle scale volume add computational complexity quently scale becomes large even trivial operation become costly example standard support tor machine svm algorithm ha training time plexity space complexity 29 number training sample therefore increase size drastically affect time memory needed train svm algorithm may even become computationally infeasible large datasets many ml algorithm also exhibit high time ity example time complexity principal nent analysis logistic regression locally weighted linear regression gaussian discriminative si 30 number ples n number feature hence algorithm time needed perform computation increase exponentially increasing data size may even render algorithm unusable large datasets moreover data size increase performance rithms becomes dependent upon architecture used store move data parallel data structure data partitioning placement data reuse become important growth data size 31 resilient distributed datasets rdds 31 example new abstraction computation large cluster rdds implemented spark cluster computing framework 32 therefore not only doe data size affect performance also lead need typical architecture used implement develop algorithm 2 curse modularity many learning algorithm rely assumption data processed held entirely memory single ﬁle disk 33 multiple class algorithm designed strategy building block depend validity assumption however data size lead failure premise entire family algorithm affected challenge referred curse modularity 15 one approach brought forward solution curse mapreduce scalable programming paradigm processing large datasets mean parallel tion large number node some machine learning algorithm inherently parallel adapted mapreduce paradigm whereas others difﬁcult pose way take advantage large number computing node grolinger et al 11 discussed lenges mapreduce big data three main category algorithm encounter curse modularity attempting use mapreduce paradigm include iterative graph gradient descent expectation maximization rithms iterative nature together dependence data create disconnect parallel distributed nature mapreduce lead difﬁculties adapting family algorithm mapreduce another distributed computation paradigm consequently although some algorithm adapted overcome curse modularity parallelization distributed computing others still bounded even unusable certain paradigm 3 class imbalance datasets grow larger assumption data uniformly distributed across class often broken 34 lead challenge referred class imbalance performance machine learning algorithm negatively affected datasets contain data class various probability occurrence problem especially prominent some class represented large number sample some class imbalance not exclusive big data ha subject research decade 35 ments performed japkowicz stephen 35 shown severity imbalance problem depends task complexity degree class imbalance overall size training set suggest large datasets good chance class represented reasonable number sample however conﬁrm observation evaluation big data set needed hand complexity big data task expected high could result severe impact class imbalance expect challenge would common severe complex big data context extent imbalance ha immense potential grow due increased data size author japkowicz stephen 35 showed decision tree neural network support vector machine algorithm sensitive class imbalance therefore tered execution big data context without addressing class imbalance may produce inadequate result similarly baughman et al 36 considered extreme class imbalance volume 5 2017 7779 l heureux et al machine learning big data challenge approach gamiﬁcation demonstrated negative effect watson machine learning consequently big data context due data size probability class imbalance occur high tion complex problem embedded data potential effect class imbalance machine learning severe 4 curse dimensionality another issue associated volume big data curse dimensionality 37 refers tie encountered working high dimensional space speciﬁcally dimensionality describes number feature attribute present dataset hughes effect 38 state training set static size dictive ability effectiveness algorithm decrease dimensionality increase therefore ber feature increase performance accuracy machine learning algorithm degrades explained breakdown reasoning upon many machine learning algorithm rely 37 tunately greater amount data available describe phenomenon greater becomes potential high dimensionality prospective feature consequently volume big data increase doe likelihood high dimensionality addition dimensionality affect processing mance time space complexity ml algorithm closely related data dimensionality 30 time plexity many ml algorithm polynomial number dimension already mentioned time complexity principal component analysis logistic regression number sample n number dimension 5 feature engineering high dimensionality closely related another volume challenge feature engineering process creating feature typically using domain knowledge make machine learning perform better indeed selection appropriate feature one time consuming processing task machine learning 14 dataset grows vertically horizontally becomes difﬁcult create new highly relevant feature consequently manner similar dimensionality size dataset increase difﬁculties associated feature engineering feature engineering related feature selection whereas feature engineering creates new feature effort improve learning outcome feature selection ality reduction aim select relevant feature although feature selection reduces dimensionality hence ha potential reduce ml time high dimension challenging due spurious correlation incidental endogeneity correlation explanatory variable error term 39 overall feature selection engineering still relevant big data context time become complex 6 data size pose challenge application common methodology used evaluate dataset characteristic algorithm performance indeed validity many metric technique relies upon set assumption including common assumption linearity 40 example correlation coefﬁcient often cited good indicator strength relationship two variable however value coefﬁcient only fully meaningful linear relationship exists ables experiment conducted kiang 41 showed performance neural network logistic regression negatively affected although problem not exclusive big data expected prominent large datasets challenge big data also stem difﬁculties associated evaluating linearity linearity often evaluated using graphical technique terplots however case big data large number point often creates large cloud making difﬁcult observe relationship 40 ass linearity therefore difﬁculty assessing linearity presence pose challenge execution machine learning algorithm context big data 7 bonferonni principle bonferonni principle 42 embodies idea one looking speciﬁc type event within certain amount data likelihood ﬁnding event high however often not occurrence bogus meaning no cause therefore le instance within dataset statistical challenge also often described spurious correlation 19 tic bonferonni correction theorem provides mean avoiding bogus positive search within dataset suggests testing hypothesis desired icance α individual hypothesis tested signiﬁcance level 43 however incidence phenomenon increase data size data become exponentially bigger chance ﬁnding event interest legitimate not bound increase recently calude longo 44 discussed impact incidence spurious correlation big data shown given large enough volume correlation tend spurious therefore including mean preventing false positive important consider context machine learning big data 8 variance bias machine learning relies upon idea generalization observation manipulation data tions generalized enable analysis prediction 7780 volume 5 2017 l heureux et al machine learning big data challenge approach figure variance bias 37 generalization error broken two nents variance bias 45 fig 2 illustrates ship variance describes consistency learner ability predict random thing whereas bias describes ability learner learn wrong thing 37 ideally variance bias error mized obtain accurate output however volume data increase learner may become closely biased training set may unable generalize adequately new data therefore dealing big data caution taken bias introduced compromising ability generalize regularization refers technique aim improve generalization reduce overﬁtting example tion technique include early stopping lasso ridge 46 although technique improve generalization also introduce additional parameter must tuned achieve good ﬁt unseen data often done using approach possibly grid search however require additional processing time especially case large datasets regularization technique well established machine learning investigation needed respect efﬁciency big data variety variety big data describes not only structural ation dataset data type contains also variety represents semantic interpretation 7 source although not many v sion challenge associated dimension substantial impact 1 data locality ﬁrst challenge associated variety data ity 42 machine learning algorithm assume entire dataset found memory single disk ﬁle 15 however case big data may not possible due sheer size not only data not ﬁt memory commonly distributed large number ﬁles residing different physical location traditional machine learning would ﬁrst require data transfer computing location large datasets transfer would result processing latency could cause massive network trafﬁc consequently approach bringing computation data opposed bringing data computation ha emerged based premise moving computation cheaper term time bandwidth moving data approach especially prominent big data mapreduce paradigm also us map task executed node data reside map task processing local data moreover large number nosql data store adapt model distributed storage solution store data large number node use duce paradigm bring computation data 47 however already mentioned approach encounter difﬁculties working highly iterative algorithm small datasets physical location ever big data data locality paramount challenge must addressed any successful big data system 2 data heterogeneity big data analytics often involve integrating diverse data several source data may diverse term data type format data model semantics two main geneity category recognized syntactic semantic heterogeneity syntactic heterogeneity refers diversity data type ﬁle format data encoding data model similar carry analytics integrated datasets syntactic variation must reconciled 7 machine learning often requires data cleaning step conﬁgure data ﬁt within speciﬁc model however data coming different source data likely formatted differently furthermore data processed may completely different type example image may need processed along categorical numerical data cause culties machine learning algorithm not designed recognize various type representation one time create efﬁcient uniﬁed generalization semantic heterogeneity refers difference meaning interpretation syntactic semantic heterogeneity increase case big data number datasets developed different party integrated 48 machine learning approach not developed handle semantically diverse data therefore heterogeneity must resolved applying approach statistic heterogeneity also refers difference statistical property among different part overall dataset although present small datasets challenge enlarged big data datasets typically involve part coming different source statistical heterogeneity break common machine learning assumption tical property similar across complete dataset syntactic semantic heterogeneity well tistical heterogeneity active research topic volume 5 2017 7781 l heureux et al machine learning big data challenge approach long time emergence big data attracted renewed attention 48 business value data analytics typically involves correlating diverse datasets integration crucial carrying machine learning datasets 3 dirty noisy data according ratner 40 data posse set tinct feature used characterization condition deﬁnes readiness data analysis location refers data physically reside population describes entity set mon attribute together form dataset big data typically described due amount time resource necessary get ready analysis also come various location unknown population combination property lead big data often described dirty fan et al 39 referred data noisy data contain various type measurement error outlier missing value discussed noise accumulation especially severe high dimensionality typical big data important note fan et al considered noisy data one three main challenge big data analysis swan 49 suggested data analysis include step extract signal noise directly following step data collection integration also recognized big data may noisy produce meaningful result study described demonstrate importance dealing noise context generic big data analysis likewise noise need considered machine learning big data velocity velocity dimension big data refers not only speed data generated also rate must analyzed omnipresence phone sensor impending need act quickly environment development technology smart home velocity big data ha become important factor consider 1 data availability historically many machine learning approach depended data availability meaning learning began entire dataset wa assumed present ever context streaming data new data constantly arriving requirement not fulﬁlled moreover even data arriving interval may pose challenge machine learning model typically learns training set performs learned task example classiﬁcation prediction new data scenario model doe not automatically learn newly arriving data instead carry already learned task new data accommodate knowledge embedded new data model must retrained without retraining may become outdated cease reﬂect current state system therefore adapt new information algorithm must support incremental learning 50 sometimes referred sequential learning deﬁned algorithm ability adapt learning based arrival new data without need retrain complete dataset approach doe not assume entire training set available learning begin process new data arrive although incremental learning relatively old concept still active research area due difﬁculty adapting some algorithm continuously arriving data 51 2 similar already discussed data availability challenge traditional machine learning approach not designed handle constant stream data 19 lead another velocity dimension challenge need cessing subtly different data availability challenge whereas data availability refers need update ml model new data arrive processing refers need processing data business value processing system lie ability provide instantaneous tion developer algorithmic trading fraud detection surveillance system especially interested solution 11 importance processing today era sensor mobile device iot ha resulted gence number streaming system example include twitter storm 52 yahoo 53 although system seen great success processing not include sophisticated diverse ml user add ml feature using external language tool need exists merge streaming solution machine learning algorithm provide instantaneous result however complexity algorithm sparse availability online learning solution make difﬁcult task 3 concept drift big data new data arriving ously consequently acquiring entire dataset cessing not possible meaning not mined whether current data follow distribution future data lead another interesting challenge machine learning big data concept drift 15 concept drift formally deﬁned change conditional distribution target output given input distribution input may remain unchanged 54 speciﬁcally lead problem occurs machine learning model built using older data no longer accurately reﬂect distribution new data 55 ple energy consumption demand prediction model built using data electricity meter 56 7782 volume 5 2017 l heureux et al machine learning big data challenge approach building retroﬁtted improve energy efﬁciency present model doe not accurately represent new energy characteristic sliding window possible way dealing concept drift model built using only sample training window moved include only recent sample windowing approach assumes recent data relevant may not always true 54 exist various type concept drift incremental gradual sudden recurring 57 bringing set issue however challenge typically lie quickly detecting concept drift occurring effectively handling model transition change like several already mentioned concept concept drift not new issue mention date back 1986 54 however advent nature big data increased frequency occurrence rendered some previous ology unusable example lavaire et al 58 conducted experiment inﬂuence high dimensional big data existing concept drift mitigation technique sion algorithm performance wa highly degraded change data therefore ﬁnding new mean handle concept drift context big data important task future machine learning 4 independent identically distributed random variable another common assumption machine learning random variable independent identically tributed 59 simpliﬁes underlying method improves convergence word assumes random variable ha probability distribution others mutually independent reality may may not true moreover some algorithm also depend distribution example markov sequence assumes probability distribution next state depends only current state 60 nonetheless big data nature may prevent reliance assumption based following 15 requires data random order many datasets order typical solution would randomize data ing algorithm however dealing big data becomes challenge often impractical nature big data fast continuous therefore not realistic randomize dataset still incomplete possible wait data arrive dundar et al 61 shown many typical machine learning algorithm neural work support vector machine depend upon tion could beneﬁt greatly way accounting high likelihood broken assumption big data make challenge important one address veracity veracity big data refers not only reliability data forming dataset also ibm ha described inherent unreliability data source 19 provenance quality big data together deﬁne veracity nent 62 also pose number challenge discussed following 1 data provenance data provenance process tracing recording origin data movement location 63 recorded information provenance data used identify source processing error since identiﬁes step transaction process undergone invalid data thus providing contextual information machine ing therefore important capture retain metadata 7 however pointed wang et al 62 text big data provenance dataset becomes large therefore data provide excellent context machine learning volume metadata creates set challenge moreover not only dataset large computational cost carrying head becomes overwhelming 62 although certain method brought forward capture data provenance speciﬁc data processing paradigm reduce map provenance ramp developed mapreduce extension hadoop 64 added burden provenance generally add already high complexity tional cost machine learning big data consequently provenance data provide way establish veracity big data mean balancing computational overhead cost veracity value needed 2 data uncertainty data gathered various aspect life different way however mean method used gather data introduce uncertainty therefore impact veracity dataset example sentiment data collected social medium 65 although data highly tant contain precious insight subjective information data imprecise certainty accuracy type data not objective relies only upon human judgment 20 lack ity absolute truth within data make difﬁcult machine learning algorithm learn another recent method capturing data crowdsourcing solicits service idea large group people data obtained crowdsourcing particularly gathered participatory sensing contain even higher degree uncertainty sentiment data 7 moreover inherent uncertainty exist various type data weather economic data example even sophisticated data method volume 5 2017 7783 l heureux et al machine learning big data challenge approach table machine learning approach challenge address not expunge intrinsic unpredictability 66 machine learning algorithm not designed handle kind imprecise data thus resulting another set unique challenge machine learning big data 3 dirty noisy data furthermore addition imprecise data also noisy 67 example label contextual information associated data may inaccurate reading could spurious machine learning perspective different imprecise data unclear picture different wrong picture although may yield similar result noise dirtiness come various source related variety many cause related variety discussed section however noise challenge associated crowdsourcing ha yet discussed crowdsourcing lead uncertainty especially used participatory sensing also lead noisy data make use human judgment assign label data moreover incorrect label either purposely accidently assigned number rect noisy label not only inﬂuences data veracity also affect performance machine learning tially providing improperly labelled data dirty noisy data not unique big data mean handled may not easily adaptable large datasets iv approach response presented challenge various approach developed although designing entirely new algorithm would appear possible solution 68 researcher mostly preferred method many approach suggested survey lished speciﬁc category solution example include survey platform big data analytics 20 21 review data mining big data 23 paper review organizes various proposed machine learning approach discus address identiﬁed challenge big picture correlation presented table 1 includes list approach along 7784 volume 5 2017 l heureux et al machine learning big data challenge approach figure data analytics pipeline challenge best address symbol indicate high degree remedy represents partial resolution seen table two main category solution ﬁrst category relies data processing algorithm manipulation handle big data second category involves creation adaptation different machine learning paradigm modiﬁcation existing algorithm paradigm addition two category important note several machine learning service offering microsoft azure machine learning part cortana intelligence suite 69 google cloud machine learning platform 70 amazon machine learning 71 ibm watson analytics 72 service backed powerful cloud provider offer not only scalability also integration cloud platform service however moment support limited number rithms compared r language 73 matlab 74 weka 75 moreover computation happens cloud resource requires data transfer remote node big data result high network trafﬁc may even become infeasible due time bandwidth requirement ml service proprietary information underlying technology limited therefore paper doe not discus following introduce technique methodology developed used handle lenges associated machine learning big data first manipulation technique used conjunction existing algorithm presented second various machine learning paradigm especially well suited handle big data challenge discussed manipulation big data data analytics using machine learning relies established suite event also known data analytics pipeline approach presented section discus possible manipulation various step existing pipeline purpose modiﬁcations respond lenges machine learning big data fig 3 show representation pipeline based work labrinidis jagadish 76 along three type manipulation discussed section data manipulation processing manipulation algorithm manipulation three category along sponding sample solution presented fig example included only representative no way provide comprehensive list solution 1 data manipulation one ﬁrst manipulation attempted effort adapt big data machine learning try modify data order mimic data modiﬁcation take place data stage pipeline illustrated fig two important aspect affecting machine learning performance high dimensionality wide datasets large number sample high datasets fore two intuitive data manipulation learning big data dimensionality reduction instance selection shown fig term data reduction sometimes refers manipulation occasionally ically denotes instance selection additionally data clearing another important aspect data manipulation dimensionality reduction aim map high ity space onto one without signiﬁcant loss information variety mean exists reduce dimension context big data one popular old technique originates 1901 principal component analysis pca pca belongs family linear mapping technique orthogonal transformation applied transform set possibly correlated variable set linearly uncorrelated variable called principal component ﬁrst principal component account largest proportion variability data second one ha next highest variance orthogonal ﬁrst thus choosing only ﬁrst p principal component reduce dimensionality example dimensionality reduction niques sometimes referred manifold learning include kernel pca laplacian eigenmaps isomap locally linear embedding lle hessian lle 77 random tion another dimensionality reduction nique 78 idea behind make use random unit matrix project original dataset onto dimensional space technique ha used variety data type text image however limited locally available static data therefore although interesting volume 5 2017 7785 l heureux et al machine learning big data challenge approach figure manipulation big data random projection address only issue related high dimensionality unable mitigate challenge data locality availability autoencoders also used reduce dimension learn encoding dataset 14 architecture similar perceptron mlp one input one put one hidden layer difference mlp autoencoder always ha number input output node whereas mlp learns mapping input target variable autoencoder learns reconstruct input hidden layer responsible encoding map input feature space x dimension space f creating compressed representation output layer hand serf decoder reconstructs input x compressed representation dimensionality reduction primarily address curse dimensionality processing performance challenge instance selection refers technique selecting data subset resembles represents whole dataset whereas dimensionality reduction deal wide datasets data reduction speciﬁcally instance selection aim reduce dataset height subset consequently used make inference whole dataset instance selection approach diverse include random tion genetic selection progressive pling using domain knowledge cluster sampling 79 although instance selection reduces dataset size thus improves processing performance eas curse modularity number question arise big sample sample size balance accuracy computing time sampling approach used choice approach ha major impact well subset represents whole good model instance selection duce sampling error due difference sample whole dataset issue although well researched learning small datasets enlarged big data context data size make difﬁcult evaluate different tie model moreover already mentioned big data context challenge class imbalance noise variance bias common difﬁcult turn make challenging select subset adequately represent whole set example large class imbalance selection approach must ensure instance class selected hand appropriate instance tion remedy class imbalance data cleaning another type data manipulation refers noise outlier removal thus tackle challenge dirty noisy data area no signiﬁcant development respect big data noise removal ha especially active research topic audio image video domain example niques include smoothing ﬁlters wavelet transforms 80 however not practical 7786 volume 5 2017 l heureux et al machine learning big data challenge approach processing data distribution may change time autoencoders addition dimensionality reduction perform denoising recover signal tially corrupted input data therefore challenge noisy dirty data also addressed method 2 processing manipulation improve machine learning performance big data processing manipulation focus modifying data processed stored term storage refers not only physical storage permanent medium also data represented memory illustrated fig 3 processing manipulation happen three phase data analytics pipeline data transformation data storage data analysis stage independent category tions process embedded capture data provenance therefore remedy provenance challenge example reduce map provenance ramp developed mapreduce extension hadoop 64 however process carry signiﬁcant computational overhead main stream solution category includes based parallelization processing technique take advantage inherent parallel nature certain rithms many learning algorithm search genetic algorithm trivially parallel therefore parallelization provide massive performance ments consequently researcher developed technique tool parallelize machine learning two category parallel system distinguished vertical horizontal scaling paradigm vertical scaling scaling paradigm includes multicore cpu supercomputer blade hardware ation including graphic processing unit gpus programmable gate array fpgas big data context often discarded limited resource able single node however machine learning important highlight gpu approach gpus specially designed manipulating image output display large number core thousand compared cpu development gpu interface nvidia cuda resulted increased use gpus general purpose processing gpus originally designed graphic display image processing matrix operation vector operation especially suited system however ml algorithm also implemented gpu parallelized sufﬁciently high degree today large number gpu accelerated ml algorithm available 81 although provides excellent performance highly parallel processing size data gpu machine learning process limited memory typically processing happens single node fpgas rarely mentioned context big data hardware component especially built speciﬁc purpose application although limit applicability big data important note excellent fpga performance achieved scanning large amount network data 82 horizontal scaling scaling paradigm refers distributed system processing dispersed worked node vertical scaling processing allelized also involves distributed node hence network communication due capability scale large number commodity node distributed system focus big data research paradigm ha developed two stream system system process large amount data access data typically concerned throughput latency based solution hadoop 83 nimble 84 belong category mapreduce encounter ﬁculties dealing iterative algorithm new tions proposed haloop 85 twister 86 extend hadoop provide better support iterative ing solution address curse larity typically not require complete dataset held memory moreover data locality also resolved solution support work data residing different physical location solution facilitate work high dimensional data not resolve breakdown reasoning thus provide partial resolution curse dimensionality similarly support type processing tively handle highly interconnected data date graph algorithm solution emerged pregel 87 algorithm behind google pagerank giraph 88 used facebook analyze social connection example category based bulk synchronous parallel paradigm retain state ory facilitates iterative processing solution category deal challenge processing performance system operate one data element small set recent data near typically computation performed system not complex performed batch system example category apache storm 52 yahoo 53 spark streaming 32 although inspired mapreduce platform present signiﬁcant departure hadoop mapreduce moved data dependence stream storm express computation using graph topology runtime engine handle parallelization message passing fault tolerance contrast storm perform processing spark streaming divide data carry computation batch system enable mitigation processing performance processing issue also gate curse modularity not require dataset ﬁt memory remedy data availability lenge work continuously arriving data however volume 5 2017 7787 l heureux et al machine learning big data challenge approach streaming system only suitable simple machine learning gorawski et al 89 cugola margara 90 surveyed data stream processing tool complex event cessing not mention machine learning ically discussion ability tool approach meet speciﬁc requirement provides insight proper tool approach selection research ml big data ha focussed mainly horizontal scaling paradigm solution solution streaming discussed earlier category address speciﬁc problem encounter difﬁculties others solution processing manipulation category primarily focus improving mance throughput latency not remedy number challenge illustrated table combination processing manipulation algorithm new learning paradigm provides research opportunity undertake remaining big data challenge 3 algorithm manipulation algorithm manipulation include approach modify existing algorithm without applying new paradigm since beginning machine learning researcher trying improve existing algorithm reduce time space complexity big data effort intensiﬁed ha become important handle large datasets illustrated fig 4 study distinguishes two egories algorithm modiﬁcations algorithm tions new paradigm approach involve modifying existing algorithm applying process manipulation new paradigm algorithm modiﬁcations focussed modifying algorithm improve performance example following approach developed speciﬁc machine learning algorithm address volume challenge pegasos 91 provides optimized version port vector machine svm algorithm text processing runtime doe not depend directly training set size hence pegasos especially suitable large datasets regularization path 92 linear model support linear regression logistic regression multinomial regression problem approach enables processing large datasets efﬁciently dle sparse feature solution category deal processing performance processing typically distributed computing solution also address data locality challenge moreover curse dimensionality modularity partially remedied solution support work high dimensional data may provide smaller memory footprint algorithm modiﬁcations new paradigm category involves modifying ml algorithm work better new process manipulation new paradigm example category would modify algorithm parallelization adapt algorithm new parallel processing paradigm mapreduce chu et al 30 adapted several algorithm multicore mapreduce ing naïve bayes gaussian discriminative analysis neural network support vector machine others chu et al 30 shown using approach mapreduce some algorithm modiﬁed improve performance however algorithm especially iterative one not easily parallelized consequently due curse modularity whole family algorithm may not usable paradigm 11 ml platform another type solution category combine algorithm adaptation new paradigm solution category started based system apache mahout 93 underlying hadoop disk access slow ml platform evolved solution example include apache spark 32 94 spark distributed computing framework based distributed datasets memory processing addition spark core vides distributed computing foundation spark also includes library built top core including spark sql spark streaming mllib machine learning library graphx mllib library offer large number machine learning algorithm still limited compared r guage matlab another distributed machine learning form like spark distributed tem therefore support massively scalable data analytics whereas spark focus providing form analytics emphasis speciﬁcally scalable machine learning installed top spark sparkling water combine machine learning capability powerful spark distributed platform mahout samsara release mahout ha also transformed system another example distributed machine learning platform petuum 95 spark mllib rely general purpose distributed platform mllib spark spark hadoop petuum plete platform developed speciﬁcally machine learning vowpal wabbit 96 yet another interesting solution category us online learning approach mean data not memory hence memory footprint not dependent number sample lastly apache samoa 97 google flow 98 provide machine learning library tributed processing environment unlike samoa abstract distributed streaming nature processing user tensorflow make use data ﬂow graph ﬂexible architecture enable user deploy computation across device although solution quite promising bound subset challenge samoa 7788 volume 5 2017 l heureux et al machine learning big data challenge approach bound stream processing tensorflow designed deep learning work classiﬁes ml platform algorithm iﬁcations solution however also considered processing modiﬁcations illustrated dashed line fig algorithm modiﬁcation solution without new paradigm focus providing capability process large datasets improving performance providing cessing capability also remedy data locality tributed computation performed data residing different physical location algorithm modiﬁcation new paradigm speciﬁcally ml platform mitigate curse modularity use memory node ter course dimensionality facilitate work high dimensional data however not ically address number challenge illustrated table although unable provide complete solution challenge discovered algorithm manipulation offer mean researcher deploy modify adapt existing algorithm big data order address some unaddressed concern machine learning paradigm big data variety learning paradigm exists ﬁeld machine learning however not type relevant area research example deng li 99 presented number paradigm applicable speech recognition gruently work presented includes machine learning paradigm relevant big data context along address identiﬁed challenge 1 deep learning deep learning approach representation ing family machine learning representation learning also often referred feature learning 100 type algorithm get name fact us data sentations rather explicit data feature perform task transforms data abstract representation enable feature learnt deep learning architecture representation subsequently used accomplish machine learning task henceforth feature learned directly data no need feature engineering context big data ability avoid feature engineering regarded great advantage due challenge associated process deep learning us hierarchical learning process similar neural network extract data representation data make use several hidden layer data pas layer transformation applied representation constitute high level complex abstraction data 14 layer attempt separate factor variation within data output last layer simply transformation original input used input machine learning algorithm well deep learning algorithm capture figure deep learning 101 various level abstraction thus type learning ideal solution problem image classiﬁcation recognition fig 5 provides abstract view deep learning process 101 layer learns speciﬁc feature edge corner contour object part deep learning architecture versatile built using multitude component autoencoders restricted boltzmann machine typical building block 14 coder unsupervised algorithm used many purpose anomaly detection context big data typically serve precursor step ral network 102 work backpropagation attempting set target output input thereby boltzmann machine 103 similar except use stochastic rather istic process deep belief network 104 another example deep learning algorithm furthermore reliance upon abstract representation also make algorithm ﬂexible adaptable data variety data abstracted diverse data type source not strong inﬂuence algorithm result making deep learning great candidate dealing data heterogeneity interestingly deep learning used vised unsupervised learning 18 possible due nature technique excels extracting global relationship pattern data reliance upon creating high level abstraction text big data great advantage render algorithm le sensitive veracity challenge dirty noisy uncertain data 18 moreover multiple layer transformation address challenge ciated data deep compression ha proposed way speeding processing without loss accuracy 105 according described characteristic deep learning seems well suited address many ously identiﬁed challenge feature engineering data volume 5 2017 7789 l heureux et al machine learning big data challenge approach heterogeneity noisy dirty data data uncertainty however algorithm not fundamentally built learn incrementally 106 therefore tible data velocity issue although especially well adapted handle large datasets complex problem not computationally efﬁcient way high dimensional data 14 large number sample algorithm may even become infeasible making deep learning susceptible curse dimensionality 2 online learning responds well processing nature online learning another machine learning paradigm ha explored bridge efﬁciency gap created big data online learning seen alternative batch ing paradigm typically used conventional machine learning name implies batch learning process data batch requires entire dataset available model created 42 furthermore generated model no longer modiﬁed make difﬁcult deal dimension big data following reason volume process large amount data one time not computationally efﬁcient always feasible variety need entire dataset available beginning processing limit use data various source velocity requirement access entire dataset time processing doe not enable time analysis use data various source veracity model not altered highly susceptible performance impediment caused poor data veracity conversely online learning us data stream training model learn one instance time 18 paradigm alleviates computational load processing performance data not entirely held memory enables processing large volume data remedy curse modularity facilitates processing provides ability learn data 18 moreover doe not require data present located place paradigm remedy data availability locality furthermore descriptor online also reﬂects fact paradigm continuously maintains model model modiﬁed whenever algorithm see ﬁt adaptive nature make possible handle certain amount dirty noisy data class imbalance concept drift indeed mirza et al 107 proposed ensemble subset online sequential extreme learning machine achieve solution concept drift detection class imbalance kanoun van der shaar 108 presented online learning solution remedying challenge concept drift apparent online learning architecture responds well challenge associated big data velocity incremental learning nature alleviates challenge data availability processing concept drift example paradigm could used handle stock data prediction due rapidly evolving nature stock market however issue associated dimensionality feature engineering variety remain unresolved moreover not machine learning algorithm easily adapted online learning paradigm 3 local learning first proposed bottou vapnik 1992 109 local learning strategy offer alternative typical global learning conventionally ml algorithm make use global learning strategy generative learning 110 approach assumes based upon data underlying distribution model used input data basically attempt summarize entire dataset whereas local learning concerned only subset interest therefore local learning viewed parametric approximation global model stronger le restrictive assumption hybrid parametric model yield low variance bias 4 figure local learning fig 6 provides abstract view local learning ce idea behind separate input space cluster build separate model cluster reduces overall cost complexity indeed much efﬁcient ﬁnd solution k problem size single problem size consequently approach could enable processing datasets considered large global paradigm another way implementing local learning modify learning algorithm only neighbouring sample inﬂuence output variable typical example local learning would ﬁcial instance predicting energy consumption 7790 volume 5 2017 l heureux et al machine learning big data challenge approach several customer building model similar customer could favourable building one unique model customer building one model per customer recently poulet 111 developed parallel ble learning algorithm random local support vector machine wa able perform much better typical svm algorithm addressing volume related issue thereby demonstrating local learning help ate some issue associated big data moreover local learning ha outperformed global learning term accuracy computation time several forecasting study 112 113 dividing problem manageable data chunk reduces size data need handled potentially loaded memory therefore paradigm alleviates curse modularity addition locality cluster model not signiﬁcantly affected challenge associated class imbalance data locality recent work ha shown local learning often yield better result global learning dealing imbalanced datasets 4 therefore challenge curse modularity class imbalance variance bias data locality ated local approach however matter dimensionality velocity concept drift among others yet addressed overall big data context local approach remains largely unexplored studying paradigm could better handle velocity veracity challenge appears particularly open 4 transfer learning transfer learning approach improving learning particular domain referred target domain training model datasets multiple domain denoted source domain similar attribute feature problem constraint type learning used data size within target domain cient learning task different 114 fig 7 show abstract view transfer learning distinguishing characteristic transfer learning traditional ml approach fact training set doe not necessarily come domain ing set moreover train data several domain individually combined together using regular adapted machine learning algorithm domain not data distribution feature space 115 ent element transferred source domain target domain instance feature representation model parameter relational knowledge 116 example use case energy consumption prediction new building target domain using datasets collected similar building source domain probably similar consumption pattern different size efﬁciency consequently transfer learning possible candidate resolving some challenge related volume variety veracity dimension big data environment figure transfer learning volume category remedy class imbalance instance transferred diverse domain better balance class target domain ability learn different domain transfer knowledge different datasets transfer learning promising solution data heterogeneity challenge variety category moreover instance transfer different domain contribute reducing challenge dirty noisy data well data uncertainty variety veracity category study discussed transfer learning big data yang et al 115 introduced automatic transfer learning algorithm big data improved vised learning approach laplacian eigenmaps algorithm enabling automatic knowledge transfer source domain target domain system wa designed analyzing short text data using knowledge long text obtained web zhang 48 described several ples transfer learning big data based concept data fusion among homogenous heterogeneous datasets data fusion refers combining data several source reason transfer learning one paradigm address data size heterogeneity 5 lifelong learning lifelong learning mimic human learning learning tinuous knowledge retained used solve different problem directed maximize overall learning able solve new task training either one single domain heterogeneous domain collectively 117 learning outcome training process collected combined together space called topic model edge model case training heterogeneous domain transfer learning might used combining step create topic model existing knowledge topic volume 5 2017 7791 l heureux et al machine learning big data challenge approach figure transfer learning model used perform new task regardless knowledge come lifelong learning related online learning transfer learning like online learning lifelong learning uous process however whereas online learning considers only single domain lifelong learning includes multitude domain like transfer learning lifelong learning ble transferring knowledge among domain unlike transfer learning lifelong learning continuous process time topic space reﬁned time new learning outcome arrives example consider process inferring individual sport interest various data available physical location social medium interaction weather data web browsing history prediction individual interest need change periodically time new data become available area interest may shift time fig 8 depicts high level view lifelong learning traditional machine learning algorithm single get domain not transfer learning one task another exception transfer learning quently khan et al 118 consider approach able big data many domain covered data constant appearance new one consider lifelong learning good candidate solution big data model continuously reﬁned learned task applicable different domain similar online learning lifelong learning promising solution processing performance processing data availability concept drift doe not rebuild model every time new piece data arrives only update existing knowledge based new ing data new knowledge course added existing knowledge base future task since lifelong learning incorporates transfer learning integral part address issue transfer learning data heterogeneity class imbalance dirty nosy data data uncertainty however presently ha little development area achieving vision challenging lifelong learning ha applied various domain chen liu 119 suggested unsupervised learning algorithm gibbs sampler mining topic model generating better knowledge space context review work big data divided small set set trained individually learning result compared yield better topic model suthaharan 120 discussed issue related combining machine learning including lifelong learning big data technology hadoop hive focussed network intrusion detection data growing quickly arriving fast different source khan et al 118 surveyed lifelong learning model including probabilistic topic model topic model natural language processing large data volume work discussed model used big data improve learning performance accuracy figure ensemble learning 6 ensemble learning ensemble learning combine multiple learner obtain ter learning outcome prediction classiﬁcation obtained any constituent learner 121 fig 9 present abstract view ensemble learning process typically overall outcome determined voting process among weighted outcome individual er 121 individual learner similar completely different category including ing supervised unsupervised ml weighting 7792 volume 5 2017 l heureux et al machine learning big data challenge approach mechanism assigns value learning output point combine voting process could implemented straightforward way directly aggregating value learning point use statistical technique obtain combined value learning put may lead better learning performance 122 waske benediktsson 123 applied svm vidual learner also used svm voting process two main way apply ensemble learning ﬁrst one train different learner one complete dataset whereas second one split dataset train learner different only subset second approach ha potential big data context speed improve learning process basically improvement achieved splitting large volume data small disjoint datasets one machine learning algorithm trained different disjoint dataset outcome learner combined using some kind voting scheme improve accuracy overall solution example detect anomalous behavior ble learning could applied breaking large dataset small one training learner small set combining result identify anomaly high accuracy false alarm several study discussed applying ensemble learning big data example tang et al 124 used decrease computation time simultaneously improve learning racy split large dataset smaller datasets using probabilistic approximation technique called reservoir sampling method research study shown ensemble ing performs well different datasets 125 126 zang et al 125 presented comparative study ensemble incremental learning observed incremental algorithm faster ensemble model performed better presence concept drift alabdulrahman 126 imented four different datasets investigated lations among ensemble size base classiﬁers voting method work tang et al 124 gruber et al 127 used ensemble learning mainly minimize computing time dividing big dataset small training set unlike work tang et al 124 gruber et al 127 suggested invoking several different machine learning algorithm small set output value algorithm weighted combined evaluated using inverse probability weight voting phase finally author showed ensemble learning could also used choose learning algorithm removing not impact ﬁnal outcome approach consequently decreased computing time ensemble learning play key role emphasizing rectness learning outcome well speeding learning process respect correctness using several different learner training different subset ha potential minimize error rate hand similar local learning splitting dataset training subset improves processing performance efﬁcient ﬁnd solution k problem size single problem size data splitting also reduces data chunk need loaded memory making ensemble learning capable addressing curse modularity moreover ensemble learning capable addressing concept drift 125 ensemble learning could modiﬁed best handle issue related variety velocity remains explored discussion ratner 40 describes machine learning ﬁeld make use algorithm solve problem underlying statistical component regression classiﬁcation clustering mean approach year researcher used machine learning solve problem without worrying whether situation facing met requirement classical statistical assumption upon certain ology rely 40 arguably lack concern regard assumption ha enabled scientist advance quickly ﬁeld machine learning ﬁeld statistic 40 however advent big data many assumption upon algorithm rely broken thereby impeding performance analytical task response pitfall together need process large datasets fast number new machine learning approach paradigm developed however remains consistently difﬁcult ﬁnd best tool technique tackle speciﬁc challenge paper ha identiﬁed presented challenge machine learning big data reviewed emerging machine learning approach discussed approach capable addressing identiﬁed challenge overview relation challenge approach ha presented table single application use case may encounter several challenge may need bine several approach handle challenge following use case demonstrate use presented work case study 1 energy prediction ing using historical sensor reading infer future energy consumption ha gained popularity due proliferation sensor smart meter grolinger et al 103 considered energy forecasting large sensor data encountered two main challenge volume category processing performance long time build model curse ularity complete data set ﬁtting memory resolve challenge applied local learning thus complying table 1 indicates local learning address challenge processing performance curse ity indicated table 1 challenge could potentially solved approach horizontal scaling study local learning not only signiﬁcantly improved performance also increased prediction accuracy volume 5 2017 7793 l heureux et al machine learning big data challenge approach case study 2 recommender system collaborative ing mechanism capable suggesting relevant online content user based browsing history million digital transaction collected daily need continuously analyzed improve recommendation increase user engagement like case study 1 address processing performance curse modularity challenge bachmann 128 applied local learning additionally local learning enabled embedding contextual awareness laborative ﬁltering case study 3 machine translation machine translation system computationally expensive case large data set may even prohibitive 129 handle processing performance challenge google us deep ing speciﬁcally tensorflow one ml form illustrated figure tensorflow deployed one cpu gpus making horizontally vertically scalable approach thus google machine tion us combination several approach deep learning horizontal vertical scaling address performance challenge case study 4 activity recognition constant ments iot ha led development numerous sensor equipped wearable device saeedi et al 130 posed autonomous reconﬁguration wearable system order handle impact conﬁguration change activity recognition main challenge faced lied erogeneity data wearable sensor data contains variety signal heterogeneity subject device sampling frequency related heterogeneity accordance table 1 transfer learning wa used tackle big data challenge deep learning lifelong learning could also considered nevertheless author reported performance increase due solution correlation approach big data lenges presented table make possible identify main opportunity direction future research machine learning big data single approach may address one challenge several challenge may addressed single approach future direction not categorized according v dimension represent broad research opportunity data fusion become even important researcher industry try combine data number different source different format semantics provide new insight process algorithm manipulation expected continue attract signiﬁcant research interest make possible use traditional algorithm adapted work big data paradigm enable updating existing model upon arrival new data without need retrain plete model promising modate bigger datasets batch learning paradigm category online learning lifelong learning stream processing presently limited relatively ple problem however new development anticipated able handle complex computation online learning may possibly merge stream cessing online learning update model real time near real time integrated stream processing integration various approach deep learning online learning present interesting promising research area worthy consideration combination various approach would ensure ter coverage issue related machine learning big data table 1 noted no correlation bonferonni principle any reviewed approach although impact big data context large 44 not aware speciﬁc big data solution addressing problem preventing false positive important appears attracted limited attention big data community vi conclusion paper ha provided systematic review lenges associated machine learning context big data categorized according v sion big data moreover ha presented overview ml approach discussed technique come various challenge identiﬁed use big data deﬁnition categorize lenges machine learning enables creation effect connection issue furthermore creation explicit relation approach challenge enables thorough understanding ml big data fulﬁlls ﬁrst objective work create foundation deeper understanding machine learning big data another objective study wa provide researcher strong foundation making easier informed choice regard machine learning big data objective wa achieved developing hensive matrix lay relationship various challenge machine learning approach thereby highlighting best choice given set condition paper enables creation connection among various issue solution ﬁeld study wa not easily possible basis existing literature development adaptation new machine ing paradigm tackle unresolved challenge nation existing solution achieve performance improvement paper ha identiﬁed research tie work ha therefore accomplished last objective providing academic community potential tions future work hopefully serve groundwork great improvement ﬁeld machine learning big data 7794 volume 5 2017 l heureux et al machine learning big data challenge approach reference 1 krikorian 2010 twitter number twitter online able 2 abi 2013 billion device wirelessly connect internet everything 2020 abi research online available 3 raghupathi raghupathi big data analytics healthcare promise potential health inf sci vol 2 no 1 pp 2014 4 yoo muhaidat karagiannidis taha efﬁcient machine learning big data review big data vol 2 no 3 pp 2015 5 beyer laney importance big data deﬁnition gartner research stamford ct usa tech 2012 6 cukier big data revolution transform live work think boston houghton mifﬂin harcourt 2013 7 jagadish et big data technical challenge commun acm vol 57 no 7 pp 2014 8 james michael brad jacques big data next frontier innovation competition productivity new york ny mckinsey global institute 2011 9 rouse 2011 machine learning deﬁnition online available 10 rouse 2009 predictive analytics deﬁnition online available 11 grolinger hayes higashino l heureux allison capretz challenge mapreduce big data proc ieee world congr service service jun 2014 pp 12 dean ghemawat mapreduce simpliﬁed data processing large cluster proc symp oper syst design 2004 pp 13 shvachko kuang radia chansler hadoop tributed ﬁle system proc ieee symp mass storage syst technol msst may 2010 pp 14 najafabadi villanustre khoshgoftaar seliya wald muharemagic deep learning application challenge big data analytics big data vol 2 no 1 1 2015 15 parker unexpected challenge large scale machine learning proc int workshop big data stream heterogeneous source mining algorithm programm model appl bigmine 2012 pp 16 sukumar machine learning big data era yet proc acm sigkdd conf knowl discovery data mining workshop data sci social good kdd 2014 pp 17 qiu wu ding xu feng survey machine learning big data processing eurasip adv signal vol 67 pp 2016 18 chen lin big data deep learning challenge spectives ieee access vol 2 pp 2014 19 gandomi haider beyond hype big data concept method analytics int inf vol 35 no 2 pp apr 2015 20 singh reddy survey platform big data analytics big data vol 2 no 1 pp 2015 21 de almeida bernardino big data open source platform proc ieee int congr big data jun 2015 pp 22 fan bifet mining big data current status forecast future sigkdd exploration vol 14 no 2 pp 2012 23 wu zhu wu ding data mining big data ieee trans knowl data vol 26 no 1 pp 2014 24 narasimhan bhuvaneshwari big brief study int sci eng vol 5 no 9 pp 2014 25 ohlhorst big data analytics turning big data big money vol hoboken nj wiley 2012 26 demchenko grosso de laat membrey addressing big data issue scientiﬁc data infrastructure proc int conf ration technol syst ct may 2013 pp 27 khan uddin gupta gupta seven v big data understanding big data extract value proc zone conf amer soc eng apr 2014 pp 28 kune konugurthi agarwal chillarige buyya anatomy big data computing pract vol 46 no 1 pp 2016 29 tsang kwok cheung core vector machine fast svm training large data set mach learn vol 6 pp apr 2005 30 chu et machine learning multicore proc conf adv neural inf process syst nip 2006 pp 31 zaharia et resilient distributed datasets tion cluster computing proc usenix conf netw syst design implement nsdi 2012 2 32 zaharia chowdhury franklin shenker stoica spark cluster computing working set proc usenix conf hot topic cloud 2010 10 33 kumar gluck deshpande lin hone scaling hadoop system proc vldb endowment vol 6 no 12 pp 2013 34 ghanavati wong chen wang perng tive integrated method learning big imbalanced data proc ieee int congr big data jun 2014 pp 35 japkowicz stephen class imbalance problem tematic study intell data vol 6 no 5 pp 2002 36 baughman chuang dixon benz basilico deepqa jeopardy gamiﬁcation perspective ieee trans comput intell ai game vol 6 no 1 pp mar 2014 37 domingo useful thing know machine learning commun acm vol 55 no 10 pp 2012 38 hughes mean accuracy statistical pattern recognizers ieee trans inf theory vol 14 no 1 pp 1968 39 fan han liu challenge big data analysis nat sci vol 1 no 2 pp 2014 40 ratner statistical data mining technique better predictive modeling analysis big data boca raton fl crc press 2011 41 kiang comparative assessment classiﬁcation method decision support vol 35 no 4 pp jul 2003 42 leskovec rajaraman ullman mining massive datasets vol cambridge cambridge univ press 2014 43 dunn multiple comparison among mean amer statist vol 56 no 293 pp 1961 44 calude longo deluge spurious correlation big data found pp mar 2016 45 domingo uniﬁed decomposition tions proc int conf mach learn icml 2000 pp 46 franklin element statistical learning data mining inference prediction math vol 27 no 2 pp 2005 47 grolinger higashino tiwari capretz data management cloud environment nosql newsql data store cloud syst vol 2 no 1 22 2013 48 zheng methodology data fusion overview ieee trans big data vol 1 no 1 pp mar 2015 49 swan quantiﬁed self fundamental disruption big data ence biological discovery big data vol 1 no 2 pp 2013 50 geng incremental learning encyclopedia biometrics new york ny usa springer 2009 pp 51 gu sheng wang ho osman li mental learning vector regression neural vol 67 pp jul 2015 52 marz 2014 apache storm online available org 53 neumeyer robbins nair kesari distributed stream computing platform proc ieee int conf data mining icdm 2010 pp 54 gama e bifet pechenizkiy bouchachia survey concept drift adaptation acm comput vol 46 no 4 pp 2014 55 tsymbal problem concept drift deﬁnitions related work dept comput trinity college dublin dublin ireland tech 2004 vol 106 56 grolinger l heureux capretz seewald energy forecasting event venue big data prediction accuracy energy building vol 112 pp volume 5 2017 7795 l heureux et al machine learning big data challenge approach 57 dongre malik review real time data stream classiﬁcation adapting various concept drift scenario proc ieee int adv comput conf iacc 2014 pp 58 lavaire singh yousef singh yue sional scalability supervised unsupervised concept drift detection empirical study proc ieee int conf big data big data 2015 pp 59 clauset brief primer probability distribution santa fe santa fe nm usa tech csci 2011 60 ghahramani probabilistic machine learning artiﬁcial gence nature vol 521 no 7553 pp 2015 61 dundar krishnapuram bi rao learning classiﬁers training data not iid proc int joint conf artif intell ijcai 2007 pp 62 wang crawl purawat nguyen altintas big data provenance challenge state art opportunity proc ieee int conf big data big data 2015 pp 63 buneman khanna tan data provenance some basic issue fst tc 2000 foundation software technology theoretical computer science berlin germany springer 2000 pp 64 park ikeda widom ramp system capturing tracing provenance mapreduce workﬂows proc vldb endowment vol 4 no 12 pp 2011 65 cao lu lin wang wen socialhelix visual analysis sentiment divergence social medium j vol 18 no 2 pp may 2015 66 schroeck shockley smart tufano analytics use big data ibm global business vice saïd business school univ oxford tech 00 2012 pp 67 lovelace birkin cross clarke big noise big data toward veriﬁcation large data set understanding regional retail ﬂows geogr vol 48 no 1 pp 2016 68 witten frank hall pal data mining practical machine learning tool technique san mateo ca morgan kaufmann 2016 69 barga fontama tok cortana analytics predictive analytics microsoft azure machine learning berkeley ca usa apress 2015 pp 70 google 2016 google cloud machine learning online available 71 amazon web service 2016 amazon machine learning online available 72 ibm 2014 ibm watson ecosystem program online available 73 r core team r language environment statistical computing vienna austria 2015 vol 1 74 matlab mathworks natick usa 2016 75 hall frank holmes pfahringer reutemann witten weka data mining software update acm sigkdd exploration vol 11 no 1 pp 2009 76 labrinidis jagadish challenge opportunity big data proc vldb endowment vol 5 no 12 pp 2012 77 chen zhang application challenge technique technology survey big data inf vol 275 pp 2014 78 bingham mannila random projection dimensionality reduction proc acm sigkdd int conf knowl discovery data mining kdd 2001 pp 79 liu motoda instance selection construction data mining vol new york ny usa springer 2013 80 buades coll morel review image denoising algorithm new one multiscale model vol 4 no 2 pp 2005 81 nvidia 2016 gpu application transforming computational research engineering online available 82 jedhe ramamoorthy varghese scalable high throughput ﬁrewall fpga proc ieee symp custom comput mach fccm apr 2008 pp 83 gesmundo tomeh hadoopperceptron toolkit tributed perceptron training prediction mapreduce proc demonstration conf eur chapter assoc comput linguistics 2012 pp 84 ghoting kambadur pednault kannan nimble toolkit implementation parallel data mining machine learning algorithm mapreduce proc acm sigkdd int conf knowl discovery data mining kdd 2011 pp 85 bu howe ernst haloop efﬁcient iterative data processing large cluster proc vldb endowment vol 3 no pp 2010 86 ekanayake et twister proc acm int symp high perform distrib comput hpdc 2010 pp 87 malewicz et pregel system graph processing proc int conf manage data sigmod 2010 pp 88 apache 2016 apache giraph online available 89 gorawski gorawska pasterak survey data stream processing tool information science system cham switzerland springer 2014 pp 90 cugola margara processing ﬂows information data stream complex event processing acm comput vol 44 no 3 15 2012 91 singer srebro cotter pegasos primal estimated solver svm math vol 127 no 1 pp 2010 92 friedman hastie tibshirani regularization path eralized linear model via coordinate descent statist vol 33 no 1 pp 2010 93 apache 2016 apache mahout online available 94 2016 online available 95 xing et petuum new platform distributed machine learning big data ieee trans big data vol 1 no 2 pp jun 2015 96 langford li strehl 2007 vowpal wabbit online learning project online available 97 de francisci morale bifet samoa scalable advanced massive online analysis mach learn vol 16 pp 2015 98 abadi et al mar 2016 tensorflow machine learning heterogeneous distributed online available 99 deng li machine learning paradigm speech recognition overview ieee trans audio speech language vol 21 no 5 pp may 2013 100 bengio courville vincent representation learning review new perspective ieee trans pattern anal mach vol 35 no 8 pp 2013 101 goodfellow bengio courville deep learning cambridge usa mit press 2016 102 le 2015 tutorial deep learning part 2 autoencoders convolutional neural network recurrent neural network online available 103 salakhutdinov hinton deep boltzmann machine proc int conf artif intell 2009 pp 104 hinton deep belief net encyclopedia machine learning sammut webb ed boston usa springer 2010 pp 105 han mao dally deep compression compressing deep neural network pruning trained quantization huffman coding corr vol 2015 106 read bifet deep learning data stream proc annu acm symp appl 2015 pp 107 mirza lin liu ensemble subset online sequential extreme learning machine class imbalance concept drift rocomputing vol 149 pp 2015 108 kanoun van der schaar streaming application scheduling online learning concept drift detection proc design autom test eur conf exhibit date 2015 pp 109 bottou vapnik local learning algorithm neural vol 4 no 6 pp 1992 7796 volume 5 2017 l heureux et al machine learning big data challenge approach 110 huang yang king lyu local learning global learning introduction margin machine support vector machine theory application berlin germany springer 2005 pp 111 poulet random local svms classifying large datasets future data security engineering vol cham switzerland springer 2015 pp 112 elattar goulermas wu electric load forecasting based locally weighted support vector regression ieee trans man cybern c appl vol 40 no 4 pp jul 2010 113 grolinger capretz seewald energy tion prediction big data balancing prediction accuracy putational resource proc ieee int congr big data bigdata congress jun 2016 pp 114 torrey shavlik handbook research machine learning application trend hershey pa igi global 2010 115 yang chu zhang xia wang tan fer learning big data proc int conf digit inf age icdim 2015 pp 116 thrun pratt learning learn norwell kluwer 1998 117 silver yang li lifelong machine learning tems beyond learning algorithm proc aaai spring 2013 pp 118 khan durrani khalid aziz lifelong aspect extraction big data knowledge engineering complex adapt syst vol 4 no 1 pp 2016 119 chen liu topic modeling using topic many domain lifelong learning big data proc int conf mach 2014 pp 120 suthaharan big data classiﬁcation problem challenge work intrusion prediction machine learning acm sigmetrics perform eval vol 41 no 4 pp 2014 121 dietterich ensemble method machine learning multiple classiﬁer system vol london 2000 pp 122 sewell ensemble learning dept comput ucl london tech 2011 12 123 waske benediktsson fusion support vector machine classiﬁcation multisensor data ieee trans geosci remote vol 45 no 12 pp 2007 124 tang xu zhuang bayesian network structure learning big data reservoir sampling based ensemble method proc int conf database syst adv dallas tx usa apr 2016 pp 125 zang zhang zhou guo comparative study incremental ensemble learning data stream case study big data vol 1 no 1 5 2014 126 alabdulrahman comparative study ensemble active learning thesis sch elect eng comput univ ottawa ottawa canada 2014 127 gruber logan jarrín monge hernán ensemble learning inverse probability weight marginal structural modeling large observational datasets statist vol 34 no 1 pp 2015 128 bachmann contextual collaborative ﬁltering recommender system thesis dept elect comput eng univ western ontario london canada 2017 129 wu et al 2016 google neural machine translation system bridging gap human machine online available 130 saeedi ghasemzadeh gebremedhin transfer learning algorithm autonomous reconﬁguration wearable tems proc ieee int conf big data big data 2016 pp alexandra l heureux received degree software engineering western university canada 2013 2015 respectively currently pursuing degree current research interest include big data machine learning data analytics concept drift katarina grolinger received degree mechanical engineering university zagreb croatia degree software engineering western university canada currently assistant professor western university also fellow also certiﬁed oracle database tor ten year industry experience database administration software ment research interest include nosql data store big data ment internet thing data analytics cloud computing hany elyamany 06 received degree computational science suez canal university ismailia egypt degree computer science sham university egypt degree software neering western university canada ha involved software engineering area academia industry 20 year currently fellow western university also associate professor puter science department suez canal university research interest include architecture data mining cloud computing security miriam capretz received degree unicamp brazil degree university durham ha involved software engineering area 35 year wa university aizu japan currently professor department electrical computer neering western university canada current research interest include cloud computing big data service oriented architecture privacy security ha involved organization workshop symposium ha serving program committee international conference volume 5 2017 7797