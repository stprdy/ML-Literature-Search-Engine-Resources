annual review fluid mechanic machine learning fluid mechanic steven bernd petros mechanical engineering university washington seattle washington 98195 usa laboratoire informatique pour la mécanique et le science de l ingénieur cnrs upr 3251 université orsay france für strömungsmechanik und echnische akustik echnische universität berlin berlin germany science engineering laboratory eth zurich zurich switzerland email petros annu rev fluid mech 2020 first published review advance september 12 2019 annual review fluid mechanic online 060214 copyright 2020 annual review right reserved keywords machine learning modeling optimization control abstract field fluid mechanic rapidly advancing driven unprecedented volume data experiment field measurement ulations multiple spatiotemporal scale machine learning ml offer wealth technique extract information data lated knowledge underlying fluid mechanic moreover ml algorithm augment domain knowledge automate task related flow control optimization article present overview past tory current development emerging opportunity ml fluid chanics outline fundamental ml methodology discus us understanding modeling optimizing controlling fluid flow strength limitation method addressed tive scientific inquiry considers data inherent part ing experiment simulation ml provides powerful processing framework augment possibly even transform current line fluid mechanic research industrial application 477 machine learning algorithm process extract information data facilitate automation task augment human domain knowledge supervised learning learning data labeled expert knowledge providing corrective information algorithm semisupervised learning learning partially labeled data generative adversarial network interaction machine environment reinforcement learning unsupervised learning learning without labeled training data introduction fluid mechanic ha traditionally dealt massive amount data experiment field surements numerical simulation indeed past decade big data reality fluid mechanic research pollard et al 2016 due ing architecture advance experimental measurement capability past 50 year many technique developed handle data ranging advanced algorithm data processing compression fluid mechanic database perlman et al 2007 wu moin 2008 however analysis fluid mechanic data ha relied large extent domain expertise statistical analysis heuristic algorithm growth data today widespread across scientific discipline gaining insight actionable information data ha become new mode scientific inquiry well mercial opportunity generation experiencing unprecedented confluence vast increasing volume data b advance computational hardware reduced cost putation data storage transfer c sophisticated algorithm abundance open source software benchmark problem e significant ongoing investment industry problem solving advance turn fueled renewed interest progress field machine learning ml extract information data ml rapidly making inroad fluid mechanic learning algorithm may categorized supervised semisupervised unsupervised learning see figure 1 depending information available data learning machine lm ml provides modular agile modeling framework tailored address many challenge fluid mechanic modeling experimental data processing shape optimization turbulence closure modeling control scientific inquiry shift first principle approach may draw parallel development merical method solve equation fluid dynamic fluid mechanic stand benefit learning algorithm return present challenge may advance algorithm complement human understanding engineering intuition support vector machine decision tree random forest neural network neighbor linear generalized linear gaussian process linear control genetic algorithm deep model predictive control estimation distribution algorithm evolutionary strategy markov decision process deep ment learning autoencoder map diffusion map generative adversarial network spectral clustering supervised semisupervised unsupervised classiﬁcation regression optimization control reinforcement learning generative model clustering dimensionality reduction figure 1 machine learning algorithm may categorized supervised unsupervised semisupervised depending extent type information available learning process abbreviation pca principal component analysis pod proper orthogonal decomposition 478 brunton noack koumoutsakos model representation system term one balancing accuracy efficiency perceptron first learning machine network binary decision unit used classification addition outlining success must note importance understanding learning algorithm work method succeed fail important balance excitement capability ml reality application fluid mechanic open challenging field context also highlight benefit incorporating domain knowledge fluid mechanic learning algorithm envision fluid mechanic community contribute advance ml reminiscent advance numerical method last century historical overview interface ml fluid dynamic ha long possibly surprising history early kolmogorov founder statistical learning theory considered turbulence one prime application domain kolmogorov 1941 advance ml characterized two distinct development one side may distinguish cybernetics wiener 1965 expert system designed emulate thinking process human brain side machine perceptron rosenblatt 1958 aimed automate process classification regression use perceptrons classification created significant excitement however excitement wa quenched finding capability severe limitation minsky papert 1969 perceptrons only able learn linearly arable function not capable learning xor function wa known multilayer perceptrons could learn xor function perhaps advancement wa limited given computational resource time recurring theme ml research reduced est perceptrons wa soon accompanied reduced interest artificial intelligence ai general another branch ml closely related budding idea cybernetics early wa pioneered two graduate student ingo rechenberg schwefel echnical university berlin performed experiment wind tunnel corrugated structure composed five linked plate goal finding optimal angle reduce drag see figure 2 breakthrough involved adding random variation angle randomness wa generated using galton board analog random number generator importantly size variance wa learned based success rate brilliance work rechenberg schwefel ha received little recognition fluid mechanic community even though significant number application fluid mechanic aerodynamics use idea traced back work renewed interest potential ai aerodynamics application materialized almost neously early development computational fluid dynamic early attention wa given expert system assist aerodynamic design development process mehta kutler 1984 indirect link fluid mechanic ml wa lighthill report 1974 criticized ai program united kingdom not delivering grand claim report played major role reduced funding interest ai united kingdom subsequently united state known ai winter lighthill main argument wa based perception ai would never able address challenge combinatorial explosion possible configuration parameter space used limitation guage processing system time key demonstration failure ai lighthill defense 40 year ago power modern computer know today may difficult fathom indeed today one may watch lighthill speech internet ml algorithm automatically provides caption machine learning fluid mechanic 479 neural network computational architecture based loosely biological network neuron nonlinear regression deep learning neural network multiple layer used create powerful hierarchical representation varying level abstraction figure 2 first example learning automation experimental fluid mechanic rechenberg 1964 experiment optimally corrugated plate drag reduction using galtonbrett galton board analog random number generator figure reprinted permission rechenberg 1973 reawakening interest ml neural network nns particular came late development backpropagation algorithm rumelhart et al 1986 enabled training nns multiple layer even though early day two layer norm source stimulus work hopfield 1982 gardner 1988 hinton sejnowski 1986 developed link ml algorithm statistical chanics however development not attract many researcher fluid mechanic early number application nns problem developed context trajectory analysis classification particle tracking velocimetry ptv ticle image velocimetry piv eo et al 1991 grant pan 1995 well identifying phase configuration multiphase flow bishop james 1993 link proper thogonal decomposition pod linear nns baldi hornik 1989 wa exploited order reconstruct turbulence flow field flow region channel flow using information milano koumoutsakos 2002 application wa one first also use multiple layer neuron improve compression result marking perhaps first use deep learning known today field fluid mechanic past year experienced renewed blossoming ml application fluid mechanic much interest attributed remarkable performance deep learning architecture hierarchically extract informative feature data ha led several advance field social science company prediction key financial factor fluid mechanic not field rapidly becoming data rich believe confluence first principle approach unique ha potential transform fluid mechanic ml 480 brunton noack koumoutsakos reinforcement learning agent learns policy maximize reward interacting environment challenge opportunity machine learning fluid dynamic fluid dynamic present challenge differ tackled many application ml image recognition advertising fluid flow often important precisely quantify underlying physical mechanism order analyze furthermore fluid flow exhibit complex multiscale phenomenon understanding control remain largely solved unsteady flow field require algorithm capable addressing nonlinearities multiple spatiotemporal scale may not present popular ml addition many nent application ml playing game go rely inexpensive system evaluation exhaustive categorization process must learned not case fluid experiment may difficult repeat automate simulation may require supercomputer operating extended period time ml ha also become instrumental robotics algorithm reinforcement learning rl used routinely autonomous driving flight many robot operate fluid appears subtlety fluid dynamic not presently major concern design reminiscent pioneering day flight solution imitating natural form process often norm see sidebar titled learning fluid mechanic living organism chine believe deeper understanding exploitation fluid mechanic become critical design robotic device energy consumption reliability complex flow environment become concern context flow control actively passively manipulating flow dynamic gineering objective may change nature system making prediction based data uncontrolled system impossible although flow data vast some dimension spatial resolution may sparse others example may expensive perform parametric study furthermore flow data highly heterogeneous requiring special care ing type lm addition many fluid system nonstationary even stationary flow may prohibitively expensive obtain statistically converged result fluid dynamic central transportation health defense system therefore essential ml solution interpretable explainable generalizable moreover learning fluid mechanic living organism machine bird bat insect fish whale aquatic aerial perform remarkable feat fluid ulation optimizing controlling shape motion harness unsteady fluid force agile propulsion efficient migration exquisite maneuver range fluid flow optimization control observed biology breathtaking ha inspired human millennium organism learn manipulate flow environment date know only one specie manipulates fluid knowledge equation human innovating engineering device harness fluid since dawn recorded history dam irrigation mill sailing early effort achieved intuitive design although recent quantitative analysis design enabled revolution performance past hundred year indeed engineering fluid system mark human achievement however serious challenge associated analysis fluid including high dimensionality nonlinearity defy solution limit optimization control beginning new millennium increasingly powerful tool machine learning optimization learning learn experience machine learning fluid mechanic 481 often necessary provide guarantee performance presently rare indeed poignant lack convergence result analysis guarantee many ml algorithm also important consider whether model used interpolation within parameter regime extrapolation considerably challenging finally emphasize importance withheld data set prevent overfitting ml suggest nonexhaustive list challenge need not barrier contrary provide strong motivation development effective ml technique technique likely impact several discipline able solve fluid mechanic problem application ml system known physic fluid mechanic may provide deeper theoretical insight algorithm also believe hybrid method combine ml first principle model fertile ground development review structured follows section 2 outline fundamental algorithm ml followed discussion application flow modeling section 3 optimization control section 4 provide summary outlook field section 5 machine learning fundamental learning problem formulated process estimating association input output parameter system using limited number observation cherkassky mulier 2007 distinguish generator sample system question lm figure emphasize approximation lm fundamentally stochastic learning process summarized minimization risk functional r w l φ x w p x dxdy data x input output sample probability distribution p φ x w defines structure w parameter lm loss function l balance iou learning objective accuracy simplicity smoothness emphasize risk functional weighted probability distribution p x also constrains predictive pabilities lm various type learning algorithm grouped three major category supervised unsupervised semisupervised figure distinction nify degree external supervisory information expert available lm sample generator probability input p x learning machine functional form weight w φ x w system conditional probability input p input vector x learning machine output ˆ system output figure 3 learning problem learning machine us input sample generator observation system generate approximation output figure based idea cherkassky mulier 2007 482 brunton noack koumoutsakos supervised learning supervised learning implies availability corrective information lm simplest common form implies labeled training data label corresponding output lm minimization cost function depends training data determine unknown parameter lm context supervised learning date back sion interpolation method proposed century ago gauss meijering 2002 commonly employed loss function l φ x w x w alternative loss function may reflect different constraint lm sparsity hastie et al 2009 brunton kutz 2019 choice approximation function reflects prior knowledge data choice linear nonlinear method directly bear putational cost associated learning method neural network nns arguably method supervised ing fundamental nonlinear function approximators recent year several effort dedicated understanding effectiveness universal approximation rem hornik et al 1989 state any function may approximated sufficiently large deep network recent work ha shown sparsely connected deep nns information nonlinear approximators wide range function system bölcskei et al 2019 power flexibility nns emanate modular structure based neuron central building element caricature neuron human brain neuron receives input process activation function produce output multiple neuron combined different structure reflect knowledge problem type data feedforward network among common structure composed layer neuron weighted output one layer input next layer nn architecture input layer receives data output layer produce diction nonlinear optimization method backpropagation rumelhart et al 1986 used identify network weight minimize error prediction labeled training data deep nns involve multiple layer various type nonlinear activation tions activation function expressed term convolutional kernel powerful class network emerges namely convolutional neural network cnns great success image pattern recognition krizhevsky et al 2012 goodfellow et al 2016 grossberg et al 1988 recurrent neural network rnns depicted figure 4 particular interest fluid chanics operate sequence data image video time series etc weight obtained backpropagation quite successful ral language processing speech recognition architecture take account inherent order data thus augmenting some pioneering application classical nns signal processing et al 1992 however effectiveness ha hindered ishing exploding gradient emerge training renewed interest rnns largely attributed development long memory lstm hochreiter schmidhuber 1997 algorithm deploy cell state gating mechanism store forget information past input thus alleviating problem gradient transmission information standard rnns suffer extended architecture called machine learning fluid mechanic 483 lstm lstm ct ht ht rnn rnn ht ht xt xt tanh tanh tanh σ σ σ figure 4 recurrent neural network rnns time series prediction long memory lstm regularization abbreviation previous cell memory ct current cell memory previous cell output ht current cell output xt input vector σ sigmoid figure based idea hochreiter schmidhuber 1997 multidimensional lstm network graf et al 2007 wa proposed efficiently handle dimensional spatiotemporal data several potent alternative rnns appeared year echo state network ha used success predicting output several namical system pathak et al 2018 classification support vector machine random forest classification pervised learning task determine label category set measurement priori labeled training data perhaps oldest method learning starting ceptron rosenblatt 1958 could classify two type linearly separable data wo fundamental classification algorithm support vector machine svms schölkopf smola 2002 random forest breiman 2001 widely adopted industry lem specified following loss functional expressed two class l φ x w 0 φ x w 1 φ x w output lm indicator class data belong risk functional quantifies probability misclassification task minimize risk based training data suitable choice φ x w random forest based ensemble decision tree hierarchically split data using simple conditional statement decision interpretable fast evaluate scale context classification svm map data feature space linear classification possible unsupervised learning learning task implies extraction feature data specifying certain global criterion without need supervision label result type problem involved include dimensionality reduction quantization clustering dimensionality reduction proper orthogonal decomposition principal nent analysis autoencoders extraction flow feature experimental data simulation cornerstone flow modeling moreover identifying dimensional representation data used preprocessing task supervised learning algorithm dimensionality reduction also viewed 484 brunton noack koumoutsakos autoencoder neural network architecture used compress decompress data linear nonlinear alternative proper orthogonal decomposition retain eigenvectors 1 n n n 1 xn sui λiui 1 n n n 1 xn x xn x x deep encoder deep decoder x input x ˆ output encoder u decoder v z latent variable φ x ψ z x input x ˆ output figure 5 left versus shallow autoencoders center deep autoencoders right node activation function shallow autoencoder linear u v matrix minimize loss function x node activation function may nonlinear minimizing loss function φ x input x reduced z note requires solution eigenvalue equation neuron module extended nonlinear activation function multiple node layer abbreviation pca principal component analysis pod proper orthogonal decomposition covariance matrix data u linear encoder ui eigenvector v linear decoder x input vector xn input vector x mean input data ˆ x autoencoder reconstruction z latent variable λi eigenvalue φ x deep encoder ψ x deep decoder figure based idea bishop james 1993 bottleneck data processed resentation mapped back ambient dimension classical pod algorithm belongs category learning discussed section pod linear pal component analysis pca widely known formulated nn autoencoder linear activation function linearly weighted input trained stochastic gradient descent see figure 5 formulation algorithmic alternative ear problem term nns offer direct route nonlinear regime deep learning adding layer nonlinear activation function work unsupervised learning algorithm seen limited use fluid mechanic community believe deserve recent year ml community ha oped numerous autoencoders properly matched possible feature flow field lead significant insight modeling stationary data dimensionality reduction ii discrete principal curve map mapping data representation tured explicit shaping space possibly reflecting priori knowledge subspace technique seen extension linear coder encoder decoder nonlinear function nonlinearity may ever come expense losing inverse relationship encoder decoder function one strength linear pca alternative define decoder approximation inverse encoder leading method principal curve principal curve structure data projected encoding step learning algorithm turn decoding step amount approximation inverse mapping adding example some smoothing onto principal curve important version process map som introduced grossberg 1976 kohonen 1995 som projection subspace described finite set value specified connectivity machine learning fluid mechanic 485 architecture distance metric encoder step amount identifying data point closest node point som decoder step weighted regression estimate using example kernel function take advantage specified distance metric map node modifies node center process iterated empirical risk autoencoder ha minimized som capability exemplified comparing linear pca set point linear pca provide approximation least square straight line point whereas som map point onto curved line better approximates data note som extended area yond floating point data offer interesting way creating database based feature flow field clustering vector quantization clustering unsupervised learning technique identifies similar group data common algorithm clustering partition data k cluster observation belongs cluster nearest troid resulting partition data space voronoi cell vector quantizers identify representative point data partitioned termined number cluster point used instead full data set future sample approximated vector quantizer φ x w provides mapping data x coordinate cluster center loss function usually squared distortion data cluster center must minimized identify parameter quantizer l φ x w x w note vector quantization data reduction method not necessarily employed sionality reduction latter learning problem seek identify feature data whereas quantization amount finding representative cluster data vector quantization must also distinguished clustering former number desired center determined priori whereas clustering aim identify meaningful ings data grouping represented some prototype clustering quantization strong similarity semisupervised learning semisupervised learning algorithm operate partial supervision either limited beled training data corrective information environment wo algorithm category generative adversarial network gans rl case lm trained process discussed generative adversarial network gans learning algorithm result ative model model produce data according probability distribution mimic data used training lm composed two network compete game goodfellow et al 2014 generative network produce candidate data example evaluated discriminative critic network optimize certain task generative network training objective synthesize novel example data fool discriminative network misclassifying belonging true data distribution 486 brunton noack koumoutsakos weight network obtained process inspired game theory called adversarial learning final objective gan training process identify tive model produce output reflects underlying system labeled data provided discriminator network function minimized gence two distribution ensuing game discriminator aim maximize probability discriminating true data data produced generator generator aim minimize probability generative discriminative work essentially train initialization labeled training data procedure often called process add appeal gans time one must cautious whether equilibrium ever reached mentioned game training algorithm large amount data help process moment no guarantee convergence reinforcement learning rl mathematical framework problem solving sutton barto 2018 implies interaction agent environment rl agent ha repertoire action perceives state unlike supervised learning agent doe not labeled information correct action instead learns experience form reward may infrequent partial thus termed semisupervised learning moreover agent concerned not only uncovering pattern action environment also maximizing reward rl closely linked dynamic programming bellman 1952 also model interaction environment markov decision process unlike dynamic programming rl doe not require model dynamic markov transition model proceeds repeated interaction environment trial error believe precisely approximation make highly suitable complex problem fluid dynamic two central element rl agent policy mapping π state system optimal action value function v represents utility reaching state maximizing agent reward game one key application rl exemplify strength limitation one early success rl backgammon learner esauro 1992 program started scratch novice player trained playing couple million time computer backgammon olympiad eventually became comparable three best human player world recent year advance computing deep nn architecture produced agent capable performing human performance video game strategy game much complicated backgammon go mnih et al 2015 ai gym mnih et al 2015 silver et al 2016 important emphasize rl requires significant computational resource due large number episode required properly account interaction agent environment cost may trivial game may prohibitive experiment flow simulation situation rapidly changing verma et al 2018 core remaining challenge rl credit assignment l tca problem cially reward sparse delayed time example consider case perching bird robot ltca implies inference long sequence state action causal tions individual decision reward several effort address issue augmenting original sparsely rewarded objective densely rewarded subgoals schaul et al 2015 lated issue proper accounting past experience agent actively form new policy novati et al 2019 machine learning fluid mechanic 487 stochastic optimization learning algorithm perspective optimization inherent part learning risk functional minimized order identify parameter lm however one link wish highlight view optimization search algorithm cast context learning algorithm specifically process learning probability distribution contains design point maximize certain objective connection wa pioneered rechenberg 1973 schwefel 1977 introduced evolution strategy e adapted variance search space based success rate experiment process also reminiscent operation selection mutation key ingredient genetic algorithm gas holland 1975 genetic programming koza 1992 e gas considered hybrid gradient search strategy may effectively march downhill toward minimum latin hypercube monte carlo sampling method maximally explore search space genetic programming wa developed late koza phd student john holland netic programming generalized parameter optimization function optimization initially coded tree operation koza 1992 critical aspect algorithm rely erative construction probability distribution based data value objective function iterative construction lengthy practically impossible problem expensive objective function evaluation past 20 year e gas begun converge estimation distribution algorithm edas covariance matrix adaptation e algorithm ostermeier et al 1994 hansen et al 2003 prominent example e using adaptive estimation variance matrix gaussian probability distribution guide search optimal parameter covariance matrix adapted iteratively using best point iteration e closely related several algorithm mixed bayesian optimization algorithm pelikan et al 2004 reader referred kern et al 2004 comparative review recent year line work ha evolved generalized mization igo framework ollivier et al 2017 igo algorithm allow family probability distribution whose parameter learned optimization process maintain cost function invariance major design principle resulting algorithm make no assumption objective function optimized flow equivalent stochastic gradient scent technique proven effective several simplified benchmark problem however scaling remains unclear guarantee convergence cost tion landscape encountered complex fluid dynamic problem note also interest deploying optimization method minimize cost function often associated classical ml task salimans et al 2017 important topic not covered bayesian inference gaussian process several learning algorithm review doe not address demand particular attention fluid mechanic community first foremost wish mention bayesian inference aim inform model structure parameter data bilistic framework bayesian inference fundamental uncertainty quantification also fundamentally learning method data used adapt model fact alternative view also possible every ml framework cast bayesian framework barber 2012 theodoridis 2015 optimization algorithm outlined review provide direct link whereas optimization algorithm aim provide best parameter model given data stochastic manner bayesian inference aim provide full probability distribution 488 brunton noack koumoutsakos may argued bayesian inference may even powerful ml provides bility distribution parameter leading robust prediction rather single value usually case classical ml algorithm however key drawback bayesian inference computational cost involves sampling integration space prohibitive expensive function evaluation wind tunnel experiment direct numerical simulation along line one must mention gaussian process gps resemble method regression however gps develop kernel tively based available data also provide probability distribution respective model parameter gps used extensively problem related lem may considered competitor albeit costly rnns finally note use gps surrogate expensive cost function optimization problem using e gas flow modeling machine learning first principle conservation law dominant building block flow eling past century however high reynolds number simulation using prominent model fluid mechanic equation beyond current computational resource alternative perform simulation based tions equation often practiced turbulence modeling laboratory experiment specific configuration however simulation experiment expensive iterative mization simulation often slow control brunton noack 2015 sequently considerable effort ha placed obtaining accurate efficient model capture essential flow mechanism fraction cost rowley dawson 2016 ml provides new avenue dimensionality reduction modeling fluid chanics providing concise framework complement extends existing methodology distinguish two complementary effort dimensionality reduction modeling dimensionality reduction involves extracting key feature dominant pattern may used reduced coordinate fluid compactly efficiently described aira et al 2017 modeling describes spatiotemporal evolution flow parametrized dynamical system although may also involve developing statistical map parameter averaged quantity drag significant effort identify coordinate transformation reduction simplify dynamic capture essential flow physic pod notable example lumley 1970 model reduction galerkin projection equation onto orthogonal basis pod mode benefit close connection governing equation however intrusive requiring human expertise develop model working simulation ml provides modular algorithm may used system identification modeling unique aspect modeling fluid flow include availability partial prior knowledge governing equation constraint advance simulation capability experimental technique fluid dynamic becoming field thus becoming amenable ml algorithm review distinguish ml algorithm model flow kinematics tion flow feature b dynamic adoption various learning architecture flow feature extraction pattern recognition data mining core strength ml many technique oped ml community readily applicable spatiotemporal fluid data discus machine learning fluid mechanic 489 linear nonlinear dimensionality reduction technique followed clustering tion also consider accelerated measurement computation strategy well method process experimental flow field data dimensionality reduction linear nonlinear embeddings common approach fluid dynamic simulation modeling define orthogonal linear transformation physical coordinate modal basis pod provides orthogonal basis plex geometry based empirical measurement sirovich 1987 introduced snapshot pod reduces computation simple procedure involving singular value composition interestingly year sirovich used pod generate feature space classification human face foundation much modern computer vision sirovich kirby 1987 pod closely related algorithm pca one fundamental algorithm applied statistic ml describe correlation data recall pca expressed neural network called autoencoder compress data compact representation shown figure network embeds data latent space decodes latent space back original space network node linear encoder decoder constrained transpose one another autoencoder closely related standard decomposition baldi hornik 1989 see also figure 6 however structure nn autoencoder modular using nonlinear activation unit node possible develop nonlinear embeddings potentially providing compact coordinate observation led development one first application deep nns reconstruct velocity field turbulent channel flow using wall pressure shear milano koumoutsakos 2002 powerful autoencoders available today ml community link deserves exploration basis universal approximation theorem hornik et al 1989 state sufficiently large nn represent arbitrarily complex function deep nns flow snapshot pod mode autoencoder mode figure 6 unsupervised learning example merging two vortex top proper orthogonal decomposition pod mode middle respective mode linear autoencoder bottom note unlike pod mode autoencoder mode not orthogonal not ordered 490 brunton noack koumoutsakos interpretability degree model may understood interpreted expert human increasingly used obtain effective nonlinear coordinate complex flow ever deep learning often implies availability large volume training data far exceed parameter network resulting model usually good interpolation may not suitable extrapolation new input data different probability distribution training data see equation 1 many modern ml application image sification training data vast natural expect future classification task fall within interpolation training data example imagenet data set 2012 krizhevsky et al 2012 contained 15 million labeled image sparked current movement deep learning lecun et al 2015 despite abundance data experiment simulation fluid mechanic community still distanced working paradigm however may possible coming year curate large labeled fluid database facilitate deployment deep learning algorithm clustering classification clustering classification cornerstone ml dozen mature algorithm choose depending size data desired number category algorithm ha successfully employed kaiser et al 2014 develop discretization phase space fluid mixing layer representation term small number cluster enabled tractable markov transition model flow evolves time one state another cause cluster centroid exist data space possible associate cluster centroid physical flow field lending additional interpretability amsallem et al 2012 used clustering partition phase space separate region local base constructed resulting improved stability robustness parameter variation classification also widely used fluid dynamic distinguish various canonical behavior dynamic regime classification supervised learning approach labeled data used develop model sort new data one several category recently colvert et al 2018 investigated classification wake topology behind pitching airfoil local vorticity measurement using nns extension compared formance various type sensor alsalman et al 2018 wang hemati 2017 used algorithm detect exotic wake similarly nns combined dynamical system model detect flow disturbance estimate parameter hou et al 2019 related graph network approach fluid nair aira 2015 used community detection wake flow meena et al 2018 finally one earliest example ml classification fluid dynamic bright et al 2013 wa based sparse representation wright et al 2009 sparse randomized method parallel ml great stride sparse optimization randomized linear algebra ml sparse algorithm synergistic underlying representation facilitate sparse measurement manohar et al 2018 fast randomized computation halko et al 2011 decreasing amount data train execute model important fast decision required control context algorithm efficient acquisition reconstruction sparse signal pressed sensing donoho 2006 already leveraged compact representation bounded turbulence bourguignon et al 2014 flow reconstruction bai et al 2014 structure data also facilitates accelerated computation via randomized linear algebra halko et al 2011 mahoney 2011 matrix ha structure efficient matrix decomposition algorithm based random sampling closely related machine learning fluid mechanic 491 generalizability ability model generalize new example including unseen data newton second law f highly generalizable idea sparsity geometry sparse vector basic idea large matrix ha structure high probability structure preserved projecting column row onto random subspace facilitating efficient downstream computation randomized numerical method potential transform computational linear algebra providing accurate matrix position fraction cost deterministic method example randomized linear algebra may used efficiently compute singular value decomposition used compute pca rokhlin et al 2009 halko et al 2011 superresolution flow cleansing much ml focused imaging science viding robust approach improve resolution remove noise corruption based tistical inference superresolution denoising algorithm potential improve quality simulation experiment fluid superresolution involves inference image surements leveraging statistical structure training data several approach developed superresolution example based library example freeman et al 2002 sparse representation library yang et al 2010 recently cnns dong et al 2014 experimental flow field measurement piv adrian 1991 willert gharib 1991 provide compelling application tension local flow resolution size imaging could leverage expensive data smaller domain improve resolution larger imaging simulation le germano et al 1991 meneveau katz 2000 may also benefit superresolution fer structure inside cell required compute boundary condition recently fukami et al 2018 developed superresolution algorithm demonstrated effectiveness turbulent flow reconstruction showing energy spectrum accurately preserved one drawback superresolution often extremely costly putationally making useful application imaging may prohibitively expensive however improved approach may drive cost significantly note also xie et al 2018 recently employed gans superresolution processing experimental piv particle tracking ha also one first tions ml nns used fast piv knaak et al 1997 ptv labonté 1999 impressive demonstration lagrangian particle tracking ouellette et al 2006 recently deep cnns used construct velocity field piv image pair lee et al 2017 related approach also used detect spurious vector piv data liang et al 2003 remove outlier fill corrupt pixel modeling flow dynamic central goal modeling balance efficiency accuracy modeling physical system interpretability generalizability also critical consideration linear model nonlinear embeddings dynamic mode decomposition koopman analysis many classical technique system identification may considered ml model generalize beyond training data dynamic mode sition dmd schmid 2010 kutz et al 2016 modern approach extract spatiotemporal herent structure time series data fluid flow resulting linear model evolution dominant coherent structure dmd based regression equally valid experimental numerical data dmd closely related 492 brunton noack koumoutsakos koopman operator rowley et al 2009 mezic 2013 linear operator describes measurement function system evolve time dmd algorithm based linear flow field measurement direct measurement fluid velocity vorticity field resulting model may not able capture nonlinear transient recently ha concerted effort identify coordinate system nonlinear dynamic appears linear extended dmd williams et al 2015 variational approach conformation dynamic noé nüske 2013 nüske et al 2016 enrich model nonlinear measurement leveraging kernel method williams et al 2015 dictionary learning li et al 2017 special nonlinear measurement generally challenging represent deep learning architecture used identify nonlinear koopman coordinate system dynamic appear linear akeishi et al 2017 lusch et al 2018 mardt et al 2018 wehmeyer noé 2018 vampnet architecture mardt et al 2018 wehmeyer noé 2018 us autoencoder custom variational score identify koopman coordinate impressive protein folding example based performance vampnet fluid dynamic may benefit neighboring field molecular dynamic similar modeling issue including stochasticity dynamic separation timescales neural network modeling last three decade nns used model dynamical system fluid mechanic problem early example include use nns learn solution ordinary partial differential equation dissanayake 1994 et al 1998 lagaris et al 1998 note potential work ha not fully explored recent year advance chen et al 2018 raissi karniadakis 2018 including discrete network note also possibility using method uncover latent variable reduce number metric study often associated partial differential equation raissi et al 2019 nns also frequently employed nonlinear system identification technique narmax often used model fluid system glaz et al 2010 semeraro et al 2016 fluid mechanic nns widely used model heat transfer jambunathan et al 1996 turbomachinery pierret van den braembussche 1999 turbulent flow milano koumoutsakos 2002 lem aeronautics faller schreck 1996 rnns lstms hochreiter schmidhuber 1997 revolutionary speech recognition considered one landmark success ai currently ing used model dynamical system prediction extreme event vlachas et al 2018 wan et al 2018 interesting finding study combining model potent method outperforms component several study gans goodfellow et al 2014 also used capture physic wu et al 2018 gans potential aid modeling simulation turbulence kim et al 2018 though field nascent despite promise widespread use nns dynamical system several challenge main nns fundamentally interpolative function well approximated only span probability distribution sampled data used train thus caution exercised using nn model extrapolation task many computer vision speech recognition example training data vast nearly future task may viewed interpolation training data although scale training ha not achieved date fluid mechanic similarly nn model prone overfitting care must taken model sufficiently chosen test set best practice discussed goodfellow et al 2016 finally important explicitly incorporate partially known physic symmetry constraint conserved quantity machine learning fluid mechanic 493 parsimonious nonlinear model parsimony recurring theme mathematical physic hamilton principle least action apparent simplicity many governing equation contrast raw representational power nns ml algorithm also employed identify minimal model balance predictive accuracy model complexity venting overfitting promoting interpretability generalizability genetic programming wa recently used discover conservation law governing equation schmidt lipson 2009 sparse regression library candidate model ha also proposed identify cal system brunton et al 2016 partial differential equation rudy et al 2017 schaeffer 2017 loiseau brunton 2018 identified sparse model several flow system enforcing energy conservation constraint genetic programming sparse fication pareto analysis used identify model best model complexity measured number term predictive accuracy case physic known approach typically discovers correct governing equation providing exceptional generalizability compared leading algorithm ml closure model machine learning use ml develop turbulence closure active area research duraisamy et al 2019 extreme separation spatiotemporal scale turbulent flow make exceedingly costly resolve scale simulation even moore law decade away resolving scale relevant configuration aircraft submarine common truncate small scale model effect large scale closure model common approach include rans le however model may require careful tuning match data fully resolved simulation experiment ml ha used identify model discrepancy reynolds stress tensor rans model simulation ling empleton 2015 parish duraisamy 2016 ling et al xiao et al 2016 singh et al 2017 wang et al 2017 ling empleton 2015 compared svms adaboost decision tree random forest classify predict region high uncertainty reynolds stress tensor wang et al 2017 used random forest build supervised model discrepancy reynolds stress tensor xiao et al 2016 aged sparse online velocity measurement bayesian framework infer discrepancy related work parish duraisamy 2016 developed field inversion ml modeling work build corrective model based inverse modeling framework wa later used singh et al 2017 develop nn enhanced correction rans model excellent performance key result ling et al employed first deep network architecture many hidden layer model anisotropic reynolds stress tensor shown figure novel architecture incorporates multiplicative layer embed galilean variance tensor prediction provides innovative simple approach embed known physical symmetry invariance learning architecture ling et al believe essential future effort combine learning physic le closure maulik et al 2019 employed artificial nns predict turbulence source term coarsely resolved quantity challenge machine learning dynamical system applying ml model ical dynamical system pose several unique challenge opportunity model interpretability generalizability essential cornerstone physic model yield phenomenon not observed principle example exhibited parsimonious formulation classical mechanic newton second law 494 brunton noack koumoutsakos input layer output layer hidden layer b invariant input layer final hidden layer g n tensor input layer n merge output layer b hidden layer figure 7 comparison standard neural network architecture modified neural network identifying galilean invariant reynolds stress model b abbreviation b anisotropy tensor g n scalar coefficient weighing basis tensor n isotropic basis tensor five tensor invariant figure adapted permission ling et al system encountered unsteady fluid dynamic challenge multiscale dynamic sensitivity noise disturbance latent variable sients require careful attention applying ml technique ml dynamic distinguish two task discovering unknown physic improving model incorporating known physic many learning architecture not readily incorporate physical constraint form symmetry boundary condition global conservation law critical area continued development several recent work presented generalizable physic el battaglia et al 2018 flow optimization control using machine learning learning algorithm well suited flow optimization control problem involving box multimodal cost function algorithm iterative often require several order magnitude cost function evaluation algorithm bewley et al 2001 moreover not offer guarantee convergence suggest avoided technique adjoint method applicable time technique rl shown outperform even optimal flow control strategy novati et al 2019 indeed several class flow control optimization problem learning algorithm may method choice described machine learning fluid mechanic 495 optimization control boundary erased fast computer optimization control intimately related boundary becoming even le distinct ingly fast computer summarized tsiotras mesbahi 2017 195 interestingly distinction optimization control largely semantic ala one ha capability solving optimization problem fast enough fly close loop one ha principle feedback control law not surprisingly algorithm viewed solving optimization control problem based solely capability available hardware continued advent faster capable computer hardware architecture boundary optimization control become even blurred ever optimization embedded implementation feedback control classical problem control robustness model uncertainty time delay process measurement noise become paramount importance particularly aerospace system contrast flow modeling learning algorithm optimization control interact data sampling process several way first line modeling effort described earlier section ml applied develop explicit surrogate model relate cost function model nns amenable even method although often get stuck local minimum multifidelity algorithm perdikaris et al 2016 also employed combine surrogate cost function complete problem learning progress new data requested guided result optimization alternatively optimization control problem may described term learning probability distribution parameter minimize cost probability distribution constructed cost function sample obtained optimization process furthermore nonconvex optimization procedure currently employed train nonlinear lm well suited nonlinear optimization problem flow control remark line optimization control becoming blurred ability powerful computer see sidebar titled optimization control boundary erased fast computer however range critical spatiotemporal scale nonlinearity underlying process likely render optimization flow control challenge decade come stochastic flow optimization learning probability distribution stochastic optimization includes e gas originally developed based inspired principle however recent year algorithm placed learning framework kern et al 2004 stochastic optimization ha found widespread use engineering design particular many engineering problem involve cost function list application includes aerodynamic shape optimization giannakoglou et al 2006 uninhabited aerial vehicle uavs hamdaoui et al 2010 shape motion optimization artificial swimmer gazzola et al 2012 van rees et al 2015 improved power extraction crossflow turbine strom et al 2017 refer reader review article skinner 2018 extensive comparison stochastic optimization algorithm aerodynamics algorithm involve large number iteration benefit massively parallel computer architecture advance automation also facilitated application experimental strom et al 2017 martin gharib 2018 industrial setting bueche et al 496 brunton noack koumoutsakos 2002 note stochastic optimization algorithm well suited address experimental industrial challenge associated uncertainty unexpected system behavior partial description system environment exogenous disturbance hansen et al 2009 proposed approach enhance capability evolutionary algorithm online tion combustor test rig stochastic flow optimization continue benefit advance computer hardware experimental technique time convergence proof explainability reliability outstanding issue need taken consideration deploying algorithm fluid mechanic problem hybrid algorithm combine manner tic technique method may offer best strategy flow control problem flow control machine learning feedback flow control modifies behavior fluid dynamic system actuation informed sensor measurement feedback necessary stabilize unstable system ate sensor noise compensate external disturbance model uncertainty challenge flow control include state nonlinearity latent variable time delay ml algorithm used extensively control system identification sensor placement neural network control nns received significant attention system fication see section 3 control including application aerodynamics phan et al 1995 application nns turbulence flow control wa pioneered lee et al 1997 drag turbulent boundary layer wa reduced using local blowing suction based sensor control law wa learned known optimal information controller little loss overall network wa optimized drag reduction without incorporating any prior knowledge actuation command strategy led conceptually simple local opposition control eral study employ nns phasor control rabault et al 2019 even frequency need optimize many parameter price theoretical advantage proximating arbitrary nonlinear control law nn control may require exorbitant computational experimental resource configuration complex nonlinearities many sensor actuator time training time nns ha improved several order magnitude since early application warrant investigation potential flow control genetic algorithm control gas deployed solve several flow control problem require structure control law prespecified contain only adjustable parameter example use ga control design fluid wa used experimental mixing optimization step benard et al 2016 nn control learning time increase number parameter making challenging even prohibitive controller nonlinearities law signal history kalman filter multiple sensor actuator genetic programming ha used extensively active control engineering cation dracopoulos 1997 fleming purshouse 2002 recent year several flow control plant includes learning multifrequency actuation sensor feedback distributed control refer reader duriez et al 2016 description method noack 2018 overview plant remark control law obtained within test evaluation requiring only second wind tunnel machine learning fluid mechanic 497 flow control via reinforcement learning recent year rl ha advanced beyond realm game ha become fundamental mode problem solving growing number domain including reproduce dynamic hydrological system loucks et al 2005 actively control oscillatory laminar flow around bluff body guéniat et al 2016 study individual gazzola et al 2014 collective tion fish gazzola et al 2016 novati et al 2017 verma et al 2018 maximize range simulated reddy et al 2016 robotic reddy et al 2018 glider optimize kinematic motion uavs kim et al 2004 edrake et al 2009 optimize motion mers colabrese et al 2017 2018 figure 8 provides schematic rl compelling example related fluid mechanic deep reinforcement learning scheme application collective fish motion gaussian policy environment state agent πw w parameter deep neural network st mean action take action receive reward observe state standard deviation action st st σ st b figure 8 deep reinforcement learning schematic application study collective motion fish via equation b panel b adapted verma et al 2018 498 brunton noack koumoutsakos fluid mechanic knowledge essential application rl success failure hinge properly selecting state action reward reflect governing mechanism flow problem natural organism sensor visual system bird lateral line fish guide choice state sensor technology progress rapid pace algorithmic challenge may optimal sensor placement papadimitriou papadimitriou 2015 manohar et al 2018 action reflect flow actuation device may involve body deformation wing flapping reward may include energetic factor cost port proximity center fish school avoid predation computational cost rl remains challenge widespread adoption believe deficiency diated parallelism inherent rl growing interest method designed transferable simulation verma et al 2018 simulation related application richter et al 2016 bousmalis et al 2017 discussion outlook review present ml algorithm perspective fluid mechanic interface two field ha long history ha attracted renewed interest last year review address application ml problem flow modeling optimization control experiment simulation highlight some success ml critical fluid ic task dimensionality reduction feature extraction piv processing superresolution modeling turbulence closure shape optimization flow control discus lesson learned effort justifies current interest light technological advance time goal provide deeper understanding ml context fluid mechanic ml comprises optimization applied regression technique well suited nonlinear problem encountered fluid namics fluid mechanic expertise necessary formulate optimization regression problem ml algorithm present arsenal tool largely unexplored fluid mechanic research augment existing mode inquiry fluid mechanic knowledge tion law remain relevant era big data knowledge help frame precise question assist reducing large computational cost often associated application ml algorithm flow control optimization exploration visualization dimensional search space simplified ml increasingly abundant computing resource near future experience ml algorithm help frame new question fluid chanics extending linearized model linear approach nonlinear regime transition nonlinear realm ml facilitated abundance open source ware method prevalent openness ml community long term ml undoubtedly offer fresh look old problem fluid mechanic light data preting ml solution refining problem statement require fluid mechanic expertise word caution necessary balance current excitement research almost magical power ml ml algorithm always provide some kind answer any question based training may not even relevant question hand properly formulating question selecting data lm training critical component learning process applying ml algorithm fluid machine learning fluid mechanic 499 reproducibility process documenting procedure archiving code data others fully reproduce scientific result mechanic face numerous outstanding challenge opportunity although many field ml concerned raw predictive performance application fluid mechanic often require model explainable generalizable guarantee although deep learning undoubtedly become critical tool several aspect flow eling not ml deep learning important consider several factor choosing od including quality quantity data desired input output cost function optimized whether task involves interpolation extrapolation important model explainable also important ml model otherwise sults may prone overfitting also important develop adapt ml algorithm not only physic informed also physic consistent major outstanding challenge ai review concludes call action fluid mechanic community brace open reproducible research product standard reproducibility cornerstone science several framework currently developed render systematic entific process barber 2015 increasingly possible document procedure archive code host data others reproduce result data essential ml thus creating curating benchmark data set software spur interest among researcher related field driving progress fluid benchmark challenging traditional age data set encountered ml fluid data multimodal multifidelity high resolution some dimension sparse others many task balance multiple objective foremost data come dynamical system many task not admit postmortem analysis entering new exciting era fluid mechanic research century theoretical development based first principle merging analysis fusion provide solution many problem fluid dynamic first foremost enhanced understanding governing mechanism summary point machine learning ml entail powerful algorithm evant modeling optimization control fluid effective problem solver expertise ml knowledge fluid mechanic fluid mechanic ha traditionally concerned big data decade ha used ml understand predict optimize control flow currently ml capability advancing incredible rate fluid mechanic beginning tap full potential powerful method many task fluid mechanic modeling shape optimization feedback control may posed optimization regression task ml improve optimization performance reduce convergence time ml also used ality reduction identifying manifold discrete flow regime benefit understanding flow control strategy traditionally based precise sequence derstanding modeling ml paradigm suggests flexibility iterates first principle approach 500 brunton noack koumoutsakos future issue ml algorithm often come without guarantee performance robustness gence even interpretability generalizability ability result achieved incorporating enforcing known flow physic challenge opportunity ml algorithm hybridize first principle approach fluid mechanic many possibility discover new physical mechanism symmetry straints invariance fluid data modeling may potent alternative revisiting existing empirical law fluid mechanic ml encourages open sharing data software assist development framework reproducible open science fluid mechanic fluid researcher benefit interfacing ml community latest advance reported conference disclosure statement author not aware any bias might perceived affecting objectivity review acknowledgment acknowledges funding army research office aro air force office scientific research afosr 0200 acknowledges funding université paris sud smemag french national research agency german research foundation se se acknowledges funding erc advanced investigator award fmcobe no 34117 swiss national science foundation swiss national supercomputing centre author grateful sion nathan kutz university washington loiseau ensam ech paris françois lusseyran paris guido novati eth zurich luc pastur ensta parist ech paris pantelis vlachas eth zurich literature cited adrian rj technique experimental fluid mechanic annu rev fluid mech 304 alsalman colvert b kanso training bioinspired sensor classify flow bioinspiration biomim amsallem zahr mj farhat nonlinear model order reduction based local base int numer meth eng bai z wimalajeewa berger z wang g glauser varshney pk approach reconstruction airfoil data via compressive sensing aiaa j baldi p hornik neural network principal component analysis learning example without local minimum neural netw machine learning fluid mechanic 501 barber bayesian reasoning machine learning cambridge uk cambridge univ press barber rf candes ej controlling false discovery rate via ann stat 85 reproducible science framework battaglia pw hamrick jb bapst v zambaldi v et al relational inductive bias deep learning graph network bellman theory dynamic programming pnas benard n j periaux j bugeda g braud p et al turbulent separated shear flow control surface plasma actuator experimental optimization genetic algorithm approach exp fluid bewley tr moin p emam predictive control turbulence optimal benchmark feedback algorithm fluid mech bishop cm james gd analysis multiphase flow using gamma densitometry neural network nucl instrum method phys bölcskei h grohs p kutyniok g petersen optimal approximation sparsely connected deep neural network siam math data sci theoretical analysis approximation property deep neural network bourguignon jl tropp ja sharma mckeon bj compact representation lence using compressive sampling phys fluid bousmalis k irpan wohlhart p bai kelcey et al using simulation domain adaptation improve efficiency deep robotic grasping breiman random forest mach learn bright lin g kutz jn compressive sensing based machine learning strategy characterizing flow around cylinder limited pressure measurement phys fluid brunton sl kutz jn science engineering machine learning dynamical system control new york cambridge univ press brunton sl noack br turbulence control progress challenge appl mech rev brunton sl proctor jl kutz jn discovering governing equation data sparse identification nonlinear dynamical system pnas bueche stoll p dornberger r koumoutsakos evolutionary algorithm optimization noisy combustion problem ieee trans syst man cybern c chen tq rubanova bettencourt j duvenaud dk neural ordinary differential equation vances neural information processing system 31 ed bengio h wallach h larochelle k grauman n r garnett pp red hook ny curran assoc cherkassky v mulier fm learning data concept theory method hoboken nj john wiley son colabrese gustavsson k celani biferale flow navigation smart microswimmers via forcement learning phys rev lett colabrese gustavsson k celani biferale smart inertial particle phys rev fluid colvert b alsalman kanso classifying vortex wake using neural network bioinspiration biomim dissanayake approximation solving partial differential equation comm numer meth eng dong c loy cc k ang x learning deep convolutional network image computer 2014 ed fleet pajdla b schiele tuytelaars pp cham switz springer donoho dl compressed sensing ieee trans inf theory dracopoulos dc evolutionary learning algorithm neural adaptive control london duraisamy k iaccarino g xiao turbulence modeling age data annu rev fluid mech duriez brunton sl noack br machine learning control taming nonlinear dynamic turbulence cham switz springer faller schreck sj neural network application opportunity aeronautics prog aerosp sci 502 brunton noack koumoutsakos fleming pj purshouse rc evolutionary algorithm control system engineering survey control eng pract freeman wt jones tr pasztor ec ieee comput graph fukami k fukagata k aira reconstruction turbulent flow machine ing gardner space interaction neural network model phys gazzola hejazialhosseini b koumoutsakos reinforcement learning wavelet adapted vortex method simulation swimmer siam sci comput 36 gazzola chieu alexeev de brauer koumoutsakos learning school presence hydrodynamic interaction fluid mech gazzola van rees wm koumoutsakos optimal start larval fish fluid mech germano piomelli u moin p cabot wh dynamic eddy viscosity model phys fluid giannakoglou k papadimitriou kampolis aerodynamic shape design using evolutionary rithms new metamodels comput method appl mech eng glaz b liu l friedmann pp nonlinear unsteady aerodynamic modeling using recurrence framework aiaa j r r kevrekidis identification distributed parameter system neural net based approach comput chem eng 22 goodfellow bengio courville deep learning cambridge mit press goodfellow j mirza xu b et al generative adversarial net advance neural information processing system 27 ed z ghahramani welling c cortes nd lawrence kq weinberger pp red hook ny curran assoc powerful deep learning architecture learns game network generate new data network expert classifier grant pan x investigation performance multi layer neural network applied analysis piv image exp fluid graf fernández schmidhuber recurrent neural artificial neural 2007 ed jm de sa la alexandre w duch mandic pp berlin springer grossberg adaptive pattern classification universal recoding parallel development coding neural feature detector biol cybernet grossberg nonlinear neural network principle mechanism architecture neural netw 61 guéniat f mathelin l hussaini statistical learning strategy control fluid flow theor comput fluid dyn halko n martinsson pg tropp ja finding structure randomness probabilistic algorithm constructing approximate matrix decomposition siam rev hamdaoui chaskalovic j doncieux sagaut using multiobjective evolutionary algorithm method optimize ornithopter kinematics aircraft hansen n müller sd koumoutsakos reducing time complexity derandomized evolution strategy covariance matrix adaptation evol comput hansen n niederberger guzzella l koumoutsakos method handling uncertainty lutionary optimization application feedback control combustion ieee trans evol comput hastie tibshirani r friedman j hastie friedman j tibshirani element statistical learning vol new york springer hinton ge sejnowski tj learning relearning boltzmann machine parallel distributed cessing exploration microstructure cognition rumelhart j mcclelland cambridge mit press hochreiter schmidhuber j long memory neural comput regularization recurrent neural network major contributor success google translate holland jh adaptation natural artificial system introductory analysis application ogy control artificial intelligence ann arbor univ press hopfield jj neural network physical system emergent collective computational ability pnas machine learning fluid mechanic 503 hornik k stinchcombe white multilayer feedforward network universal approximators neural netw hou w darakananda eldredge j machine learning based detection flow disturbance using surface pressure measurement paper presented aiaa atmospheric flight mechanic conference 2019 san diego aiaa pap jambunathan k hartle fontama evaluating convective heat transfer coefficient using neural network int heat mass transf kaiser e noack br cordier l spohn segond et al modelling mixing layer fluid mech kern müller sd hansen n büche ocenasek j koumoutsakos learning probability tions continuous evolutionary comparative review nat comput kim b azevedo vc thuerey n kim gross solenthaler b deep fluid generative network parameterized fluid simulation kim hj jordan mi sastry ng ay autonomous helicopter flight via reinforcement learning advance neural information processing system 17 ed b scholkopf vi jc platt pp cambridge mit press knaak rothlubbers c orglmeister hopfield neural network flow field computation based particle image tracking velocimetry image sequence ieee int conf neural netw kohonen map berlin kolmogorov local structure turbulence incompressible viscous fluid large reynolds number cr acad sci ussr koza genetic programming programming computer mean natural selection boston mit press krizhevsky sutskever hinton ge imagenet classification deep convolutional neural work advance neural information processing system 25 ed f pereira cjc burges l bottou kq weinberger pp red hook ny curran assoc kutz jn brunton sl brunton bw proctor jl dynamic mode decomposition modeling complex system philadelphia siam labonté new neural network velocimetry exp fluid lagaris ie likas fotiadis di artificial neural network solving ordinary partial differential equation ieee trans neural netw lecun bengio hinton deep learning nature lee c kim j babcock goodman application neural network turbulence control drag reduction phys fluid lee yang h yin z cascaded deep convolutional neural network particle image velocimetry exp fluid li q dietrich f bollt em kevrekidis ig extended dynamic mode decomposition dictionary learning adaptive spectral decomposition koopman operator chaos liang jiang c li cellular neural network detect spurious vector piv data exp fluid ling j jones r empleton j machine learning strategy system invariance property comput phys ling j kurzawski empleton j reynolds averaged turbulence modelling using deep neural work embedded invariance fluid mech ling j empleton j evaluation machine learning algorithm prediction region high reynolds averaged navier stokes uncertainty phys fluid loiseau jc brunton sl constrained sparse galerkin regression fluid mech loucks van beek e stedinger j dijkman j villars water resource system planning ment introduction method vol cham switz springer lumley j stochastic tool turbulence new york academic 504 brunton noack koumoutsakos lusch b kutz jn brunton sl deep learning universal linear embeddings nonlinear dynamic nat commun mahoney mw randomized algorithm matrix data found trend mach learn manohar k brunton bw kutz jn brunton sl sparse sensor placement tion demonstrating benefit exploiting known pattern ieee control syst mag mardt pasquali l wu h noé vampnets deep learning molecular kinetics nat commun martin n gharib experimental trajectory optimization flapping fin propulsor using tionary strategy bioinspiration biomim maulik r san rasheed vedula subgrid modelling turbulence using neural network fluid mech meena mg nair ag aira network model reduction vortical flow phys rev e mehta ub kutler computational aerodynamics artificial intelligence nasa ech 85994 ames moffett field ca meijering chronology interpolation ancient astronomy modern signal image cessing proc ieee meneveau c katz j turbulence model simulation annu rev fluid mech mezic analysis fluid flow via spectral property koopman operator annu rev fluid mech milano koumoutsakos neural network modeling near wall turbulent flow comput phys minsky papert sa perceptrons introduction computational geometry cambridge mit press mnih v kavukcuoglu k silver rusu aa veness j et al control deep forcement learning nature nair ag aira approach sparsified discrete vortex dynamic fluid mech noack br turbulence human machine learning retour interaction control proceeding symposium tions control ed zhou kimura g peng ad lucey l hung pp singapore springer noé f nüske variational approach modeling slow process stochastic dynamical system siam multiscale model simul novati g mahadevan l koumoutsakos controlled gliding perching phys rev fluid novati g verma alexeev rossinelli van rees wm koumoutsakos synchronisation learning two swimmer bioinspiration biomim 12 nüske f schneider r vitalini f noé variational tensor approach approximating kinetics macromolecular system chem phys ollivier arnold l auger hansen optimization algorithm unifying picture via invariance principle mach learn ostermeier gawelczyk hansen adaptation based use selection mation international conference parallel problem solving nature 1994 oct 9 pp berlin springer ouellette nt xu h bodenschatz quantitative study lagrangian particle tracking algorithm exp fluid papadimitriou di papadimitriou optimal sensor placement estimation turbulent model parameter cfd int uncert quant parish ej duraisamy paradigm predictive modeling using field inversion chine learning comput phys machine learning fluid mechanic 505 pathak j hunt b girvan lu z ott prediction large spatiotemporally chaotic system data reservoir computing approach phys rev lett pelikan ocenasek j trebst troyer alet computational complexity simulation rare event ising spin glass genetic evolutionary 2004 pp berlin springer perdikaris p venturi karniadakis multifidelity information fusion algorithm dimensional system massive data set siam sci comput 38 perlman e burn r li meneveau data exploration turbulence simulation using database cluster proceeding 2007 conference supercomputing new york acm phan mq juang jn hyland dc neural network identification control dynamic tems wave motion intelligent structure nonlinear mechanic ed guran dj inman pp singapore world sci pierret van den braembussche turbomachinery blade design using solver artificial neural network turbomach pollard castillo l danaila l glauser whither turbulence big data century switz springer rabault j kuchta jensen réglade u cerardi artificial neural network trained deep reinforcement learning discover control strategy active flow control fluid mech raissi karniadakis ge hidden physic model machine learning nonlinear partial differential equation comput phys raissi perdikaris p karniadakis neural network deep learning framework solving forward inverse problem involving nonlinear partial differential equation comput phys rechenberg kybernetische lösungsansteuerung einer experimentellen forschungsaufgabe annual conference wglr berlin september vol 35 33 rechenberg evolutionsstrategie optimierung technischer systeme nach prinzipien der biologischen evolution stuttgart ger reddy g celani sejnowski tj vergassola learning soar turbulent environment pnas 113 reddy g j celani sejnowski tj vergassola glider soaring via reinforcement learning field nature richter sr vineet v roth koltun playing data ground truth computer game european conference computer vision 2016 ed b leibe j matas n sebe welling pp cham switz springer r krischer k kevrekidis ig kube mc hudson jl nonlinear signal processing cu electrodissolution data chem eng commun rokhlin v szlam ygert randomized algorithm principal component analysis siam matrix anal appl rosenblatt perceptron probabilistic model information storage organization brain psychol rev first example simple binary network learning capability rowley cw dawson model reduction flow analysis control annu rev fluid mech 417 rowley cw c bagheri schlatter p henningson spectral analysis nonlinear flow fluid mech rudy sh brunton sl proctor jl kutz jn discovery partial differential equation sci adv 3 rumelhart de hinton ge williams rj learning representation error nature salimans ho j chen x sutskever evolution strategy scalable alternative reinforcement learning schaeffer learning partial differential equation via data discovery sparse optimization proc soc 506 brunton noack koumoutsakos schaul horgan gregor k silver universal value function approximators proceeding international conference machine learning ed f bach dm blei pp red hook ny curran assoc schmid pj dynamic mode decomposition numerical experimental data fluid mech schmidt lipson distilling natural law experimental data science schölkopf b smola aj learning kernel support vector machine regularization optimization beyond cambridge mit press schwefel hp numerische optimierung von mittels der evolutionsstrategie basel switz birkhäuser semeraro lusseyran f pastur l jordan qualitative dynamic wavepackets turbulent jet silver huang maddison cj guez sifre l et al mastering game go deep neural network tree search nature singh ap medida duraisamy predictive modeling turbulent separated flow airfoil aiaa j sirovich turbulence dynamic coherent structure part appl math sirovich l kirby procedure characterization human face opt soc skinner sn aerodynamic shape optimisation method appl soft comput strom b brunton sl polagye b intracycle angular velocity control turbine nat energy sutton r barto ag reinforcement learning introduction cambridge mit press ed classic book reinforcement learning aira k brunton sl dawson rowley cw colonius et al modal analysis fluid flow overview aiaa j akeishi n kawahara yairi learning koopman invariant subspace dynamic mode position advance neural information processing system 30 ed guyon uv luxburg bengio h wallach r fergus et pp red hook ny curran assoc edrake r jackowski z cory r robert jw hoburg learning fly like bird paper presented international symposium robotics research lucerne switz eo c lim k hong g yeo neural net approach analysing photograph piv ieee trans syst man cybern esauro practical issue temporal difference learning mach learn theodoridis machine learning bayesian optimization perspective san diego ca academic monograph linking machine learning bayesian inference algorithm siotras p mesbahi oward algorithmic control theory guid control dyn van rees wm gazzola koumoutsakos optimal morphokinematics undulatory swimmer intermediate reynolds number fluid mech verma novati g koumoutsakos efficient collective swimming harnessing vortex deep reinforcement learning pnas vlachas pr byeon w wan zy sapsis tp koumoutsakos forecasting dimensional chaotic system long memory network proc soc wan zy vlachas p koumoutsakos p sapsis modeling extreme event complex dynamical system plo one 13 wang jx wu jl xiao machine learning approach reconstructing reynolds stress modeling discrepancy based dns data phys rev fluid wang hemati detecting exotic wake hydrodynamic sensor wehmeyer c noé autoencoders deep learning slow collective variable molecular kinetics chem phys wiener cybernetics control communication animal machine vol cambridge mit press machine learning fluid mechanic 507 willert ce gharib digital particle image velocimetry exp fluid williams mo rowley cw kevrekidis ig kernel approach koopman spectral analysis comput dyn wright j yang ganesh sastry robust face recognition via sparse representation ieee trans pattern anal mach intell wu h mardt pasquali l noe deep generative markov state model adv neural inf process syst wu x moin direct numerical simulation study mean velocity characteristic turbulent pipe flow fluid mech xiao h wu jl wang jx sun r roy quantifying reducing uncertainty simulation bayesian approach comp phys xie franz e chu thuerey tempogan temporally coherent volumetric gan resolution fluid flow acm trans graph yang j wright j huang image via sparse representation ieee trans image process 508 brunton noack koumoutsakos