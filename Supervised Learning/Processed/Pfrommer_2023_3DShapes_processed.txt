learning latent representation shape euclidean input chengzhi julius mingyuan urgen anthropomatics robotics karlsruhe institute technology germany institute optronics system technology image exploitation iosb germany center machine learning germany abstract propose combined generative contrastive neural architecture learning latent representation metric shape architecture us two encoder branch voxel grid image lying shape main idea combine contrastive loss resulting latent representation tional reconstruction loss help avoid collapsing latent representation trivial solution minimizing contrastive loss novel switching scheme used train two encoders shared decoder switching scheme also enables stop gradient operation random branch classiﬁcation experiment show tent representation learned method integrate useful information additional input data implicitly thus leading better reconstruction classiﬁcation performance introduction shape represented range different mat euclidean side may represented image image volumetric data side may represented point cloud mesh computer vision task like cation segmentation even generative task like shape reconstruction target shape usually converted latent representation ﬁrst rise deep learning 16 popular latent representation shape descriptor laplacian spectral eigenvectors 36 heat kernel nature 38 neural network latent representation usually result encoder reduces shape vector representation ﬁxed dimensionality general pipeline contrastive learning augmented data b pipeline proposed learning input figure 1 illustration general pipeline trastive learning method b proposed generative contrastive learning pipeline shape input data available question arises use jointly learning task take euclidean data example method computer vision deal image voxel grid input data either concatenate individual latent representation supervised task 22 use only one input loss side separately 11 40 39 45 use jointly ﬁnetuning 15 interested seeking better way learning better latent representation volumetric shape additional input modality 1 11 jan 2023 apart pretext method 14 17 two main learning way method 1 11 method 5 18 volumetric shape easy implement generative model still open question contrastive way let alone combination two recent review paper learning 28 thor argue only way learning train generate synthetic sample discriminator distinguish real sample disagree argument deﬁnition discriminator contrastive part thus model only focus negative pair think also possible use only use positive pair case using modality input shape two branch figure 1 show main idea proposed contrastive learning pipeline compared existing trastive learning method method share some tie some signiﬁcant difference also exist similarity use scheme encode two input origin raw data ii getting encoded latent representation compute contrastive loss latent space iii use positive pair training optionally additional tive pair also use positive pair difference use different augmented data raw data use different modality raw data ii thus network architecture encoder b not cal identical mostly iii add decoder part reconstruction loss iv possibly stop gradient one ﬁxed branch stop gradient random branch switching scheme main contribution paper follows propose novel learning pipeline volumetric shape make joint training encoders input data possible switching scheme doe work stopping gradient random branch model collapse avoided training also possible without ments special better experimental result achieved shape reconstruction classiﬁcation task proposed model compared result model learn only data using voxel encoder feature extractor outperform classiﬁcation task much shorter latent vector representation 128 compared ca million sion voxel encoder one single category still performs surprisingly well feature extractor full dataset category testing related work contrastive learning work contrastive learning wa pioneered yann lecun group face veriﬁcation 10 topic getting popular recently since people ﬁnd learning important feature extraction really mature deep ing technique simclr 5 proposes use two identical encoders two branch positive pair negative pair used moco 7 stop gradient second branch using method update parameter encoder swav 2 proposes use memory bank get negative pair batch contrastive loss case computed clustering method only use positive sample byol 18 keep idea momentum updating moco add ditional block ﬁrst branch only us positive pair simsiam 8 report observation competitive result may still achieved modifying byol making two encoders identical review relevant method comparison given 12 learning shape euclidean data pervised task voxnet 30 pioneer use lutional network learn feature volumetric data recognition subsequent work cnn 13 learns spatial feature considering tiple resolution voxel input qi et al 32 propose use ﬁltering cnns well using subvolume supervision auxiliary ing fusionnet 22 fuse three network together two voxnets 30 one mvcnn 37 three network fuse score layer linear combination score taken classiﬁcation prediction task shapenet 41 us reverse voxnet reconstruct volumetric shape latent resentations learned depth map network 15 combine autoencoder image gressor encode uniﬁed vector representation given image autoencoders also widely use shape retrieval paper 44 46 variant vae ha used similar way shape learning 1 view mation image ha also widely investigated shape reconstruction choy et al 11 proposed framework named reconstruct shape image leveraging power recurrent neural network 24 33 also us approach taking depth image input some method use view mation auxiliary constraint 39 45 19 method us gan volumetric shape generation ha proposed 40 some latest work 31 27 also used input data joint training not use switching scheme aware lot work applying deep method 2 data format point cloud mesh scope work would like leave future work methodology learning figure 1 b show main idea proposed learning pipeline similar existing contrastive learning method use architecture two encoder branch compute contrastive loss latent representation branch input two branch voxel grid image identical shape generative decoder part added compute reconstruction loss decoder shared two encoders two encoder branch help switching scheme contrastive learning method mode collapse big issue possible way dealing adding additional block encoder stop gradient encoder b update parameter momentum way slowly along updated parameter encoder case encoder b already different network architecture thus momentum method not applied still managed avoid model collapse successfully experiment attribute success two thing reconstruction loss switching scheme reconstruction loss ha strong supervision representational capacity latent representation switching scheme doe work stopping gradient random branch improve latent representation variational autoencoders vae 26 used instead vanilla coder vae input mapped multivariate normal distribution around point latent space make continuous latent space continuous latent space make smooth transition shape possible tent representation learned feature usually smooth meaningful switch encoding dealing input art method encode separately latent sentations perform concatenation unlike propose use switching scheme latent space jointly train encoders shared decoder training switch actuated every training epoch preset probability randomly select encoded output one encoder latent representation operation switching encoders continues whole training decoder tasked reconstruct voxel tation shape since switched encoders trained concurrently decoder forced produce mutually compatible latent representation different input modality result different feature urally emerge respective latent representation example encoder much likely erate overall volume feature simply number ﬁlled voxels compared image encoder switched encoding useful feature latent representation translate one encoder via shared decoder result improved latent representation also individual encoder one input modality used training loss function switchvae loss function consists three part reconstruction loss lrecon kl divergence lkl latent representation normal prior distribution contrastive loss lcontras latent representation different input format overall network parameterized θ θvox θimg θd voxel image encoder voxel decoder respectively ing sample denoted xα input α img vox switch value α randomly selected prior ery training epoch latent representation resulting vae encoders µα σα eα xα latent representation sampled current training epoch zα µα σα decoder part shared input modality reconstruct voxel tation ˆ xα zα formally overall loss function decomposes three term lθ α ximg xvox lrecon xvox ˆ xα λkllkl µα σα λcontraslcontras zimg zvox 1 weight λkl λcontras modiﬁed binary cross entropy bce voxel ground truth used reconstruction loss improve training modiﬁcation ha made introduction γ weight relative importance false positive false negative reconstructed voxels indexed k value ˆ xα k 0 1 lrecon xvox ˆ xα x k h xvox k log ˆ xα k 1 1 k log 1 xα k 2 set hyperparameter γ training experiment conducted section training vae kl gence used actual distribution latent vector n 0 gaussian distribution note latent representation ha n dimension lkl µ σ 2 n x 1 log 3 3 figure 2 switchvae architecture based posed learning pipeline detail block illustrated order force close distance latent representation learned image volumetric data switchvae model contrastive loss encoders proposed used latent space training phase contrastive loss deﬁned euclidean distance latent vector image volumetric data lcontras zimg zvox 2 4 although contrastive learning method some different contrastive loss ha used infonce loss simclr 5 ﬁnd latent representation normalized method already yield satisfying result simple norm loss contrastive loss experiment use modelnet datasets experiment dataset 11 subset 13 category shapenet dataset 3 provides good quality rendered image alongside class label 32 32 32 voxel representation divide dataset training set sample test set 7406 sample modelnet dataset 41 come two variation either 10 40 class shape dataset contains sample contains sample switchvae model use voxel image encoder decoder always reconstructs voxel representation training voxel test input switch layer randomly selects either voxel encoder probability 80 image encoder probability 20 concerning training parameter use tent dimension 128 experiment network parameter trained minimizing loss function equation 1 using sgd optimizer momentum nesterov accelerated gradient 34 learning rate 2 decay per 10 epoch ﬁrst 50 epoch batch size 32 experiment training image input us 8 view every sample ha reported 11 subsequent work 42 43 improvement additional view negligible ﬁrst view detailed network conﬁguration figure 2 show based proposed contrastive learning pipeline switched encoding plemented vae image voxel grid input encoder block switchvae build idea volumetric convolutional network 41 voxel input recurrent reconstruction neural network 11 image input detailed network conﬁgurations given follows image encoder switchvae learns latent vector image composed view feature embedding module view feature aggregator module view feature embedding module 21 whose weight shared across view part weight map single view 137 137 3 rgb image 5 5 512 feature map ﬂatten feature map add fully connected layer output 1024 dimensional feature single view image shape 8 view image fed shared weight view feature embedding module training output 8 1024 view feature view feature aggregator module ﬁrstly tried max pooling mvcnn 37 not yield satisfying result average pooling better aggregate image feature ﬁnally use gated recurrent unit gru 9 view feature aggregator output 1024 dimensional feature aggregating feature view fed last fully connected layer generate mean variance latent vector using reparametrization trick introduced 25 image encoder ﬁnally output 128 dimensional sampled latent vector voxel encoder volumetric convolutional ral network encoder ha 4 convolutional layer two fully connected layer convolutional layer use kernel size 3 3 3 stride 1 2 1 2 channel number 8 16 32 64 respectively layer use exponential linear unit elu activation function cept last fully connected layer layer map shape 32 32 32 voxels 343 dimensional feature 343 dimensional feature fed last fully connected layer generate mean variance latent vector ﬁnally produce 128 dimensional sampled latent vector decoder switchvae mirror voxel encoder except last layer us sigmoid activation function 4 voxel vae switchvae reconstruction test voxel input input view gt image vae switchvae b reconstruction test image input figure 3 some reconstruction result different model only voxel image test input test input training model reconstruction metric iou precision accuracy image image vae switchvae λcontras 0 switchvae λcontras 1 voxel voxel vae switchvae λcontras 0 switchvae λcontras 1 table 1 reconstruction performance test set training testing chair category dataset decoder map 128 dimensional latent vector wa randomly sampled encoder 32 32 32 umetric reconstruction represents predicted voxel occupancy possibility voxel cube shape reconstruction use iou precision recall accuracy referred average precision 15 quantitative metric reconstruction shape threshold voxel considered ﬁlled 50 similar last part show result only voxel input training only image input training input training switchvae table 1 show reconstruction performance switchvae similar slightly better vaes focus making every predicted pied voxel correct higher precision score istic may clearly observed some reconstruction result table 1 also show contrastive loss term key method figure 3 show some qualitative construction result switchvae model trained chair category comparison result network only use one input format training also presented ﬁgure observe vae take attention not occupying original negative voxels quite obvious third row figure 3 b image vae switchvae not certain leg number ofﬁce chair 4 image vae decides merge together switchvae decides only guess occupy some voxels small area shape classiﬁcation classiﬁcation task network ﬁrst trained perform reconstruction voxel sentations encoder part trained network 5 training dataset test input training model classiﬁcation accuracy chair category image image vae switchvae voxel data voxel vae switchvae image image vae switchvae voxel data voxel vae switchvae table 2 classiﬁcation accuracy classiﬁcation task model trained image vae voxel vae switchvae chair category full dataset supervision method data modality classiﬁcation accuracy supervised shapnets 41 voxels voxnet 30 voxels mvcnn 37 image fusionnets 22 image voxels 20 image vrn ensemble 1 voxels lfd 4 image network 15 image voxels 35 voxels gan 40 voxels switchvae trained only chair category image voxels switchvae trained dataset image voxels table 3 classiﬁcation accuracy dataset different method result method only used image voxels listed note latent representation only 128 dimension used produce latent representation 128 dimension input classiﬁcation svm rbf kernel parameter γ trained latent representation perform classiﬁcation sample used train network latent representation svm evaluation svm performed sample neither used train network svm table 2 show impact switched training modelnet classiﬁcation task make clear let take voxel data testing example training phase voxel vae only train voxel train set data switchvae train voxel train set data correspondent image train set data testing phase only identical voxel test set data given trained voxel vae model trained switchvae model latent representation shape voxel test set obtained vae model always outperform vanilla voxel vae modelnet classiﬁcation task note no view image data test set needed switchvae testing table 2 clearly observe condition training dataset test input result switchvae better result image vae voxel vae case note even trained number epoch mean using data format training phase testing phase classiﬁcation mance ha improved compared model only use single format training conclusion better latent representation learned shape using data data input format not used evaluation network trained table 3 list classiﬁcation result comparison network architecture compared pervised learning method achieve better classiﬁcation performance comparing outperform 6 voxel vae trained b switchvae λcontras 0 trained c switchvae λcontras 1 trained switchvae λcontras 1 trained dataset figure 4 plot latent representation shape 10 category vanilla voxel vae model trained dataset b vae model without contrastive loss trained dataset c switchvae model contrastive loss trained dataset switchvae model trastive loss trained full dataset color represents one category latent representation used plot use voxel data testing set test input classiﬁcation task achieve competitive performance classiﬁcation task ever method us much smaller latent vector only 128 dimension use feature map last three convolution layer make presentation shape million dimensional vector input classiﬁcation visualization order visualize learned latent representation use 29 map latent representation plane figure 4 give tion result use tion experiment comparing figure 4 figure 4 b observe switching scheme contributes classiﬁcation make clustering bit fuzzy category bit far category bit le clustered paring figure 4 b figure 4 c observe adding contrastive loss term switchvae help top row trained switchvae chair arm feature size feature entangled middle bottom row trained β 5 chair arm feature size feature disentangled changing one feature doe not impact one much b top row trained switchvae changing chair leg type feature also lead morphing top part bottom row trained β 5 top part stay ﬁxed changing chair leg type feature figure 5 disentangling latent feature clustering making performance whole classiﬁcation task mush better comparing figure 4 c figure 4 observe larger ing dataset even better feature clustering result may achieved increased gap different category clearly observed exploring latent representation subsection showcase some qualitative result give indication switchvae training result superior latent representation allows better disentanglement category well salient feature shape category latent space interpolation similar construction paper also interpolation trained model shown figure served proposed method ha ability smooth transition two shape even different category shape arithmetic another way explore learned latent representation perform arithmetic operation latent space whilst observing effect structed geometry show some shape arithmetic result figure 7 model trained full dataset model seems capture underline information capable generating meaningful combined shape 7 figure 6 shape interpolation different category shape arithmetic example chair object b shape arithmetic example table object figure 7 shape arithmetic chair table adding chair arm chair object latent space b adding middle layer table object latent space not occur shape original dataset feature disentanglement vae variation one good thing vae model latent space learned meaningful comparing gan model tuning value one speciﬁc latent dimension one observe certain feature output side changing smoothly however feature get entangled multiple latent dimension vanilla vae ha reported 23 6 producing better disentangled feature latent space merge proposed method switchbtcvae train model β 5 chair category number epoch experiment shown section although small decrease reconstruction performance metric observed investigating learned latent representation ﬁnd some feature better disentangled shown figure 5 conclusion outlook paper propose ing pipeline learning better latent representation volumetric shape help additional ity input switching scheme make joint training encoders possible competitive reconstruction result classiﬁcation experiment modelnet also carried validate effectiveness proposed method improved classiﬁcation result indicate better latent representation learned proposed switchvae architecture future direction data modality point cloud mesh may also used new contrastive loss may designed optimal switching policy may studied research may conducted make latent presentation feature disentangled interpretable experiment although additional contrastive loss ha applied still observe large tances latent representation generated different input format understanding force close distance representation without leading collapse increased contrastive loss would lead insight contrastive learning 8 reference 1 brock lim ritchie weston generative discriminative voxel modeling convolutional neural network neurips 2016 2 caron misra mairal goyal bojanowski joulin unsupervised learning visual feature ing cluster assignment neurips 2020 3 chang funkhouser guibas hanrahan huang li savarese savva song su xiao yi yu shapenet model repository arxiv 2015 4 chen tian shen ouhyoung visual ilarity based model retrieval computer graphic forum 22 2003 5 chen kornblith norouzi hinton simple framework contrastive learning visual tations icml 2020 6 chen li grosse duvenaud isolating source disentanglement variational autoencoders 2018 7 chen fan girshick improved baseline momentum contrastive learning cvpr 2020 8 chen exploring simple siamese representation learning cvpr 2021 9 cho merrienboer ulc bahdanau bougares schwenk bengio learning phrase resentations using rnn statistical machine translation arxiv 2014 10 chopra hadsell lecun learning similarity metric discriminatively application face veriﬁcation cvpr page 2005 11 choy xu gwak chen savarese uniﬁed approach single object reconstruction eccv 2016 12 ericsson gouk hospedales well model transfer cvpr 2021 13 ghadai lee balu sarkar murthy cnn learning spatial feature conference computer vision pattern recognition workshop cvprw page 2019 14 gidaris singh komodakis unsupervised resentation learning predicting image rotation iclr 2018 15 girdhar fouhey rodriguez gupta ing predictable generative vector representation object eccv 2016 16 goodfellow bengio courville deep ing nature 2015 17 goyal mahajan gupta misra scaling benchmarking visual representation learning iccv 2019 18 grill strub altch e tallec richemond buchatskaya doersch pires guo azar piot kavukcuoglu munos valko bootstrap latent new approach learning neurips 2020 19 gwak choy chandraker garg savarese weakly supervised reconstruction ial constraint 2017 international conference vision page 2017 20 han lu liu vong liu zwicker han chen aggregating sequential view global feature learning cnn hierarchical tion aggregation ieee transaction image processing 2019 21 zhang ren sun deep residual learning image recognition cvpr page 2016 22 hegde zadeh fusionnet object classiﬁcation using multiple data representation arxiv 2016 23 higgins matthey pal burgess glorot botvinick mohamed lerchner learning basic visual concept constrained variational work iclr 2017 24 hochreiter schmidhuber long memory neural computation 1997 25 kingma welling variational bayes corr 2014 26 kingma welling introduction variational autoencoders foundation trend machine learning 2019 27 klokov verbeek boyer probabilistic tion network shape inference single image 2019 28 liu zhang hou wang mian zhang tang learning generative contrastive ieee transaction knowledge data engineering 2020 29 maaten hinton visualizing data using journal machine learning research 2008 30 maturana scherer voxnet convolutional neural network object recognition international conference intelligent robot system iros page 2015 31 muralikrishnan kim fisher chaudhuri shape unicode uniﬁed shape representation cvpr page 2019 32 qi su nießner dai yan guibas volumetric cnns object classiﬁcation data cvpr page 2016 33 rezende eslami mohamed battaglia berg heess unsupervised learning structure image 2016 34 ruder overview gradient descent optimization algorithm arxiv 2016 35 sharma grau fritz deep volumetric shape learning without object label arxiv 2016 36 laplacian mesh processing ic 2005 37 su maji kalogerakis view convolutional neural network shape recognition iccv page 2015 9 38 sun ovsjanikov guibas concise provably informative signature based heat diffusion computer graphic forum 28 2009 39 tulsiani efros malik consistency supervisory signal learning shape pose prediction cvpr page 2018 40 wu zhang xue freeman tenenbaum learning probabilistic latent space object shape via modeling arxiv 2016 41 wu song khosla yu zhang tang xiao shapenets deep representation volumetric shape cvpr page 2015 42 xie yao sun zhou zhang tong reconstruction single image iccv page 2019 43 xie yao zhang zhou sun object reconstruction gle multiple image international journal computer vision page 1 17 2020 44 xie yi fang zhu wong deepshape deep learned shape descriptor shape matching retrieval cvpr page 2015 45 yan yang yumer guo lee perspective transformer net learning object tion without supervision 2016 46 zhu wang bai yao bai deep learning representation using autoencoder shape retrieval ieee international conference security pattern analysis cybernetics spac page 2014 10