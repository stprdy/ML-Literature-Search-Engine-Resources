fairness supervised learning information theoretic approach amiremad sajad negar department coordinated science university illinois urbana usa kiyavash decision making system increasingly used application system part decision rule derived minimizing training error available historical data therefore bias related sensitive attribute gender race religion etc data say due criminatory practice certain demographic system could continue discrimination decision including said bias decision rule present information theoretic framework designing fair predictor data aim prevent discrimination speciÔ¨Åed sensitive attribute supervised learning setting use equalized odds criterion discrimination demand prediction independent protected attribute conditioned actual label ensure fairness generalization simultaneously compress data auxiliary variable used prediction task auxiliary variable chosen decontaminated discriminatory attribute sense equalized odds Ô¨Ånal predictor obtained applying bayesian decision rule auxiliary variable index equalized odds supervised learning introduction automated decision making system based statistical inference learning increasingly common wide range application health care law enforcement education Ô¨Ånance system trained based historical data might biased towards certain attribute data point 1 3 hence data without noticing possible bias could result discrimination deÔ¨Åned gratuitous distinction individual different sensitive attribute attribute include sex race religion referred protected attribute literature example u justice system court use feature criminal age race sex year jail estimate possible arrest considering feature court assigns score individual decides whether release person score exceeds some certain limit safe release individual instance noted angwin et al analysis 4 risk score criminal justice compas risk biased negatively towards showed risk score tiÔ¨Åably show high risk recidivism people compared actually another example author 5 studied accuracy gender representation online image search result indicate instance google image search 11 percent depicted result woman even though 27 percent chef executive woman search telemarketer 64 percent people depicted female occupation evenly split men woman interesting connection problem fairness differential privacy 6 8 differential privacy problem one try hide identity individual fairness problem goal hide information protected attribute detail regarding connection presented 1 different criterion assessing discrimination ha gested literature commonly used criterion demographic parity requires predictor statistically independent protected attribute denoting protected attribute prediction ÀÜ respectively demographic parity requires model satisfy p ÀÜ p p ÀÜ demographic parity variant used several work 9 12 some scenario criterion fails provide fairness demographic 1 example case hiring employee majority applicant certain demographic force decision making system independent graphic system ha pick equal number applicant demographic therefore system may admit lower qualiÔ¨Åed individual smaller demographic guarantee percentage hired people different demographic match moreover denoting true label case image search example correlated protected attribute see figure 1 therefore demographic parity force ÀÜ independent criterion not satisÔ¨Åed ideal predictor ÀÜ hardt price srebro recently proposed equalized odds new criterion fairness 2 notion demand predictor independent protected tribute conditioned actual label therefore equalized 29 jul 2018 odds requires model satisfy p ÀÜ p p ÀÜ 1 returning example hiring employee measure implies among qualiÔ¨Åed applicant probability hiring two people different demographic two people different demographic qualiÔ¨Åed not qualiÔ¨Åed system hire equal probability also note unlike graphic parity equalized odds allows ideal predictor ÀÜ paper present new framework designing fair predictor data utilize information theoretic approach model information content variable system relative one another use equalized odds criterion ass discrimination proposed scheme data variable x Ô¨Årst mapped auxiliary variable u decontaminate discriminatory attribute well ensuring generalization design auxiliary variable input variable x true label seek Ô¨Ånd compact representation u x contains certain level information variable x avoid overÔ¨Åtting maximizes u quality decision auxiliary variable u turn used input prediction task similar 2 framework only based joint statistic variable rather functional form hence formulation general furthermore many case functional form score underlying training data not public formulation unlike 2 instance allows arbitrary cardinality implies protected attribute label cast task Ô¨Ånding fair predictor optimization problem propose iterative solution solving problem observe proposed solution doe not necessarily converge some level fairness suggests given requirement accuracy predictor certain level fairness may not achievable somewhat similar idea approach presented 9 author used intermediate representation space element called prototype however besides fact work demographic parity used measure discrimination method used choosing prototype quite different speciÔ¨Åcally main approach avoid overÔ¨Åtting learning process limiting number achieve goal controlling information auxiliary variable data approach 9 ha extended 13 deep variational prior encourage independence tween sensitive latent factor variation rest paper organized follows section ii review notion equalized odds introduce model well detail proposed learning procedure additionally propose optimization must nothing said work choosing number prototype ùê¥ ùëã ùëå ùëà ùëå fig 1 graphical model proposed framework x denote protected attribute rest attribute true label respectively u compressed representor x used designing prediction ÀÜ solved address fairness issue section iii propose iterative approach solving optimization problem introduced concluding remark presented section iv ii model description consider purely observational setting train predictor labeled data sample set attribute includes protected attribute gender race religion etc protected attribute denoted use x denote rest attribute denote true label prediction label ÀÜ instance example regarding risk recidivism explained section represents race individual x represents feature individual could correlated individual race determines whether ha committed any crime released jail graphical model setup depicted figure seen Ô¨Ågure x correlated given x independent true label property essential otherwise protected attribute fact direct cause label using attribute prediction process not considered discriminatory order Ô¨Ånd fair predictor joint distribution p x wa known could Ô¨Ånd p ÀÜ close p sense equalized odds however reality only empirical distribution ÀÜ p x obtained data available therefore required make sure predictor generalizes generalization since number available sample Ô¨Ånite prevent overÔ¨Åtting ensuring generalization constraint hypothesis space compress variable x auxiliary variable u turn used prediction task also choose u not contaminated discrimination sense equalized odds 2 deÔ¨Åned following deÔ¨Ånition 1 equalized odds say variable u satisÔ¨Åes equalized odds respect protected attribute outcome u independent conditional deÔ¨Ånition equivalent one expression 1 u decontaminated discriminatory attribute one use any predictor predict auxiliary variable propose apply bayesian empirical risk minimization decision rule work prediction task obtain mechanism generating auxiliary able seek compact representation u x maximizes prediction u contains certain level information variable essence similar goal information bottleneck ib method 14 maximizing u corresponds maximizing utility u keeping x u bounded could viewed regularization reject complex hypothesis ensure generalization see 15 detailed discussion regarding using mutual information Ô¨Ånding bound generalization error note fact present fairness accuracy compactness via mutual information provides u setting not need any requirement cardinality variable opposed 2 9 next present detail designing transition probability kernel generating auxiliary variable well designing Ô¨Ånal predictor designing auxiliary variable stated earlier goal learning scheme produce compressed representor x ha much information true label possible fair sense deÔ¨Ånition relax equalized odds requirement allow u certain amount information variable conditioned reason choice become clear section iii therefore objective Ô¨Ånd mechanism p maximizes u well 1 ensures fairness information shared protected attribute u given true label doe not exceed certain threshold c 2 ensures generalization mutual information x u doe not exceed certain threshold x u therefore aim solve following optimization lem max p u x u designing predictor stated obtaining decontaminated variable u variable used prediction task utilize bayesian decision rule described following let u alphabet variable u alphabet variable ÀÜ quantify quality decision deÔ¨Åne loss function ‚Ñì ‚Ñì ÀÜ determines cost predicting ÀÜ true label wa decision based auxiliary variable u statistically related true label denote decision rule Œ¥ u loss decision rule Œ¥ deÔ¨Åned follows l Œ¥ eu ‚Ñì Œ¥ u using l Œ¥ bayesian risk minimization decision rule arg min Œ¥ l Œ¥ instance case binary label hamming loss deÔ¨Åned ‚Ñì ÀÜ 1 ÀÜ u 1 h p implies vote label maximum posterior probability iii solving fairness optimization problem section propose solution fairness optimization problem presented section ii lagrangian problem l p Œ±i x u Œ≤i u 2 parameter Œ± Œ≤ determine trade accuracy information compression fairness equation 2 similar objective function 16 given variable x author aimed uncover structure p x not exist p x used hierarchical text categorization propose alternating optimization method solve aforementioned problem proposed approach presented algorithm iteration l reduced minimizing objective function three tributions q r u separately function f x u Œ± Œ≤ z x Œ± Œ≤ used updating q deÔ¨Åned follows z x Œ± Œ≤ x u r u exp f x u Œ± Œ≤ 3 f x u Œ± Œ≤ Œ≤ Œ± x p p p q p x p q p x Œ±d p 4 theorem value Œ≤ small enough any arbitrary value Œ± algorithm 1 converges stationary point lagrangian function l given equation 2 see appendix proof general no guarantee algorithm 1 converges global minimum lagrangian nevertheless imental result show altenative optimization algorithm paper uppercase letter argument bution indicate parameter distribution p p x algorithm 1 designing conditional distribution input empirical distribution ÀÜ p x initial tions u parameter Œ± Œ≤ termination threshold œµ initiate 0 œµ lt qt u x Œ± Œ≤ exp f x u Œ± Œ≤ rt u qt p st 1 rt u p qt p x u Œ≤i u end output conditional distribution q almost always converges local minimum objective function 2 note since achieving global optimum not guaranteed one initiate algorithm several different starting distribution fact convergence occurs only certain range value parameter Œ≤ suggests given requirement accuracy predictor certain level fairness may not achievable imply inherent bound level fairness any algorithm achieve conclusion could not obtained existing work iv conclusion studied problem fairness supervised learning motivated fact automated decision making system may inherit bias related sensitive attribute gender race religion historical data trained presented new framework designing fair predictor data via information theoretic machinery equalized odds wa used criterion discrimination demand prediction independent protected attribute conditioned actual label proposed scheme data variable Ô¨Årst mapped auxiliary variable decontaminate discriminatory attribute well ensuring generalization modeled task designing auxiliary variable optimization problem aim force variable fair sense equalized odds maximizes mutual information auxiliary variable true label whilst keeping information variable contains data limited proposed alternative solution solving optimization problem observed proposed solution doe not necessarily converge some level fairness suggests given requirement accuracy predictor certain level fairness may not achievable Ô¨Ånal predictor obtained applying bayesian decision rule auxiliary variable finding exact bound achievable level fairness well applying proposed method real data considered future work appendix proof theorem 1 lagrangian equation 2 written follows l p x x u p x p log p p u Œ≤g p x x u p x p log p p x 5 g p x u x p p x log p p p p p p note only unknown parameter p distribution estimated given sample x changing notation p q emphasize designed using 17 lemma write optimization follows min q l q min q h Œ± x x u p x q log q p u Œ≤g q x x u p x q log p p x min q h min min r u Œ± x x u p x q log q r u Œ≤g q x x u p x q log p x inner minimization probability butions changing order three minimization obtain min min r u min q Œ± x x u p x q log q r u Œ≤g q x x u p x q log p x 6 since x log x convex function summation convex function linear function remains convex Ô¨Årst third term equation 6 combined convex function q any function g q exist Œ≤ small enough combination Ô¨Årst three term equation 6 remains convex respect q add one term Œª x p u q lagrangian constraint x q sum result taking derivative function respect q x setting equal zero minimum function found derivative term taken separately x p q log q r therefore p x log q r u x p p x log q r u p x second term l x p log p p due graphical model figure 1 p p p q p therefore p p derivative p p obtained similarly therefore x p x p log p u p x p x p p q p x p q p x x p x p third term l x p log p therefore x p p x p summing term derivative setting equal zero get desired result 3 4 using calculated q x minimize r u using 17 lemma mum achieved marginal distribution p p u found q according algorithm regarding convergence note lagrangian equation 2 could written follows l Œ±ex p u Œ≤ea p ex ud p x since Ô¨Årst three term l linear combination hence l lower bounded x constant addition algorithm 1 assuming small enough Œ≤ three step alternating algorithm value l decrease therefore exists Œ≤max value Œ≤ algorithm converges stationary point objective function 2 acknowledgment work wa part supported muri grant army navy nsf cns reference 1 dwork hardt pitassi reingold zemel fairness awareness proceeding innovation theoretical computer science conference acm 2012 pp 2 hardt price srebro et equality opportunity supervised learning advance neural information processing system 2016 pp 3 celis straszak vishnoi ranking fairness constraint arxiv preprint 2017 4 angwin larson mattu kirchner machine bias pro publica 2016 5 kay matuszek munson unequal representation gender stereotype image search result occupation proceeding annual acm conference human factor computing system acm 2015 pp 6 dwork differential privacy survey result international conference theory application model computation springer 2008 pp 7 dwork mcsherry nissim smith calibrating noise sensitivity private data analysis tcc vol springer 2006 pp 8 kalantari sankar sarwate optimal differential privacy mechanism hamming distortion structured source class information theory isit 2016 ieee international symposium ieee 2016 pp 9 zemel wu swersky pitassi dwork learning fair representation proceeding international conference machine learning 2013 pp 10 feldman friedler moeller scheidegger subramanian certifying removing disparate impact ings acm sigkdd international conference knowledge discovery data mining acm 2015 pp 11 zafar valera gomez rodriguez gummadi fairness constraint mechanism fair classiÔ¨Åcation arxiv preprint 2017 12 edward storkey censoring representation sary arxiv preprint 2015 13 louizos swersky li welling zemel variational fair autoencoder arxiv preprint 2015 14 tishby pereira bialek information bottleneck method allerton conference communication control computing 1999 15 xu raginsky analysis alization capability learning algorithm advance neural information processing system 2017 pp 16 chechik tishby extracting relevant structure side information advance neural information processing system 2003 pp 17 cover thomas element information theory john wiley son 2012