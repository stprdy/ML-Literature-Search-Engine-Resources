approach addressing learning problem ademola okerinde sam hoggatt divya vani lakkireddy nolan brubaker william hsu lior shamir brian spiesman kansa state university 2164 engineering hall manhattan k usa okerinde schoggatt divyalakki ncbrubaker bhsu lshamir bspiesman abstract recent year learning ha signiﬁcant success application involving computer vision natural language processing type pretext task important boost formance one common pretext task measure similarity dissimilarity pair image scenario two image make negative pair visibly diﬀerent human ever entomology specie nearly indistinguishable thus hard diﬀerentiate study explored performance siamese neural network using contrastive loss learning push apart ding bumblebee specie pair dissimilar pull together similar embeddings experimental result show 61 instance performance showing 11 improvement sample class share intersection training set keywords learning learning siamese neural network pretext task contrastive loss 1 introduction learning zsl problem machine learning test time learner observes sample class not observed training learner need predict sample class 1 deep learning dl requires large amount carefully labeled data often diﬃcult acquire expensive annotate even large amount data supervised learning still ha blind spot learning useful rich representation moreover supervision signal bias network unexpected way learning ssl eﬀective way tract training signal massive amount unlabeled data learn good representation facilitate downstream task expensive collect label representation feature vector contains tic information input image ssl special type representation learning enables learning good data representation unlabeled dataset ssl necessary data labeling often expensive thus labeled datasets limited also good learned representation enables easier 21 jan 2022 2 author suppressed due excessive length transfer useful variety downstream task research downstream task consists transfer new task use contrastive loss cost function critical success ssl objective function pull together embeddings augmentation bumblebee specie pair push embeddings view diﬀerent specie pair far apart arguably challenging task even human many specie bumblebee quite similar even expert pretext task shown figure 2 important component any ssl training pipeline goal wa model learn downstream task like zsl although model trained pretext task transferred speciﬁc task some occasion data could data research explored two data could either bumblebee image dataset recent year researcher become creative determining diﬀerent form pretext task 2 task wa model predict degree rotation image patch 3 predicted eight neighboring location another patch force model learn innate relationship among patch input image research formulated pretext task measure similarity specie dissimilarity diﬀerent specie bumblebee existing retrieval model often pretext task data distribution shift minimal domain entomology ha term rare task siamese neural network snn architecture comprises two identical neural network shared weight parameter trained determine similarity two data sample using distance metric embeddings research used snn determine two bumblebee image belong specie 2 related work recently ssl ha gained lot momentum new paradigm tation learning supervised learning often requires large number label time consuming not available certain domain sult researcher become creative using part data form supervision seemingly frivolous exercise ha produced remarkable outcome often achieved either contrastive learning cl 4 video colorization learning method vides rich representation used video segmentation unlabeled visual region tracking without extra without using supervised label training clip 5 classiﬁer performs quite well challenging classiﬁcation task 6 learned joint tion using cl training one billion noisy image pair best approach addressing learning problem 3 knowledge enormous dataset not yet available entomology make learning task harder cl ha helped make many ssl application successful ideally cl keep positive pair close negative pair far apart feature space according cl currently performs level ssl 9 adopted memory bank store instance class representation vector momentum contrast moco 10 trained visual representation encoder matching encoded query q dictionary encoded key contrastive loss simclr 7 used normalized loss contrastive loss byol 8 relied only positive pair not negative pair learn feature representation simsiam removed momentum encoder provided simpler design based byol ﬁrst paper snn wa published 11 author depicted signiﬁcance network signature veriﬁcation task goal wa identify signature authenticity zsl model ability detect class never seen training even human diﬃcult class sometimes referred distribution ood sample earlier work zsl use attribute approach infer unknown class vision research recent advanced model learn mapping image feature space semantic space 12 proposed address generalized recognition research visual feature corresponding semantics fed architecture contrast based approach only visual signal 3 proposed approach determine well model used pretext task downstream task novelty detection trained model not output class bumblebee rather similarity dissimilarity diﬀerrent specie using contrastive loss shown figure task force model aware visual signal needed downstream task figure 1 show convolutional snn us feature extractor pretrained imagenet snn ha three convolutional layer 16 32 64 ﬁlters use 3 3 kernel size padding ﬁnal fully connected layer ha 128 neuron energy function computed estimate distance tor euclidean distance used energy function rectiﬁed linear activation function relu applied conv layer followed avoid overﬁtting applied dropout probability 20 feature extraction stage passing image pair feature extractor augmented image randomly ﬂipping rotating use contrastive 4 author suppressed due excessive length loss objective function optimized loss equation deﬁned equation 1 l w 1 1 w 1 2 max 0 2 w f 2 1 bumblebee specie image pair w euclidean distance represent energy function either 1 0 depending whether pair similar not represent margin threshold embedding satisfactory separable w network parameter learnt training experimented feature extractor measuring energy function embedding input image pair 4 methodology experimental design dataset dataset consisted 45 specie bumblebee totalling 104770 sample shown table figure 3 show percentage diﬀerent specie histogram bombus impatiens dominates entire dataset data preprocessing preprocessed dataset moving specie fewer sand sample test set mean 21 specie not represented training set randomly selected 20 sample remaining specie include test data 45 specie represented test data fig siamese neural network approach addressing learning problem 5 fig pretext task fig pie chart various specie 6 author suppressed due excessive length table bumblebee b specie zero shot bold specie sample specie sample appositus 888 aﬃnis 1855 crotchii 457 bifarius 5237 bohemicus 21 bimaculatus 7595 caliginosus 147 borealis 2256 franklini 9 citrinus 1449 cockerelli 3 centralis 1755 cryptarum 419 fernaldae ﬂavidus 1047 suckleyi 14 ﬂavifrons 3866 fraternus 424 fervidus californicus 5020 frigidus 179 griseocollis 8787 variabilis 12 impatiens 10008 jonellus 5 insularis 1241 kirbiellus 69 melanopygus 5892 morrisoni 276 mixtus 3359 natvigi 3 nevadensis 1982 occidentalis 943 pensylvanicus sonorus 6522 polaris 11 perplexus 2503 sandersoni 163 rufocinctus 4719 sitkensis 647 huntii 3335 sylvicola 366 ternarius 6467 vandykei 625 terricola 2145 vagans 3546 vosnesenskii 6284 auricomus 2219 total 104770 experimental result trained convolutional snn maximum 100 epoch patience level 7 80 training set evaluated trained model 20 validation set result shown table 9 5 result discussion table 9 show average accuracy recall precision score diﬀerent threshold result reveal good decision boundary specie similarity score threshold table confusion matrix threshold 45 specie predicted similar predicted dissimilar actually similar 61 29 actually dissimilar 43 47 approach addressing learning problem 7 table confusion matrix threshold testset 24 specie predicted similar predicted dissimilar actually similar 3725 1267 actually dissimilar 1514 3478 table confusion matrix threshold 21 unknown test set specie learning predicted similar predicted dissimilar actually similar 24 18 actually dissimilar 15 27 classiﬁed similar vice versa also inspected performance trastive learning within specie bumblebee discover hard easy data pair test data best performing snn model us base feature extractor achieves 73 precision 72 recall 73 72 accuracy result shown table 10 show ssl network detect zero shot instance bumblebee although snn performs much better specie share intersection training dataset table 5 show network still diﬀerentiate pair instance network could diﬀerentiate cockerelli fraternus pair well cryptarum fraternus pair high conﬁdence useful deciding specie novel instance fall entomologist quickly narrow novel specie class either ood sample conventional learning involves learning classiﬁer detect only unknown test sample network achieved 61 5681 unknown specie bumblebee explained 13 task made diﬃcult high class imbalance some specie sample seen table 1 generalized learning goal generalized learning train classiﬁer detect test instance seen unseen class useful thus table specie pair natvigi variabilis appositus fraternus frigidus cockerelli polaris occidentalis cryptarum caliginosus 8 author suppressed due excessive length table confusion matrix threshold validation predicted similar predicted dissimilar actually similar 3197 1123 actually dissimilar 1243 3077 table confusion matrix threshold validation predicted similar predicted dissimilar actually similar 2897 1423 actually dissimilar 1608 2712 challenging entire 45 specie test set network achieved 60 various pairing specie shown table 10 6 conclusion work explored using learning approach detect novel bumblebee instance setting showed model performs well learning embeddings similar dissimilar bumblebee specie pair experimental result showed model generalize zero shot instance not part training future work focus improving performance zsl task learning network map image description also explore cosine similarity energy triplet loss loss function reference wikipedia contributor learning wikipedia free encyclopedia 2021 online accessed fig example image various bee specie approach addressing learning problem 9 table number sample dataset dataset image train validation 79280 24 test 25490 45 fig positive pair negative pair gidaris singh komodakis unsupervised representation learning predicting image rotation arxiv preprint 2018 doersch gupta efros unsupervised visual representation learning context prediction proceeding ieee international conference computer vision pp 2015 vondrick shrivastava fathi guadarrama murphy tracking emerges colorizing video proceeding european conference puter vision eccv pp 2018 radford kim hallacy ramesh goh agarwal sastry askell mishkin clark et al learning transferable visual model natural language supervision arxiv preprint 2021 jia yang xia chen parekh pham le sung li duerig scaling visual representation learning noisy text supervision arxiv preprint 2021 chen kornblith norouzi hinton simple framework trastive learning visual representation international conference machine learning pp pmlr 2020 grill strub e tallec richemond buchatskaya doersch pires guo azar et al bootstrap latent new approach learning arxiv preprint 2020 wu xiong yu lin unsupervised feature learning via parametric instance discrimination proceeding ieee conference computer vision pattern recognition pp 2018 fan wu xie girshick momentum contrast unsupervised visual representation learning proceeding conference computer vision pattern recognition pp 2020 bromley bentz bottou guyon lecun moore ackinger shah signature veriﬁcation using siamese time delay neural network international journal pattern recognition artiﬁcial intelligence 7 04 688 1993 narayan gupta khan snoek shao latent embedding back discriminative feature classiﬁcation computer eccv 2020 european conference glasgow uk august 2020 ceedings part xxii pp springer 2020 10 author suppressed due excessive length table classiﬁcation accuracy precision recall using diﬀerent method validation set model threshold precision recall accuracy snn 14 snn 15 table classiﬁcation accuracy precision recall test set using feature extractor threshold precision recall accuracy 21 specie 45 specie 24 specie okerinde hsu theis naﬁ shamir egan unsupervised proach class imbalance using transfer learning international conference computer analysis image pattern pp springer 2021 zhang ren sun deep residual learning image recognition proceeding ieee conference computer vision pattern recognition pp 2016 sandler howard zhu zhmoginov chen verted residual linear bottleneck proceeding ieee conference computer vision pattern recognition pp 2018