review deep learning application biomedicine chensi cao 1 feng liu 2 b hai tan 3 c deshou song 3 wenjie shu 2 e weizhong li 4 f yiming zhou g xiaochen bo 2 h zhi xie 3 1 capitalbio corporation beijing 102206 china 2 department biotechnology beijing institute radiation medicine beijing 100850 china 3 state key lab ophthalmology zhongshan ophthalmic center sun university guangzhou 500040 china 4 zhongshan school medicine sun university guangzhou 500040 china 5 department biomedical engineering medical system biology research center tsinghua university school medicine beijing 100084 china received 18 june 2017 accepted 5 july 2017 available online 6 march 2018 handled xuegong zhang keywords deep learning big data bioinformatics biomedical informatics medical image sequencing abstract advance biological medical technology providing u explosive umes biological physiological data medical image electroencephalography mic protein sequence learning data facilitates understanding human health disease developed artiﬁcial neural network deep algorithm show great promise extracting feature learning pattern complex data aim paper provide overview deep learning technique some application biomedical ﬁeld ﬁrst introduce development artiﬁcial neural network deep learning describe two main component deep learning deep learning architecture model optimization subsequently some example demonstrated deep learning equal contribution corresponding author yimingzhou zhou boxc bo x xie z orcid b orcid c orcid orcid e orcid f orcid g orcid h orcid orcid peer review responsibility beijing institute genomics chinese academy science genetics society china genomics proteomics bioinformatics 16 2018 ho sted genomics proteomics bioinformatics 2018 author production hosting elsevier behalf beijing institute genomics chinese academy science genetics society china open access article cc license downloaded guest 28 march 2024 application including medical image classiﬁcation genomic sequence analysis well protein structure classiﬁcation prediction finally offer perspective future direction ﬁeld deep learning introduction deep learning recent ﬁeld machine learning attempt model abstraction data employing deep neural network dnns thus making sense data image sound text 1 deep learning general ha two property 1 multiple layer nonlinear processing unit 2 supervised pervised learning feature presentation layer 1 early framework deep learning wa built artiﬁcial neural network anns 2 real impact deep learning became apparent 2006 since deep ing ha applied wide range ﬁelds including matic speech recognition image recognition natural language processing drug discovery bioinformatics past decade witnessed massive growth biomedical data genomic sequence protein tures medical image due advance throughput technology deluge biomedical big data necessitates effective efﬁcient computational tool store analyze interpret data deep algorithmic framework shed light challenging lem aim paper provide bioinformatics biomedical informatics community overview deep learning technique some tions deep learning biomedical ﬁeld hope paper provide reader overview deep learning used analyzing biomedical data development anns basis deep learning anns inspired biological process wa discovered different visual cortex cell activated cat visualized different object study illustrated tions eye cell visual cortex information wa processed layer layer visual system anns mimicked perception object ing artiﬁcial neuron within layer could extract tures object however ann research stagnated due low capability resulting shallow structure limited computational capacity computer time 17 thanks improvement computer capability methodology 18 anns efﬁcient backpropagation bp facilitated study pattern recognition neural network bp classiﬁcations ﬁrst processed ann model weight modiﬁed ating difference predicted true class label although bp helped minimize error ent descent seemed work only certain type anns 24 improving steeper gradient bp several learning method proposed momentum 25 adaptive learning rate method method conjugate gradient cg however due complexity anns ple machine learning algorithm support vector machine svms 37 random forest neighbor algorithm 40 gradually overtook anns popularity figure 1 development deep learning ann hidden layer offer much higher capacity feature extraction 4 however ann often converges local optimum encounter gradient diffusion contains deep complex structure 41 gradient agated backwards rapidly diminishes magnitude along layer resulting slight modiﬁcation weight er near input 42 subsequently deep ae network wa proposed bringing anns new stage development figure 1 network layer trained minimizing discrepancy original reconstructed data 4 break barrier dient diffusion 4 also result better choice weight deep neural network dnns thereby preventing reconstructed data reaching local optimum local optimum usually caused random selection tial weight addition employment graphic processing unit gpus also renews interest researcher deep learning focus attention effort deep learning ha burgeoned recent year ha applied broadly industry instance deep belief network dbns stack restricted boltzmann machine rbms applied speech image recognition natural language processing 51 proposed better ick animal perception object 52 convolutional neural network cnn widely applied image tion image segmentation 56 video recognition natural language processing 59 recurrent neural network rnns another class anns exhibit dynamic behavior artiﬁcial neuron associated time step rnns become primary tool handling sequential data 62 applied natural language processing 63 handwriting tion 64 later variant aes including sparse aes stacked aes saes aes also gained popularity deep network although application deep learning primarily focused image recognition video sound analysis well natural language processing also open door life science discussed detail next section brief description deep learning although underlying assumption theory ent basic idea process feature extraction 18 genomics proteomics bioinformatics 16 2018 downloaded guest 28 march 2024 deep nn dnn architecture similar forward pas network activated input ﬁrst layer spread activation ﬁnal layer along weighted connection generates prediction reconstruction result backward pas weight connection tuned minimizing difference predicted real data basic concept activation function activation function form layer deep learning framework combination layer used simulate transformation input output 62 therefore better feature extraction achieved selecting appropriate activation function introduce several tion function represented sigmoid function gðaþ 1 input front layer sigmoid function transforms variable ues ranging 0 1 commonly used produce bernoulli distribution example g 0 gðaþ 6 1 gðaþ hyperbolic tangent gðaþ tan hðaþ derivative g calculated 1 making easy work bp algorithm softmax gðaþ eai p jeaj softmax output considered probability distribution category commonly used ﬁnal layer rectiﬁed linear unit relu gðaþ aþ tion function variant show superior performance many case popular activation function deep learning far relu also solve gradient diffusion problem softplus gðaþ þ eaþ one variant relu representing smooth approximation relu article log always represents natural logarithm absolute value rectiﬁcation gðaþ jaj function ful pooling layer take average value cnns 75 thus preventing otherwise negative feature positive feature diminishing maxout giðxþ max ðbi þ wi xþ weight matrix function array third array corresponds connection neighboring layer 76 optimization objective optimization objective often composed loss function regularization term loss function measure crepancy output network depend model parameter h fðxjhþ expected result true class label classiﬁcation task true level prediction task however good learning algorithm performs well not only training data also test data tion strategy designed reduce test error called ularization 62 some regularization term apply penalty figure 1 timeline development deep learning machine learning algorithm development deep learning neural network shown top panel several machine learning algorithm shown bottom panel nn neural network bp backpropagation dbn deep belief network svm support tor machine ae vae variational ae gan generative adversarial network wgan wasserstein gan cao c et al deep learning biomedicine 19 downloaded guest 28 march 2024 parameter prevent overly complex model brieﬂy introduce commonly used loss function lðfðxjhþ yþ regularization term xðhþ optimization objective usually deﬁned lðx hþ lðfðxjhþ yþ þ axðhþ balance two component practice loss function usually calculated across sampled training sample rather tribution since latter unknown loss function dnns use cross entropy training data model distribution loss function monly used form cross entropy negative conditional lðfðxjhþ yþ log pðf yjx hþ lection loss function corresponding distribution given value input variable introduce several commonly used loss function follow pattern suppose continuous ha gaussian distribution given variable loss function would lðfðxjhþ yþ log ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ 1 r exp 1 ðy 1 ðy þ 1 2 equivalently described squared error squared error wa commonly used loss function 62 however often tends penalize outlier excessively leading slower convergence rate 77 follows bernoulli distribution loss tion lðfðxjhþ yþ log fðxjhþ yþ fðxjhþþ discrete ha only two value instance 2 2 kg take softmax value see activation function probability category loss function lðfðxjhþ yþ log eay p jeaj þ log x j eaj regularization term parameter regularization common form ularization term contributes convexity mization objective leading easy solution minimum using hessian matrix parameter ularization deﬁned xðhþ 1 2 x represents weight connecting unit network following context compared parameter regularization parameter regularization result sparser solution x tends learn small group feature parameter regularization deﬁned xðhþ x jxij frobenius parameter regularization induced inner product block decomposable therefore easier compute frobenius parameter regularization deﬁned xðhþ ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ x x j ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ ﬃ x rankðxþ v u u ri largest singular value frobenius parameter regularization ha function similar nuclear norm term regularization nuclear norm ha widely used regularization recent year nuclear norm regularization measure sum singular value x deﬁned xðhþ x rankðxþ ri optimization method learning task transformed optimization problem achieve minimum objective function selecting appropriate hyperparameters basic process different optimization method similar first output f optimization objective l model computed using initial parameter network parameter h tuned decrease objective function value ﬁnal layer ﬁrst layer 18 process repeated proper model small ﬁt error loss function value obtained however different optimization method different advantage disadvantage different architecture loss function stochastic gradient descent sgd variant method update parameter gap corresponding jacobian matrix computation time per update doe not grow much even large training set adagrad update parameter according accumulation squared ents converge rapidly applied convex tions performs worse certain model 62 rmsprop adagrad algorithm ha effective popular method parameter optimization another type algorithm make use second order derivative improve optimization instance algorithm bfgs one type method iteratively reﬁnes approximation inverse hessian matrix avoids storing matrix bfgs good dealing low dimensionality problem particularly convolutional model 85 addition conjugate gradient combine conjugacy gradient descent update tion decision parameter efﬁciently avoiding tion inverse hessian contrastive divergence usually used rbm model help gpu 47 many algorithm accelerated signiﬁcantly 85 proper architecture objective function selected according data considered type machine learning deep learning also encounter overﬁtting low error training data high error test data addition regularization term method larization also important reducing test error adding 20 genomics proteomics bioinformatics 16 2018 downloaded guest 28 march 2024 noise input weight efﬁcient regularization strategy case denoising ae 93 stopping optimization early setting iteration number another commonly used strategy prevent network overﬁtting 62 parameter sharing like cnn also contribute regularization 94 dropout force unit independently evolve randomly remove portion unit ann iteration therefore achieve better result inexpensive computation deep learning architecture aes different ordinary anns aes extract feature unlabeled data set target value equal input given input vector xðiþ 2 rn ae try learn model hw bðxþ gðwx þ bþ x w b parameter model g vation function deﬁnition applied following text hw b represents hidden unit number hidden unit represents dimension feature smaller input dimension ae performs tion data dimensionality similar principal component analysis 98 besides pattern recognition ae ﬁer ﬁnal layer perform classiﬁcation task well rbms dbns rbms generative graphical model aim learn distribution training data since not know tribution data obeys not directly compute model parameter using maximum likelihood principle mann machine bm use energy function generate probability distribution see equation 12 13 optimize parameter model learns true distribution data original bm not demonstrated useful practical problem rbms commonly used deep learning rbms restrict bm bipartite graph no connection within visible unit x hidden unit restriction ensures conditional independency den unit visible unit 91 pðhjvþ pipðhijvþ pðvjhþ pjpðvjjhþ furthermore rbms rely assumption unit network take only one two possible value 0 1 mj hi 2 provided activation function conditional distribution hidden visible unit expressed following form pðhi gðwiv þ ciþ pðvj jh þ bjþ according boltzmann distribution probability butions hidden visible vector deﬁned pðm hþ 1 z hþ z p hþ normalizing constant eðv hþ energy function 99 conditional probability distribution also computed integral parameter optimized mizing divergence overall given network architecture optimized parameter distribution visible unit could puted pðvþ x h pðv hþ x h hþ z dbn viewed stack rbms aes similar rbms dbns learn distribution sample learn classify input given class label 3 however pðhþ formula pðvþ p hpðv hþ p replaced better model weight connection w learned rbm addition feature extraction rbms also learn tributions unlabeled data generative model classify labeled data discriminative model regard hidden unit label similar aes rbms also parameter complex network convolutional neural network different deep learning structure artiﬁcial ron convolutional neural network cnns extract feature small portion input image called receptive ﬁelds type feature extraction wa inspired visual mechanism living organism cell visual tex sensitive small region visual ﬁeld besides activation function two particular type layer cnns convolutional layer ing layer figure 2 convolutional layer image convolved different convolutional ﬁlters via shifting receptive ﬁelds step step 87 figure tional ﬁlters share parameter every small portion image largely reducing number hyperparameters model pooling layer taking advantage stationarity property image take mean max statistic feature various location feature map thus reducing variance capturing essential feature figure recurrent neural network recurrent neural network rnns outperform deep learning approach dealing sequential data based property sequential data parameter across different time step rnn model shared taking speech example some vowel may last longer sound difference make absolute time step meaningless demand model parameter among time step 62 beside parameter sharing rnns different multilayer network virtue circuit represents recurrence simple recurrent network corresponds following equation hðtþ gðb þ þ wxðtþþ oðtþ c þ vhðtþ label time w v represent weight connecting hidden input unit hidden output cao c et al deep learning biomedicine 21 downloaded guest 28 march 2024 unit respectively b c offset visible den layer respectively g activation function u resents weight connecting hidden unit time 1 hidden unit time figure 3 similar deep learning architecture rnns also trained using bp method variant bp method called back propagation time bptt standard optimization method rnns some alternative method also proposed speed optimization extend capacity application biomedicine owing advance technology deluge biological medical data ha obtained recent ade including data related medical image biological sequence protein structure some successful tions deep learning biomedical ﬁelds reviewed section summary application shown table medical image classiﬁcation segmentation machine learning medical image ha long powerful tool diagnosis assessment disease traditionally discriminative feature referring medical image tion manually designed classiﬁcation detection lesion abnormality segmentation region est tissue organ different medical application requires participation physician expertise nonetheless complexity ambiguity medical image limited knowledge medical image interpretation requirement large amount annotated data hindered figure 2 illustration convolutional neural network convolution layer ﬁelds different color block table input patch represented multiplied matrix convolution kernel represented k pooling layer result convolution summarized max pooling taken example aij cij kij represent number located line column j corresponding matrix 22 genomics proteomics bioinformatics 16 2018 downloaded guest 28 march 2024 wide use machine learning medical image domain notably deep learning method attained success variety computer vision task object recognition localization segmentation natural image soon brought active ﬁeld machine learning ical image analysis segmentation tissue organ crucial qualitative quantitative assessment medical image pereira et al used data augmentation small convolutional kernel stage achieve accurate brain tumor tation 108 segmentation method ﬁrst place brain tumor segmentation brat challenge 2013 second place havaei et al presented fully automatic brain tumor segmentation method based dnns magnetic resonance mr image training procedure 109 obtained second place 2013 brat methodology wa tested publicly able datasets inbreast 110 digital database ing mammography ddsm 111 outperforming term accuracy efﬁciency several method tested ddsm additional medical application employing deep learning architecture demonstrated menting left ventricle heart mr data 112 pancreas computed tomography ct 113 tibial cartilage magnetic resonance imaging mri 114 prostate mri 115 pocampus mr brain image ation tissue organ medical image ha termed semantic segmentation pixel image assigned class label skeletal muscle organ fat ct image well delineated semantic segmentation based dnn architecture 120 similarly semantic segmentation mr image also attained accurate segmentation result detection lesion abnormality major issue medical image analysis deep learning method learn resentations directly instead using feature training data classiﬁer used assign figure 3 illustration recurrent neural network unfold form common neural network top schema bottom illustration recurrent neural network top unfold form bottom red square represents one time step delay different panel arrow panel b represent set connection w b represent weight matrix bias vector respectively x represent input output network respectively h indicates hidden unit network l consists couple transformation layer dropout layer u indicates transformation two neighbor time point represents time point cao c et al deep learning biomedicine 23 downloaded guest 28 march 2024 table 1 application deep learning framework biomedical informatics topic dl architecture brief description ref medical image analysis cnn brain tumor segmentation top 2 brat 108 segmentation pancreas ct 113 knee cartilage segmentation 114 segmentation hippocampus 117 predict semantic description medical image 118 segmentation mr brain image 121 classiﬁcation medical image 123 cerebral microbleeds mr image 125 coronary artery calcium scoring ct image 126 nucleus detection routine colon cancer histology image 129 histopathological cancer classiﬁcation 130 invasive ductal carcinoma segmentation wsi 132 mammographic lesion detection 133 haemorrhage detection fundus image 137 exudate detection fundus image 138 sae segmentation hippocampus infant brain 116 organ detection patient data 122 histological characterization healthy skin healing wound 124 scoring percentage mammographic density mammographic texture related breast cancer risk 134 optic disc detection fundus photograph 135 dbn segmentation left ventricle heart mr data 112 discriminate disease 139 dnn brain tumor segmentation mr image place brat 109 prostate mr segmentation 115 gland instance segmentation 119 semantic segmentation tissue ct image 120 mitosis detection breast cancer histological image 131 rnn prediction epileptic seizure propagation using nn 141 classiﬁcation pattern eeg synchronization seizure prediction 142 lapse detection 143 prediction epileptic seizure 144 genomic sequencing gene expression analysis dnn gene expression inference 145 identiﬁcation region replication timing domain 151 prediction enhancer 152 prediction splicing pattern individual tissue diﬀerences splicing pattern across tissue 159 annotation pathogenicity genetic variant 161 dbn modeling structural binding preference predicting binding site protein 146 prediction splice junction dna level 156 prediction transcription factor binding site annotation interpretation noncoding genome 151 prediction noncoding variant eﬀects de novo sequence 162 24 genomics proteomics bioinformatics 16 2018 downloaded guest 28 march 2024 representation probability indicates whether not image contains lesion word deep learning schema classify pixel lesion point not done two way 1 classifying mini patch around pixel deep network 2 using fully tional network classify pixel sheet et al 124 applied dnn histologically ize healthy skin healing wound reduce clinical ing variability two unsupervised layer denoising aes daes used learn feature hybrid architecture subsequently whole network wa learned using labelled tissue characterization detection cerebral microbleeds 125 coronary artery calciﬁcation 126 also produced better result using deep based approach addition brain tumor progression diction implemented deep learning architecture 127 ha also shown robust tumor progression model comparison manifold learning approach 128 detection pathology stained histopathology image exemplify high precision deep approach breast cancer detection histopathology image et al 132 established deep learning model precisely delineate invasive ductal carcinoma idc region distinguish invasive tumor tissue invasive healthy tissue cnn architecture composed two cascading convolutional pooling layer layer logistic regression classiﬁer prediction attained better higher balanced accuracy bac comparison approach using handcrafted image feature machine learning classiﬁer mammogram one effective imaging modality early diagnosis risk prediction breast cer deep learning model 133 trained large dataset image attained performance similar certiﬁed screening radiologist mammographic lesion detection lenberg et al 134 investigated scoring percentage mographic density pmd mammographic texture mt related prediction breast cancer risk employed sparse ae learn deep hierarchical feature unlabeled mammogram multinomial logistic regression softmax regression wa used classiﬁer supervised ing result performance approach wa parable subjective expensive manual pmd mt scoring color fundus photography important diagnostic tool ophthalmic disease deep method fundus image recently gained considerable interest key developing automated diagnosis system dnn tecture wa proposed srivastava et al 135 distinguish optic disc od parapapillary atrophy ppa dnn consisting saes followed reﬁned active shape model attained accurate od segmentation image registration deep learning combination hessian matrix 136 wa used detect vessel landmark retinal image whereas convolutional neural network also duced excellent result detection hemorrhage 137 exudate 138 color fundus image difﬁcult design automatic screening system disease molecular degeneration diabetic thy retinoblastoma retinal detachment retinitis rnn prediction mirna precursor mirna target detection splice junction dna sequence 157 prediction function de novo sequence 163 analysis human splicing code determination disease 161 protein structure prediction dbn modeling structural binding preference predicting binding site rbps 146 ab initio prediction protein secondary structure 171 prediction protein disorder 184 prediction secondary structure local backbone angle solvent accessible surface area protein 170 cnn prediction protein region 183 prediction protein secondary structure prediction protein structure property including secondary structure solvent accessibility disorder region 185 sae prediction backbone ca angle dihedrals 169 rnn prediction protein secondary structure prediction protein contact map note nn neural network cnn convolutional nn sae stacked dbn deep belief network rnn recurrent nn cao c et al deep learning biomedicine 25 downloaded guest 28 march 2024 tosa disease share similar characteristic deep learning method arunkumar et al 139 cessfully built system discriminate disease only using fundus image first dbn composed stack rbms wa designed feature extraction ized regression neural network grnn wa employed reduce dimensionality finally svm wa used classiﬁcation interestingly kaggle organized tion staging diabetic retinopathy ing test color fundus image using convolutional neural network top model outperformed machine learning method kappa score addition static image medical record signal map toencephalography also analyzed using deep learning method deep learning schema take coded feature signal raw signal 144 input extract feature data anomaly classiﬁcation understanding emotion aforementioned application illustrate frontier machine learning deep learning ha made tial progress medical image segmentation classiﬁcation expect clinical trial systematic medical image analytic application emerge help achieve better performance applying deep learning medicine genomic sequencing gene expression analysis deep learning also play important role genomic sequencing gene expression analysis infer sion proﬁles target gene based approximately 1000 mark gene nih integrated cellular signature lincs program chen et al presented deep learning method dropout regularization signiﬁcantly outperformed linear regression lr term prediction accuracy microarray data 145 applying multimodal dbn model structural binding preference predict binding site binding protein rbps using primary sequence well secondary tertiary structural proﬁles zhang et al achieved auc some protein 146 predict binding site protein alipanahi et al developed deepbind method passed method even trained vitro data tested vivo data 147 subsequently lanchantin et al 148 zeng et al 149 also applied cnn predict transcription factor binding site tfbss study demonstrated improvement formance deepbind auc input deep cnns encoded sequence character obtained protein binding microarrays assay output real value indicating whether sequence binding site not deeper model make accurate tion extracting feature raw nucleotide sequence 148 addition kelley et al presented basset open source package apply deep cnns learn matin accessibility code enabling annotation tion noncoding genome 150 application include li et al 134 liu et al proposed deep learning approach identiﬁcation region replication timing domain tively addition yoon collaborator employed rnns predict mirna precursor target result achieved 25 increase compared existing alternative method genetic variation inﬂuence transcription dna translation mrna 155 understanding effect sequence variant splicing facilitates not only whole genome annotation also understanding ome function predict splice junction dna level yoon collaborator developed novel method wa trained rbms boosting contrastive divergence categorical gradient 156 method not only achieved better accuracy robustness also ered subtle splicing pattern 156 furthermore exploiting rnns model detect splice junction dna sequence author also achieved better formance previous method 157 frey et al formulated assembly splicing code statistical inference problem 158 proposed bayesian method predict splicing using rna sequence cellular context subsequently developed dnn model dropout learn predict alternative splicing 159 model took genomic feature tissue context input predicted splicing pattern individual tissue difference splicing pattern across sue showed method surpassed previous bayesian method common machine learning rithms multinomial logistic regression mlr svms term prediction furthermore built computational model using bayesian deep learning rithm predict effect genetic variant 160 model took dna sequence alone input without using disease annotation population data scored effect variant providing valuable insight genetic determinant spinal muscular atrophy polyposis colorectal cancer autism spectrum disorder annotate pathogenicity genetic variant quang et al developed dnn algorithm named dann performs logistic regression lr svms auc metric increased 14 svms 161 zhou et al posed algorithmic framework deepsea predict functional effect noncoding variant de novo sequence 162 deepsea directly learns regulatory sequence code data predict chromatin effect sequence alteration sensitivity prioritize tional variant based predicted chromatin effect signal subsequently danq novel hybrid framework combine cnn long memory blstm rnns wa presented predict function de novo sequence alone 163 danq achieved auc 50 higher model including aforementioned deepsea prediction protein structure structure protein determined comprising amino acid sequence 164 however computational diction protein structure sequence remains 26 genomics proteomics bioinformatics 16 2018 downloaded guest 28 march 2024 challenging 165 correct structure protein cial function improper structure could lead wide range disease deep learning technology shown great capability area protein structure prediction aim predict secondary structure contact map protein lyon et al reported ﬁrst sae diction backbone ca angle dihedrals 169 heffernan et al also employed saes predict secondary structure local backbone angle surface area asa protein amino acid sequence 170 achieved accuracy 82 secondary structure tion spencer et al proposed dnss ab initio approach predicting secondary structure protein using deep learning network architecture 171 dnss wa trained using scoring matrix protein sequence atchley factor residue wa optimized accelerate computation using gpu compute uniﬁed device architecture cuda baldi colleague successfully applied various algorithm predict protein ondary structure protein contact map 177 accuracy 84 30 respectively derby et al used bidirectional rnn brnn long memory cell improve prediction ondary structure better accuracy using state art 178 compared saes dbns rnns cnns seldom used protein structure prediction recently li et al developed malphite cnn ensemble method predicting protein secondary structure achieved accuracy dataset containing 3000 protein 179 ally lin et al proposed multilayer stitch convolutional neural network architecture predict protein secondary structure primary amino acid sequence 180 besides classical deep learning architecture some architecture also employed predict tein secondary structure example lena et al introduced deep learning architecture achieved accuracy roughly 10 higher method 181 zhou et al presented deep supervised tional generative stochastic network achieving accuracy 182 addition secondary structure prediction deep learning wa also employed protein region prediction instance predictor protein disorder using boosted ensemble deep network der deep neural network rbms 184 achieved average balanced accuracy auc incorporated predicted secondary structure predicted asa weighted deep convolutional neural ﬁelds deepcnf wa proposed predict protein region obtains auc critical sessment technique protein structure prediction dataset 183 method surpassed predictor accuracy still maintaining extremely high computing speed recently web server employing deepcnf wa also presented predict protein structure property ing secondary structure solvent accessibility disorder region 185 easily used offer good performance auc test data conclusion perspective deep learning moving toward original goal artiﬁcial intelligence feature extraction capacity deep learning enables application wide range ﬁelds many deep learning framework open source including framework like torch caffe theano mxnet dmtk tensorflow some designed wrapper easy use kera lasagne block application deep learning rithms facilitated freely available source figure 4 summarizes framework github number star reﬂects popularity framework breakthrough technology particularly sequencing producing large quantity genomic data efﬁcient interpretation data ha attracting much attention recent year scenario uncovering tionship genomic variant disease ing regulatory process gene cell important research area review introduced way deep learning get involved area using example deep architecture model simulate complex formation discover hierarchical data representation hand almost model trained parallel gpus fast processing furthermore deep learning extract feature deal dimensional data machine learning usually depends feature suitable only data thus deep learning becoming popular genomic sequence analysis figure 4 popularity deep learning framework github distribution star github deep learning framework written lua python matlab julia java shown pie chart star github indicate higher popularity font size framework pie chart reﬂects number star cao c et al deep learning biomedicine 27 downloaded guest 28 march 2024 deep learning represented group technology introduced brief description deep learning ha widely used biomedical data introduced application biomedicine saes rbms extract pattern beled data 186 well labeled data stacked classiﬁer 156 also deal dynamic data 187 cnns commonly used biomedical image ysis domain due outstanding capacity analyzing tial information although relatively cnns used sequencing data cnns great potential omics analysis 147 biomedical signal 142 hand based architecture tailored sequential data often used sequencing data dynamic biomedical signal 144 le frequently static cal image currently attention paid usage deep learning biomedical information new application schema may discovered near future despite notable advantage deep learning challenge applying deep learning biomedical domain still remain take biomedical image analysis instance use fundus image exemplify deep learning work deﬁne level diabetic retinopathy detect lesion area different way besides high accuracy speed intelligent use receptive ﬁelds also endows deep learning whelming superiority term image recognition development classiﬁcation method based deep learning shed new light classifying pixel lesioned not however usage deep learning medical image still challenging model training need large amount data label sometimes label term pixel classiﬁcation manually labeling medical image laborious requires professional expert hand medical image highly associated privacy collecting protecting data demanding biomedical data usually imbalanced quantity data normal class much larger class addition balancing challenge large amount data required labeling biomedical data deep learning also requires technological improvement unlike image subtle change medical image may indicate disease therefore analyzing image requires resolution input high training speed large memory additionally difﬁcult ﬁnd uniform assessment ric biomedical data classiﬁcation prediction unlike project tolerate false positive some extent reject no false negative disease diagnosis different data necessary ass model carefully tune model according characteristic data fortunately deeper network inception ules accelerated provide higher accuracy biomedical image analysis 190 hand crowdsourcing approach begun pave way collecting annotation may important tool next year bidirectional driver would promote application deep learning biomedical informatics goal precision medicine research demand active learning biological biomedical well health data together medical device instrument wearable sensor smart phone providing dented amount health data deep learning promising interpreter data serving disease prediction tion diagnosis prognosis therapy expect deep learning application available epidemic tion disease prevention clinical competing interest author declared no competing interest acknowledgment work wa supported center precision cine sun university national r program 863 program grant no china awarded yz reference 1 yu deng deep learning application signal information processing ieee signal process mag 2011 2 fukushima neocognitron neural network model mechanism pattern recognition unaffected shift position biol cybern 1980 3 hinton ge osindero teh yw fast learning algorithm deep belief net neural comput 2006 4 hinton ge salakhutdinov rr reducing dimensionality data neural network science 2006 5 cio kj mamitsuka h nagashima tadeusiewicz putational intelligence solving bioinformatics problem artif intell med 2005 6 la ngkvist karlsson l loutﬁa review unsupervised feature learning deep learning modeling pattern recognit lett 2014 7 krizhevsky sutskever hinton ge imagenet classiﬁcation deep convolutional neural network adv neural inform process syst 2012 8 asgari e mofrad mrk protvec continuous distributed representation biological sequence 9 hubel dh wiesel tn receptive ﬁelds binocular interaction functional architecture cat visual cortex j physiol 1962 10 hubel dh wiesel tn receptive ﬁelds single neurones cat striate cortex j physiol 1959 11 weng j ahuja n huang cresceptron neural network grows adaptively proc int jt conf neural netw 1992 12 weng jj ahuja n huang learning recognition segmentation object image proc ieee int conf comput vi 13 weng j ahuja n huang learning recognition segmentation using cresceptron int j comput vi 1997 14 riesenhuber poggio hierarchical model object recognition cortex nat neurosci 1999 15 joseph rd contribution perceptron theory si cornell university 1961 16 viglione application pattern recognition technology mendel jm fu k editor mathematics science engineering amsterdam elsevier v 1970 17 newell papert mm perceptrons introduction tational geometry science 1969 28 genomics proteomics bioinformatics 16 2018 downloaded guest 28 march 2024 18 werbos beyond regression new tool prediction analysis behavioral science dissertation harvard university 1974 19 werbos application advance nonlinear sensitivity analysis drenick rf kozin f editor system modeling optimization berlin springer berlin heidelberg 1982 20 werbos backwards differentiation ad neural net past link new opportunity bu cker corliss g naumann u hovland p norris b editor automatic differentiation application theory implementation berlin springer berlin heidelberg 2006 21 lecun une proce dure apprentissage pour seau seuil asyme trique proc cogn 22 lecun theoretical framework proc 1988 connect model summer sch 23 lang kj waibel ah hinton ge neural network architecture isolated word recognition neural netw 1990 24 schmidhuber deep learning neural network overview neural netw 2015 25 rumelhart de mcclelland jl pdp research group parallel distributed processing exploration ture cognition cambridge mit press 1986 26 west ahl saad adaptive learning multilayer network nip 95 proc int conf neural inform process syst 27 battiti accelerated backpropagation learning two tion method complex syst 1989 28 almeida lb artiﬁcial neural network piscataway ieee press 1990 29 marquardt dw algorithm estimation nonlinear parameter j soc ind appl math 1963 30 gauss cf theoria motus corporum coelestium sectionibus conicis solem ambientium cambridge cambridge university press 1809 31 broyden cg class method solving nonlinear taneous equation math comput 1965 32 fletcher r powell mjd rapidly convergent descent method minimization comput j 1963 33 goldfarb family method derived variational mean math comput 1970 34 shanno df conditioning method tion minimization math comput 1970 35 møller exact calculation product hessian matrix network error function vector 0 n time daimi rep 36 hestenes mr stiefel method conjugate gradient solving linear system j nat bur stand 1952 37 cortes c vapnik network mach learn 1995 38 ho tk random decision forest proc int conf doc anal recognit 1995 39 ho tk random subspace method constructing decision forest ieee trans pattern anal mach intell 1998 40 altman n introduction kernel nonparametric regression stat 1992 41 graf practical variational inference neural network j zemel r bartlett pl pereira f weinberger kq editor advance neural information processing system new york curran associate 2011 42 bengio simard p frasconi learning cies gradient descent difﬁcult ieee trans neural netw learn syst 1994 43 lecun bengio hinton deep learning nature 2015 44 ciresan dc meier u masci j gambardella lm schmidhuber flexible high performance convolutional neural network image classiﬁcation ijcai 11 proc int joint conf artif intell 2011 45 hinton g deng l yu dahl ge mohamed jaitly n et al deep neural network acoustic modeling speech tion shared view four research group signal process mag ieee 2012 46 cires dc meier u gambardella lm schmidhuber deep big simple neural net handwritten digit recognition neural comput 2010 47 raina r madhavan ng ay deep unsupervised learning using graphic processor icml 09 proc ann int conf mach learn 48 hinton ge boltzmann machine scholarpedia 2007 49 bengio learning deep architecture ai delft publisher 2009 50 sutskever hinton ge learning multilevel distributed sentations sequence j mach learn 2007 51 sarikaya r hinton ge deoras application deep belief network natural language understanding trans audio speech lang process 2014 52 matsugu mori k mitari kaneda subject independent facial expression recognition robust face detection using convolutional neural network neural netw 2003 53 sermanet p lecun trafﬁc sign recognition convolutional network neural netw 2011 54 lawrence giles cl tsoi ac back ad face recognition convolutional approach ieee trans neural netw learn syst 1997 55 szegedy c liu w jia sermanet p reed anguelov et al going deeper convolution proc ieee comput soc conf comput vi pattern recognit 56 long j shelhamer e darrell fully convolutional network semantic segmentation proc ieee comput soc conf comput vi pattern recognit 2015 57 karpathy toderici g shetty leung sukthankar r li ff video classiﬁcation convolutional neural network proc ieee conf comput vi pattern recognit 58 simonyan k zisserman convolutional network action recognition video ghahramani z welling cortes c lawrence nd weinberger kq editor advance neural information processing system new york curran associate 2014 59 collobert r weston uniﬁed architecture natural language processing deep neural network multitask learning acm proc int conf mach learn 60 hochreiter schmidhuber long memory neural comput 1997 61 graf supervised sequence labelling recurrent neural network berlin berlin heidelberg 2012 62 goodfellow bengio courville modern practical deep network goodfellow bengio courville editor deep learning cambridge mit press 2015 63 gers fa schmidhuber lstm recurrent network learn simple language ieee trans neural netw 2001 64 graf schmidhuber ofﬂine handwriting recognition multidimensional recurrent neural network koller schuurmans bengio bottou l editor advance neural information processing system new york curran associate 2009 65 ballard dh modular learning neural network proc conf aaai artif intell 66 scho lkopf b platt j hofmann greedy training deep network adv neural inf process syst 67 scho lkopf b platt j hofmann efﬁcient sparse coding algorithm adv neural inf process syst cao c et al deep learning biomedicine 29 downloaded guest 28 march 2024 68 bengio practical recommendation ing deep architecture lect note comput sci 2012 69 singh rg kishore impact transformation function classiﬁcation ability complex valued extreme learning machine int conf control comput commun mater 70 toth phone recognition deep sparse rectiﬁer neural network proc ieee int conf acoust speech signal process 71 maas al hannun ay ng ay rectiﬁer nonlinearities improve neural network acoustic model proc int conf mach learn 72 nair v hinton ge rectiﬁed linear unit improve restricted boltzmann machine icml 10 proc int conf mach learn 73 lai deep learning medical image segmentation 74 glorot x bordes bengio deep sparse rectiﬁer neural network j mach learn 2011 75 jarrett k kavukcuoglu k ranzato lecun best architecture object recognition proc ieee int conf comput vi 76 goodfellow ij mirza courville maxout network 77 rosasco l de vito e caponnetto piana verri loss function neural comput 2004 78 binmore kg davy calculus concept method bridge cambridge university press 2002 79 boyd vandenberghe convex optimization bridge cambridge university press 2004 80 huang j dong li new method regularization parameter estimation source localization ieee cie int conf 2011 81 yu schuurmans regularization form solution application subspace clustering assoc tain artif intell 82 abernethy j bach f evgeniou vert jp new approach collaborative ﬁltering operator estimation spectral ization j mach learn 2009 83 argyriou evgeniou pontil convex feature learning mach learn 2008 84 obozinski g taskar b jordan mi joint covariate selection joint subspace selection multiple classiﬁcation problem stat comput 2010 85 gauriau r cuingnet r lesage bloch localization cascaded regression shape prior med image anal 2015 86 bottou stochastic gradient learning neural network proc neuro nımes 1991 91 87 lecun bottou l bengio haffner learning applied document recognition proc ieee 1998 88 zinkevich weimer li l smola aj parallelized stochastic gradient descent lafferty jd williams cki j zemel r culotta editor advance neural tion processing system new york curran associate 2010 89 hinton ge product expert icann 90 hinton ge training product expert contrastive gence neural comput 91 hinton ge contrastive divergence learning proc artif intell stat 92 jim kc giles cl horne bg analysis noise recurrent neural network convergence generalization ieee trans neural netw 1996 93 vincent p larochelle h lajoie bengio manzagol stacked denoising autoencoders learning useful representation deep network local denoising criterion j mach learn 2010 94 lasserre ja bishop cm minka tp principled hybrid generative discriminative model proc ieee comput soc conf comput vi pattern recognit 2006 95 hinton ge srivastava n krizhevsky sutskever dinov rr improving neural network preventing tation feature detector 96 srivastava n hinton ge krizhevsky sutskever dinov dropout simple way prevent neural network overﬁtting j mach learn 2014 97 aurelio ranzato poultney c chopra cun yl efﬁcient learning sparse representation model scho lkopf b platt jc hoffman editor advance neural information processing system new york curran associate 2007 98 bourlard h kamp multilayer trons singular value decomposition biol cybern 1988 99 hinton practical guide training restricted boltzmann machine montavon g orr g mu ller kr editor neural network trick trade berlin springer berlin berg 2012 100 hinton ge deep belief network oxford oxford univ press 2009 5947 101 erhan bengio courville manzagol pa vincent p bengio doe unsupervised help deep learning j mach learn 2010 102 ciresan meier u schmidhuber deep neural network image classiﬁcation proc ieee comput soc conf comput vi pattern recognit 103 werbos generalization backpropagation application recurrent gas market model neural netw 1988 104 pearlmutter learning state space trajectory recurrent neural network neural comput 2011 105 hochreiter bengio frasconi p schmidhuber gradient ﬂow recurrent net difﬁculty learning dependency kolen jf kremer sc editor ﬁeld guide dynamical recurrent neural network press 2001 106 syed applying genetic algorithm recurrent neural network learning network parameter ture cleveland case western reserve university press 1995 107 gomez f schmidhuber j miikkulainen accelerated neural evolution cooperatively coevolved synapsis j mach learn 2008 108 pereira pinto alves v silva ca brain tumor tion using convolutional neural network mri image ieee trans med imaging 2016 109 havaei davy biard courville bengio et al brain tumor segmentation deep neural network med image anal 2017 110 moreira ic amaral domingues cardoso cardoso mj cardoso j inbreast toward digital mammographic database acad radiol 2012 111 health bowyer k kopans moore r kegelmeyer wp sallam et al digital database screening phy yaffe mj editor detection characterization mammographic mass artiﬁcial neural network berlin springer netherlands 2001 112 ngo ta lu z carneiro combining deep learning level set automated segmentation left ventricle heart cardiac cine magnetic resonance med image anal 2017 113 roth hr farag lu l turkbey eb summer rm deep convolutional network pancreas segmentation ct ing 30 genomics proteomics bioinformatics 16 2018 downloaded guest 28 march 2024 114 prasoon petersen k igel c lauze f dam e nielsen deep feature learning knee cartilage segmentation using triplanar convolutional neural network med image comput comput assist interv 2013 115 liao gao oto shen representation learning uniﬁed deep learning framework automatic prostate mr segmentation med image comput comput assist interv 2013 116 guo yr wu gr commander la szary jewells v lin wl et al segmenting hippocampus infant brain sparse patch matching feature med image comput comput assist interv 2014 117 kim wu g shen unsupervised deep learning hippocampus segmentation tesla mr image wu g zhang shen yan p suzuki k wang f editor proceeding international workshop machine learning medical imaging new york new york 2013 118 schlegl waldstein sm vogl wd u langs predicting semantic description medical image convolutional neural network basel springer international publishing ag 2015 119 xu li liu wang fan lai et al gland instance segmentation deep multichannel neural network 120 lerouge j herault r chatelain c jardin f modzelewski ioda deep architecture image labeling pattern recognit 2015 121 moeskops p viergever mendrik de vries l bender mjnl isgum automatic segmentation mr brain image convolutional neural network ieee trans med imaging 2016 122 shin hc orton mr collins dj doran sj leach mo stacked autoencoders unsupervised feature learning multiple organ detection pilot study using patient data ieee trans pattern anal mach intell 2013 123 roth hr lee ct shin hcc seff kim l yao j et al classiﬁcation medical image using deep convolutional net proc ieee int symp biomed imaging 124 sheet karri spk katouzian navab n ray ak chatterjee deep learning tissue speciﬁc speckle tions optical coherence tomography deeper exploration situ histology proc ieee int symp biomed imaging 125 dou q chen h yu l zhao l qin j wang et al automatic detection cerebral microbleeds mr image via convolutional neural network ieee trans med imaging 2016 126 wolterink jm leiner de vos bd van hamersvelt rw viergever ˇ gum automatic coronary artery calcium scoring cardiac ct angiography using paired convolutional neural network med image anal 2016 127 zhou dq tran l wang jh li comparative study two prediction model brain tumor progression image process algorithm syst 128 tran l banerjee wang j kumar aj mckenzie f li et al mri data analysis using manifold learning approach mach vi appl 2013 24 129 sirinukunwattana k raza sea tsang yw snead drj cree ia rajpoot nm locality sensitive deep learning detection classiﬁcation nucleus routine colon cancer histology image ieee trans med imaging 2016 130 xu zhu jy chang e tu multiple clustered instance learning histopathology cancer image classiﬁcation tation clustering proc ieee comput soc conf comput vi pattern recognit 131 cires dc giusti gambardella lm schmidhuber mitosis detection breast cancer histology image deep neural network med image comput comput assist interv 132 basavanhally gonzalez f gilmore h feldman ganesan et al automatic detection invasive ductal carcinoma whole slide image convolutional neural network med imaging 133 kooi litjens g van ginneken b rida sa nchez ci mann r et al large scale deep learning computer aided detection mammographic lesion med image anal 2017 134 kallenberg petersen k nielsen ng ay diao pf igel c et al unsupervised deep learning applied breast density segmentation mammographic risk scoring ieee trans med imaging 2016 135 srivastava r cheng j wong dwk liu using deep learning robustness parapapillary atrophy optic disc tion ieee int symp biomed imaging 136 fang su r xie l gu q li q liang p et al retinal vessel landmark detection using deep learning hessian matrix proc int symp image signal process anal 137 van grinsven mjjp van ginneken b hoyng cb theelen sanchez ci fast convolutional neural network training using selective data sampling application hemorrhage detection color fundus image ieee trans med imaging 2016 138 prentas ˇ ic p lonc ˇ aric detection exudate fundus photograph using convolutional neural network proc int symp image signal process anal 139 arunkumar r karthigaikumar disease cation reduced deep learning feature neural comput appl 140 mirowski pw lecun madhavan kuzniecky ing svm convolutional network epileptic seizure prediction intracranial eeg ieee int workshop mach learn signal process 141 mirowski pw madhavan lecun neural network independent component analysis prediction epileptic seizure propagation proc conf aaai artif intell 142 mirowski p madhavan lecun kuzniecky tion pattern eeg synchronization seizure prediction clin neurophysiol 2009 143 davidson pr jones rd peiris mtr lapse tion high temporal resolution ieee trans biomed eng 2007 144 petrosian prokhorov homan r dasheiff r wunsch recurrent neural network based prediction epileptic seizure extracranial eeg neurocomputing 2000 145 chen li narayan r subramanian xie gene expression inference deep learning bioinfarmatics 2016 146 zhang zhou j hu h gong h chen l cheng c et al deep learning framework modeling structural feature protein target nucleic acid 2016 44 147 alipanahi b delong weirauch mt frey bj predicting sequence speciﬁcities protein deep learning nat biotechnol 2015 148 lanchantin j singh r lin z qi deep motif visualizing genomic sequence classiﬁcations 149 zeng h edward md liu g gifford dk convolutional neural network architecture predicting ing bioinformatics 2016 32 150 kelley dr snoek j rinn jl basset learning regulatory code accessible genome deep convolutional neural network genome 2016 cao c et al deep learning biomedicine 31 downloaded guest 28 march 2024 151 liu f ren c li h zhou p bo x shu de novo identiﬁcation domain human genome deep learning bioinformatics 2015 152 liu f li h ren c bo x shu pedla predicting enhancer deep algorithmic framework sci seq 2016 153 park min choi h yoon deepmirgene deep neural network based precursor microrna prediction 154 lee b baek j park yoon deeptarget learning framework microrna target prediction using deep recurrent neural network 155 guigo r valcarcel prescribing splicing science 2015 156 lee yoon boosted categorical restricted boltzmann machine computational prediction splice junction proc int conf mach learn 2015 37 157 lee b lee na b yoon splice junction prediction using deep recurrent neural network 158 xiong hy barash frey bj bayesian prediction regulated splicing using rna sequence cellular context bioinformatics 2011 159 leung mkk xiong hy lee lj frey bj deep learning splicing code bioinformatics 2014 30 160 xiong hy alipanahi b lee lj bretschneider h merico yuen rkc et al human splicing code reveals new insight genetic determinant disease science 2014 161 quang chen xie dann deep learning approach annotating pathogenicity genetic variant bioinformatics 2015 162 zhou j troyanskaya og predicting effect noncoding variant deep sequence model nat method 2015 163 quang xie danq hybrid convolutional recurrent deep neural network quantifying function dna sequence nucleic acid 2016 164 anﬁnsen cb formation stabilization protein structure biochem j 1972 165 gibson kd scheraga ha minimization polypeptide energy preliminary structure bovine pancreatic ribonuclease peptide proc natl acad sci u 1967 166 hammarstrom p wiseman rl power et kelly jw tion transthyretin amyloid disease changing protein misfolding energetics science 2003 167 chiti f dobson cm protein misfolding functional amyloid human disease annu rev biochem 2006 168 selkoe dj folding protein fatal way nature 2003 169 lyon j dehzangi heffernan r sharma paliwal k sattar et al predicting backbone ca angle dihedrals protein sequence stacked sparse deep neural network j comput chem 2014 170 heffernan r paliwal k lyon j dehzangi sharma wang j et al improving prediction secondary structure local backbone angle solvent accessible surface area protein iterative deep learning sci rep 2015 171 spencer eickholt j cheng deep learning network approach ab initio protein secondary structure prediction trans comput biol bioinform 2015 172 baldi p pollastri g andersen caf brunak matching protein partner feedforward recurrent neural network proc int conf intell syst mol biol 173 baldi p brunak frasconi p soda g pollastri exploiting past future protein secondary structure prediction bioinformatics 1999 174 pollastri g przybylski rost b baldi improving prediction protein secondary structure three eight class using recurrent neural network proﬁles protein 2002 175 pollastri g baldi prediction contact map giohmms recurrent neural network using lateral propagation four cardinal corner bioinformatics 2002 18 176 baldi p pollastri principled design recursive neural network protein structure prediction problem j mach learn 2004 177 di lena p nagata k baldi deep architecture protein contact map prediction bioinformatics 2012 178 sønderby sk winther protein secondary structure prediction long short term memory network 179 li shibuya malphite convolutional neural network ensemble learning based protein secondary structure predictor proc ieee int conf bioinformatics biomed 180 lin z lanchantin j qi multilayer stitch deep convolutional architecture protein structure prediction proc conf aaai artif intell 181 lena pd nagata k baldi pf deep tures learning protein structure prediction adv neural inf process syst 182 troyanskaya og deep supervised convolutional generative stochastic network protein secondary structure prediction proc int conf mach learn 2014 183 wang weng j tang predicting protein region weighted deep convolutional neural ﬁelds int j mol sci 2015 184 eickholt j cheng dndisorder predicting protein disorder using boosting deep network bmc bioinformatics 2013 185 wang li w liu xu web server protein structure property prediction nucleic acid 2016 44 186 shin hc orton collins dj doran leach mo coder analysis unsupervised tissue isation large unlabelled medical image dataset proc int conf mach learn appl 2011 187 jia x li k li x zhang novel deep learning framework affective state recognition eeg signal proc ieee int symp bioinformatics bioeng 188 k zhang x ren sun deep residual learning image recognition proc ieee comput soc conf comput vi pattern recognit 2015 189 szegedy c ioffe vanhoucke tionresnet impact residual connection learning 190 yarlagadda dvk rao p rao mitosisnet deep learning network mitosis detection breast cancer histopathology image ieee embs int conf biomed health inform 2017 191 irshad h oh ey schmolze quintana lm collins l tamimi rm et al crowdsourcing scoring chemistry image evaluating performance crowd automated computational method 192 albarqouni baur c achilles f belagiannis v demirci navab aggnet deep learning crowd mitosis detection breast cancer histology image ieee trans med imaging 2016 32 genomics proteomics bioinformatics 16 2018 downloaded guest 28 march 2024