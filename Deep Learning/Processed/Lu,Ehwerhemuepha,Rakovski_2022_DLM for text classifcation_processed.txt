lu et al bmc medic research methodolog http research compar studi deep learn model text classif unstructur medic note variou level class imbal hongxia loui cyril abstract background discharg medic note written physician contain import inform health tion patient mani deep learn algorithm success appli extract import inform unstructur medic note data entail subsequ action result medic domain thi studi aim explor model perform variou deep learn algorithm text classif task medic note respect differ diseas class imbal scenario method thi studi employ seven artifici intellig model cnn convolut neural network transform encod pretrain bert bidirect encod represent transform four typic sequenc neural network model name rnn recurr neural network gru gate recurr unit lstm long memori long memori classifi presenc absenc diseas condit patient discharg summari note analyz thi question composit binari separ classif problem model perform seven model dataset ou level imbal class compar term area curv receiv oper characterist area curv precis recal score balanc accuraci well train time model perform also compar combin differ word ding approach glove biowordvec word embed result analys binari classif problem show transform encod model form best nearli scenario addit diseas preval close greater convolut neural network model achiev compar perform transform encod ing time wa shorter second fastest model shorter transform encod shorter model biowordvec embed slightli improv perform model diseas preval scenario cnn model perform better without word embed addit train time wa significantli reduc glove embed model author open access thi articl licens creativ common attribut intern licens permit use share adapt distribut reproduct ani medium format long give appropri credit origin author sourc provid link creativ common licenc indic chang made imag third parti materi thi articl includ articl creativ common licenc unless indic otherwis credit line materi materi includ articl creativ common licenc intend use permit statutori regul exce permit use need obtain permiss directli copyright holder view copi thi licenc visit http creativ common public domain dedic waiver http appli data made avail thi articl unless otherwis state credit line data open access correspond rakovski schmid colleg scienc technolog chapman univers univers dr orang ca usa full list author inform avail end articl page lu et al bmc medic research methodolog background unstructur medic note discharg rie valuabl health record contain rich clinic inform patient health condit diseas detail may reflect structur data field mani studi carri extract addit inform unstructur medic note make mortal predict base data alon thi studi aim explor model perform variou deep learn algorithm text classif task medic note help point attent research commun potenti text tion behavior variou nlp natur languag process algorithm medic note data differ class imbal scenario algorithm compar thi studi includ tradit recurr network rnn gru lstm well cnn attent algorithm transform encod model perform evalu term score balanc accuraci deep learn algorithm rnn gru lstm model typic use nlp task achiev promis result design work sequenc data allow viou output use input allow flow inform previou element posterior ment sequenc gru lstm advanc variant vanilla rnn addit gate mathemat oper involv addit weight train ad rnn unit overcom vanish explod gradient problem rnn often suffer long sequenc lstm two addit gate pare gru entail better perform long sequenc allow inform back carri current unit addit layer top lstm unit goe backward inform posterior element pass previou unit thi featur work particularli well text data sinc context inform previou element terior element import interpret word extra gate layer howev consequ result complex longer train time recent cnn attract attent nlp task due superior perform especi lengthi text cnn wide use comput vision imag classif imag recognit cnn comput vision featur sional convolut layer extract inform neighbor pixel thu nize pattern across space cnn nlp task employ convolut layer extract mation adjac word quit clear exactli whi cnn outperform tradit nlp algorithm rnn gru lstm mani case wide accept number kernel convolut layer cnn serv n adjac word treat one techniqu nlp tradit nlp algorithm anyth would cumbersom cnn rithm howev easili adopt even higher gram techniqu depend length text without increas comput cost transform success appli mani nlp task sinc introduct transform vaswani et al transform model novel network architectur base sole attent mechan dispens recurr tion entir transform task lation question answer encod decod transform text classif task typic onli encod encod ha two layer layer feedforward layer unlik recurr network process word sequenti take inform ou word input process current word transform process input sequenc whole anoth novel design transform duce posit embed captur inform order word posit embed ad word embed befor fed encod one major disadvantag transform high comput cost especi text sequenc long longer sequenc tionat expens becaus attent quadrat sequenc length due word everi word sequenc bert encod represent transform languag sentat model wa design deep bidirect represent unlabel text conclus classif task medic note transform encod best choic comput resourc issu otherwis class rel balanc cnn lead candid becaus competit perform comput effici keyword medic note text classif bert cnn deep learn embed transform encod page lu et al bmc medic research methodolog bookscorpu english wikipedia two ture bert model introduc origin paper model ha transform encod head encod hidden size total paramet model ha former encod head encod hidden size total paramet bert model achiev perform number natur languag understand task wa publish ha success appli mani nlp task sinc one major drawback bert costli comput resourc need train model due larg number paramet data thi studi use discharg summari data made avail harvard univers challeng classifi obes comorbid multipl class presenc absenc question diseas annot textual ment intuit judgment respect data consist uniqu discharg summari partner healthcar research patient data tori annot list diseas tion three expert massachusett gener hospit literatur classif task use thi dataset focus optim score classif task primarili ing method method bine tradit machin learn algorithm svm involv heavi text preprocess tailor specif discharg summari associ diseas exampl ware et al employ apelon terminolog engin provid synonym set drug name use domain specif languag dsl frame rule identifi presenc diseas yang et al built ari diseas symptom treatment medic synonym solt et al also develop regular express driven string replac dictionari occurr relev abbrevi synonym plain english equival spell variant frequent typo suffix form etc goal thi studi compar behavior deep learn algorithm term perform dataset train effici abil handl imbalanc class well effect two type word embed approach therefor simplifi task problem intuit label onli appli eral text preprocess convert data dataset binari classif discharg summari differ binari come variabl denot presenc absenc ticular diseas diseas preval diseas condit dataset list tabl eas preval rang eridemia least preval hypertens preval diseas preval also reflect class imbal level posit diseas enc neg diseas absenc class binari classif problem discharg summari note dataset includ content descript current ill medic histori inform physic tion laboratori examin treatment servic provid applic discharg medic unstructur medic note requir special treatment befor fed deep learn algorithm first convert word lower case word diseas diseas treat word remov number tion carri signific inform diagnos standard stop word common word ani natur languag add much valu nlp model thi remov well templat word discharg admiss date word onli one two acter mg detail descript statist variabl denot number word charact discharg summari befor clean shown tabl particular averag number word befor clean minimum maximum respect similarli averag number acter befor clean minimum maximum respect tabl diseas preval n osa obstruct sleep apnea pvd peripher vascular diseas oa osteo arthriti gerd gastroesophag reflux diseas chf congest heart failur cad coronari arteri diseas diseas diseas preval diseas diseas preval hypertriglyceridemia gerd venou insuffici depress asthma obes gout chf osa hypercholesterolemia pvd cad gallston diabet oa hypertens page lu et al bmc medic research methodolog dataset wa randomli split stratifi accord diseas label train test set contain data respect iter averag metric iter use comparison model formanc iter dataset wa randomli split stratif model train train set test test set regular token kera token wa form convert text number model except bert use differ token techniqu wordpiec token lar token procedur take follow two step first creat dictionari base word frequenc train set everi uniqu word assign integ valu index integ maximum number uniqu word text reserv pad form text sequenc integ take word discharg summari note look dictionari replac respond index next medic note test set convert sequenc integ look word dictionari previous construct train set reason dictionari built base train set onli avoid inform leak test set becaus test set suppos contain new data model ha never seen thi point cal note convert number differ length becaus discharg note ha differ length arbitrarili chose maximum sequenc length averag length sequenc dataset forc sequenc length truncat longer sequenc pad shorter sequenc preprocess step origin discharg summari note transform sequenc integ length readi fed deep learn model model maximum sequenc length allow method cnn model eight filter nel size eight rnn model eight unit gru model eight unit lstm model eight unit model eight unit transform encod one encod two head fit dataset batch size epoch model layer befor classif output layer wa also fit batch size epoch el word embed layer word represent captur similar word input length output dimens base model word embed posit embed dimens sinc focu thi studi wa compar formanc differ model instead optim specif model tri use default hyperparamet model mani studi debat choic hyperparamet batch size ani number number sampl train set mani factor could affect optim choic batch size avail comput resourc size data choic optim ing rate gener speak larger batch size like algorithm converg global minimum memori requir dure ing process batch size small model prone noisi thu requir smaller learn rate stabil result train step thu longer train time sweet spot dataset model specif requir trial error search commonli use batch size small dataset chose use becaus dataset wa rel small tabl descript statist descript statist number word number charact befor clean clean befor clean clean minimum percentil median mean percentil maximum standard deviat page lu et al bmc medic research methodolog input sequenc long similar choic batch size choic number epoch also dataset model specif larger number epoch requir longer train time could result overfit small number epoch could result underfit chose use epoch model except bert epoch author bert mend epoch bert dropout wa use mitig overfit problem commonli use dropout rate chose use model hyperparamet learn rate activ function optim chose use default valu model tabl show architectur inform seven model model evalu term roc area curv receiv ing characterist area curv precis recal score balanc accuraci detail report metric includ precis recal specif shown tabl appendix word embed replac tradit bow represent count vector becom essenti nlp task project token word vector onto embed matrix learn data dure train larg dataset one advantag word embed bow significantli lower dimens equal maximum length input sequenc versu imum number uniqu word dataset bow anoth advantag dens featur less zero word embed compar spars featur bow word embed wide use nlp task small dataset becaus better ture semant syntact mean word sinc train larg dataset mani differ model creat word embed glove fasttext biowordvec among develop thi studi implement glove embed dimens biowordvec embed dimens model except transform encod word embed model word embed dimens learn data dure train train word embed use former encod thi studi becaus prioriti design transform bert addit requir special token input sequenc cl sep glove wa train five corpora vari size includ wikipedia gigaword web data common wordvec embed train biomed text biomed control vocabulari call medic subject head mesh accommod nlp need biomed domain result figur b c show score balanc accuraci seven model dataset order lowest highest ing diseas preval transform encod produc highest dataset highest diabet highest dataset highest diabet highest score dataset highest diabet highest balanc accuraci dataset highest diabet cnn exceed transform encod dataset term hypertriglyceridemia chf cad dataset term triglyceridemia cad dataset term score cad dataset term tabl model architectur model number embed dimens max sequenc length dropout activ function optim total paramet cnn relu adam rnn relu adam relu adam lstm relu adam relu adam transform encod encod head relu adam encod head layer relu layer adam layer page lu et al bmc medic research methodolog balanc accuraci cad hypertens valu score balanc accuraci unavail model due zero valu true posit actual diseas presenc correctli predict wa encount diseas preval wa less zero valu true posit occur rithm predict posit case neg similarli good portion posit case veri small number small sampl classifi score balanc accuraci would low overal accuraci still high thi surpris becaus class highli imbalanc sampl size small mani minor case algorithm learn distinct characterist minor class cost misclassifi minor case small even minor case misclassifi sordo et al report sampl size increas machin learn algorithm naïv bay svm decis tree show substanti improv formanc predict smoke statu patient text excerpt extract narr medic report thi reason becaus algorithm need learn latent inform data expos larg enough amount data class given small sampl size total lengthi medic note fact deep learn algorithm data hungri perform transform encod cnn algorithm quit promis rel balanc dataset dataset transform encod cnn algorithm form poorli highli imbalanc five model perform even wors low perform imbalanc dataset result sampl minor class rithm learn number minor case fig model perform score balanc accuraci point graph miss due na valu result zero valu true posit highli imbalanc dataset page lu et al bmc medic research methodolog train set big enough repres minor class test set tabl show small sampl size minor class train set especi class highli imbalanc dataset diseas preval less number ple minor class train set challeng ani algorithm perform well shown fig b c preval number sampl minor class increas perform model improv substanti term score balanc raci therefor use big enough dataset larg enough number sampl class algorithm could render excel perform figur display train time seven rithm averag classif task comput intel r core tm cpu ghz gb ram cnn model ran consist faster model task averag cnn ran faster much rnn wa second fastest algorithm faster tabl number sampl class train test set diseas preval train set test set diseas presenc presenc diseas absenc diseas presenc diseas absenc hypertriglyceridemia venou insuffici asthma gout osa pvd gallston oa gerd depress obes chf hypercholesterolemia cad diabet hypertens fig averag train time page lu et al bmc medic research methodolog transform encod faster base model time ing due larg number paramet fed top layer even though wa onli use epoch figur show model perform word embed wa slight improv term score balanc raci rnn gru lstm glove biowordvec embed diseas preval greater biowordvec embed perform slightli better glove embed case improv signific model cnn model perform better without word embed figur show train time model without word embed averag iter dataset word embed shorten train time significantli model model glove embed ran fastest train time wa shorten much glove embed without embed discuss medic note often lengthi thu constitut data data rel small sampl size challeng due inevit overfit problem longest discharg summari data word clean sampl size wa onli thi issu wa gate follow treatment data first token discharg note differ length forc arbitrari length studi truncat longer note pad shorter note wa formula choic length ying wen et al report length close averag length text train fig model perform without word embed score balanc accuraci point graph miss due nan valu result zero valu true posit highli imbalanc dataset page lu et al bmc medic research methodolog set gener produc better result length small result great loss inform length larg lead spars data shorter note includ nois longer note second rel small number epoch epoch wa use train model avoid model memor train data anoth sourc overfit data thi studi transform encod stood among model nearli class imbal scenario strength lie featur word sequenc consid onc encod specif word effect resolv issu forget inform previou word long sequenc recurr network often ter cnn also outperform five model achiev compar perform transform encod diseas preval close greater somewhat surprisingli power nlp model perform poorli scenario like due fact wa train gener text medic text thu fail captur inform relationship medic word addit maximum sequenc length allow averag length charg summari note dataset could lead much loss inform result five model differ word embed show biowordvec embed slightli improv perform model dataset gener model biowordvec embed perform slightli better glove embed reason sinc wordvec embed train biomed text glove embed train corpora biomed domain reason improv biowordvec wa quit notic may due fact mani medic word cialli medic name zanflex fondapurinox diurhesi word dopthromycin fig averag train time without word embed page lu et al bmc medic research methodolog anesthet amoxicil dataset still ogniz biowordvec expect even word recogn glove presum ute faster train time class highli imbalanc diseas preval lower higher el perform poorli veri low veri low score balanc accuraci even abl score balanc accuraci thi mainli due unequ misclassif cost ing minor class doe result much cost thi especi true dataset small sampl minor class matter misclassifi dataset larg major class minor class combin two use balanc class small dataset collect data minor class feasibl use data augment smote random swap random delet etc increas number sampl minor class may help improv perform model addit lengthi text data length text sequenc fed model may also affect model perform sinc short sequenc may lose much inform long sequenc may result spars data introduc nois well longer train time overfit problem medic expert consult avail appli text preprocess method implement top challeng solut also help improv model perform exampl abbrevi veri common medic note expand help improv result sinc otherwis often treat unknown word thu contribut ani inform addit drug name also recogn tag drug name strongli indic certain diseas also help improv predict accuraci conclus binari text classif task studi former encod stood among algorithm studi term model perform metric roc score balanc accuraci class balanc cnn model perform equal well markedli shorter train time dataset wa highli imbalanc posit class diseas presenc minor roc may inflat may abl metric evalu model perform turn dataset highli imbalanc neg class diseas absenc minor may accur measur model perform addit domain specif word embed biobert clinicalbert may help yield better result sinc word embed train medic text use power bert model summari classif task medic note transform encod best choic comput resourc issu otherwis class rel balanc cnn lead candid becaus compar perform comput effici abbrevi ai artifici intellig nlp natur languag process cnn tional neural network rnn recurr neural network gate recurr unit lstm long memori long memori bert encod represent transform bow area curv receiv ing characterist area curv precis recal osa obstruct sleep apnea pvd peripher vascular diseas oa osteo arthriti gerd gastroesophag reflux diseas chf congest heart failur cad coronari arteri diseas smote synthet minor oversampl techniqu supplementari inform onlin version contain supplementari materi avail http addit file appendix tabl model perform evalu metric averag iter tabl model perform evalu metric averag iter cnn word embed tabl model perform evalu metric averag iter rnn word embed tabl model perform evalu metric averag iter gru word embed tabl model manc evalu metric averag iter lstm word embed tabl model perform evalu metric averag iter word embed acknowledg applic author contribut hl aggreg manag qualiti check medic discharg mari note carri ai model fit summar result wrote section manuscript le review analyz result cr analyz data interpret result wrote section manuscript provid guidanc insight thi studi author read approv final manuscript fund thi studi receiv specif grant ani fund agenc public commerci sector avail data materi data support find thi studi deriv dataset publicli avail simpl step approv http code thi studi avail http git page lu et al bmc medic research methodolog declar ethic approv consent particip thi studi use deidentifi data harvard websit follow ethic consider institut provid data particip involv thi studi consent public applic compet interest author declar compet interest regard thi articl author detail schmid colleg scienc technolog chapman univers univers dr orang ca usa children health orang counti choc orang ca usa receiv august accept may refer feder vainstein rosenfeld r hartman hassidim matia activ deep learn detect demograph trait clinic note j biom inform miotto r percha bl glicksberg bs lee hc cruz l dudley jt nabeel identifi acut low back pain episod primari care practic clinic note observ studi jmir med inform gunjal h patel p thaker k nagrecha moham marchawala text summar classif clinic discharg summari use deep learn ye j yao l shen j janarthanam r luo predict mortal calli ill patient diabet use machin learn clinic note bmc med inform deci mak yang yu x zhou lstm gru neural network perform comparison studi take yelp review dataset exampl intern workshop electron commun artifici intellig iwecai girgi amer e gadallah deep learn algorithm detect fake news onlin text intern confer comput engin system icc onan sentiment analysi product review base weight word embed deep neural network concurr putat practic experi kim h jeong ys sentiment classif use convolut neural network appl sci hugh li kotoula suzumura medic text classif use convolut neural network informat health connect well popul health io press widiastuti ni convolut neural network text mine natur languag process iop confer seri materi scienc engin banerje ling chen mc hasan sa langlotz cp moradzadeh n chapman b amrhein mong rubin dl et al compar ness convolut neural network cnn recurr neural network rnn architectur radiolog text report classif artif intel med hijazi kumar r rowen c et al use convolut neural network imag recognit san jose cadenc design system li q cai w wang x zhou feng dd chen medic imag cation convolut neural network intern confer control autom robot vision icarcv liu z huang h lu c lyu multichannel cnn attent text classif arxiv preprint zhao w joshi nair vn sudjianto shap valu explain base text classif model arxiv preprint cheng h yang x li z xiao lin interpret text classif use cnn arxiv preprint vaswani shazeer n parmar n uszkoreit j jone l gomez kaiser ł polosukhin attent need advanc neural mation process system devlin j chang mw lee k toutanova bert deep bidirect transform languag understand arxiv preprint samghabadi ns patwa p sriniva p mukherje p da solorio aggress misogyni detect use bert approach proceed second workshop troll aggress cyberbulli gao z feng song x wu sentiment tion bert ieee access geng z yan h qiu x huang fasthan toolkit chines nlp arxiv preprint zhang j chang w cheng yu h fu dhillon fast former extrem text classif advanc neural inform process system harvard univers obes challeng data internet cite apr avail http uzun recogn obes comorbid spars data j med inform assoc ware h mullett cj jagannathan natur languag process framework assess clinic condit j med inform assoc yang h spasic kean ja nenad text mine approach predict diseas statu clinic discharg summari j med inform assoc solt tikk gál v kardkovác zt semant classif diseas discharg summari use classifi j med inform assoc schuster nakajima japanes korean voic search ieee intern confer acoust speech signal cess icassp jastrzebski kenton z arpit balla n fischer bengio storkey three factor influenc minima sgd arxiv preprint kandel castelli effect batch size generaliz convolut neural network histopatholog dataset ict express smith sl kinderman pj ying c le q decay learn rate increas batch size arxiv preprint almeida f xexéo word embed survey arxiv preprint pennington j socher r man cd glove global vector word represent proceed confer empir method natur languag process emnlp zhang chen q yang z lin h lu biowordvec improv cal word embed subword inform mesh sci data sordo zeng sampl size classif accuraci formanc comparison intern symposium biolog medic data analysi wen zhang w luo r wang learn text represent use recurr convolut neural network highway layer arxiv preprint ibrahim torki imbalanc toxic comment sific use data augment deep learn ieee intern confer machin learn applic icmla lauren p qu g watta convolut neural network clinic tive categor ieee intern confer big data big data lee j yoon w kim kim kim ch kang biobert train biomed languag represent model biomed text mine bioinformat alsentz e murphi jr boag w weng wh jin naumann mott publicli avail clinic bert embed arxiv preprint page lu et al bmc medic research methodolog fast conveni onlin submiss thorough peer review experienc research ﬁeld rapid public accept support research data includ larg complex data type gold open access foster wider collabor increas citat maximum visibl research websit view per year bmc research alway progress learn readi submit research readi submit research choos bmc benefit choos bmc benefit huang k altosaar j ranganath clinicalbert model clinic note predict hospit readmiss arxiv preprint publish note springer natur remain neutral regard jurisdict claim lish map institut affili