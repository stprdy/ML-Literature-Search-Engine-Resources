review deep learn concept cnn architectur challeng applic futur direct laith jinglan amjad ayad ye omran moham muthana laith abstract last year deep learn dl comput paradigm ha deem gold standard machin learn ml commun moreov ha gradual becom wide use comput approach field ml thu ing outstand result sever complex cognit task match even beat provid human perform one benefit dl abil learn massiv amount data dl field ha grown fast last year ha extens use success address wide rang tradit applic importantli dl ha outperform ml techniqu mani domain cybersecur natur languag process bioinformat robot control medic inform process among mani despit ha ute sever work review dl onli tackl one aspect dl lead overal lack knowledg therefor thi contribut propos use holist approach order provid suitabl start point develop full understand dl specif thi review attempt provid comprehens survey tant aspect dl includ enhanc recent ad field particular thi paper outlin import dl present type dl niqu network present convolut neural network cnn util dl network type describ develop cnn architectur togeth main featur start alexnet network close network final present challeng suggest solut help research understand exist research gap follow list major dl applic comput tool includ fpga gpu cpu summar along descript influenc dl paper end evolut matrix benchmark dataset summari conclus keyword deep learn machin learn convolut neural network cnn deep neural network architectur deep learn applic imag classif transfer learn medic imag analysi supervis learn fpga gpu open access author thi articl licens creativ common attribut intern licens permit use share adapt distribut reproduct ani medium format long give appropri credit origin author sourc provid link creativ common licenc indic chang made imag third parti materi thi articl includ articl creativ common licenc unless indic otherwis credit line materi materi includ articl creativ common licenc intend use permit statutori regul exce ted use need obtain permiss directli copyright holder view copi thi licenc visit http survey paper alzubaidi et al j big data http correspond school comput scienc queensland univers technolog brisban qld australia full list author inform avail end articl page alzubaidi et al j big data introduct recent machin learn ml ha becom veri widespread research ha incorpor varieti applic includ text mine spam detect video recommend imag classif multimedia concept retriev among differ ml algorithm deep learn dl veri commonli employ applic anoth name dl represent learn rl continu appear novel studi field deep distribut learn due unpredict growth abil obtain data amaz progress made hardwar technolog high perform comput hpc dl deriv convent neural network consider outperform predecessor moreov dl employ transform graph technolog neousli order build learn model recent develop dl techniqu obtain good outstand perform across varieti tion includ audio speech process visual data process natur languag process nlp among usual effect ml algorithm highli depend integr represent ha shown suitabl data represent vide improv perform compar poor data represent thu signific research trend ml mani year ha featur engin ha inform numer research studi thi approach aim construct featur raw data addit extrem frequent requir sizabl human effort instanc sever type featur introduc compar comput vision context histogram orient gradient hog invari featur transform sift bag word bow soon novel featur introduc found perform well becom new research direct pursu multipl decad rel speak featur extract achiev automat way throughout dl algorithm thi encourag research extract discrimin featur use smallest possibl amount human effort field knowledg algorithm data represent architectur first layer extract featur last layer extract featur note artifici intellig ai origin inspir thi type architectur simul process occur core sensori region within human brain use differ scene human brain automat extract data represent specif output thi process classifi object receiv scene inform repres input thi process simul work methodolog human brain thu emphas main benefit dl field ml dl due consider success current one promin research trend thi paper overview dl present adopt variou perspect main concept architectur challeng applic comput tool evolut matrix convolut neural network cnn one popular use dl network becaus cnn dl veri ular nowaday main advantag cnn compar predecessor matic detect signific featur without ani human supervis made use therefor dug deep cnn present main page alzubaidi et al j big data compon furthermor elabor detail common cnn architectur start alexnet network end network sever publish dl review paper present last year ever onli address one side focus one applic topic review cnn architectur dl classif plant diseas dl object detect dl applic medic imag analysi etc although review present good topic provid full understand dl topic concept detail research gap comput tool dl tion first requir understand dl aspect includ concept challeng applic go deep applic achiev requir extens time larg number research paper learn dl includ research gap applic therefor propos deep review dl provid abl start point develop full understand dl one review paper motiv behind review wa cover import aspect dl includ open challeng applic comput tool perspect review first step toward dl topic main aim thi review present import aspect dl make easi research student clear imag dl singl review paper thi review advanc dl research help peopl discov recent develop field research would allow decid abl direct work taken order provid accur altern field contribut outlin follow thi first review almost provid deep survey import aspect deep learn thi review help research student good understand one paper explain cnn deep popular deep learn algorithm describ concept theori architectur review current challeng limit deep learn includ lack ing data imbalanc data interpret data uncertainti scale catastroph forget model compress overfit vanish gradient problem explod gradient problem underspecif addit discuss propos solut tackl issu provid exhaust list medic imag applic deep learn categor base task start classif end registr discuss comput approach cpu gpu fpga compar influenc tool deep learn algorithm rest paper organ follow survey methodolog section describ survey methodolog background section present background classif dl approach section defin classif dl approach type dl work section display type dl network cnn architectur section show cnn architectur challeng limit deep learn altern solut section page alzubaidi et al j big data detail challeng dl altern solut applic deep learn tion outlin applic dl comput approach section explain influenc comput approach cpu gpu fpga dl evalu ric section present evalu metric framework dataset section list framework dataset summari conclus section present summari conclus survey methodolog review signific research paper field publish dure mainli year paper main focu wa paper reput publish ieee elsevi mdpi natur acm springer paper select arxiv review paper variou dl topic paper year paper year paper year thi cate thi review focus latest public field dl select paper analyz review list defin dl approach network type list explain cnn architectur present challeng dl gest altern solut assess applic dl assess comput approach keyword use search criteria thi review paper deep learn machin learn convolut neural network deep learn architectur deep learn imag detect ficat segment local deep learn detect classif segment local deep learn cpu gpu fpga deep learn transfer learn deep ing imbalanc data deep learn interpret data deep learn overfit deep learn underspecif figur show search structur survey paper tabl present detail journal cite thi review paper background thi section present background dl begin quick introduct dl follow differ dl ml show situat requir dl final present reason appli dl dl subset ml fig inspir inform process pattern found human brain dl doe requir ani rule oper rather use larg amount data map given input specif label dl design use numer layer algorithm artifici neural network ann provid differ interpret data ha fed achiev classif task use convent ml techniqu requir sever sequenti step specif featur extract wise featur select learn classif furthermor featur select ha great impact perform ml techniqu bias featur select may lead incorrect nation class convers dl ha abil autom learn ture set sever task unlik convent ml method dl enabl learn classif achiev singl shot dl ha becom incred page alzubaidi et al j big data popular type ml algorithm recent year due huge growth evolut field big data still continu develop regard novel formanc sever ml task ha simplifi improv mani learn field imag object detect imag recognit recent dl perform ha come exceed human perform task imag classif nearli scientif field felt impact thi technolog industri busi alreadi disrupt transform use dl lead technolog compani around world race improv dl even perform capabl exceed perform dl mani area predict time taken make car eri decis certifi loan request predict movi rate winner nobel prize comput also known ture award three pioneer field dl yann lecun geoffrey hinton yoshua bengio although larg number goal achiev progress made dl context fact dl ha abil enhanc human live ing addit accuraci diagnosi includ estim natur disast coveri new drug cancer diagnosi esteva et al found dl network ha abil diagnos diseas dermatologist use imag diseas furthermor grade prostat fig search framework page alzubaidi et al j big data cancer us gener pathologist achiev averag accuraci googl ai outperform specialist achiev averag raci dl play increasingli vital role earli diagnosi novel coronaviru dl ha becom main tool mani pital around world automat classif detect use chest tabl journal cite thi review paper journal citescor publish journal homepag pattern recognit elsevi http nition pattern recognit letter elsevi http rs artifici intellig review springer http com expert system applic elsevi http ns neurocomput elsevi http ting natur medicin natur http natur natur http journal big data springer http multimedia tool applic springer http comput method program biomedicin elsevi http dicin machin learn springer http machin vision applic springer http medic imag analysi elsevi http si ieee access ieee http jsp ieee transact knowledg data engin ieee http jsp natur commun natur http ieee transact intellig transport system ieee http jsp method elsevi http ds acm journal emerg nolog comput system acm http jetc acm comput survey acm http csur appli soft comput elsevi http ting electron mdpi http ronic appli scienc mdpi http ci ieee transact industri informat ieee http jsp page alzubaidi et al j big data fig deep learn famili fig differ deep learn tradit machin learn page alzubaidi et al j big data imag type imag end thi section say ai pioneer geoffrey hinton deep learn go abl everyth appli deep learn machin intellig use mani situat equal better human expert case mean dl solut follow problem case human expert avail case human unabl explain decis made use expertis guag understand medic decis speech recognit case problem solut updat time price predict stock enc weather predict track case solut requir adapt base specif case person biometr case size problem extrem larg exce inadequ sone abil sentiment analysi match ad facebook calcul webpag rank whi deep learn sever perform featur may answer thi question univers learn approach becaus dl ha abil perform mate applic domain sometim refer univers learn robust gener precis design featur requir dl niqu instead optim featur learn autom fashion relat fig deep learn perform compar human page alzubaidi et al j big data task consider thu robust usual chang input data attain gener differ data type differ applic use dl techniqu approach frequent refer transfer learn tl explain latter section furthermor use approach problem data insuffici scalabl dl highli scalabl resnet wa invent microsoft compris layer frequent appli supercomput scale renc livermor nation laboratori llnl larg enterpris work evolv framework network adopt similar approach thousand node implement classif dl approach dl techniqu classifi three major categori unsupervis partial vise supervis furthermor deep reinforc learn drl also known rl anoth type learn techniqu mostli sider fall categori partial supervis occasion unsupervis learn techniqu deep supervis learn thi techniqu deal label data consid techniqu environ collect input result output xt yt instanc smart agent guess input xt obtain loss valu next network paramet repeatedli updat agent obtain improv mate prefer output follow posit train outcom agent acquir abil obtain right solut queri environ dl sever supervis learn techniqu recurr neural network rnn convolut neural network cnn deep neural network dnn addit rnn categori includ gate recurr unit gru long memori lstm approach main advantag thi techniqu abil collect data gener data output prior knowledg howev disadvantag thi techniqu decis boundari might overstrain train set sampl class overal thi techniqu simpler niqu way learn high perform deep learn thi techniqu learn process base dataset occasion gener adversari network gan drl employ way thi techniqu addit rnn includ gru lstm also employ partial supervis learn one advantag thi techniqu minim amount label data need hand one disadvantag thi techniqu irrelev input featur present train data could furnish incorrect sion text document classifi one popular exampl applic page alzubaidi et al j big data learn due difficulti obtain larg amount label text document learn ideal text document classif task deep unsupervis learn thi techniqu make possibl implement learn process absenc avail label data label requir agent learn nific featur interior represent requir discov unidentifi structur relationship input data techniqu gener network dimension reduct cluster frequent count within categori unsupervis learn sever member dl famili perform well dimension reduct cluster task includ restrict boltzmann machin gan recent develop niqu moreov rnn includ gru lstm approach also employ unsupervis learn wide rang applic main disadvantag unsupervis learn unabl provid accur inform concern data sort comput complex one popular unsupervis learn approach cluster deep reinforc learn reinforc learn oper interact environ vise learn oper provid sampl data thi techniqu wa develop googl deep mind subsequ mani enhanc techniqu ent reinforc learn construct exampl input ment sampl xt agent predict receiv cost agent p unknown probabl distribut ment ask question agent answer give noisi score thi method sometim refer learn base thi concept sever supervis unsupervis techniqu develop comparison tional supervis techniqu perform thi learn much difficult straightforward loss function avail reinforc learn techniqu addit two essenti differ supervis learn forcement learn first complet access function requir optim mean queri via interact second state interact found environ input xt base preced action solv task select type reinforc learn need perform base space scope problem exampl drl best way problem involv mani paramet optim contrast reinforc learn techniqu perform well problem limit paramet applic reinforc learn ness strategi plan robot industri autom main drawback reinforc learn paramet may influenc speed learn main motiv util reinforc learn page alzubaidi et al j big data assist identifi action produc highest reward longer period assist discov situat requir action also enabl figur best approach reach larg reward reinforc learn also give learn agent reward function reinforc learn util situat case suffici data resolv issu supervis learn niqu reinforc learn special workspac larg type dl network famou type deep learn network discuss thi section includ recurs neural network rvnn rnn cnn rvnn rnn briefli explain thi section cnn explain deep due tanc thi type furthermor use sever applic among network recurs neural network rvnn achiev predict hierarch structur also classifi output lize composit vector recurs memori raam primari inspir rvnn develop rvnn architectur ate process object randomli shape structur like graph tree thi approach gener distribut represent structur network train use introduc structur bt learn system bt system track niqu propag algorithm ha abil support treelik structur train network regener pattern output layer rvnn highli effect nlp context socher et al duce rvnn architectur design process input varieti modal author demonstr two applic classifi natur languag sentenc case sentenc split word natur imag case imag separ variou segment interest rvnn comput like pair score merg construct syntact tree furthermor rvnn calcul score relat merg plausibl everi pair unit next pair largest score merg within composit vector follow everi merg rvnn gener larger area numer unit b composit vector area c label class instanc noun phrase becom class label new area two unit noun word composit vector entir area root rvnn tree structur exampl rvnn tree shown rvnn ha employ sever applic page alzubaidi et al j big data recurr neural network rnn commonli employ familiar algorithm disciplin dl rnn mainli appli area speech process nlp context unlik convent network rnn use sequenti data network sinc embed structur sequenc data deliv valuabl inform thi featur fundament rang differ applic instanc tant understand context sentenc order determin mean specif word thu possibl consid rnn unit memori x repres input layer output layer repres state hidden layer given input sequenc typic unfold rnn diagram illustr pascanu et al introduc three differ type deep rnn techniqu name deep rnn introduc lessen learn difficulti deep network bring benefit deeper rnn base three techniqu howev rnn sensit explod gradient vanish problem resent one main issu thi approach specif dure train process redupl sever larg small deriv may caus gradient exponenti explod decay entranc new input work stop think initi one therefor thi sensit decay time furthermor thi issu handl use lstm thi approach offer rent connect memori block network everi memori block contain number memori cell abil store tempor state network addit contain gate unit control flow inform veri deep network residu connect also abil consider reduc impact vanish gradient issu explain later section fig exampl rvnn tree page alzubaidi et al j big data cnn consid power rnn rnn includ less featur patibl compar cnn convolut neural network field dl cnn famou commonli employ algorithm main benefit cnn compar predecessor automat identifi relev featur without ani human supervis cnn extens appli rang differ field includ comput vision speech process face recognit etc structur cnn wa inspir ron human anim brain similar convent neural network ical cat brain complex sequenc cell form visual cortex thi sequenc simul cnn goodfellow et al identifi three key benefit cnn equival represent spars interact paramet share unlik convent fulli connect fc network share weight local connect cnn employ make full use structur like imag signal thi oper util extrem small number paramet simplifi train process speed network thi visual tex cell notabl onli small region scene sens cell rather whole scene cell spatial extract local correl avail input like local filter input commonli use type cnn similar perceptron mlp consist numer convolut layer preced pool layer end layer fc layer exampl cnn architectur imag classif illustr input x layer cnn model organ three dimens height width depth r height equal width depth also refer channel number exampl rgb imag depth r equal three sever kernel filter avail convolut layer denot k also three dimens n n q similar input imag fig typic unfold rnn diagram page alzubaidi et al j big data howev n must smaller q either equal smaller tion kernel basi local connect share similar paramet bia bk weight w k gener k featur map hk size convolv input mention abov convolut layer calcul dot product input weight eq similar nlp input unders area initi imag size next appli nonlinear activ function output obtain follow next step everi featur map layer thi lead reduct network paramet acceler train process turn enabl handl overfit issu featur map pool tion max averag appli adjac area size p p p kernel size final fc layer receiv featur creat abstract repres layer typic neural work classif score gener use end layer support vector machin svm softmax given instanc everi score repres iti specif class benefit employ cnn benefit use cnn tradit neural network comput vision environ list follow main reason consid cnn weight share featur reduc number trainabl network paramet turn help network enhanc gener avoid overfit concurr learn featur extract layer classif layer caus model output highli organ highli reliant extract ture hk f w k bk fig exampl cnn architectur imag classif page alzubaidi et al j big data network implement much easier cnn ral network cnn layer cnn architectur consist number layer block layer cnn architectur includ function describ detail convolut layer cnn architectur signific compon convolut layer consist collect convolut filter nel input imag express metric convolv filter gener output featur map kernel definit grid discret number valu describ kernel valu call kernel weight random number assign act weight kernel begin cnn train process tion sever differ method use initi weight next weight adjust train era thu kernel learn extract cant featur convolut oper initi cnn input format describ vector format input tradit neural network channel imag input cnn instanc format imag rgb imag format understand convolut oper let us take exampl imag random kernel first nel slide whole imag horizont vertic addit dot product input imag kernel determin correspond valu multipli sum creat singl lar valu calcul concurr whole process repeat slide possibl note calcul dot product valu repres featur map output figur graphic illustr primari culat execut step thi figur light green color repres kernel light blue color repres similar size area input imag multipli end result sum result product valu mark light orang color repres entri valu output featur map howev pad input imag appli previou exampl stride one denot select vertic zontal locat appli kernel note also possibl use anoth stride valu addit featur map lower dimens obtain result increas stride valu hand pad highli signific determin border size inform relat input imag contrast border move carri away veri fast appli pad size input imag page alzubaidi et al j big data increas turn size output featur map also increas core benefit convolut layer spars connect neuron layer fc neural network link neuron follow layer contrast cnn onli weight avail two adjac layer thu number requir weight connect small memori requir store weight also fig primari calcul execut step convolut layer page alzubaidi et al j big data small henc thi approach addit matrix oper comput much costli dot oper cnn weight share alloc weight ani two neuron neighbor layer cnn whole weight oper one pixel input matrix learn singl group weight whole input significantli decreas requir train time variou cost necessari learn addit weight neuron pool layer main task pool layer featur map map gener follow convolut oper word thi approach shrink featur map creat smaller featur map concurr maintain major domin inform featur everi step pool stage similar manner convolut oper stride kernel initi befor pool oper execut sever type pool method avail util variou pool layer method includ tree pool gate pool averag pool min pool max pool global averag pool gap global max pool familiar frequent util pool method max min gap pool figur illustr three pool oper sometim overal cnn perform decreas result thi repres main shortfal pool layer thi layer help cnn determin whether certain featur avail particular input imag focus exclus ascertain correct locat featur thu cnn model miss relev inform activ function map input output core tion type activ function type neural network input valu determin comput weight summat neuron input along bia present thi mean activ function make decis whether fire neuron refer particular input creat correspond output fig three type pool oper page alzubaidi et al j big data activ layer employ layer weight learnabl layer fc layer convolut layer cnn architectur thi perform activ layer mean map input output moreov layer give cnn abil learn thing activ function must also abil entiat extrem signific featur allow error use train network follow type activ function commonli use cnn deep neural network sigmoid input thi activ function real number output restrict zero one sigmoid function curv repres mathemat tanh similar sigmoid function input real number put restrict mathemat represent relu mostli commonli use function cnn context convert whole valu input posit number lower comput load main benefit relu mathemat represent occasion signific issu may occur dure use relu instanc consid error algorithm larger gradient flow pass thi gradient within relu function updat weight way make neuron certainli activ onc thi issu refer die relu relu altern exist solv issu follow discuss leaki relu instead relu neg input thi activ function ensur input never ignor employ solv die relu problem leaki relu repres mathemat note leak factor denot commonli set veri small valu noisi relu thi function employ gaussian distribut make relu noisi repres mathemat f x sigm f x tanh ex ex f x relu max x f x leakyrelu x x mx x f x noisyrelu max x σ x page alzubaidi et al j big data parametr linear unit thi mostli leaki relu main enc leak factor thi function updat model train process parametr linear unit repres mathemat note learnabl weight denot fulli connect layer commonli thi layer locat end cnn architectur insid thi layer neuron connect neuron viou layer fulli connect fc approach util cnn classifi follow basic method convent perceptron neural network type ann input fc layer come last pool convolut layer thi input form vector creat featur map flatten output fc layer repres final cnn output illustr loss function previou section ha present variou cnn architectur addit final classif achiev output layer repres last layer cnn architectur loss function lize output layer calcul predict error creat across train sampl cnn model thi error reveal differ actual put predict one next optim cnn learn cess howev two paramet use loss function calcul error cnn estim output refer predict first paramet actual output refer label second paramet sever type loss function employ variou problem type follow concis explain loss function type f x parametriclinear x x ax x fig fulli connect layer page alzubaidi et al j big data softmax loss function thi function commonli employ measur cnn model perform also refer log loss function output probabl p addit usual employ substitut squar error loss function sific problem output layer employ softmax activ gener output within probabl distribut mathemat sentat output class probabl eai repres output preced layer n repres number neuron output layer final ical represent loss function b euclidean loss function thi function wide use regress problem addit also mean squar error mathemat sion estim euclidean loss c hing loss function thi function commonli employ problem relat binari classif thi problem relat sific thi mostli import svm use hing loss function wherein optim attempt maxim margin around dual object class mathemat formula margin commonli set moreov predict output denot pi desir output denot yi regular cnn cnn model repres central issu associ obtain gener model entitl case model execut especi well train data doe succeed test data unseen data explain latter section model opposit thi case occur model doe learn suffici amount train data model refer execut well train test data three type illustr variou intuit concept use help regular avoid detail fit discuss latter section pi eai n ea k h p yi log pi n h p n pi h p n max pi page alzubaidi et al j big data dropout thi wide util techniqu gener dure train epoch neuron randomli drop thi featur select power distribut equal across whole group neuron well forc model learn differ independ featur dure train process drop ron part contrast network util perform predict dure test process thi method highli similar dropout train epoch connect neuron weight drop rather drop ron thi repres onli differ dropout data augment train model sizeabl amount data easiest way avoid achiev thi data augment use sever niqu util artifici expand size train dataset detail found latter section describ data augment techniqu batch normal thi method ensur perform output activ thi perform follow unit gaussian distribut subtract mean divid standard deviat normal output layer possibl consid thi task layer network also possibl differenti integr network addit employ reduc intern covari shift activ layer layer variat activ distribut defin intern covari shift thi shift becom veri high due continu weight updat ing may occur sampl train data gather ou dissimilar sourc exampl day night imag thu model sume extra time converg turn time requir train also increas resolv thi issu layer repres oper batch tion appli cnn architectur advantag util batch normal follow prevent problem vanish gradient aris effect control poor weight initi significantli reduc time requir network converg dataset thi extrem use struggl decreas train depend across fig issu page alzubaidi et al j big data chanc reduc sinc ha minor influenc tion optim select thi section discuss cnn learn process two major issu includ learn process first issu learn algorithm select optim second issu use mani enhanc adadelta adagrad tum along learn algorithm enhanc output loss function found numer learnabl paramet bias weight etc minim error variat actual predict output core purpos supervis learn algorithm techniqu base learn cnn network appear usual select network ter alway updat though train epoch network also look local optim answer train epoch order minim error learn rate defin step size paramet updat ing epoch repres complet repetit paramet updat involv complet train dataset one time note need select learn rate wise doe influenc learn process imperfectli although gradient descent learn algorithm minim ing error thi algorithm repetit updat network paramet everi train epoch specif updat paramet correctli need pute object function gradient slope appli deriv respect network paramet next paramet updat revers direct gradient reduc error paramet updat process form though network gradient everi neuron neuron preced layer mathemat tion thi oper final weight current train epoch denot wijt weight preced train epoch denot learn rate η tion error differ altern learn algorithm abl commonli employ includ follow batch gradient descent dure execut thi techniqu network paramet updat mere one time behind consid train dataset via network depth calcul gradient whole train set subsequ use thi gradient updat paramet dataset cnn model converg faster creat gradient use bgd sinc paramet chang onli onc everi train epoch requir substanti amount resourc contrast larg train dataset addit wijt wijt wijt η page alzubaidi et al j big data time requir converg could converg local optimum convex instanc stochast gradient descent paramet updat train sampl thi techniqu prefer arbitrarili sampl train sampl everi epoch advanc train train dataset thi techniqu much faster bgd howev becaus frequent updat take extrem noisi step direct answer turn caus converg behavior becom highli unstabl gradient descent thi approach train sampl partit sever everi consid size collect sampl overlap next paramet updat perform follow gradient comput everi advantag thi method come combin advantag bgd sgd techniqu thu ha steadi converg comput effici extra memori effect follow describ sever enhanc niqu learn algorithm usual sgd fulli enhanc cnn train process momentum neural network thi techniqu employ object tion enhanc accuraci train speed sum pute gradient preced train step weight via factor known momentum factor howev therefor simpli becom stuck local minimum rather global minimum thi repres main disadvantag learn algorithm issu thi kind frequent occur issu ha convex surfac solut space togeth learn algorithm momentum use solv thi issu express mathemat weight increment current train epoch denot wijt η learn rate weight increment preced train epoch momentum factor valu maintain within rang turn step size weight updat increas direct bare minimum minim error valu momentum factor becom veri low model lose abil avoid local bare minimum contrast tum factor valu becom high model develop abil converg much rapidli high valu momentum factor use togeth lr model could miss global bare minimum cross howev gradient vari direct continu throughout train process suitabl valu momentum factor ter caus smoothen weight updat variat adapt moment estim adam anoth optim techniqu ing algorithm wide use adam repres latest trend deep wijt η page alzubaidi et al j big data learn optim thi repres hessian matrix employ deriv adam learn strategi ha design calli train deep neural network memori effici less tional power two advantag adam mechan adam calcul adapt lr paramet model integr pro tum rmsprop util squar gradient scale learn rate rmsprop similar momentum use move averag dient equat adam repres design algorithm backpropag let start notat refer weight network unambigu denot wh ij weight connect ith input neuron h th jt neuron hth layer fig show weight connect neuron first layer anoth neuron next layer network ha repres weight first neuron first layer first neuron second layer base second weight neuron mean weight come second neuron previou layer first layer next layer second thi net regard bia sinc bia connect neuron layer easili handl neuron must bia network layer ha certain bia seen abov net layer ha bia network ha paramet layer net number neuron layer weight connect layer connect easili determin base neuron layer exampl ten input fulli connect two neuron next layer wijt η e e fig mlp structur page alzubaidi et al j big data number connect connect weight error defin weight updat imagin two layer neural network label induvi input ith output individu input backpropag understand chang weight bias work base chang cost function error ultim thi mean ing partial deriv ij j comput local variabl introduc j call local error jth neuron hth layer base local error backpropag give procedur comput ij j error defin weight updat imagin two layer neural network shown output error j l l neuron output e k error epoch k shown eq vj k deriv activ function vj output backpropag error rest layer except output j k output error jl k repres weight layer error need obtain find error neuron layer updat weight layer base eq improv perform cnn base experi differ dl applic conclud activ solut may improv perform cnn error di j k e k vj k δh j k vj k l j jl k fig neuron activ function page alzubaidi et al j big data expand dataset data augment use transfer learn explain ter section increas train time increas depth width model add regular increas hyperparamet tune cnn architectur last year sever cnn architectur present model architectur critic factor improv perform differ applic variou modif achiev cnn architectur today modif includ structur reformul regular paramet zation etc convers note key upgrad cnn perform occur larg due reorgan well develop novel block particular novel develop cnn architectur perform use network depth thi section review popular cnn architectur begin alexnet model end resolut hr model studi architectur featur input size depth robust key help research choos suitabl architectur target task tabl present brief overview cnn architectur alexnet histori deep cnn began appear lenet time cnn restrict handwritten digit recognit task scale imag class deep cnn architectur alexnet highli respect achiev innov result field imag recognit classif krizheveski et al first propos alexnet consequ improv cnn learn abil increas depth implement sever paramet tion strategi figur illustr basic design alexnet architectur learn abil deep cnn wa limit thi time due hardwar restrict overcom hardwar limit two gpu nvidia gtx use parallel train alexnet moreov order enhanc iti cnn differ imag categori number featur extract stage wa increas five lenet seven alexnet regardless fact depth enhanc gener sever imag resolut wa fact overfit resent main drawback relat depth krizheveski et al use hinton idea address thi problem ensur featur learn algorithm extra robust krizheveski et al algorithm randomli pass sever tional unit throughout train stage moreov reduc vanish gradient problem relu could util activ function enhanc rate converg local respons normal overlap subsampl also perform enhanc gener decreas overfit improv perform previou network modif made use filter earlier layer alexnet ha consider page alzubaidi et al j big data tabl brief overview cnn architectur model main find depth dataset error rate input size year alexnet util dropout relu imagenet nin new layer call mlpconv util gap mnist zfnet visual idea middl layer imagenet vgg increas depth small filter size imagenet googlenet increas depth block concept ent filter size concaten concept imagenet util small filters better featur tation imagenet highway present tipath concept divid transform integr concept imagenet resnet robust overfit due symmetri skip link imagenet introduc concept residu link imagenet fractalnet introduc concept regular wideresnet decreas depth increas width xception depthwis volutionfollow pointwis convolut imagenet residu attent neural network present attent niqu tation network model depend nel imagenet densenet block layer layer connect imagenet competit squeez excit work residu ident ping util rescal channel page alzubaidi et al j big data signific recent cnn gener well begin innov research era cnn applic thi network model ha slight differ preced model introduc two innov concept first wa employ multipl layer tabl continu model main find depth dataset error rate input size year invert residu structur imagenet capsulenet pay attent special ship featur mnist represent imagenet fig architectur lenet fig architectur alexnet page alzubaidi et al j big data percept convolut convolut execut use filter port addit extra nonlinear network moreov thi support ing network depth may later regular use dropout dl model thi idea frequent employ bottleneck layer substitut fc layer gap also employ repres second novel concept enabl nific reduct number model paramet addit gap consider updat network architectur gener final featur vector reduct featur map dimens possibl gap use larg featur map figur show structur network zefnet befor cnn learn mechan wa basic construct error basi preclud understand precis purpos follow enhanc thi issu restrict deep cnn perform convolut imag respons zeiler fergu introduc deconvnet multilay ral network thi method later becam known zefnet wa ope order quantit visual network monitor cnn perform via understand neuron activ wa purpos network activ zation howev erhan et al util thi exact concept optim deep belief network dbn perform visual featur hidden layer moreov addit thi issu le et al assess deep unsupervis ae formanc visual creat class imag use output neuron revers oper order convolut pool layer denconvnet oper like cnn revers map thi kind launch tional layer output backward creat visual observ imag shape accordingli give neural interpret intern featur represent learn layer monitor learn schemat train stage wa key cept underli zefnet addit util outcom recogn abil issu coupl model thi concept wa experiment proven alexnet ing deconvnet thi indic onli certain neuron work action first two layer network furthermor indic featur extract via second layer contain alias object thu zeiler fergu chang cnn topolog due exist outcom addit execut paramet optim also exploit cnn learn ing stride filter size order retain featur initi two lution layer improv perform wa accordingli achiev due thi fig architectur page alzubaidi et al j big data rearrang cnn topolog thi rearrang propos visual featur could employ identifi design weak conduct appropri paramet alter figur show structur network visual geometri group vgg cnn wa determin effect field imag recognit easi effici design principl cnn wa propos simonyan zisserman thi vativ design wa call visual geometri group vgg multilay model ture nineteen layer zefnet alexnet simul relat network represent capac depth convers petit zefnet wa frontier network propos filter small size could enhanc cnn perform refer result vgg insert layer heap filter rather filter zefnet thi show experiment parallel assign filter could duce influenc filter word filter made recept field similarli effici filter decreas number paramet extra advantag reduc comput complic wa achiev use filter outcom establish novel research trend work filter cnn addit insert convolut middl convolut layer vgg regul network complex learn linear group subsequ featur map respect network tune max pool layer insert follow convolut layer pad implement maintain spatial resolut gener vgg obtain signific result local problem imag classif achiev first place competit acquir reput due enlarg depth homogen topolog simplic howev vgg tional cost wa excess due util around million paramet repres main shortcom figur show structur network googlenet competit googlenet also call emerg winner achiev accuraci decreas comput cost core aim googlenet architectur propos novel incept block modul concept cnn context sinc combin convolut mation employ merg transform split function featur extract ure illustr incept block architectur thi architectur incorpor filter fig architectur zefnet page alzubaidi et al j big data differ size captur channel inform togeth spatial inform divers rang spatial resolut common convolut layer googlenet substitut small block use concept nin architectur replac layer work googlenet concept merg transform split util support attend issu correl differ learn type variant exist similar class sever imag motiv googlenet wa improv cienci cnn paramet well enhanc learn capac addit regul comput insert convolut filter bottleneck layer ahead use kernel googlenet employ spars connect overcom redund inform problem decreas cost neglect irrelev nel note onli input channel connect output channel employ gap layer end layer rather util fc layer densiti connect wa decreas number paramet wa also significantli decreas million paramet due paramet tune addit regular factor use includ employ rmsprop mizer batch normal furthermor googlenet propos idea iliari learner speed rate converg convers main shortcom googlenet wa heterogen topolog thi shortcom requir adapt one modul anoth shortcom googlenet includ represent fig architectur vgg fig basic structur googl block page alzubaidi et al j big data jam substanti decreas featur space follow layer turn occasion lead valuabl inform loss highway network increas network depth enhanc perform mainli complic task contrast network train becom difficult presenc sever layer deeper network may result small gradient valu error lower layer srivastava et al suggest novel cnn architectur call highway network overcom thi issu thi approach base tiviti concept unhind inform flow highway network empow instruct two gate unit insid layer gate mechan concept wa motiv rnn inform aggreg wa conduct ing inform ıth layer next ıth layer gener tion impact make train deeper network veri simpl thi empow train network layer deeper network layer sgd algorithm highway network depth fifti layer present improv rate converg better thin deep architectur time contrast empir demonstr plain net perform declin ten hidden layer insert note even highway network layer depth converg much rapidli plain network resnet et al develop resnet residu network wa winner vrc object wa design network free vanish gradient issu compar previou network sever type resnet develop base number layer start layer go layer common type wa compris convolut er plu singl fc layer overal number network weight wa overal number mac wa novel idea resnet use bypass pathway concept shown fig wa employ highway net address problem train deeper network thi illustr fig contain fundament resnet block diagram thi convent forward network plu residu connect residu layer output fie l th output deliv preced layer xl execut differ oper convolut use filter batch normal befor appli activ function like relu xl output f xl end residu output xl mathemat repres numer basic residu block includ residu network base type residu network architectur oper residu block also chang xl f xl xl page alzubaidi et al j big data comparison highway network resnet present shortcut connect insid layer enabl connect independ note layer character function gate shortcut close highway network contrast individu shortcut never close residu inform perman pass resnet thermor resnet ha potenti prevent problem gradient diminish shortcut connect residu link acceler deep network converg resnet wa winner championship layer depth thi repres time depth vgg time depth alexnet parison vgg ha lower comput complex even enlarg depth incept resnet szegedi et al propos upgrad type concept behind wa minim comput cost effect deeper network gener thu szegedi et al use asymmetr filter rather size filter moreov util bottleneck convolut prior filter chang make oper tradit fig block diagram resnet page alzubaidi et al j big data convolut veri similar correl previous lin et al util filter potenti nin architectur subsequ util idea intellig manner use convolut oper input data map three four isol space smaller initi input space next correl map smaller space common convolut contrast szegedi et al bring togeth incept block residu learn power replac filter concaten residu connect szegedi et al empir onstrat residu connect achiev similar gener power enlarg width depth residu connect thu clearli illustr use residu connect train significantli acceler incept network train figur show basic block diagram incept residu unit densenet solv problem vanish gradient densenet wa present follow direct resnet highway network one back resnet clearli conserv inform mean preserv vidual transform sever layer contribut extrem littl inform addit resnet ha larg number weight sinc layer ha isol group weight densenet employ connect improv approach address thi problem connect layer layer network use approach therefor featur map previou layer employ input follow layer tradit cnn l nection previou layer current layer densenet l direct connect densenet demonstr influenc depth fig basic block diagram incept residu unit page alzubaidi et al j big data thu network gain abil discrimin clearli ad preserv inform sinc densenet concaten featur preced layer rather ad howev due narrow layer ture densenet becom parametr addit increas number featur map direct admiss layer gradient via loss function enhanc inform flow across network addit thi includ lariz impact minim overfit task alongsid minor train set ure show architectur densenet network resnext resnext enhanc version incept network also known aggreg residu transform network cardin new term present util split transform merg topolog easi effect way denot size transform set extra dimens howev incept network manag network resourc effici well enhanc learn abil convent cnn transform branch differ spatial embed employ use thu custom layer requir separ contrast resnext deriv characterist featur resnet vgg incept employ vgg deep homogen topolog basic architectur googlenet set filter spatial resolut insid block split transform merg figur show resnext build block resnext util insid block split transform merg well outlin transform cardin term perform nificantli improv increas cardin xie et al show complex fig architectur densenet network adopt page alzubaidi et al j big data resnext wa regul employ filter low embed ahead convolut contrast skip connect use optim train wideresnet featur reus problem core shortcom relat deep residu network sinc certain featur block transform contribut veri small amount ing zagoruyko komodaki accordingli propos wideresnet address thi problem author advis depth ha supplement influenc residu unit convey core learn abil deep residu network wideresnet util residu block power via make resnet wider instead deeper enlarg width present extra factor k handl network width word indic layer widen highli success method formanc enhanc compar deepen residu network enhanc represent capac achiev deep residu network network also certain drawback explod vanish gradient problem featur reus problem inactiv sever featur map natur train et al tackl featur reus problem includ dropout residu block regular network effici manner similar manner util dropout huang et al present stochast depth concept solv slow learn gradient vanish problem earlier research wa focus ing depth thu ani small enhanc perform requir addit sever new layer compar number paramet wideresnet ha twice resnet experiment studi show contrast wideresnet present improv method train rel deep network note ture prior residu network includ highli effect vgg incept wider resnet thu wider residu network establish onc thi wa mine howev insert dropout convolut layer oppos within residu block made learn effect wideresnet pyramid net depth featur map increas succeed layer due deep ing layer shown previou deep cnn architectur fig basic block diagram resnext build block page alzubaidi et al j big data resnet vgg alexnet contrast spatial dimens reduc sinc pling follow convolut layer thu augment featur represent pens decreas size featur map extrem expans depth featur map alongsid spatial inform loss interfer learn abil deep cnn resnet obtain notabl outcom issu imag sific convers delet convolut number channel spatial dimens vari channel depth enlarg spatial dimens reduc result decreas classifi perform accordingli chastic resnet enhanc perform decreas inform loss pani residu unit drop han et al propos pyramid net address resnet learn interfer problem address depth enlarg extrem reduct spatial width via resnet pyramid net slowli enlarg residu unit width cover feasibl place rather save spatial dimens insid residu block appear wa refer pyramid net due slow enlarg featur map depth base method factor l wa determin eq regul depth featur map dimens lth residu unit indic dl moreov n indic overal number residu unit step factor indic depth increas regul factor n uniformli distribut weight increas across dimens featur map ident map use insert ual connect among layer comparison shortcut nection ident map requir fewer paramet turn lead enhanc gener widen two differ approach use pyramid net network widen specif first approach multipl enlarg geometr second one tion enlarg linearli main problem associ width enlarg growth time space requir relat quadrat time xception extrem incept architectur main characterist xception main idea behind xception depthwis separ convolut xception model adjust origin incept block make wider exchang singl dimens follow convolut reduc comput iti figur show xception block architectur xception network becom extra comput effect use decoupl channel spatial correspond moreov first perform map convolv output embed short dimens appli convolut perform k spatial transform note k repres cardin obtain via transform number xception howev comput made simpler xception distinctli convolv channel around spatial axe dl l n page alzubaidi et al j big data axe subsequ use convolut pointwis convolut perform correspond convolut util xception regular depth channel tradit convolut oper tion util number transform segment equival number channel incept moreov util three transform segment tradit cnn architectur util onli singl transform segment convers suggest xception transform approach achiev extra learn effici better manc doe minim number paramet residu attent neural network improv network featur represent wang et al propos residu attent network ran enabl network learn awar featur object main purpos incorpor attent cnn ran consist stack residu block addit attent modul henc cnn howev attent modul divid two branch name mask branch trunk branch branch adopt learn strategi respect encapsul two differ strategi attent model support attent feedback fast process onli one particular forward process specif architectur gener dens featur make infer everi aspect moreov feedforward ture gener featur map addit robust semant inform restrict boltzmann machin employ strategi ousli propos studi dure train reconstruct phase goh et al use mechan attent deep boltzmann machin dbm regular factor note network global optim use learn strategi similar manner map progress output input throughout learn process incorpor attent concept convolut block easi way wa use transform network obtain previou studi unfortun inflex repres main problem along inabl fig basic block diagram xception block architectur page alzubaidi et al j big data use vari surround contrast stack modul ha made ran veri effect recogn noisi complex clutter imag ran chical organ give capabl adapt alloc weight everi featur map depend import within layer furthermor incorpor three distinct level attent spatial channel mix enabl model use thi abil captur featur distinct level convolut block attent modul import featur map util attent mechan certifi via ran convolut block attent cbam modul novel cnn wa first develop woo et al thi modul similar simpl design disregard object spatial local imag consid onli channel contribut dure imag classif regard object detect object spatial locat play nific role convolut block attent modul sequenti infer attent map specif appli channel attent preced spatial attent obtain refin featur map spatial attent perform use convolut pool function literatur gener effect featur descriptor achiev use spatial axi along pool featur addit erat robust spatial attent map possibl cbam concaten max ing averag pool oper similar manner collect gap max pool oper use model featur map statist woo et al strate util gap return infer channel attent wherea max pool provid indic distinguish object featur thu util max pool averag pool enhanc network tional power featur map improv represent power well facilit focu signific portion chosen featur express attent map serial learn procedur assist decreas comput cost number paramet woo et al experiment prove note ani cnn architectur simpli integr cbam concurr spatial channel excit mechan make work valid segment task roy et al expand hu et al effort ad influenc spatial inform channel inform roy et al present three type modul channel squeez tion concurr channel scse excit spatial squeez sse excit squeez spatial cse segment pose employ cnn addit suggest insert modul follow encod decod layer specif highlight specif featur map alloc attent everi channel express scale factor channel spatial inform first modul scse second modul sse featur map inform ha lower import spatial local spatial inform play signific role dure segment cess therefor sever channel collect spatial divid develop page alzubaidi et al j big data employ segment final modul cse similar cept use furthermor scale factor deriv found contribut featur map within object detect capsulenet cnn effici techniqu detect object featur achiev recognit perform comparison innov handcraft featur detector number restrict relat cnn present mean cnn doe consid certain relat orient size perspect featur instanc consid face imag cnn doe count variou face compon mouth eye nose etc posit incorrectli activ cnn ron recogn face without take specif relat size orient etc account thi point consid neuron ha probabl addit featur properti size orient perspect etc specif thi type ha abil effect detect face along differ type mation thu mani layer capsul node use construct capsul network encod unit contain three layer capsul node form capsulenet capsnet initi version capsul network exampl mnist architectur compris imag appli filter size stride output plu featur map next output input first capsul layer produc vector rather scalar fact thi modifi convolut layer note stride filter employ first convolut layer thu dimens output initi capsul employ filter gener group neuron neuron size figur repres complet capsnet encod decod process cnn context layer frequent employ handl translat chang detect featur move event featur still within window thi approach ha abil detect overlap featur fig complet capsnet encod decod process page alzubaidi et al j big data thi highli signific detect segment oper sinc capsul involv weight featur sum preced layer convent cnn particular cost function employ evalu global error grow toward back throughout train process convers case activ neuron grow onc weight two neuron turn zero instead singl size provid plete cost function repetit dynam rout alongsid agreement signal direct base featur paramet sabour et al provid detail thi architectur use mnist recogn handwritten digit thi innov cnn architectur give superior accuraci applic tive thi architectur ha extra suitabl segment detect approach compar classif approach network hrnet represent necessari vision task semant segment object detect human pose estim present framework input imag encod sentat use subnetwork construct connect seri resolut convolut vggnet resnet tion recov becom one altern tion represent maintain dure entir process use novel network refer network hrnet thi network ha two princip featur first convolut seri resolut nect parallel second inform across resolut repeatedli exchang advantag achiev includ get represent accur spatial domain semant domain moreov hrnet ha sever applic field object detect semant tion human pose predict comput vision problem hrnet sent robust backbon figur illustr gener architectur hrnet challeng limit deep learn altern solut employ dl sever difficulti often taken consider challeng list next sever possibl altern accordingli provid fig gener architectur hrnet page alzubaidi et al j big data train data dl extrem consid also involv represent learn dl demand extens larg amount data achiev formanc model data increas extra perform model achiev case avail data suffici obtain good perform model howev sometim shortag data use dl directli properli address thi issu three suggest method abl first involv employ concept data collect similar task note transfer data directli ment actual data help term enhanc origin input sentat data map function thi way model perform boost anoth techniqu involv employ model similar task end two layer even one layer base limit origin data refer review differ techniqu appli dl approach second method data augment perform thi task veri help use augment imag data sinc imag translat mirror rotat commonli chang imag label vers import take care appli thi techniqu case bioinformat data instanc mirror enzym sequenc output data may repres actual enzym sequenc third method simul data consid increas volum train set occasion possibl creat simul base physic process issu well understood therefor result involv simul much data need process data requir simul obtain exampl ref transfer learn recent research ha reveal widespread use deep cnn offer break support answer mani classif problem gener speak deep cnn model requir sizabl volum data obtain good perform fig perform dl regard amount data page alzubaidi et al j big data common challeng associ use model concern lack train data inde gather larg volum data exhaust job success solut avail thi time unders dataset problem therefor rentli solv use tl techniqu highli effici ing lack train data issu mechan tl involv train cnn model larg volum data next step model ing small request dataset relationship suitabl approach clarifi tl gather detail knowledg subject first step next teacher provid cours convey inform within lectur seri time put simpli teacher transfer inform student detail expert teacher transfer knowledg inform learner student similarli dl network train use vast volum data also learn bia weight dure train process weight transfer differ network retrain test similar novel model thu novel model enabl weight rather requir train scratch figur illustr conceptu diagram tl techniqu model mani cnn model alexnet googlenet resnet train larg dataset imagenet imag ognit purpos model employ recogn differ task without need train scratch furthermor weight remain apart learn featur case data sampl lack model veri use mani reason employ model first train larg model sizeabl dataset requir comput power second train larg model take multipl week final model assist network gener speed converg fig conceptu diagram tl techniqu page alzubaidi et al j big data research problem use model train dl approach requir massiv number imag thu obtain good perform challeng circumst achiev excel outcom imag classif ognit applic perform occasion superior human becom possibl use deep convolut neural network dcnn includ sever layer huge amount data avail ever avoid overfit problem applic requir sizabl dataset properli gener dcnn model train dcnn model dataset size ha lower limit howev accuraci model becom insuffici case util model ha fewer layer small dataset use train due problem due abil lize hierarch featur sizabl dataset model fewer layer poor accuraci difficult acquir suffici train data dl model ple medic imag environment scienc gather label dataset veri costli moreov major crowdsourc worker unabl make accur note medic biolog imag due lack medic biolog knowledg thu ml research often reli field expert label imag howev thi process costli time consum therefor produc larg volum label requir develop flourish deep network turn unfeas recent tl ha wide employ address later issu nevertheless although tl enhanc accuraci sever task field tern recognit comput vision essenti issu relat sourc data type use tl compar target dataset instanc enhanc medic imag classif perform cnn model achiev train model use imagenet dataset contain natur imag howev natur imag complet dissimilar raw medic imag mean model perform enhanc ha proven tl differ domain doe significantli affect perform medic imag task lightweight model train scratch perform nearli well standard model therefor exist nario use model becom afford solut research util tl achiev excel result tl approach use imag look similar target dataset train exampl use imag differ chest eas train model train chest imag diagnosi detail tl implement process found data augment techniqu goal increas amount avail data avoid overfit issu data augment techniqu one possibl solut techniqu solut ani problem data augment incorpor collect method improv attribut size train dataset thu dl page alzubaidi et al j big data network perform better techniqu employ next list data augment altern solut flip flip vertic axi less common practic flip zontal one flip ha verifi valuabl dataset like imagenet moreov highli simpl implement addit conserv transform dataset involv text recognit svhn mnist color space encod digit imag data commonli use dimens tensor height width colorchannel accomplish augment color space channel altern techniqu extrem workabl mentat veri easi color augment involv separ channel ticular color red green blue simpl way rapidli convert imag use channel achiev separ matrix insert tional doubl zero remain two color channel furthermor ing decreas imag bright achiev use straightforward matrix oper easili manipul rgb valu deriv color histogram describ imag addit improv color augment obtain light alter also made possibl adjust intens valu gram similar employ applic crop crop domin patch everi singl imag techniqu employ combin dimens height width specif process step imag data furthermor random crop may employ produc impact similar translat differ translat random crop translat conserv spatial dimens thi imag random ping reduc input size exampl accord select reduct threshold crop transform may address rotat rotat imag left right within degre around axi rotat augment obtain rotat degre paramet greatli determin suitabl rotat augment digit recognit task small rotat degre veri help contrast data label preserv rotat degre increas translat avoid posit bia within imag data veri use tion shift imag left right instanc common whole dataset imag center moreov test dataset entir made center imag test model note translat initi imag particular direct residu space fill gaussian random nois constant valu spatial dimens imag preserv use thi pad nois inject thi approach involv inject matrix arbitrari valu matrix commonli obtain gaussian distribut et al employ nine dataset test nois inject dataset taken uci repositori inject nois within imag enabl cnn learn addit robust featur page alzubaidi et al j big data howev highli solut posit bias avail within train data achiev mean geometr transform separ distribut test data train data sever prospect sourc bia exist instanc face complet center within frame facial recognit dataset problem posit bias emerg thu geometr translat best solut geometr translat help due simplic implement well effect capabl abl posit bias sever librari imag process avail enabl begin simpl oper rotat horizont flip addit train time higher comput cost addit memori shortcom geometr transform furthermor number metric transform arbitrari crop translat alli observ ensur chang imag label final bias separ test data train data complic tional posit chang henc trivial answer geometr transform suitabl appli imbalanc data commonli biolog data tend imbalanc neg sampl much numer posit one exampl compar imag volum normal imag veri larg note undesir result may produc train dl model use imbalanc data follow techniqu use solv thi issu first necessari employ correct criteria evalu loss well predict result consid imbalanc data model perform well small class well larger one thu model employ area curv auc result loss well criteria second employ weight loss ensur model perform well small class still prefer employ loss simultan dure model train possibl either larg class small class final make data balanc ref possibl construct model everi hierarch level biolog system frequent ha hierarch label space howev effect imbalanc data perform dl model ha comprehens tigat addit lessen problem frequent use techniqu also compar nevertheless note techniqu specifi biolog problem interpret data occasion dl techniqu analyz act black box fact pretabl need method interpret dl use obtain abl motif pattern recogn network common mani field bioinformat task diseas diagnosi onli requir know diseas diagnosi predict result train dl model also enhanc sureti predict outcom model make decis base verif achiev thi possibl give score import everi page alzubaidi et al j big data portion particular exampl within thi solut niqu approach use approach portion input chang effect thi chang model output observ thi concept ha high comput complex simpl understand hand check score import ou input portion signal output propag back input layer techniqu techniqu proven valuabl differ scenario variou mean repres model interpret uncertainti scale commonli final predict label onli label requir employ dl techniqu achiev predict score confid everi inquiri model also desir score confid defin confid model predict sinc score confid prevent belief unreli mislead predict signific attribut regardless applic scenario biolog confid score reduc resourc time expend prove outcom mislead predict gener speak healthcar similar applic uncertainti scale frequent veri signific help evalu autom clinic decis reliabl machin nosi becaus overconfid predict output differ dl model score probabl achiev softmax output often correct scale note softmax output requir achiev reliabl probabl score output probabl score rect scale sever techniqu introduc includ bayesian bin quantil bbq isoton regress histogram bin endari platt scale specif dl techniqu temperatur scale wa recent introduc achiev superior perform compar techniqu catastroph forget thi defin incorpor new inform plain dl model made possibl interf learn inform instanc consid case type flower model train classifi flower new type flower introduc model onli thi new class perform becom unsuccess older class logic data continu collect renew fact highli typic scenario mani field biolog address thi issu direct solut involv employ old new data train entir new model scratch thi solut comput intens furthermor lead unstabl state learn represent initi data thi time three differ type ml techniqu catastroph forget made avail solv human brain problem found neurophysiolog theori niqu first type found regular ewc techniqu second type employ rehears train techniqu dynam neural network page alzubaidi et al j big data architectur like icarl final techniqu third type found learn system refer order gain detail model compress obtain model still employ product dl model intens memori comput requir due huge complex larg number paramet one field character intens field healthcar environment scienc need reduc deploy dl limit machin mainli healthcar field numer method assess human health data heterogen becom far complic vastli larger size thu issu requir addit comput furthermor novel parallel process solut fpga gpu develop solv putat issu associ dl recent numer techniqu compress dl model design decreas comput issu model start point also introduc techniqu classifi four class first class redund paramet signific impact model perform reduc thi class includ famou deep sion method call paramet prune second class larger model use distil knowledg train compact model thu call knowledg distil third class compact convolut filter use reduc number paramet final class inform paramet mate preserv use factor model compress class repres repres techniqu ha provid comprehens discuss topic overfit dl model excess high possibl result data overfit ing stage due vast number paramet involv correl plex manner situat reduc model abil achiev good perform test data thi problem onli limit specif field involv differ task therefor propos dl techniqu thi problem fulli consid accur handl dl impli bia train process enabl model overcom crucial overfit problem recent studi suggest even still necessari develop techniqu handl ting problem investig avail dl algorithm eas overfit problem categor three class first class act model architectur model paramet includ familiar approach weight decay batch normal dropout dl default niqu weight decay use extens almost ml algorithm univers regular second class work model input data corrupt data augment one reason overfit problem lack train data make learn distribut mirror real distribut data augment enlarg train data contrast margin data tion improv solut exclus augment data final class work page alzubaidi et al j big data model output recent propos techniqu penal output regular model thi techniqu ha demonstr abil regular rnn cnn vanish gradient problem gener use backpropag learn techniqu along ann larg train stage problem call vanish gradient lem aris specif train iter everi weight neural network updat base current weight proport rel partial deriv error function howev thi weight updat may occur case due vanishingli small gradient worst case mean extra train possibl neural network stop complet convers larli activ function sigmoid function shrink larg input space tini input space thu deriv sigmoid function small due larg variat input produc small variat output shallow network onli layer use activ signific issu use layer lead gradient becom veri small train stage thi case network work effici techniqu use determin dient neural network initi thi techniqu determin network tive layer revers direct start last layer progress back first layer next step involv multipli deriv layer network similar manner first step instanc multipli n small deriv togeth n hidden layer employ activ function sigmoid function henc gradient declin exponenti propag back first layer specif bias weight first layer updat effici dure train stage becaus gradient small moreov thi condit decreas overal network accuraci first layer frequent critic recogn essenti element input data howev problem avoid employ activ function function lack ing properti abil squish input space within small space map x max relu popular select doe yield small tive employ field anoth solut involv employ batch maliz layer mention earlier problem occur onc larg input space squash small space lead vanish deriv employ batch maliz degrad thi issu simpli normal input express doe accomplish exterior boundari sigmoid function normal process make largest part come green area ensur deriv larg enough action furthermor faster hardwar tackl previou issu provid gpu thi make standard possibl mani deeper layer network compar time requir nize vanish gradient problem page alzubaidi et al j big data explod gradient problem opposit vanish problem one relat gradient specif larg error gradient accumul dure latter lead extrem signific updat weight network mean system becom unsteadi thu model lose abil learn effect grosso modo move backward network dure gradient grow tialli repetit multipli gradient weight valu could thu becom ibli larg may overflow becom nan valu potenti solut includ use differ weight regular techniqu redesign architectur network model underspecif team comput scientist googl ha identifi new challeng call underspecif ml model includ dl model often show surprisingli poor behavior test applic comput vision cal imag natur languag process medic genom reason behind weak perform due underspecif ha shown small tion forc model toward complet differ solut well lead ferent predict deploy domain differ techniqu address underspecif issu one design stress test examin good model work data find possibl issu nevertheless thi demand reliabl understand process model work inaccur team state design stress test appli ment provid good coverag potenti failur mode major challeng underspecif put major constraint credibl ml predict may requir reconsid certain applic sinc ml link human serv sever applic medic imag car requir proper attent thi issu applic deep learn present variou dl applic widespread around world tion includ healthcar social network analysi audio speech process like ognit enhanc visual data process method multimedia data analysi comput vision nlp translat sentenc classif among fig applic classifi five categori classif local detect segment registr although task ha target fundament overlap pipelin tion applic shown classif concept categor set data class detect use locat interest object imag consider given background detect multipl object could dissimilar class surround bound box local concept page alzubaidi et al j big data use locat object surround singl bound box tion semant segment target object edg surround outlin also label moreov fit singl imag could onto anoth refer registr one import dl applic healthcar thi area research critic due relat human live moreov dl ha shown tremend perform healthcar therefor take dl applic medic imag analysi field exampl describ dl applic fig exampl dl applic fig workflow deep learn task page alzubaidi et al j big data classif diagnosi cadx anoth titl sometim use tion bharati et al use chest dataset detect lung diseas base cnn anoth studi attempt read imag employ cnn thi modal compar access imag ha like enhanc progress dl use improv googlenet cnn contain imag train test process thi dataset wa augment chest creator reorgan imag orient later frontal view achiev approxim accuraci thi work orient sific ha clinic limit use part ultim fulli autom si workflow obtain data augment effici learn metadata relev imag chest infect commonli refer nia extrem treatabl commonli occur health problem worldwid convers rajpurkar et al util chexnet improv version densenet convolut layer classifi fourteen type diseas author use dataset compris imag thi network achiev excel perform recogn fourteen differ diseas particular pneumonia classif accomplish auc score use receiv oper characterist roc analysi addit network obtain better equal perform panel four individu ologist zuo et al adopt cnn candid classif lung nodul shen et al employ random forest rf svm classifi cnn classifi lung nodul employ two convolut layer three parallel cnn lung imag databas consortium dataset tain ct lung scan wa use classifi two type lung nodul malign benign differ scale imag patch use everi cnn extract featur output featur vector wa construct use learn featur next vector classifi malign benign use either rf classifi svm radial basi function rbf filter model wa robust variou noisi input level achiev accuraci nodul classif convers model interpol imag data miss pet mri imag use cnn alzheim diseas neuroimag initi adni databas contain pet mri patient scan wa util work pet mri imag use train cnn first input output furthermor patient pet imag cnn util train imag rebuild pet imag rebuilt imag approxim fit actual diseas recognit outcom howev thi approach address overfit issu turn restrict techniqu term possibl capac eral diagnos normal versu alzheim diseas patient ha achiev sever cnn model et al attain accuraci outcom diagnos normal versu alzheim diseas patient author appli architectur use cnn gener brain ture caddementia dataset subsequ outcom learn featur becam input higher layer differenti patient scan alzheim diseas mild cognit impair normal brain base page alzubaidi et al j big data adni dataset use deep supervis techniqu architectur vggnet rnn order basi voxcnn resnet model develop korolev et al also discrimin alzheim diseas normal patient use adni databas accuraci wa voxnet resnet compar work model achiev lower accuraci convers implement algorithm wa simpler requir ture korolev declar mehmood et al train ope network call scnn mri imag task classif alzheim diseas achiev result obtain accuraci recent cnn ha taken medic imag classif task differ level tradit diagnosi autom diagnosi tremend perform ple task diabet foot ulcer dfu normal abnorm dfu class sickl cell anemia sca normal abnorm sca blood compon breast cancer classifi breast biopsi imag four class invas carcinoma carcinoma benign tumor normal tissu skin cancer classif cnn play vital role earli diagnosi novel coronaviru cnn ha becom primari tool automat diagnosi mani hospit around world use chest imag detail classif medic imag applic found local although applic anatomi educ could increas practic clinician like interest local normal anatomi radiolog imag independ examin describ outsid human intervent zation could appli complet automat applic zhao et al introduc new deep approach local pancreat tumor project imag radiat therapi without need fiduci roth et al construct train cnn use five convolut layer classifi around ct imag author use five egori classif leg pelvi liver lung neck data augment niqu appli achiev auc score classif error rate model wa detect posit spleen kidney heart liver shin et al employ stack mri scan stomach area contain kidney liver tempor spatial domain use learn hierarch featur base organ approach achiev detect accuraci sirazitdinov et al present gate two convolut neural network name retinanet mask pneumonia detect local detect detect cade anoth method use detect clinician patient overlook lesion scan may dire consequ page alzubaidi et al j big data thu detect field studi requir accuraci sensit chouhan et al introduc innov deep learn framework tion pneumonia adopt idea transfer learn approach obtain accuraci recal unseen data area pulmonari diseas sever convolut neural network approach propos automat detect imag show excel manc area skin cancer sever applic introduc detect task et al introduc deep learn approach skin cancer detect five convolut neural network el address issu lack train data adopt idea transfer learn data augment techniqu network ha shown superior result compar model anoth interest area histopatholog imag progress digit sever paper publish thi field human gist read imag labori search malign marker high index cell prolifer use molecular marker cellular necrosi sign abnorm cellular architectur enlarg number mitot figur denot augment cell replic enlarg ratio note cal slide may contain huge number cell thousand thu risk disregard abnorm neoplast region high wade cell excess level magnif ciresan et al employ cnn layer identifi mitot figur fifti breast histolog imag mito dataset use techniqu attain recal precis score tive sirinukunwattana et al util histolog imag colorect cinoma detect cell nuclei use cnn roughli nuclei train purpos novelti thi approach wa use spatial constrain cnn thi cnn detect center nuclei use surround spatial context spatial regress instead thi cnn xu et al employ stack spars encod ssae identifi nuclei histolog slide breast cancer achiev recal precis score respect thi field show pervis learn techniqu also effect util medic imag albarquoni et al investig problem insuffici label actual mitos label histolog imag breast cancer amateur onlin solv recurr issu inadequ label dure analysi medic imag achiev feed input label cnn thi method signifi remark effort lei et al introduc employ deep convolut neural network automat identif mitot candid histolog section mitosi screen obtain detect result dataset intern pattern recognit confer icpr mitosi detect competit segment although mri ct imag segment research includ differ organ knee cartilag prostat liver research work ha concentr brain page alzubaidi et al j big data segment particularli tumor thi issu highli signific surgic prepar obtain precis tumor limit shortest surgic resect ing surgeri excess sacrif key brain region may lead neurolog shortfal includ cognit damag emotionless limb difficulti convent cal anatom segment wa done hand specif clinician draw line within complet stack ct mri volum slice slice thu perfect implement solut computer thi painstak work wadhwa et al present brief overview brain tumor segment mri imag akku et al wrote brilliant review brain mri segment address differ metric cnn architectur employ moreov explain sever competit detail well dataset includ ischem stroke lesion segment isl mild traumat brain injuri outcom predict mtop brain tumor segment brat chen et al propos convolut neural network precis brain tumor segment approach employ involv sever approach better featur learn includ deepmed model novel train scheme label loss function cess conduct method two modern brain tumor tion dataset brat brat dataset hu et al introduc brain tumor segment method adopt convolut neural network mccnn fulli connect condit random field crf achiev result excel compar method moeskop et al employ three cnn input patch dissimilar size segment classifi mri brain imag imag includ adult infant classifi variou sue categori cerebrospin fluid grey matter white matter everi patch concentr captur variou imag aspect benefit employ three dissimilar size input patch bigger size incorpor spatial featur lowest patch size concentr local textur gener algorithm ha dice coeffici rang achiev satisfactori accuraci although imag slice employ major segment research letrat et al implement cnn segment mri prostat imag use challeng dataset fifti mri scan use train thirti test architectur ronnerberg et al inspir thi model attain dice coeffici score win team competit reduc overfit creat model deeper layer cnn pereira et al appli intent size filter model use mri scan glioma type brain tumor train achiev first place brat challeng well second place brat challeng havaei et al also consid glioma use brat dataset investig differ cnn architectur compar winner brat algorithm work better requir onli min execut rather min concept cascad architectur form basi model thu refer inputcascadecnn employ fc tional random field crf atrou spatial pyramid pool filter page alzubaidi et al j big data techniqu introduc chen et al author aim enhanc accuraci local enlarg field view everi filter model deeplab attain miou mean intersect union cal imag segment model obtain excel perform recent automat segment lung infect ct imag help detect develop infect employ sever deep learn techniqu registr usual given two input imag four main stage canon procedur imag registr task target select illustr determin input imag second part input imag need remain accur superimpos featur extract comput set featur extract input imag featur match allow find similar previous obtain ture pose optim aim minim distanc input imag result registr procedur suitabl geometr transform translat rotat scale etc provid input imag within coordin system way distanc minim level optim scope thi work provid extens review thi topic nevertheless short summari accordingli introduc next commonli input imag registr approach could ou form point cloud voxel grid mesh addit techniqu allow input result featur extract match step canon scheme specif outcom could data particular form well result step classic pipelin featur vector match vector format nevertheless newest method novel conceptu type ecosystem issu contain acquir characterist target materi behavior regist input data conceptu ecosystem form neural network train manner could count input registr approach nevertheless input one might adopt everi registr situat sinc correspond interior data represent dl interpret conceptu design enabl tiat input data registr approach defin model particular illustr phase model depict particular spatial data one gener data set creat learn system yumer et al develop framework model acquir characterist object mean readi identifi sporti car seem like comfi chair also adjust model fit characterist maintain main characterist primari data likewis fundament perspect vise learn method introduc ding et al target page alzubaidi et al j big data registr approach thi instanc network abl place input point cloud global space solv slam issu mani point cloud ister rigidli hand mahadevan propos combin two conceptu model util growth imagin machin give flexibl cial intellig system relationship learn phase train scheme inspir label classif anoth practic applic dl especi cnn imag registr reconstruct object wang et al appli adversari way use cnn rebuild model object imag network learn mani object oral accomplish tration imag conceptu model similarli hermoza et al also util gan network prognost absent geometri damag logic object provid reconstruct object base voxel grid format label select class dl medic imag registr ha numer applic list review paper yang et al implement stack convolut er approach predict morph input pixel last format use mri brain scan oasi dataset employ tration model known larg deform diffeomorph metric map lddmm attain remark enhanc comput time miao et al use thetic imag train cnn regist model probe hand implant knee implant onto imag pose estim determin model achiev execut time repres import enhanc convent registr techniqu base intens moreov achiev effect registr time li et al introduc neural approach registr later cephalogram volumetr ct cbct imag comput approach comput exhaust applic complex ml dl approach idli identifi signific techniqu wide use differ field develop enhanc algorithm aggreg capabl comput perform larg dataset make possibl tive execut sever applic earlier applic either possibl ficult take consider current sever standard dnn configur avail interconnect pattern layer total number layer repres main differ configur tabl illustr growth rate overal ber layer time seem far faster moor law growth rate normal dnn number layer grew around year period recent investig futur resnet version reveal number layer extend howev sgd techniqu employ fit weight paramet differ optim techniqu employ obtain paramet updat dure dnn train process repetit updat requir enhanc network accuraci addit minorli augment rate enhanc exampl train process use imagenet larg dataset contain page alzubaidi et al j big data million imag along resnet network model take around repetit converg steadi solut addit overal comput load predict may exceed flop train set size dnn complex increas prior boost train satisfactori extent wa achiev use gpu usual day week need train session even gpu port contrast sever optim strategi develop reduc extens learn time comput requir believ increas dnn continu enlarg complex size addit comput load cost memori bandwidth capac signific effect entir train perform lesser extent deduct specif paramet distribut everi layer input data sizeabl amount reus data comput sever network layer exhibit excess ratio contrast ute paramet amount reus data extrem small addit fc layer extrem small ratio tabl present parison differ aspect relat devic addit tabl lish facilit familiar tradeoff obtain optim approach configur system base either fpga gpu cpu devic note ha correspond weak strength accordingli clear solut although gpu process ha enhanc abil address comput challeng relat network maximum gpu cpu perform achiev sever techniqu model turn strongli link bandwidth worst case gpu effici mum theoret perform thi issu requir enlarg memori bandwidth use stack memori next differ approach base fpga gpu cpu accordingli detail tabl comparison differ aspect relat devic featur assess leader develop cpu easiest program gpu fpga cpu size fpga cpu smaller volum solut due lower power consumpt custom broader flexibl provid fpga fpga eas chang easier way vari applic function provid gpu cpu backward compat transfer rtl novel fpga requir addit work furthermor gpu ha less stabl architectur cpu cpu interfac sever varieti interfac implement use fpga fpga fpga configur assist util wider acceler space due consider process abil gpu win custom design optim fpga time latenc implement fpga algorithm offer determinist time turn much faster gpu fpga larg data analysi fpga perform well inlin process cpu support storag capabl largest memori dcnn infer fpga ha lower latenc custom fpga dcnn train greater capabl provid gpu gpu page alzubaidi et al j big data approach perform cpu node usual assist robust network nectiv storag abil larg memori although cpu node purpos fpga gpu lack abil match unprocess comput facil sinc thi requir increas network abil larger memori capac approach gpu extrem effect sever basic dl primit includ greatli oper activ function matrix multipl convolut incorpor memori gpu model significantli enhanc bandwidth thi enhanc allow numer primit effici util comput resourc avail gpu improv gpu perform cpu perform usual relat dens linear algebra oper maxim parallel process base initi gpu program model exampl gpu model may involv comput unit four simd engin per comput layer simd ha sixteen comput lane peak perform tflop tflop percentag employ approach addit gpu perform may achiev addit multipli function vector combin inner product instruct match primit relat matrix oper dnn train gpu usual consid optim design infer oper may also offer consider perform improv approach fpga wildli util variou task includ deep learn infer acceler commonli implement util fpga fpga effect configur reduc unnecessari overhead function involv gpu system compar gpu fpga restrict perform integ infer main fpga aspect capabl calli reconfigur array characterist well capabl figur array mean effect design littl overhead mention earlier fpga offer perform latenc everi watt gain gpu cpu dl infer oper implement custom perform hardwar prune network reduc arithmet precis three factor enabl fpga implement dl algorithm achiev fpga thi level effici addit fpga may employ implement cnn lay engin effici accuraci top peak manc thi use convent cnn xillinx partner demonstr recent contrast prune techniqu mostli employ lstm context size model effici minim provid tant benefit dure implement optim solut mlp neural ing demonstr recent studi field implement precis page alzubaidi et al j big data custom ha reveal lower extrem promis aid suppli addit advanc implement peak perform fpga relat dnn model evalu metric evalu metric adopt within dl task play crucial role achiev mize classifi util within usual data classif procedur two main stage train test util optim classif algorithm dure train stage thi mean evalu metric util discrimin select optim solut discrimin erat forecast upcom evalu relat specif classifi time evalu metric util measur effici ate classifi evalu within model test stage use hidden data given eq tn tp defin number neg posit instanc respect success classifi addit fn fp defin number misclassifi posit neg instanc respect next evalu metric list accuraci calcul ratio correct predict class total number sampl evalu sensit recal util calcul fraction posit pattern correctli classifi specif util calcul fraction neg pattern correctli classifi precis util calcul posit pattern correctli predict predict pattern posit class calcul harmon averag recal precis rate j score thi metric also call youden j statist eq repres metric accuraci tp tn tp tn fp fn sensit tp tp fn speciﬁc tn fp tn precis tp tp fp precis recal precis recal page alzubaidi et al j big data fals posit rate fpr thi metric refer possibl fals alarm ratio calcul eq area roc curv auc common rank type metric util conduct comparison learn algorithm well construct optim learn model contrast probabl threshold ric auc valu expos entir classifi rank perform follow formula use calcul auc valu problem eq sp repres sum posit rank sampl number neg posit sampl denot nn np respect compar raci metric auc valu wa verifi empir theoret make veri help identifi optim solut evalu classifi manc classif train consid discrimin evalu process auc manc wa brilliant howev multiclass issu auc comput ili discrimin larg number creat solut tion time complex comput auc n log n respect hand till auc model n log n accord provost domingo auc model framework dataset sever dl framework dataset develop last year ou framework librari also use order expedit work good result use train process ha becom easier tabl list util framework librari base star rate github well background field tensorflow deem effect easi use ha abil work sever platform github one biggest softwar host site github star refer project site moreov sever benchmark dataset employ differ dl task list tabl summari conclus final mandatori inclus brief discuss gather relev data provid along thi extens research next item analysi present order conclud review exhibit futur direct jscore sensit speciﬁc fpr auc sp nn npnn page alzubaidi et al j big data dl alreadi experi difficulti simultan model modal data recent dl develop anoth common approach multimod dl dl requir sizeabl dataset label data prefer predict unseen data train model thi challeng turn particularli difficult data process requir provid dataset limit tabl benchmark dataset dataset num class applic link dataset imagenet imag classif object local object detect etc http imag classif http html mnist classif handwritten digit http pascal voc imag classif tion object detect http microsoft coco object detect semant segment http home video imag understand http video classif http human action detect http php kinet human action detect http ic googl open imag imag classif tion object detect http html classif http label face wild face recognit http scene dataset indoor scene recognit http htm tabl list common framework librari framework licens core languag year releas homepag tensorflow apach python http kera mit python http caff bsd http matconvnet oxford matlab http mxnet apach http mxnet cntk mit http cntk theano bsd python http torch bsd c lua http apach java http gluon aw microsoft http opendeep mit python http page alzubaidi et al j big data case healthcar data allevi thi issu tl data augment research last year although ml slowli transit unsupervis learn manag practic data without need manual human label mani rent model util supervis learn cnn perform greatli influenc select ani small chang valu affect gener cnn perform therefor care paramet select extrem signific issu consid dure optim scheme develop impress robust hardwar resourc like gpu requir effect cnn train moreov also requir explor effici use cnn smart embed system cnn context ensembl learn repres prospect research area collect differ multipl architectur support model improv generaliz across differ imag categori extract sever level semant imag represent similarli idea new tion function dropout batch normal also merit investig exploit depth differ structur adapt significantli improv cnn learn capac substitut tradit layer tion block result signific advanc cnn perform ha shown recent literatur current develop novel effici block tectur main trend new research model cnn architectur hrnet onli one exampl show alway way improv architectur expect platform play essenti role futur develop comput dl applic util cloud comput offer solut handl enorm amount data also help increas cienci reduc cost furthermor offer flexibl train dl ture recent develop comput tool includ chip neural work mobil gpu see dl applic mobil devic easier user use dl regard issu lack train data expect variou techniqu transfer learn consid train dl model larg unlabel imag dataset next transfer knowledg train dl model small number label imag task last thi overview provid start point commun dl est field dl furthermor research would allow decid suitabl direct work taken order provid accur nativ field acknowledg would like thank professor queensland univers technolog univers inform technolog commun gave feedback paper author contribut conceptu la jz methodolog la jz js softwar la maf valid la jz lf formal analysi la jz yd js investig la jz resourc la jz maf data curat la oa nal draft prepar la oa edit la jz ajh aa yd oa js maf lf visual page alzubaidi et al j big data la maf supervis jz yd project administr jz yd js fund acquisit la ajh aa yd author read approv final manuscript fund thi research receiv extern fund avail data materi applic declar ethic approv consent particip applic consent public applic compet interest author declar compet interest author detail school comput scienc queensland univers technolog brisban qld australia control tem engin depart univers technolog baghdad iraq electr engin technic colleg middl technic univers baghdad iraq faculti electr engin comput scienc univers missouri columbia mo usa alnidh campu univers inform technolog commun baghdad iraq depart comput scienc univers jaén jaén spain colleg comput scienc inform technolog univers sumer thi qar iraq school engin manchest metropolitan univers manchest uk receiv januari accept march refer rozenwald mb galitsyna aa sapunov gv khrameeva ee gelfand machin learn framework predict chromatin fold drosophila use epigenet featur peerj comput sci amrit c paauw ali r lavric identifi child abus text mine machin learn expert syst appl hossain e khan f sikand ss sunni msh applic big data machin learn smart grid associ secur concern review ieee access crawford khoshgoftaar tm prusa jd richter al najada survey review spam detect use machin learn techniqu j big data deldjoo elahi cremonesi p garzotto f piazzolla p quadrana video recommend system base stylist visual featur j data semant k chandran v nguyen k bank j benchmark specimen cell tion use linear discrimin analysi higher order spectra featur cell shape pattern recogn lett liu w wang z liu x zeng n liu alsaadi fe survey deep neural network architectur tion neurocomput pouyanfar sadiq yan tian h tao rey mp shyu ml chen sc iyengar survey deep learn rithm techniqu applic acm comput surv csur alom mz taha tm yakopc c westberg sidik p nasrin ms hasan van essen bc awwal aa asari vk survey deep learn theori architectur electron potok te schuman c young patton r spedalieri f liu j yao kt rose g chakma studi complex deep learn network neuromorph quantum comput acm j emerg technol comput syst jetc adeel gogat hussain contextu deep switch speech enhanc environ inf fusion tian h chen sc shyu ml evolutionari program base deep learn featur select network struction visual data classif inf syst front young hazarika poria cambria recent trend deep learn base natur languag process ieee comput intel mag kopp g durstewitz deep learn small big data psychiatri harmacolog dalal n trigg histogram orient gradient human detect ieee comput societi enc comput vision pattern recognit cvpr vol ieee low dg object recognit local featur proceed seventh ieee intern confer comput vision vol ieee wu l hoi sc yu model applic ieee tran imag process page alzubaidi et al j big data lecun bengio hinton deep learn natur yao g lei zhong review action recognit pattern recogn lett dhillon verma gk convolut neural network review model methodolog applic object detect prog artif intel khan sohail zahoora u qureshi survey recent architectur deep convolut neural work artif intel rev hasan ri yusuf sm alzubaidi review state art deep learn plant diseas broad analysi discuss plant xiao tian z yu j zhang liu du lan review object detect base deep learn multim tool appl ker j wang l rao j lim deep learn applic medic imag analysi ieee access zhang z cui p zhu deep learn graph survey ieee tran knowl data eng http shrestha mahmood review deep learn algorithm architectur ieee access najafabadi mm villanustr f khoshgoftaar tm seliya n wald r muharemag deep learn applic challeng big data analyt j big data goodfellow bengio courvil bengio deep learn vol cambridg mit press shorten c khoshgoftaar tm furht deep learn applic j big data krizhevski sutskev hinton ge imagenet classif deep convolut neural network commun acm bhowmick nagarajaiah veeraraghavan vision deep algorithm detect quantifi crack concret surfac uav video sensor goh gb hoda vishnu deep learn comput chemistri j comput chem li zhang sun gao acceler flash calcul deep learn method j comput phi yang w zhang x tian wang w xue jh liao deep learn singl imag brief review ieee tran multim tang j li liu review lane detect method base deep learn pattern recogn zhao zq zheng p xu st wu object detect deep learn review ieee tran neural netw learn syst k zhang x ren sun deep residu learn imag recognit proceed ieee confer comput vision pattern recognit ng machin learn yearn technic strategi ai engin era deep learn http org metz ture award pioneer artifici intellig new york time nevo anisimov v elidan g r gienck p gigi hassidim mosh z schlesing shalev g et al ml flood forecast scale arxiv preprint arxiv chen h engkvist wang olivecrona blaschk rise deep learn drug discoveri drug discov today benhamm achchab b herrera f tabik breakhi base breast cancer automat diagnosi use deep ing taxonomi survey insight neurocomput wulczyn e steiner df xu z sadhwani wang h mermel ch chen phc liu stump mc deep surviv predict multipl cancer type use histopatholog imag plo one nagpal k foot liu chen phc wulczyn e tan f olson n smith jl mohtashamian wren jh et al ment valid deep learn algorithm improv gleason score prostat cancer npj digit med esteva kuprel b novoa ra ko j swetter sm blau hm thrun classif skin cancer deep neural network natur brunes l mercaldo f reginelli santon explain deep learn pulmonari diseas coronaviru detect comput method program biom jamshidi lalbakhsh talla j peroutka z hadjilooei f lalbakhsh p jamshidi la spada l mirmozafari dehghani et al artifici intellig deep learn approach diagnosi treatment ieee access shorfuzzaman hossain metacovid siames neural network framework contrast loss diagnosi patient pattern recogn carvelli l olesen leari eb peppard pe mignot e sørensen hb jennum design deep learn model automat score period leg movement dure sleep valid multipl human expert sleep med de fauw j ledsam jr b nikolov tomasev n blackwel askham h glorot x donoghu b visentin et al clinic applic deep learn diagnosi referr retin diseas nat med topol ej medicin converg human artifici intellig nat med kermani ds goldbaum cai w valentim cc liang h baxter sl mckeown yang g wu x yan f et al ing medic diagnos treatabl diseas deep learn cell van essen b kim h pearc r boaky k chen lbann livermor big artifici neural network hpc toolkit proceed workshop machin learn comput environ saeed mm al aghbari z alsharidah big data cluster techniqu base spark literatur review peerj comput sci page alzubaidi et al j big data mnih v kavukcuoglu k silver rusu aa veness j bellemar mg grave riedmil fidjeland ak ostrovski g et al control deep reinforc learn natur arulkumaran k deisenroth mp brundag bharath aa deep reinforc learn brief survey ieee signal process mag socher r perelygin wu j chuang j man cd ng ay pott recurs deep model semant sition sentiment treebank proceed confer empir method natur languag process goller c kuchler learn distribut represent backpropag structur proceed intern confer neural network icnn vol ieee socher r lin cci ng ay man cd pars natur scene natur languag recurs neural work icml loupp g cho k becot c cranmer recurs neural network jet physic j high energi phi sadr h pedram mm teshnehlab robust sentiment analysi method base sequenti combin convolut recurs neural network neural process lett urban g subrahmanya n baldi inner outer recurs neural network chemoinformat applic j chem inf model hewamalag h bergmeir c bandara recurr neural network time seri forecast current statu futur direct int j forecast jiang kim h asnani h kannan oh viswanath learn code invent code via recurr neural network ieee j sel area inf theori john ra acharya j zhu c surendran bose sk chaturvedi tiwari n gao zhang kk et al optogenet inspir transit metal dichalcogenid neuristor deep recurr neural network nat commun batur dinler ö aydin optim featur paramet set base gate recurr unit recurr neural work speech segment detect appl sci jagannatha yu structur predict model rnn base sequenc label clinic text ing confer empir method natur languag process confer empir method natur languag process vol nih public access pascanu r gulcehr c cho k bengio construct deep recurr neural network proceed second intern confer learn represent iclr glorot x bengio understand difficulti train deep feedforward neural network proceed thirteenth intern confer artifici intellig statist gao c yan j zhou varshney pk liu long deep recurr neural network target track inf sci zhou dx theori deep convolut neural network downsampl neural netw jhong sy tseng py siriphockpirom n hsia ch huang ms hua kl chen yy autom biometr tion system use palm vein recognit intern confer advanc robot intellig system ari ieee ouadou max h duan tanner jj cheng deepcryopick fulli autom deep neural network singl protein particl pick bmc bioinform wang lu c yang hong f liu hybrid method heartbeat classif via convolut neural work multilay perceptron focal loss peerj comput sci li g zhang li j lv f tong effici dens connect convolut neural network pattern recogn gu j wang z kuen j l shahroudi shuai b liu wang x wang g cai j et al recent advanc tional neural network pattern recogn fang w love pe luo h ding comput vision safeti construct review futur direct adv eng inform palaz collobert acoust model use convolut neural network automat speech recognit speech commun li hc deng zy chiang hh lightweight learn network face recognit perform optim sensor hubel dh wiesel tn recept field binocular interact function architectur cat visual cortex j physiol ioff szegedi batch normal acceler deep network train reduc intern covari shift arxiv preprint arxiv ruder overview gradient descent optim algorithm arxiv preprint arxiv bottou machin learn stochast gradient descent proceed compstat springer hinton g srivastava n swerski neural network machin learn lectur overview ent descent cite zhang improv adam optim deep neural network intern symposium qualiti servic iwqo ieee alzubaidi l fadhel zhang j duan deep learn model classif red blood cell microscopi imag aid sickl cell anemia diagnosi electron alzubaidi l fadhel zhang j santamaría j duan oleiwi toward better understand transfer learn medic imag case studi appl sci alzubaidi l fadhel farhan l zhang j duan optim perform breast cancer classif employ domain transfer learn hybrid deep convolut neural network model electron page alzubaidi et al j big data lecun jackel ld bottou l cort c denker js drucker h guyon muller ua sacking e simard p et al ing algorithm classif comparison handwritten digit recognit neural netw stat mech perspect srivastava n hinton g krizhevski sutskev salakhutdinov dropout simpl way prevent neural work overfit j mach learn dahl ge sainath tn hinton ge improv deep neural network lvcsr use rectifi linear unit ieee intern confer acoust speech signal process ieee xu b wang n chen li empir evalu rectifi activ convolut network arxiv preprint arxiv hochreit vanish gradient problem dure learn recurr neural net problem solut int j uncertain fuzzi knowl base syst lin chen q yan network network arxiv preprint arxiv hsiao ty chang yc chou hh chiu global averag pool tional network j syst arch li z wang sh fan rr cao g zhang yd guo teeth categori classif via deep convolut neural network max pool global averag pool int j imag syst technol zeiler md fergu visual understand convolut network european confer comput vision springer erhan bengio courvil vincent visual featur deep network univ montreal le qv build featur use larg scale unsupervis learn ieee intern confer acoust speech signal process ieee grün f rupprecht c navab n tombari taxonomi librari visual learn featur convolut neural network arxiv preprint arxiv simonyan k zisserman veri deep convolut network imag recognit arxiv print arxiv ranzato huang fj boureau yl lecun unsupervis learn invari featur hierarchi applic object recognit ieee confer comput vision pattern recognit ieee szegedi c liu w jia sermanet p reed anguelov erhan vanhouck v rabinovich go deeper convolut proceed ieee confer comput vision pattern recognit bengio et al rmsprop equilibr adapt learn rate nonconvex optim arxiv srivastava rk greff k schmidhub highway network arxiv preprint arxiv kong w dong zy jia hill dj xu zhang residenti load forecast base lstm recurr neural network ieee tran smart grid ordóñez fj roggen deep convolut lstm recurr neural network multimod wearabl activ recognit sensor cireşan meier u masci j schmidhub deep neural network traffic sign classif neural netw szegedi c ioff vanhouck v alemi impact residu connect learn arxiv preprint arxiv szegedi c vanhouck v ioff shlen j wojna rethink incept architectur comput vision proceed ieee confer comput vision pattern recognit wu zhong liu deep residu learn imag steganalysi multim tool appl huang g liu z van der maaten l weinberg kq dens connect convolut network proceed ieee confer comput vision pattern recognit rubin j parvaneh rahman conroy b babaeizadeh dens connect convolut network tion atrial fibril short ecg record j electrocardiol kuang p chen z li imag dens connect convolut network appl intel xie girshick r dollár p tu z aggreg residu transform deep neural network ing ieee confer comput vision pattern recognit su x zhao jpeg steganalysi base resnext gauss partial deriv filter multim tool appl yadav jalal garlapati hossain k goyal pant deep resnext model phycolog futur algal han w feng r wang l gao adapt deep convolut neural network tion remot sens imageri scene classif igarss ieee intern geoscienc remot sens symposium ieee zagoruyko komodaki wide residu network arxiv preprint arxiv huang g sun liu z sedra weinberg kq deep network stochast depth european confer comput vision springer huynh ht nguyen joint age estim gender classif asian face use wide resnet sn comput sci takahashi r matsubara uehara data augment use random imag crop patch deep cnn ieee tran circuit syst video technol han kim j kim deep pyramid residu network proceed ieee confer comput vision pattern recognit wang wang l wang h li imag via deep shallow convolut network ieee access page alzubaidi et al j big data chollet xception deep learn depthwis separ convolut proceed ieee confer comput vision pattern recognit lo ww yang x wang xception convolut neural network malwar classif transfer ing ifip intern confer new technolog mobil secur ntm ieee rahimzadeh attar modifi deep convolut neural network detect nia chest imag base concaten xception inform med unlock wang f jiang qian c yang li c zhang h wang x tang residu attent network imag classif proceed ieee confer comput vision pattern recognit salakhutdinov r larochel effici learn deep boltzmann machin proceed thirteenth intern confer artifici intellig statist goh h thome n cord lim jh regular deep belief network adv neural inf process syst guan j lai r xiong liu z gu fix pattern nois reduct infrar imag base cascad residu attent cnn neurocomput bi q qin k zhang h li z xu residu attent base convolut network aerial scene sific neurocomput jaderberg simonyan k zisserman et al spatial transform network advanc neural inform process system san mateo morgan kaufmann publish hu j shen l sun network proceed ieee confer comput vision pattern recognit mou l zhu xx learn pay attent spectral domain spectral attent convolut network hyperspectr imag classif ieee tran geosci remot sen woo park j lee jy kweon cbam convolut block attent modul proceed european confer comput vision eccv roy ag navab n waching concurr spatial channel squeez excit fulli convolut work intern confer medic imag comput intervent springer roy ag navab n waching recalibr fulli convolut network spatial channel squeez excit block ieee tran med imag sabour frosst n hinton ge dynam rout capsul advanc neural inform process system san mateo morgan kaufmann publish arun p buddhiraju km porwal classifi hyperspectr imag ieee j sel topic appl earth ob remot sen xinwei l lianghao x yi compact video fingerprint via improv capsul net syst sci control eng b li x xia zhang autonom deep learn genet dcnn design imag classif comput wang j sun k cheng jiang b deng c zhao liu mu tan wang x et al deep sentat learn visual recognit ieee tran pattern anal mach intel http cheng b xiao b wang j shi h huang ts zhang higherhrnet represent learn human pose estim cvpr http karimi h derr tang character decis boundari deep neural network arxiv preprint arxiv li ding l gao decis boundari deep neural network arxiv preprint arxiv yosinski j clune j bengio lipson transfer featur deep neural network advanc neural inform process system san mateo morgan kaufmann publish tan c sun f kong zhang w yang c liu survey deep transfer learn intern confer artifici neural network springer weiss k khoshgoftaar tm wang survey transfer learn j big data shorten c khoshgoftaar tm survey imag data augment deep learn j big data wang f wang h wang h li g situ learn simul approach putat ghost imag opt express pan survey transfer learn collabor recommend auxiliari data neurocomput deng j dong w socher r li lj li k imagenet hierarch imag databas ieee confer comput vision pattern recognit ieee cook feuz kd krishnan nc transfer learn activ recognit survey knowl inf syst cao x wang z yan p li transfer learn pedestrian detect neurocomput raghu zhang c kleinberg j bengio transfus understand transfer learn medic imag advanc neural inform process system san mateo morgan kaufmann publish pham tn van tran l dao svt earli diseas classif mango leav use neural network hybrid metaheurist featur select ieee access saleh hamoud analysi best paramet select person recognit base gait model use cnn algorithm imag augment j big data hirahara takaya e takahara ueda effect data count imag scale deep learn train peerj comput sci page alzubaidi et al j big data fj strazzera f jerez jm urda franco forward nois adjust scheme data tion ieee symposium seri comput intellig ssci ieee dua karra taniskid uci machin learn repositori irvin univers california school inform comput scienc http ml johnson jm khoshgoftaar tm survey deep learn class imbal j big data yang p zhang z zhou bb zomaya ay sampl subset optim classifi imbalanc biolog data confer knowledg discoveri data mine springer yang p yoo pd fernando j zhou bb zhang z zomaya ay sampl subset optim techniqu imbalanc ensembl learn problem bioinformat applic ieee tran cybern wang sun xu deep convolut neural field sequenc label arxiv preprint arxiv li wang umarov r xie b fan li l gao deepr enzym ec number predict deep learn bioinformat li huang c ding l li z pan gao deep learn bioinformat introduct applic perspect big data era method choi e bahadori mt sun j kula j schuetz stewart retain interpret predict model healthcar use revers time attent mechan advanc neural inform process system san mateo morgan kaufmann publish ching himmelstein ds bk kalinin aa bt way gp ferrero e agapow pm zietz man mm et al opportun obstacl deep learn biolog medicin j r soc interfac zhou j troyanskaya og predict effect noncod variant deep sequenc model nat method pokuri bss ghosal kokat sarkar ganapathysubramanian interpret deep learn guid explor photovolta npj comput mater ribeiro mt singh guestrin whi trust explain predict ani classifi ing acm sigkdd intern confer knowledg discoveri data mine wang l nie r yu z xin r zheng c zhang z zhang j cai interpret architectur capsul network identifi gene express program data nat mach intel sundararajan tali yan axiomat attribut deep network arxiv preprint arxiv platt j et al probabilist output support vector machin comparison regular likelihood od adv larg margin classif nair precup arnold dl arbel explor uncertainti measur deep network multipl sclerosi lesion detect segment med imag anal herzog l murina e dürr wegen sick integr uncertainti deep neural network mri base stroke analysi med imag anal pereyra g tucker g chorowski j kaiser ł hinton regular neural network penal confid output distribut arxiv preprint arxiv naeini mp cooper gf hauskrecht obtain well calibr probabl use bayesian bin ing aaai confer artifici intellig aaai confer artifici intellig vol nih public access li sethi ik classifi design pattern recogn zadrozni b elkan obtain calibr probabl estim decis tree naiv bayesian classifi icml vol cites steinwart consist support vector machin regular kernel classifi ieee tran inf theori lee k lee k shin j lee overcom catastroph forget unlabel data wild proceed ieee intern confer comput vision shmelkov k schmid c alahari increment learn object detector without catastroph forget proceed ieee intern confer comput vision zenk f gerstner w ganguli tempor paradox hebbian learn homeostat plastic curr opin neurobiol andersen n krauth n nabavi hebbian plastic vivo relev induct curr opin neurobiol zheng r chakraborti phase ii nonparametr adapt exponenti weight move averag control chart qual eng rebuffi sa kolesnikov sperl g lampert ch icarl increment classifi represent learn ceed ieee confer comput vision pattern recognit hinton ge plaut dc use fast weight deblur old memori proceed ninth annual confer cognit scienc societi parisi gi kemker r part jl kanan c wermter continu lifelong learn neural network review neural netw soltoggio stanley ko risi born learn inspir progress futur evolv plastic artifici neural network neural netw parisi gi tani j weber c wermter lifelong learn human action deep neural network tion neural netw cheng wang zhou p zhang model compress acceler deep neural network principl progress challeng ieee signal process mag page alzubaidi et al j big data wiedemann kirchhoff h matlag haas p marban marinč neumann nguyen schwarz h wiegand et al deepcabac univers compress algorithm deep neural network ieee j sel topic signal process mehta n pandit concurr big data analyt healthcar systemat review int j med inform esteva robicquet ramsundar b kuleshov v depristo chou k cui c corrado g thrun dean guid deep learn healthcar nat med shawahna sait sm acceler deep learn network learn tion review ieee access min public welfar organ manag system base fpga deep learn microprocess microsyst fadhel hame ra alzubaidi l zhang boost convolut neural network perform base fpga acceler intern confer intellig system design applic springer han mao h dalli wj deep compress compress deep neural network prune train quantiz huffman code arxiv preprint arxiv chen z zhang l cao z guo distil knowledg handcraft featur human activ recognit ieee tran ind inform hinton g vinyal dean distil knowledg neural network arxiv preprint arxiv lenssen je fey libuschewski group equivari capsul network advanc neural inform cess system san mateo morgan kaufmann publish denton el zaremba w bruna j lecun fergu exploit linear structur within convolut network effici evalu advanc neural inform process system san mateo morgan kaufmann lisher xu q zhang gu z pan overfit remedi sparsifi regular layer cnn neurocomput zhang c bengio hardt recht b vinyal understand deep learn requir rethink gener commun acm xu x jiang x c du p li x lv yu l ni q chen su j et al deep learn system screen novel ru diseas pneumonia engin sharma k alsadoon prasad p nguyen tqv pham dth novel solut use deep learn left ventricl detect enhanc featur extract comput method program biom zhang g wang c xu b gross three mechan weight decay regular arxiv preprint arxiv laurent c pereyra g brakel p zhang bengio batch normal recurr neural network ieee tional confer acoust speech signal process icassp ieee salamon j bello jp deep convolut neural network data augment environment sound sific ieee signal process lett wang x qin wang xiang chen reltanh activ function vanish gradient resist dnn applic rotat machineri fault diagnosi neurocomput tan hh lim kh vanish gradient mitig deep learn neural network optim intern confer smart comput commun icscc ieee macdonald g godbout gillcash b cairn neural network solut vanish gradient problem arxiv preprint arxiv mittal vaishay survey techniqu optim deep learn gpu j syst arch kanai fujiwara iwamura prevent gradient explos gate recurr unit advanc neural inform process system san mateo morgan kaufmann publish hanin neural net architectur give rise explod vanish gradient advanc neural inform process system san mateo morgan kaufmann publish ribeiro ah tiel k aguirr la schön beyond explod vanish gradient analys rnn train use attractor smooth intern confer artifici intellig statist pmlr amour heller k moldovan adlam b alipanahi b beutel chen c deaton j eisenstein j hoffman md et al underspecif present challeng credibl modern machin learn arxiv preprint arxiv chea p mandel jc current applic futur direct deep learn musculoskelet radiolog skelet radiol wu x sahoo hoi sc recent advanc deep learn object detect neurocomput kuutti bowden r jin barber p fallah survey deep learn applic autonom vehicl control ieee tran intel transp syst yolcu g oztel kazan oz c bunyak deep face analysi system monitor custom est j ambient intel humaniz comput jiao l zhang f liu f yang li l feng z qu survey deep object detect ieee access muhammad k khan del ser j de albuquerqu vhc deep learn multigrad brain tumor classif smart healthcar system prospect survey ieee tran neural netw learn syst litjen g kooi bejnordi setio aaa ciompi f ghafoorian van der laak ja van ginneken b sánchez ci survey deep learn medic imag analysi med imag anal mukherje mondal r singh pk sarkar r bhattacharje ensemconvnet deep learn approach human activ recognit use smartphon sensor healthcar applic multim tool appl page alzubaidi et al j big data zeleznik r foldyna b eslami p weiss j alexand taron j parmar c alvi rm banerji uno et al deep convolut neural network predict cardiovascular risk comput tomographi natur commun wang j liu q xie h yang z zhou boost efficientnet detect lymph node metastas breast cancer use convolut neural network cancer yu h yang lt zhang q armstrong deen mj convolut neural network medic imag analysi comparison improv perspect neurocomput http bharati podder p mondal mrh hybrid deep learn detect lung diseas imag inform med unlock dong pan zhang j xu learn read chest imag exampl use cnn intern confer connect health applic system engin technolog chase ieee rajkomar lingam taylor ag blum mongan classif radiograph use deep convolut neural network j digit imag rajpurkar p irvin j zhu k yang b mehta h duan ding bagul langlotz c shpanskaya k et al chexnet pneumonia detect chest deep learn arxiv preprint arxiv wang x peng lu l lu z bagheri summer rm chest databas mark classif local common thorax diseas proceed ieee confer comput vision pattern recognit zuo w zhou f li z wang cnn knowledg transfer candid classif lung nodul detect ieee access shen w zhou yang f yang c tian convolut neural network lung nodul classif intern confer inform process medic imag springer li r zhang w suk hi wang l li j shen ji deep learn base imag data complet improv brain diseas diagnosi intern confer medic imag comput intervent springer wen j e j routier bottani dormont durrleman burgo n colliot et al convolut neural network classif alzheim diseas overview reproduc evalu med imag anal mehmood maqsood bashir shuyuan deep siames convolut neural network sific alzheim diseas brain sci e ghazal mahmoud aslanta shalabi casanova barn g gimel farb g keynton r alzheim diseas diagnost deepli supervis adapt convolut network front biosci korolev safiullin belyaev dodonova residu plain convolut neural network brain mri classif ieee intern symposium biomed imag isbi ieee alzubaidi l fadhel oleiwi sr zhang diabet foot ulcer classif use novel deep convolut neural network multim tool appl goyal reev nd davison ak rajbhandari spragg j yap mh dfunet convolut neural network diabet foot ulcer classif ieee tran emerg topic comput intel yap hachiuma r alavi brungel r goyal zhu h cassidi b ruckert j olshanski huang x et al deep learn diabet foot ulcer detect comprehens evalu arxiv preprint arxiv tulloch j zamani r akrami machin learn prevent diagnosi manag diabet foot ulcer systemat review ieee access fadhel alzubaidi l oleiwi sickl cell anemia diagnosi base hardwar tor intern confer new trend inform commun technolog applic springer debele tg kebed sr schwenker f shewarega zm deep learn select cancer imag survey j imag khan islam n jan z din iu rodrigu jjc novel deep learn base framework detect sific breast cancer use transfer learn pattern recogn lett alzubaidi l hasan ri awad fh fadhel alshamma zhang breast cancer classif novel deep convolut neural network architectur intern confer develop esystem engin dese ieee roy k banik bhattacharje nasipuri system classif breast histolog imag use deep learn comput med imag gr hame z zahia b javier aguirr j maría vanega breast cancer histopatholog imag sific use ensembl deep learn model sensor hosni km kassem foaud mm skin cancer classif use deep learn transfer learn cairo intern biomed engin confer cibec ieee dorj uo lee kk choi jy lee skin cancer classif use deep convolut neural network multim tool appl kassem hosni km fouad mm skin lesion classif eight class isic use deep tional neural network transfer learn ieee access heidari mirniaharikandehei khuzani az danala g qiu zheng improv perform cnn predict likelihood use chest imag preprocess algorithm int j med inform ah khushaba rn mosa zm escudero effici mixtur deep machin learn model tuberculosi detect use imag resourc limit set arxiv preprint arxiv page alzubaidi et al j big data abraham b nair detect imag use bayesnet classifi biocybern biom eng nour cömert z polat novel medic diagnosi model infect detect base deep featur bayesian optim appl soft comput mallio ca napolitano castiello g giordano fm alessio p iozzino sun angeletti russano santini et al deep learn algorithm train pneumonia also identifi immun checkpoint inhibitor pneumon cancer fourcad khonsari deep learn medic imag analysi third eye doctor j stomatol oral maxillofac surg guo z li x huang h guo n li deep imag segment multimod medic imag ieee tran radiat plasma med sci thakur n yoon h chong current trend artifici intellig colorect cancer patholog imag analysi systemat review cancer lundervold lundervold overview deep learn medic imag focus mri zeitschrift für medizinisch physik yadav ss jadhav sm deep convolut neural network base medic imag classif diseas diagnosi j big data nehm e freedman gordon r ferdman b weiss le alalouf naor orang r micha shechtman dens local microscopi psf design deep learn nat method zulkifley abdani sr zulkifley nh deep learn approach pterygium detect local multim tool appl sirazitdinov kholiavchenko mustafaev yixuan kuleev r ibragimov deep neural network ensembl pneumonia local chest databas comput electr eng zhao w shen l han b yang cheng k toesca da koong ac chang dt xing markerless pancreat tumor target local enabl deep learn int j radiat oncol biol phi roth hr lee ct shin hc seff kim l yao j lu l summer rm classif medic imag use deep convolut net ieee intern symposium biomed imag isbi ieee shin hc orton mr collin dj doran sj leach mo stack autoencod unsupervis featur ing multipl organ detect pilot studi use patient data ieee tran pattern anal mach intel li z dong wen hu x zhou p zeng object detect medic imag neurocomput gao j jiang q zhou b chen convolut neural network detect diagnosi medic imag analysi overview math biosci eng lumini nanni review fair comparison skin detect approach publicli avail dataset expert syst appl http chouhan v singh sk khamparia gupta tiwari p moreira c damaševičiu r de albuquerqu vhc novel transfer learn base approach pneumonia detect chest imag appl sci apostolopoulo id mpesiana ta automat detect imag util transfer learn convolut neural network phi eng sci med mahmud rahman fattah sa covxnet convolut neural network automat pneumonia detect chest imag transfer featur tion comput biol med mh applic artifici intellig battl literatur review chao ton fractal toraman alaku tb turkoglu convolut capsnet novel artifici neural network approach detect diseas imag use capsul network chao soliton fractal dascalu david skin cancer detect deep learn sound analysi algorithm prospect clinic studi elementari dermoscop ebiomedicin adegun viriri deep learn techniqu skin lesion analysi melanoma cancer detect survey artif intel rev zhang n cai yx wang yy tian yt wang xl badami skin cancer diagnosi base optim convolut neural network artif intel med k domínguez convolut neural network framework accur skin cancer detect neural process lett http jain ms massoud tf predict tumour mutat burden histopatholog imag use multiscal deep learn nat mach intel lei h liu elazab lei convolut neural network mitosi detect histopatholog imag ieee j biom health inform celik talo yildirim karabatak acharya ur autom invas ductal carcinoma detect base use deep transfer learn imag pattern recogn lett sebai wang x wang maskmitosi deep learn framework fulli supervis weakli supervis unsupervis mitosi detect histopatholog imag med biol eng comput sebai wang sa partmitosi partial supervis deep learn framework mitosi detect breast cancer histopatholog imag ieee access mahmood arsalan owai lee mb park kr artifici mitosi detect breast cancer histopatholog imag use faster deep cnn j clin med srinidhi cl ciga martel al deep neural network model comput histopatholog survey med imag anal page alzubaidi et al j big data cireşan dc giusti gambardella lm schmidhub mitosi detect breast cancer histolog imag deep neural network intern confer medic imag comput vention springer sirinukunwattana k raza sea tsang yw snead dr cree ia rajpoot nm local sensit deep learn detect classif nuclei routin colon cancer histolog imag ieee tran med imag xu j xiang l liu q gilmor h wu j tang j madabhushi stack spars autoencod ssae nuclei tion breast cancer histopatholog imag ieee tran med imag albarqouni baur c achil f belagianni v demirci navab aggnet deep learn crowd mitosi detect breast cancer histolog imag ieee tran med imag mk awad ai khalaf aa hame hf automat brain tumour diagnosi system magnet reson imag use convolut neural network eurasip j imag video process thaha mm kumar kpm murugan b dhanasekeran vijayakarthick p selvi brain tumor segment use convolut neural network mri imag j med syst talo yildirim baloglu ub aydin g acharya ur convolut neural network brain diseas detect use mri imag comput med imag gr gabr coronado robinson sujit sj datta sun x allen wj lublin fd wolinski js narayana brain lesion segment multipl sclerosi use fulli convolut neural network studi mult scler j chen ding c liu convolut neural network accur brain tumor segment pattern recogn hu k gan q zhang deng xiao f huang w cao c gao brain tumor segment use convolut neural network condit random field ieee access wadhwa bhardwaj verma review brain tumor segment mri imag magn reson imag akku z galimzianova hoogi rubin dl erickson bj deep learn brain mri segment state art futur direct j digit imag moeskop p viergev mendrik de vri ls bender mj išgum automat segment mr brain imag convolut neural network ieee tran med imag milletari f navab n ahmadi sa fulli convolut neural network volumetr medic imag tation fourth intern confer vision ieee ronneberg fischer p brox convolut network biomed imag segment tional confer medic imag comput intervent springer pereira pinto alv v silva ca brain tumor segment use convolut neural network mri imag ieee tran med imag havaei davi biard courvil bengio pal c jodoin pm larochel brain tumor mentat deep neural network med imag anal chen lc papandr g kokkino murphi k yuill al deeplab semant imag segment deep convolut net atrou convolut fulli connect crf ieee tran pattern anal mach intel yan q wang b gong luo c zhao w shen j shi q jin zhang l chest ct imag deep convolut neural network solut arxiv preprint arxiv wang g liu x li c xu z ruan j zhu h meng li k huang n zhang framework automat segment pneumonia lesion ct imag ieee tran med imag khan sh sohail khan lee ys classif region analysi infect use lung ct imag deep convolut neural network arxiv preprint arxiv shi f wang j shi j wu z wang q tang z k shi shen review artifici intellig techniqu ing data acquisit segment diagnosi ieee rev biom eng santamaría j roca overview latest imag registr algorithm appl sci santamaría j cordón dama compar studi evolutionari imag registr od model comput vision imag underst yumer mitra nj learn semant deform flow convolut network european enc comput vision springer ding l feng deepmap unsupervis map estim multipl point cloud proceed ieee confer comput vision pattern recognit mahadevan imagin machin new challeng artifici intellig aaai wang l fang unsupervis reconstruct singl imag via adversari learn arxiv preprint arxiv hermoza r sipiran reconstruct incomplet archaeolog object use gener adversari network proceed comput graphic intern associ comput machineri fu lei wang curran wj liu yang deep learn medic imag registr review phi med biol haskin g kruger u yan deep learn medic imag registr survey mach vision appl de vo bd berendsen ff viergev sokooti h stare išgum deep learn framework unsupervis affin deform imag registr med imag anal yang x kwitt r styner niethamm quicksilv fast predict imag deep learn approach neuroimag page alzubaidi et al j big data miao wang zj liao cnn regress approach registr ieee tran med imag li p pei guo g xu zha registr use convolut autoencod ieee intern symposium biomed imag isbi ieee zhang j yeung sh shu b wang effici memori manag deep learn system arxiv preprint arxiv zhao h han z yang z zhang q yang f zhou l yang lau fc wang xiong et al hive share gpu cluster deep learn guarante usenix symposium oper system design mentat osdi lin jiang z gu j li w dhar ren h khailani b pan dz dreamplac deep learn gpu erat modern vlsi placement ieee tran comput aid de integr circuit syst hossain lee dj deep detect track aerial imageri via fli robot embed devic sensor castro fm guil n mj j ujaldón tune convolut neural network concurr comput pract exp gschwend zynqnet embed convolut neural network arxiv preprint arxiv zhang n wei x chen h liu fpga implement optic remot sens object detect electron zhao hu c wei f wang k wang c jiang underwat imag recognit fpga embed system convolut neural network sensor liu x yang j zou c chen q yan x chen cai collabor edg comput cnn tor face track system ieee tran comput soc syst http hossin sulaiman review evalu metric data classif evalu int j data min knowl manag process provost f domingo tree induct rank mach learn rakotomamonyj optim area roc svm proceed european confer artifici intellig workshop roc curv artifici intellig rocai mingot v miguel ortega lleida optim area roc curv use neural network vector speaker verif comput speech lang fawcett introduct roc analysi pattern recogn lett huang j ling cx use auc accuraci evalu learn algorithm ieee tran knowl data eng hand dj till rj simpl generalis area roc curv multipl class classif problem mach learn masoudnia mersa araabi bn vahabi ah sadeghi ahmadabadi mn learn offlin signatur verif use snapshot ensembl cnn expert syst appl coupé p mansenc b clément giraud r de sennevil bd ta vt lepetit v manjon jv assemblynet larg ensembl cnn whole brain mri segment neuroimag publish note springer natur remain neutral regard jurisdict claim publish map institut affili