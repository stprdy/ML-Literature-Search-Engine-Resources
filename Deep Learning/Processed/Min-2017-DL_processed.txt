deep learning bioinformatics seonwoo min byunghan lee sungroh yoon corresponding author sungroh yoon department electrical computer engineering seoul national university seoul 08826 korea tel fax sryoon abstract era big data transformation biomedical big data valuable knowledge ha one important challenge bioinformatics deep learning ha advanced rapidly since early demonstrates art performance various ﬁelds accordingly application deep learning bioinformatics gain insight data ha emphasized academia industry review deep learning bioinformatics presenting example current research provide useful comprehensive perspective categorize research bioinformatics main omics biomedical imaging biomedical signal processing deep learning architecture deep neural work convolutional neural network recurrent neural network emergent architecture present brief description study additionally discus theoretical practical issue deep learning bioinformatics suggest future research direction believe review provide valuable insight serve starting point researcher apply deep learning approach bioinformatics study key word deep learning neural network machine learning bioinformatics omics biomedical imaging biomedical signal processing introduction era big data transformation large quantity data valuable knowledge ha become increasingly important various domain 1 bioinformatics no exception significant amount biomedical data including omics image signal data accumulated resulting tential application biological healthcare research ha caught attention industry academia stance ibm developed watson oncology platform ing patient medical information assisting clinician treatment option 2 3 addition google deepmind achieved great success alphago game go cently launched deepmind health develop effective care technology 4 5 extract knowledge big data bioinformatics chine learning ha widely used successful ology machine learning algorithm use training data uncover underlying pattern build model make prediction based best fit model indeed some algorithm support vector machine random forest hidden markov el bayesian network gaussian network applied genomics proteomics system biology numerous domain 6 proper performance conventional machine learning algorithm relies heavily data representation called tures 7 however feature typically designed human gineers extensive domain expertise identifying feature appropriate given task remains cult deep learning branch machine learning ha recently emerged based big data power parallel distributed computing sophisticated algorithm deep learning ha overcome previous limitation academic interest ha increased rapidly since early figure 1 furthermore deep learning responsible major advance diverse field seonwoo min candidate department electrical computer engineering seoul national university korea research area clude bioinformatics machine learning biomedical big data deep learning byunghan lee candidate department electrical computer engineering seoul national university korea research area include bioinformatics machine learning biomedical big data data mining sungroh yoon associate professor department electrical computer engineering seoul national university seoul korea received postdoctoral training stanford university stanford usa research interest include machine learning deep learning informatics bioinformatics submitted 20 march 2016 received revised form 16 june 2016 v c author published oxford university press right reserved permission please email 851 briefing bioinformatics 18 5 2017 doi advance access publication date 25 july 2016 paper downloaded guest 28 march 2024 artificial intelligence ai community ha struggled many year 8 one important advancement thus far ha image speech recognition though promising result disseminated natural language processing 16 17 language translation 18 19 certainly bioinformatics also benefit deep learning figure 2 splice junction discovered dna quences finger joint recognized image lapse detected electroencephalography eeg nals previous review addressed machine learning informatics 6 20 fundamental deep learning 7 8 21 addition although recently published review leung et al 22 mamoshina et al 23 greenspan et al 24 cussed deep learning application bioinformatics research former two limited application genomic medicine latter medical imaging article provide comprehensive review deep learning bioinformatics research example categorized bioinformatics domain omics biomedical imaging biomedical signal processing deep learning architecture deep neural network volutional neural network recurrent neural network gent architecture goal article provide valuable insight serve starting point facilitate tion deep learning bioinformatics study best knowledge one first group review deep learning application bioinformatics deep learning brief overview effort create ai system long history figure 3 trates relationship schematic different discipline early approach attempted explicitly program required knowledge given task however faced difficulty dealing complex problem cause designing detail required ai system complish satisfactory result hand demanding job 7 machine learning provided viable solution capability improve experience data although machine learning extract pattern data tations raw data processing highly dependent feature advance feature representation learning particularly deep learning ha shown great promise representation learning discover effective feature well mapping data given task furthermore deep learning learn complex feature combining simpler feature learned data word artificial neural network multiple ear layer referred deep learning architecture ical representation data discovered increasing level abstraction 25 key element deep learning success deep learning built foundation nificant algorithmic detail generally understood two part construction training deep learning tures deep learning architecture basically artificial neural network multiple layer several type proposed according input data characteristic search objective table 1 categorized deep learning architecture four group deep neural network dnns convolutional neural network cnns recurrent neural network rnns emergent architecture explained group detail table 2 some paper used dnns encompass deep learning architecture 7 8 however review use dnns refer specifically multilayer perceptron mlp 26 stacked sae 27 28 deep belief network dbns 29 30 use ceptrons 42 aes 43 restricted boltzmann machine rbms 44 45 building block neural work respectively cnns architecture ceeded particularly image recognition consist convolution layer layer pooling layer rnns designed utilize sequential information input data cyclic connection among building block like perceptrons long memory unit lstms 36 37 gated rent unit grus 19 addition many emergent deep learning architecture suggested deep neural network 38 dimensional recurrent neural network 39 convolutional caes 40 41 goal training deep learning architecture tion weight parameter layer gradually figure approximate number published deep learning article year number article based search result two query deep learning deep learning bio 852 min et al downloaded guest 28 march 2024 combine simpler feature complex feature suitable hierarchical representation learned data single cycle optimization process organized follows 8 first given training dataset forward pas quentially computes output layer propagates function signal forward network final output layer objective loss function measure error inferenced output given label minimize training error backward pas us chain rule propagate error signal compute gradient respect weight throughout neural network 46 finally weight parameter updated using optimization algorithm based stochastic gradient descent sgd 47 whereas batch gradient descent performs parameter update figure application deep learning bioinformatics research overview diagram input data research objective b research example omics domain prediction splice junction dna sequence data deep neural network 94 c research example biomedical imaging finger joint detection image convolutional neural network 145 research example biomedical signal processing lapse detection eeg signal recurrent neural network 178 figure relationship schematic artiﬁcial intelligence machine learning representation learning deep learning 7 deep learning bioinformatics 853 downloaded guest 28 march 2024 complete dataset sgd provides stochastic approximation performing update small set data example several optimization algorithm stem sgd example adagrad 48 adam 49 perform sgd adaptively ifying learning rate based update frequency moment gradient parameter respectively another core element training deep learning tectures regularization refers strategy intended avoid overfitting thus achieve good generalization ance example weight decay 50 tional approach add penalty term objective loss function weight parameter converge smaller lute value currently widely used regularization proach dropout 51 dropout randomly remove hidden unit neural network training considered ensemble possible subnetworks 52 enhance ities dropout new activation function maxout 53 variant dropout rnns called rnndrop 54 posed furthermore recently proposed batch normalization 55 provides new regularization method normalization scalar feature activation within learning mean variance parameter deep learning library actually implement deep learning algorithm great deal attention algorithmic detail required fortunately many open source deep learning library available online table 3 still no clear library ha strength 56 according benchmark test result cnns specifically alexnet 33 implementation baharampour et al 57 neon 58 show great advantage processing speed c þþ based caffe 59 torch 60 offer great advantage term trained model functional extensionality respectively theano 61 62 provides library fine optimize mathematical expression moreover ous wrapper kera 63 lasagne 64 block 65 developed top theano vide intuitive interface google recently released c þþ based tensorflow 66 python interface library currently show limited performance undergoing tinuous improvement heterogeneous distributed computing supported addition tensorflow also take tage kera provides additional interface deep neural network basic structure dnns consists input layer multiple hidden layer output layer figure 4 input data given dnns output value computed sequentially along layer network layer input vector comprising output value unit layer multiplied weight vector unit current layer produce weighted sum function sigmoid hyperbolic tangent rectified linear unit relu 67 applied weighted sum compute output ues layer computation layer transforms representation layer slightly abstract representation 8 based type layer used dnns corresponding learning method dnns classified mlp sae dbn mlp ha similar structure usual neural network includes stacked layer trained purely supervised manner us only labeled data since training method process optimization parameter space mlp typically used large number labeled data available 25 sae dbn use aes rbms building block architecture respectively main difference mlp training executed two phase vised supervised first vised figure 5 layer stacked sequentially trained manner ae rbm using labeled data afterwards supervised output classifier layer stacked whole neural network mized retraining labeled data since sae dbn exploit unlabeled data help avoid overfitting searcher able obtain fairly regularized result even labeled data insufficient common real world 68 dnns renowned suitability analyzing dimensional data given bioinformatics data typically complex dnns great promise bioinformatics research believe dnns hierarchical representation learning method discover previously known highly abstract pattern correlation provide sight better understand nature data however ha occurred u capability dnns not yet fully exploited although key characteristic dnns hierarchical feature learned solely data designed feature often given input instead raw data form expect future progress dnns bioinformatics come investigation proper way encode raw data learn suitable feature table abbreviation alphabetical order abbreviation full word ae ai artiﬁcial intelligence auc operation characteristic curve curve brnn bidirectional recurrent neural network cae convolutional cnn convolutional neural network dbn deep belief network dnn deep neural network deep neural network ecg electrocardiography ecog electrocorticography eeg electroencephalography emg electromyography eog electrooculography gru gated recurrent unit lstm long memory recurrent neural network mlp multilayer perceptron mri magnetic resonance image pca principal component analysis pet positron emission tomography pssm position speciﬁc scoring matrix rbm restricted boltzmann machine relu rectiﬁed linear unit rnn recurrent neural network sae stacked sgd stochastic gradient descent 854 min et al downloaded guest 28 march 2024 convolutional neural network cnns designed process multiple data type especially image directly inspired visual cortex brain visual cortex hierarchy two basic cell type simple cell complex cell 69 simple cell react primitive pattern visual stimulus complex cell synthesize information simple cell identify intricate form since visual cortex powerful natural visual processing system cnns applied imitate three key idea local connectivity invariance location invariance local transition 8 basic structure cnns consists convolution layer layer pooling layer figure 6 use highly correlated data group local weighted sum called feature map obtained convolution layer computing convolution local patch weight tor called filter furthermore since identical pattern pear regardless location data filter applied repeatedly across entire dataset also improves ing efficiency reducing number parameter learn layer increase property feature map pooling layer maximum average sampling region feature map formed subsampling enables cnns handle somewhat different semantically similar feature thus aggregate local feature identify complex feature currently cnns one successful deep ing architecture owing outstanding capacity analyze spatial information thanks development field object recognition believe primary research ments bioinformatics come biomedical imaging domain despite different data characteristic mal biomedical imaging cnn nonetheless offer straightforward application compared domain indeed cnns also great potential omics biomedical table categorization deep learning applied research bioinformatics omics biomedical imaging biomedical signal processing research topic reference research topic reference research topic reference deep neural network protein structure anomaly classiﬁcation brain decoding gene expression regulation segmentation 133 anomaly classiﬁcation protein classiﬁcation 108 recognition 142 143 anomaly classiﬁcation 111 brain decoding 149 150 convolutional neural network gene expression regulation anomaly classiﬁcation brain decoding segmentation anomaly classiﬁcation 176 recognition recurrent neural network protein structure brain decoding 168 gene expression regulation anomaly classiﬁcation 177 178 protein classiﬁcation 109 110 emergent architecture protein structure 91 92 segmentation 141 brain decoding 169 170 table comparison deep learning library core speed batch distributed strength caffe c þþ x model supported neon python x speed tensorflow c þþ heterogeneous distributed computing theano python x x ease use wrapper torch lua x functional extensionality note speed batch based averaged processing time alexnet 33 batch size 256 single gpu 57 caffe neon theano torch wa utilized cudnn tensorflow wa utilized cudnn figure basic structure dnns input unit x three hidden unit layer output unit 26 layer weighted sum function input computed hierarchical resentations obtained deep learning bioinformatics 855 downloaded guest 28 march 2024 signal processing three key idea cnns applied not only grid discover meaningful recurring pattern small variance genomic quence motif also grid action within omics data matrix biomedical signal thus believe popularity promise cnns bioinformatics application continue year ahead recurrent neural network rnns designed utilize sequential information basic structure cyclic connection figure 7 since input data processed sequentially recurrent computation performed hidden unit cyclic connection exists therefore past information implicitly stored hidden unit called state vector output current input computed considering previous input using state tor 8 since many case past future input affect output current input speech tion bidirectional recurrent neural network brnns 70 also designed used widely figure 8 although rnns not seem deep dnns cnns term number layer regarded even deeper structure unrolled time figure 7 therefore long time researcher struggled vanishing gradient problem training rnns learning ency among data difficult 35 fortunately substituting simple perceptron hidden unit complex unit lstm 36 37 gru 19 function memory cell significantly help prevent problem recently rnns used successfully many area including ural language processing 16 17 language translation 18 19 even though rnns explored le dnns cnns still provide powerful analysis method quential information since omics data biomedical signal typically sequential often considered language ture capability rnns mapping put sequence another sequence prediction promising bioinformatics research regard ical imaging rnns currently not first choice many searcher nevertheless believe dissemination dynamic ct mri 71 72 would lead incorporation rnns cnns elevate importance long term furthermore expect success natural language processing lead rnns applied biomedical text lysis 73 employing attention mechanism improve performance extract relevant tion bioinformatics data emergent architecture emergent architecture refer deep learning architecture side dnns cnns rnns review introduce three emergent architecture caes application bioinformatics 38 designed learn put target progressive refinement basic structure consists hidden layer figure 9 key aspect structure progressive refinement siders local correlation performed via input feature figure unsupervised process sae dbn 29 first weight vector trained input unit x hidden unit ﬁrst den layer rbm ae trained another hidden layer stacked obtained representation used train hidden unit another rbm ae process repeated desired number layer figure basic structure cnns consisting convolution layer layer pooling layer 32 convolution layer cnns us multiple learned ters obtain multiple ﬁlter map detecting ﬁlters pooling layer combine feature 856 min et al downloaded guest 28 march 2024 composition layer spatial feature temporal tures spatial feature refer original input whole used identically every layer however poral feature gradually altered progress upper layer except first layer compute hidden unit current layer only adjacent hidden unit coordinate layer used local ations reflected progressively 39 designed apply capability rnns data treating group sequential data instance data treated group horizontal vertical sequence data similar brnns use context direction dimensional data use context possible tions data figure 10 example dataset four context vary order data processing reflected computation four hidden unit position hidden layer hidden unit connected single output layer final sults computed consideration possible context caes 40 41 designed utilize advantage ae cnns learn good hierarchical tions data reflecting spatial information well ized unsupervised training figure 11 training aes reconstruction error minimized using encoder decoder extract feature vector input data create data feature vector respectively cnns convolution pooling layer regarded type coder therefore cnn encoder decoder consisting deconvolution unpooling layer integrated form cae trained manner ae deep learning rapidly growing research area plethora new deep learning architecture proposed awaits wide application bioinformatics newly proposed architecture different advantage existing tures expect produce promising result ous research area example progressive refinement fit dynamic folding process protein effectively utilized protein structure prediction 38 capability suitable segmentation medical image since segmentation requires interpretation local global context unsupervised representation learning consideration spatial information caes provide great advantage discovering recurring pattern limited imbalanced bioinformatics data omics omics research genetic information genome tome proteome data used approach problem matics some common input data omics raw biological sequence dna rna amino acid sequence become relatively affordable easy obtain generation sequencing technology addition extracted feature sequence position specific scoring matrix pssm 78 physicochemical property 79 80 atchley factor 81 structural property 82 83 often used put deep learning algorithm alleviate difficulty plex biological data improve result addition protein contact map present distance amino acid pair structure microarray gene expression data also used according characteristic interest gorized topic interest omics four group table 4 one researched problem protein structure tion aim predict secondary structure contact map protein gene expression regulation including splice junction rna binding protein protein classification figure basic structure rnns input unit x hidden unit h output unit 8 cyclic connection exists computation den unit receives input hidden unit previous time step input unit current time step recurrent computation expressed explicitly rnns unrolled time index symbol represents time step way ht receives input xt propagates computed result yt ht þ figure basic structure brnns unrolled time 70 two hidden unit h h time step h receives input xt h reﬂect past information h receives input xt h reﬂect future tion information hidden unit propagated yt figure basic structure 38 notation hk j represents hidden unit j coordinate kth hidden layer conduct progressive ment neighborhood unit hk j input unit x used tion j deep learning bioinformatics 857 downloaded guest 28 march 2024 including super family subcellular localization also actively investigated furthermore anomaly classification 111 approach used omics data detect cancer deep neural network dnns widely applied protein structure prediction research since complete prediction space complex challenging several study used simpler approach predicting secondary ture torsion angle protein instance heffernan et al 85 applied sae protein amino acid sequence solve diction problem secondary structure torsion angle cessible surface area another study spencer et al 86 applied dbn amino acid sequence along pssm atchley factor predict protein secondary structure dnns also shown great capability area gene expression regulation example lee et al 94 lized dbn splice junction prediction major research enue understanding gene expression 112 proposed new dbn training method called boosted contrastive gence imbalanced data new regularization term sparsity dna sequence work showed not only cantly improved performance also ability detect tle splicing signal moreover chen et al 96 applied mlp microarray expression data infer expression 21 000 target gene only 1000 landmark gene term protein classification asgari et al 108 adopted model widely known method natural language processing considered variant mlp showed could effectively learn distributed representation biological sequence general use many omics application including protein family tion anomaly classification fakoor et al 111 used figure basic structure data 39 four group hidden unit reﬂecting different context ample j hidden unit context 1 receives input j hidden unit context 1 j unit input layer information reﬂected hidden unit four context propagated compute j unit output layer figure basic structure caes consisting convolution layer pooling layer working encoder deconvolution layer unpooling layer ing decoder 41 basic idea similar ae learns hierarchical representation reconstructing input data cae additionally utilizes spatial information integrating convolution 858 min et al downloaded guest 28 march 2024 principal component analysis pca 113 reduce sionality microarray gene expression data applied sae classify various cancer including acute myeloid leukemia breast cancer ovarian cancer convolutional neural network relatively study used cnns solve problem involving biological sequence specifically gene expression regulation problem nevertheless duced strong advantage cnns showing great promise future research first initial convolution layer powerfully capture local sequence pattern sidered motif detector pssms solely learned data instead depth cnns enables learning complex pattern capture longer motif integrate cumulative effect observed motif eventually learn sophisticated regulatory code 114 moreover cnns suited exploit benefit multitask joint learning training cnns simultaneously predict closely related factor feature predictive strength efficiently learned shared across different task example early approach denas et al 99 cessed data matrix row transcription factor activity profile gene exploited cnn similar use image processing recently study focused directly using cnns biological sequence data alipanahi et al 100 kelley et al 103 proposed approach transcription factor binding site prediction 164 dna accessibility multitask prediction ively group presented downstream application genetic variant identification furthermore zeng et al 102 performed systematic exploration cnn architecture transcription site prediction showed number convolutional filter important number layer task zhou et al 104 developed algorithmic framework deepsea performs multitask joint learning chromatin factor transcription factor binding dnase sensitivity profile prioritizes expression quantitative trait locus genetic variant based prediction table deep learning applied bioinformatics research avenue input data input data research avenue omics sequencing data feature genomic sequence position speciﬁc scoring matrix pssm physicochemical property steric parameter volume atchley factor fac structural property contact map distance amino acid pair structure microarray gene expression protein structure prediction structural property contact map structure model quality assessment gene expression regulation splice junction genetic variant affecting splicing sequence speciﬁcity protein classiﬁcation super family subcellular localization anomaly classiﬁcation 111 cancer biomedical imaging magnetic resonance image mri radiographic image positron emission tomography pet histopathology image volumetric electron microscopy image retinal image situ hybridization ish image anomaly classiﬁcation gene expression pattern cancer alzheimer disease schizophrenia segmentation cell structure neuronal structure vessel map brain tumor recognition cell nucleus finger joint anatomical structure brain decoding behavior biomedical signal processing ecog ecg emg eog eeg raw wavelet frequency differential entropy extracted feature eeg normalized decay peak variation brain decoding behavior emotion anomaly classiﬁcation alzheimer disease seizure sleep stage deep learning bioinformatics 859 downloaded guest 28 march 2024 recurrent neural network rnns expected appropriate deep learning ture biological sequence variable length sequential information ha great importance several study applied rnns protein structure prediction 90 gene expression regulation protein tion 109 110 early study baldi et al 88 used brnns perceptron hidden unit protein secondary structure tion thereafter improved performance lstm hidden unit became widely recognized sønderby et al 110 applied brnns lstm hidden unit lution layer learn representation amino acid sequence classify subcellular location protein furthermore park et al 105 lee et al 107 exploited rnns lstm hidden unit microrna identification target prediction obtained significantly improved accuracy relative approach demonstrating high capacity rnns analyze biological sequence emergent architecture emergent architecture used protein structure diction research 91 92 specifically contact map prediction di lena et al 91 applied using spatial feature ing protein secondary structure orientation probability alignment probability additionally baldi et al 92 applied rnns amino acid sequence correlated profile protein secondary structure biomedical imaging biomedical imaging 115 another actively researched main wide application deep learning general related task biomedical image used clinical treatment resonance imaging mri 116 117 graphic imaging 118 119 positron emission tomography pet 120 histopathology imaging 121 used input data deep learning algorithm categorized research avenue biomedical imaging four group table 4 one researched problem anomaly classification diagnose disease cancer schizophrenia eral task segmentation partitioning specific structure cellular structure brain tumor recognition detection cell nucleus finger joint studied frequently biomedical imaging study popular high content screening 148 involves quantifying microscopic image cell biology covered former group 128 134 137 additionally cranial mri used brain decoding 149 150 interpret human behavior emotion deep neural network term biomedical imaging dnns applied eral research area including anomaly classification segmentation 133 recognition 142 143 brain decoding 149 150 plis et al 122 classified schizophrenia patient brain mri using dbn xu et al 142 used sae detect cell nucleus histopathology image interestingly similar handwritten digit image recognition van gerven et al 149 classified handwritten digit image dbn not analyzing image indirectly analyzing indirectly functional mri participant looking digit image convolutional neural network largest number study ha conducted ical imaging since avenue similar general related task anomaly classification roth et al 125 applied cnns three different ct image datasets sify sclerotic metastasis lymph node colonic polyp additionally ciresan et al 128 used cnns detect mitosis breast cancer histopathology image crucial approach cancer diagnosis assessment pet image esophageal cancer used ypsilantis et al 129 predict response neoadjuvant chemotherapy application cnns found segmentation recognition example ning et al 134 studied segmentation pattern cell wall cytoplasm nuclear membrane nucleus outside medium using microscopic image havaei et al 139 proposed cascaded cnn architecture exploiting local global contextual feature performed brain tumor segmentation mri recognition cho et al 144 searched anatomical structure recognition among ct image lee et al 145 proposed finger joint detection system fingernet crucial step medical ations bone age growth disorder rheumatoid arthritis 151 recurrent neural network traditionally image considered data involve internal correlation spatial information rather sequential mation treating biomedical image data study biomedical imaging chosen approach involving dnns cnns instead rnns emergent architecture attempt apply unique capability rnns image data using augmented rnn structure continued rnns 39 applied beyond image image example stollenga et al 141 applied electron microscopy image mri segment neuronal structure biomedical signal processing biomedical signal processing 115 domain searcher use recorded electrical activity human body solve problem bioinformatics various data eeg 152 electrocorticography ecog 153 electrocardiography ecg 154 electromyography emg 155 phy eog 156 157 used study focusing eeg activity far recorded signal usually noisy include many artifact raw signal often posed wavelet frequency component used input deep learning algorithm addition designed feature like normalized decay peak variation used some study improve result categorized research avenue biomedical signal processing two group table 4 brain decoding using eeg signal anomaly classification diagnose disease deep neural network since biomedical signal usually contain noise artifact decomposed feature frequently used raw nals brain decoding et al 159 applied dbn 860 min et al downloaded guest 28 march 2024 frequency component eeg signal classify motor imagery skill moreover jia et al 161 jirayucharoensak et al 163 used dbn sae respectively emotion classification anomaly classification huanhuan et al 171 published one study applying dbn ecg signal classified beat either normal abnormal beat study used raw eeg signal wulsin et al 172 analyzed individual waveform abnormality using dbn raw eeg signal tracted feature input whereas zhao et al 174 used only raw eeg signal input dbn diagnose alzheimer disease convolutional neural network raw eeg signal analyzed brain decoding anomaly classification 176 via cnns perform convolution instance stober et al 165 classified rhythm type genre music participant listened cecotti et al 167 classified character participant viewed another approach apply cnns medical signal processing wa reported mirowski et al 176 extracted feature synchrony wavelet coherence coded pixel color formulate pattern ordinary cnns like one used biomedical imaging used predict seizure recurrent neural network since biomedical signal represent naturally sequential data rnns appropriate deep learning architecture analyze data expected produce promising result present some study brain decoding 168 anomaly fication 177 178 petrosian et al 177 applied perceptron rnns raw eeg signal corresponding wavelet decomposed tures predict seizure addition davidson et al 178 used lstm rnns eeg spectrum feature detect lapse emergent architecture cae ha applied brain decoding study 169 170 wang et al 169 performed finger flex extend tions using raw ecog signal addition stober et al 170 sified musical rhythm participant listened raw eeg signal discussion limited imbalanced data considering necessity optimizing tremendous number weight parameter neural network deep learning algorithm assumed sufficient balanced data unfortunately however usually not true problem bioinformatics complex expensive data acquisition es limit size bioinformatics datasets addition process often show significantly unequal class distribution instance one class significantly higher stance class 179 example clinical case inevitably le data ment group normal control group former also rarely disclosed public due privacy restriction ethical requirement creating imbalance able data 180 assessment metric used clearly observe limited imbalanced data might compromise formance deep learning 181 accuracy often give misleading result harmonic mean sion recall provides insightful performance score measure performance different class distribution operating characteristic curve auc curve commonly used two measure strongly correlated curve dominates one measure only dominates nevertheless contrast auc might present optimistic view performance since false positive rate receiver operating characteristic curve fail capture large change false positive class negatively skewed 182 solution limited imbalanced data divided three major group 181 183 data preprocessing learning algorithmic modification data preprocessing ically provides better dataset sampling basic ture extraction sampling method balance distribution imbalanced data several approach proposed including informed undersampling 184 synthetic minority oversampling technique 185 sampling 186 example li et al 127 roth et al 146 performed ment analysis ct image spatial deformation random shifting rotation although basic feature tion method deviate concept deep learning occasionally used lessen difficulty learning limited imbalanced data research bioinformatics using human designed feature input data pssm omics sequence wavelet energy eeg signal understood context 86 92 172 176 learning method define different cost misclassifying data example individual class solve limited imbalanced data problem cost sensitivity applied objective loss function neural network ther explicitly implicitly 187 example explicitly replace objective loss function reflect class imbalance implicitly modify learning rate according data instance class training algorithmic modification method accommodate learning rithms increase suitability limited imbalanced data simple effective approach adoption unsupervised great help learn tion class produce regularized result 68 addition transfer learning consists ficient data similar different domain real data ha great advantage 24 188 instance lee et al 107 proposed microrna target prediction method exploit unsupervised rnn based ae achieved 25 increase compared existing alternative bar et al 132 performed transfer learning using ural image imagenet database 189 data chest image identify chest gy classify healthy abnormal image addition sophisticated training method also cuted lee et al 94 suggested dbn boosted categorical rbm havaei et al 139 suggested cnns training combining idea undersampling changing main criticism deep learning used even though produce outstanding result deep learning bioinformatics 861 downloaded guest 28 march 2024 know little result derived internally bioinformatics particularly biomedical domain not enough simply produce good outcome since many study connected patient health crucial change providing logical reasoning clinician medical treatment transformation deep learning still early stage one widely used approach interpretation visualizing trained deep learning model term image input deconvolutional network ha proposed reconstruct visualize archical representation specific input cnns 190 addition visualize generalized class representative image rather dependent particular input gradient ascent optimization input space cf ha provided another effective methodology 191 192 regarding genomic sequence input several approach proposed infer pssms trained model visualize corresponding motif heat map sequence logo example lee et al 94 extracted motif choosing class discriminative weight vector among first layer dbn deepbind 100 demo 101 extracted motif trained cnns counting nucleotide frequency positive input subsequence high activation value feature map respectively specifically transcription factor binding site prediction alipanahi et al 100 developed visualization method tion map illustrating effect genetic variant ing score predicted cnns mutation map consists heat map show much mutation alters binding score input sequence logo height base scaled maximum decrease binding score among possible mutation moreover kelley et al 103 ther complemented mutation map line plot show maximum increase well maximum decrease prediction score addition interpretation ization attention mechanism designed focus citly salient point mathematical rationale behind deep learning 193 194 studied selection appropriate deep learning architecture hyperparameters choosing appropriate deep learning architecture crucial proper application deep learning obtain robust liable result awareness capability deep ing architecture selection according capability addition input data characteristic research objective essential however date advantage ture only roughly understood example dnns able analysis internal correlation data cnns suitable analysis spatial information rnns suitable analysis sequential information 7 indeed detailed methodology selecting ate best fit deep learning architecture remains challenge studied future even deep learning architecture selected many number layer number hidden unit weight initialization value learning iteration even learning researcher set influence result remarkably 195 many year hyperparameter tuning wa rarely systematic left human machine learning expert nevertheless automation machine learning research aim automatically mize hyperparameters growing constantly 196 rithms proposed including sequential model based global optimization 197 bayesian optimization gaussian process prior 198 random search approach 199 multimodal deep learning multimodal deep learning 200 exploit information multiple input source promising avenue ture deep learning research particular bioinformatics expected benefit greatly field various type data assimilated naturally 201 example not only omics data image signal drug response electronic medical record available input data ct mri pet form also available single image bioinformatics study already begun use multimodal deep learning example suk et al 124 studied alzheimer disease classification using cerebrospinal fluid brain image form mri pet scan soleymani et al 168 conducted emotion detection study eeg signal face image data accelerating deep learning deep learning model parameter training data come available better learning performance achieved however time inevitably lead drastic crease training time emphasizing necessity ated deep learning 7 25 approach accelerating deep learning divided three group advanced optimization algorithm parallel distributed computing specialized hardware since main reason long training time parameter tion plain sgd take long several study focused advanced optimization algorithm 202 end some widely employed algorithm include adagrad 48 adam 49 batch normalization 55 optimization 203 parallel distributed computing significantly erate time completion enabled many deep learning study approach exploit method use graphic processing unit method use cluster machine tributed environment deep learning framework ing recently released deepspark 209 tensorflow 210 provide parallel distributed computing ability although development specialized hardware deep learning still infancy provide major acceleration become far important long term 211 currently field mable gate processor development neuromorphic chip modeled brain greatly pated promising technology future trend deep learning incorporation traditional deep learning architecture promising future trend instance joint network cnns rnns integrated attention model applied image captioning 75 video summarization 215 image question answering 216 study toward augmenting structure rnns conducted well neural turing machine 217 memory network 218 adopted dressable external memory rnns shown great result task requiring intricate inference algorithm learning complex question answering recently adversarial 862 min et al downloaded guest 28 march 2024 example degrade performance small imperceptible perturbation received increased attention machine learning community 219 220 since sarial training neural network result regularization provide higher performance expect additional study area including involving adversarial generative work 221 manifold regularized network 222 term learning methodology learning reinforcement learning also receiving attention supervised learning exploit unlabeled labeled data algorithm proposed example ladder network 223 add skip connection mlp cnns taneously minimize sum supervised unsupervised cost function denoise representation every level model reinforcement learning leverage reward outcome nals resulting action rather correctly labeled data since reinforcement learning closely resembles human actually learn approach ha great promise ficial general intelligence 224 currently application mainly focused game playing 4 robotics 225 conclusion enter major era big data deep learning taking center stage international academic business interest bioinformatics great advance made conventional machine learning deep learning anticipated produce promising result review provided tensive review bioinformatics research applying deep ing term input data research objective characteristic established deep learning architecture discussed limitation approach promising direction future research although deep learning hold promise not silver bullet not provide great result ad hoc bioinformatics cation remain many potential challenge including limited imbalanced data interpretation deep learning sults selection appropriate architecture parameter furthermore fully exploit capability deep learning multimodality acceleration deep learning require study thus confident prudent arations regarding issue discussed herein key success future deep learning approach bioinformatics believe review provide valuable insight serve starting point application deep learning vance bioinformatics future research key point great deal biomedical data ha lated various machine algorithm widely applied bioinformatics extract knowledge big data deep learning ha evolved acquisition big data power parallel distributed computing sophisticated training algorithm ha facilitated major advance numerous domain image recognition speech recognition natural language processing review deep learning bioinformatics sent research categorized bioinformatics domain omics biomedical imaging biomedical signal cessing deep learning architecture deep neural network convolutional neural network current neural network emergent architecture furthermore discus theoretical practical issue plaguing application deep learning bioinformatics including imbalanced data pretation hyperparameter optimization multimodal deep learning training acceleration comprehensive review existing work lieve paper provide valuable insight serve launching point researcher apply deep learning approach bioinformatics study acknowledgement author would like thank rus altman tsachy weissman stanford university honglak lee university michigan narry kim daehyun baek seoul national university kim university california san diego helpful discussion applying artiﬁcial intelligence machine learning bioinformatics funding research wa supported national research foundation nrf korea grant funded korean government ministry science ict future planning no korea health technology r project korea health industry development institute khidi funded ministry health welfare no snu ece brain korea project reference manyika j chui brown b et al big data next frontier innovation competition productivity technical report mckinsey global institute 2011 ferrucci brown e j et al building watson overview deepqa project ai magazine 2010 31 3 ibm watson oncology ibm 2016 silver huang maddison cj et al mastering game go deep neural network tree search nature 2016 529 7587 deepmind health google deepmind 2016 naga p calvo b santana r et al machine learning bioinformatics brief bioinformatics 2006 7 1 goodfellow bengio courville deep learning book preparation mit press 2016 lecun bengio hinton deep learning nature 2015 521 7553 farabet c couprie c najman l et al learning hierarchical feature scene labeling ieee trans pattern anal mach intell 2013 35 8 szegedy c liu w jia et al going deeper tions arxiv preprint 2014 tompson jj jain lecun et al joint training tional network graphical model human pose deep learning bioinformatics 863 downloaded guest 28 march 2024 estimation advance neural information processing system 2014 liu n han j zhang et al predicting eye ﬁxations using convolutional neural network proceeding ieee conference computer vision pattern recognition hinton g deng l yu et al deep neural network acoustic modeling speech recognition shared view four research group ieee signal process mag 2012 29 6 sainath tn mohamed kingsbury b et al deep tional neural network lvcsr 2013 ieee international conference acoustic speech signal processing icassp ieee new york chorowski jk bahdanau serdyuk et al model speech recognition adv neural inf process syst 2015 kiros r zhu salakhutdinov rr et al vector advance neural information processing system 2015 li j luong jurafsky hierarchical neural coder paragraph document arxiv preprint 2015 luong pham h manning cd effective approach neural machine translation arxiv preprint 2015 cho k van enboer b gulcehre c et al learning phrase representation using rnn statistical machine translation arxiv preprint 2014 libbrecht mw noble w machine learning application genetics genomics nat rev genet 2015 16 6 schmidhuber deep learning neural network view neural network 2015 leung mk delong alipanahi b et al machine learning genomic medicine review computational problem data set proc ieee 2016 mamoshina p vieira putin e et al application deep learning biomedicine mol pharm 2016 greenspan h van ginneken b summer rm guest editorial deep learning medical imaging overview future promise exciting new technique ieee trans med imaging 2016 35 5 lecun ranzato deep learning tutorial tutorial international conference machine learning icml 13 citeseer svozil kvasnicka v pospichal introduction layer neural network chemometr intell lab syst 1997 39 1 vincent p larochelle h bengio et al extracting posing robust feature denoising autoencoders proceeding international conference machine learning 2008 acm new york vincent p larochelle h lajoie et al stacked denoising autoencoders learning useful representation deep work local denoising criterion j mach learn 2010 hinton g osindero teh fast learning algorithm deep belief net neural comput 2006 18 7 hinton g salakhutdinov rr reducing dimensionality data neural network science 2006 313 5786 lecun boser b denker j et al handwritten digit tion network advance neural information processing system citeseer lawrence giles cl tsoi ac et al face recognition volutional approach ieee trans neural netw 1997 8 1 krizhevsky sutskever hinton imagenet classiﬁcation deep convolutional neural network advance neural information processing system williams rj zipser learning algorithm continually running fully recurrent neural network neural comput 1989 1 2 bengio simard p frasconi learning encies gradient descent difﬁcult ieee trans neural netw 1994 5 2 hochreiter schmidhuber long memory neural comput 1997 9 8 gers fa schmidhuber j cummins learning forget tinual prediction lstm neural comput 2000 12 10 lena pd nagata k baldi pf deep tures learning protein structure prediction advance neural information processing system graf schmidhuber ofﬂine handwriting recognition multidimensional recurrent neural network advance neural information processing system hadsell r sermanet p ben j et al learning vision autonomous driving j field robot 2009 26 2 masci j meier u cires et al stacked convolutional hierarchical feature extraction artiﬁcial neural network machine learning icann springer berlin heidelberg 2011 minsky papert perceptron introduction tional geometry mit press cambridge expanded edition 1969 19 88 fukushima cognitron multilayered neural network biol cybern 1975 20 hinton g sejnowski tj learning releaming boltzmann machine parallel distrib process explor microstruct cogn 1986 hinton practical guide training restricted boltzmann machine momentum 2010 9 1 theory backpropagation neural work international joint conference neural network ijcnn ieee washington dc bottou stochastic gradient learning neural network proc 1991 91 8 duchi j hazan e singer adaptive subgradient method online learning stochastic optimization j mach learn 2011 kingma ba adam method stochastic optimization arxiv preprint 2014 moody j hanson krogh et al simple weight decay improve generalization adv neural inf process syst 1995 srivastava n hinton g krizhevsky et al dropout simple way prevent neural network overﬁtting j mach learn 2014 15 1 baldi p sadowski pj understanding dropout advance neural information processing system 2013 goodfellow ij mirza et al maxout work arxiv preprint 2013 moon choi h lee h et al rnndrop novel dropout rnns asr automatic speech recognition understanding asru scottsdale az 2015 864 min et al downloaded guest 28 march 2024 ioffe szegedy batch normalization accelerating deep network training reducing internal covariate shift arxiv preprint 2015 development team source distributed deep learning jvm apache software foundation license 2016 bahrampour ramakrishnan n schott l et al comparative study deep learning software framework arxiv preprint 2015 nervana system neon 2016 jia caffe open source convolutional architecture fast feature embedding acm international conference multimedia acm washington dc 2014 collobert r kavukcuoglu k farabet environment machine learning biglearn nip workshop 2011 bergstra j breuleux bastien f et al theano cpu gpu math expression compiler proceeding python scientiﬁc computing conference scipy 2010 austin tx bastien f lamblin p pascanu r et al theano new feature speed improvement arxiv preprint 2012 chollet kera deep learning library code documentation 2015 dieleman heilman kelly j et al lasagne first release 2015 van enboer b bahdanau dumoulin v et al block fuel framework deep learning arxiv preprint 2015 abadi agarwal barham p et al tensorflow machine learning heterogeneous distributed system arxiv preprint 2016 nair v hinton rectiﬁed linear unit improve stricted boltzmann machine proceeding international conference machine learning erhan bengio courville et al doe unsupervised help deep learning j mach learn 2010 hubel dh wiesel tn receptive ﬁelds functional tecture monkey striate cortex j physiol 1968 195 1 schuster paliwal kk bidirectional recurrent neural work ieee trans signal process 1997 45 11 cenic nabavi dg craen ra et al dynamic ct ment cerebral blood ﬂow validation study j neuroradiol 1999 20 1 tsao j boesiger p pruessmann kp blast sense dynamic mri high frame rate exploiting ral correlation magn reson med 2003 50 5 cohen hersh wr survey current work ical text mining brief bioinformatics 2005 6 1 bahdanau cho k bengio neural machine translation jointly learning align translate arxiv preprint 2014 xu k ba j kiros r et al show attend tell neural image caption generation visual attention arxiv preprint 2015 cho k courville bengio describing multimedia content using network ieee trans multimed 2015 17 11 mnih v heess n graf recurrent model visual tention advance neural information processing system 2014 jones dt protein secondary structure prediction based scoring matrix j mol biol 1999 292 2 ponomarenko jv ponomarenko mp frolov et al conformational physicochemical dna feature speciﬁc transcription factor binding site bioinformatics 1999 15 7 cai lin sl support vector machine predicting protein amino acid sequence biochim biophys acta bba protein proteomics 2003 1648 1 atchley wr zhao j fernandes ad et al solving protein sequence metric problem proc natl acad sci usa 2005 102 18 branden ci introduction protein structure garland science new york 1999 richardson j anatomy taxonomy protein ture adv protein chem 1981 lyon j dehzangi heffernan r et al predicting backbone ca angle dihedrals protein sequence stacked sparse deep neural network j comput chem 2014 35 28 heffernan r paliwal k lyon j et al improving prediction secondary structure local backbone angle solvent cessible surface area protein iterative deep learning sci rep 2015 spencer eickholt j cheng deep learning network proach ab initio protein secondary structure prediction trans comput biol bioinformat 2015 12 1 nguyen sp shang xu novel deep learning method protein model quality assessment 2014 international joint conference neural network ijcnn 2014 ieee new york baldi p brunak frasconi p et al exploiting past future protein secondary structure prediction bioinformatics 1999 15 11 baldi p pollastri g andersen ca et al matching protein partner feedforward recurrent neural network proceeding 2000 conference intelligent system molecular biology la jolla ca sønderby sk winther protein secondary structure diction long short term memory network arxiv preprint 2014 lena pd nagata k baldi deep architecture protein contact map prediction bioinformatics 2012 28 19 baldi p pollastri principled design cursive neural network architecture protein structure prediction problem j mach learn 2003 leung mk xiong hy lee lj et al deep learning splicing code bioinformatics 2014 30 12 lee yoon boosted categorical restricted boltzmann chine computational prediction splice junction international conference machine learning lille france zhang zhou j hu h et al deep learning framework modeling structural feature protein target nucleic acid 2015 chen li narayan r et al gene expression inference deep learning bioinformatics 2016 deep learning bioinformatics 865 downloaded guest 28 march 2024 li shi w wasserman ww prediction region using supervised deep learning od biorxiv 2016 041616 liu f ren c li h et al de novo identiﬁcation timing domain human genome deep learning bioinformatics 2015 denas taylor deep modeling gene expression tion erythropoiesis model international conference machine learning workshop representation learning atlanta georgia usa 2013 b delong weirauch mt et al predicting quence speciﬁcities protein deep learning nat biotechnol 2015 33 8 j singh r lin z et al deep motif visualizing genomic sequence classiﬁcations arxiv preprint arxiv 2016 h edward md liu g et al convolutional neural work architecture predicting binding bioinformatics 2016 32 12 dr snoek j rinn basset learning regulatory code accessible genome deep convolutional ral network biorxiv 2015 028399 j troyanskaya og predicting effect noncoding variant deep sequence model nat method 2015 12 10 min choi et al deepmirgene deep neural work based precursor microrna prediction arxiv preprint 2016 b lee na b et al splice junction prediction using deep recurrent neural network arxiv preprint 2015 b baek j park et al deeptarget learning framework microrna target prediction using deep rent neural network arxiv preprint 2016 e mofrad continuous distributed representation biological sequence deep proteomics genomics plo one 2015 10 11 heusel obermayer fast tein homology detection without alignment bioinformatics 2007 23 14 sk sønderby ck nielsen h et al convolutional lstm network subcellular localization protein arxiv preprint 2015 r ladhak f nazi et al using deep learning hance cancer diagnosis classiﬁcation proceeding international conference machine learning 2013 tw graveley br expansion eukaryotic ome alternative splicing nature 2010 463 7280 principal component analysis wiley online library 2002 kellis deep learning regulatory genomics nat biotechnol 2015 33 8 k splinter biomedical signal image processing crc press new york 2005 rr warach magnetic resonance imaging n engl j med 1993 328 10 lee kay ar et al brain magnetic resonance imaging contrast dependent blood oxygenation proc natl acad sci 1990 87 24 computed tomography principle design artifact recent advance spie bellingham wa 2009 thomlinson w johnston r et al diffraction enhanced imaging phys med biol 1997 42 11 dl townsend dw valk pe et al positron emission tomography springer london 2005 mn boucheron le et al histopathological image analysis review biomed eng ieee rev 2009 sm hjelm dr salakhutdinov r et al deep learning neuroimaging validation study front neurosci 2014 hsu hidayati sc et al ﬁcation lung nodule computed tomography image via deep learning technique onco target ther 2015 8 shen deep feature representation classiﬁcation medical image computing intervention miccai springer new york 2013 hr lu l liu j et al improving tion using convolutional neural network random view aggregation arxiv preprint 2015 hr yao j lu l et al detection sclerotic spine stases via random aggregation deep convolutional neural network classiﬁcations recent advance computational method clinical application spine imaging springer heidelberg 2015 q cai w wang x et al medical image classiﬁcation convolutional neural network 2014 international conference control automation robotics vision icarcv ieee singapore dc giusti gambardella lm et al mitosis tion breast cancer histology image deep neural work medical image computing intervention miccai springer heidelberg 2013 siddique sohn et al predicting sponse neoadjuvant chemotherapy pet imaging using convolutional neural network plo one 2015 10 9 li r mukkamala r et al deep convolutional neural network annotating gene expression pattern mouse brain bmc bioinformatics 2015 16 1 aa ovalle jea madabhushi et al deep ing architecture image representation visual ability automated carcinoma cancer detection medical image computing intervention miccai springer heidelberg 2013 diamant wolf l et al deep learning medical training used chest pathology identiﬁcation spie medical imaging international society optic photonics 2015 q feng b xie l et al learning approach vessel segmentation retinal image ieee trans med imaging 2015 35 1 f delhomme lecun et al toward automatic notyping developing embryo video ieee trans image process 2005 14 9 sc murray jf jain v et al convolutional network learn generate afﬁnity graph image tion neural comput 2010 22 2 briggman kl turaga sc et al connectomic reconstruction inner plexiform layer mouse retina nature 2013 500 7461 giusti gambardella lm et al deep neural work segment neuronal membrane electron copy image advance neural information processing system 2012 866 min et al downloaded guest 28 march 2024 petersen k igel c et al deep feature learning knee cartilage segmentation using triplanar convolutional neural network medical image computing assisted intervention miccai springer heidelberg 2013 davy et al brain tumor mentation deep neural network arxiv preprint 2015 hr lu l farag et al deeporgan deep convolutional network automated pancreas tion medical image computing intervention miccai springer heidelberg 2015 mf byeon w liwicki et al parallel dimensional lstm application fast biomedical metric image segmentation arxiv preprint 2015 j xiang l liu q et al stacked sparse autoencoder ssae nucleus detection breast cancer histopathology image ieee trans med imaging 2015 35 1 cl mahjoubfar tai et al deep learning free cell classiﬁcation sci rep 2016 6 j lee k shin e et al medical image deep learning hospital pac dataset arxiv preprint 2015 choi choi et al fingernet deep based robust ﬁnger joint detection radiograph biomedical circuit system conference biocas 2015 ieee ieee new york hr lee ct shin et al tion medical image using deep convolutional net arxiv preprint 2015 hr lu l seff et al new representation lymph node detection using random set deep tional neural network observation medical image computing intervention miccai springer heidelberg 2014 oz frey bj computer vision high content ing crit rev biochem mol biol 2016 51 2 mav de lange fp heskes neural decoding hierarchical generative model neural comput 2010 22 12 shikauchi nakae k et al deep learning fmri big data novel approach ing arxiv preprint 2015 j jiang countryman p et al automated algorithm identiﬁcation joint space phalanx margin cation digitized hand radiograph med phys 1999 26 3 e da silva fl electroencephalography basic principle clinical application related field lippincott williams wilkins new york 2005 aki g anastassiou ca koch origin lar ﬁelds current eeg ecog lfp spike nat rev neurosci 2012 13 6 hjl wagner g practical electrocardiography williams wilkins baltimore 1988 luca cj use surface electromyography mechanic j appl biomech 1997 lr sheena measurement niques psychol 1975 30 3 r boquete l mazo et al system assisted ity using eye movement based electrooculography ieee trans neural syst rehabil eng 2002 10 4 zv ramsey nf wronkeiwicz et al time naive learning neural correlate ecog physiology int j mach learn comput 2011 x kuang guo x et al deep learning method siﬁcation eeg data based motor imagery intelligent computing bioinformatics springer heidelberg 2014 k li x zhang et al affective state recognition eeg deep belief network 2013 ieee international conference bioinformatics biomedicine bibm ieee new york x li k li x et al novel deep learning framework affective state recognition eeg signal 2014 ieee international conference bioinformatics bioengineering bibe ieee new york guo lu revealing critical channel frequency band emotion recognition eeg deep belief network 2015 international conference neural engineering ner ieee new york israsena emotion recognition using deep learning network cipal component based covariate shift adaptation sci world j 2014 2014 cameron dj grahn ja classifying eeg recording rhythm perception international society music information retrieval conference ismir 14 cameron dj grahn ja 2014 using lutional neural network recognize rhythm advance neural information processing system h graeser convolutional neural network embedded fourier transform eeg classiﬁcation international conference pattern recognition icpr 2008 ieee new york h aser convolutional neural network detection application interface ieee trans pattern anal mach intell 2011 33 3 pantic et al continuous emotion detection using eeg signal facial expression 2014 ieee international conference multimedia expo icme ieee new york z lyu schalk g et al deep feature learning using target prior application ecog signal decoding bci proceeding international joint conference artiﬁcial intelligence aaai press palo alto sternin owen et al deep feature learning eeg recording arxiv preprint 2015 yue classiﬁcation electrocardiogram nals deep belief network 2014 ieee international conference computational science engineering cse ieee new york gupta j mani r et al modeling raphy waveform deep belief net fast classiﬁcation anomaly measurement j neural eng 2011 8 3 j page mohsenin et al deep belief network used high resolution multichannel raphy data seizure detection 2014 aaai spring symposium series 2014 deep learning eeg diagnosis alzheimer disease computer 2014 workshop springer new york 2014 deep learning bioinformatics 867 downloaded guest 28 march 2024 angkvist karlsson l loutﬁa sleep stage classiﬁcation using unsupervised feature learning adv artif neural syst 2012 p madhavan lecun et al classiﬁcation tern eeg synchronization seizure prediction clin neurophysiol 2009 120 11 prokhorov homan r et al recurrent neural network based prediction epileptic seizure extracranial eeg neurocomputing 2000 30 1 pr jones rd peiris mt lapse detection high temporal resolution ieee trans biomed eng 2007 54 5 lee zhang ensemble learning active ample selection imbalanced biomedical data tion trans comput biol bioinformatics tcbb 2011 8 2 ba el emam k keefe cm biomedical data privacy problem perspective recent advance j med inform assoc 2013 20 1 h garcia ea learning imbalanced data ieee trans knowledge data eng 2009 21 9 j goadrich relationship roc curve proceeding international conference machine learning acm new york opez v andez ıa et al insight cation imbalanced data empirical result current trend using data intrinsic characteristic inform sci 2013 wu j zhou exploratory undersampling learning ieee trans syst man cybern part b cybern 2009 39 2 nv bowyer kw hall lo et al smote synthetic nority technique j artif intell 2002 japkowicz class imbalance versus small disjuncts acm sigkdd explor newslett 2004 6 1 kononenko learning neural network ecai 1998 citeseer sj yang survey transfer learning ieee trans knowl data eng 2010 22 10 j dong w socher r et al imagenet archical image database cvpr ieee conference computer vision pattern recognition 2009 ieee md fergus visualizing understanding lutional network computer springer 2014 bengio courville et al visualizing layer feature deep network university montreal 2009 1341 k vedaldi zisserman deep inside tional network visualising image classiﬁcation model saliency map arxiv preprint 2013 henaff mathieu et al loss surface multilayer network arxiv preprint 2014 yn pascanu r gulcehre c et al identifying tacking saddle point problem convex optimization advance neural information processing system 2014 practical recommendation training deep architecture neural network trick trade springer heidelberg 2012 j bardenet r bengio et al algorithm parameter optimization advance neural information processing system 2011 f hoos hh sequential based optimization general algorithm conﬁguration learning intelligent optimization springer berlin 2011 j larochelle h adam rp practical bayesian mization machine learning algorithm advance neural information processing system 2012 j bengio random search optimization j mach learn 2012 13 1 j khosla kim et al multimodal deep learning proceeding international conference machine learning steffey j et al medical image retrieval modal approach cancer inform 2014 13 suppl 3 j coates lahiri et al optimization thods deep learning proceeding international conference machine learning deep learning via optimization proceeding international conference machine learning r madhavan ng ay deep unsupervised learning using graphic processor proceeding annual international conference machine learning acm q cipar j cui h et al effective distributed ml via stale synchronous parallel parameter server advance neural information processing system schwenk h sene et al neural probabilistic language model innovation machine learning springer berlin 2006 andersen dg park jw et al scaling distributed chine learning parameter server usenix symposium operating system design implementation osdi 14 j corrado g monga r et al large scale distributed deep network advance neural information processing system 2012 h park j jang j et al deepspark deep ing supporting asynchronous update caffe ity arxiv preprint 2016 agarwal barham p et al tensorflow scale machine learning heterogeneous system software available tensorﬂow org 2015 thinking silicon mit technology review 2013 k ruwase kim et al accelerating deep convolutional neural network using specialized hardware microsoft whitepaper 2015 2 c poulet c han jy et al cnp sor convolutional network fpl international conference field programmable logic application 2009 ieee new york rd neuromorphic chip mit technology review 2014 l torabi cho k et al describing video exploiting temporal structure proceeding ieee international conference computer vision h seo ph han image question answering using volutional neural network dynamic parameter tion arxiv preprint 2015 wayne g danihelka neural turning machine arxiv preprint 2014 j chopra bordes memory network arxiv preprint 2014 868 min et al downloaded guest 28 march 2024 c zaremba w sutskever et al intriguing erties neural network arxiv preprint 2013 ij shlens j szegedy explaining ing adversarial example arxiv preprint 2014 j mirza et al generative versarial net advance neural information processing system 2014 choi yoon manifold regularized deep neural work using adversarial example arxiv preprint arxiv 2015 berglund honkala et al learning ladder network advance neural information processing system 2015 deep reinforcement learning foundation cial general intelligence theoretical foundation artiﬁcial general intelligence springer berlin 2012 jp efﬁcient reinforcement learning robot using informative simulated prior 2015 ieee international conference robotics automation icra ieee new york deep learning bioinformatics 869 downloaded guest 28 march 2024