deep learn bioinformat seonwoo min byunghan lee sungroh yoon correspond author sungroh yoon depart electr comput engin seoul nation univers seoul korea tel fax sryoon abstract era big data transform biomed big data valuabl knowledg ha one import challeng bioinformat deep learn ha advanc rapidli sinc earli demonstr art perform variou ﬁeld accordingli applic deep learn bioinformat gain insight data ha emphas academia industri review deep learn bioinformat present exampl current research provid use comprehens perspect categor research bioinformat main omic biomed imag biomed signal process deep learn architectur deep neural work convolut neural network recurr neural network emerg architectur present brief descript studi addit discuss theoret practic issu deep learn bioinformat suggest futur research direct believ thi review provid valuabl insight serv start point research appli deep learn approach bioinformat studi key word deep learn neural network machin learn bioinformat omic biomed imag biomed signal process introduct era big data transform larg quantiti data valuabl knowledg ha becom increasingli import variou domain bioinformat except signific amount biomed data includ omic imag signal data accumul result tential applic biolog healthcar research ha caught attent industri academia stanc ibm develop watson oncolog platform ing patient medic inform assist clinician treatment option addit googl deepmind achiev great success alphago game go centli launch deepmind health develop effect care technolog extract knowledg big data bioinformat chine learn ha wide use success olog machin learn algorithm use train data uncov underli pattern build model make predict base best fit model inde algorithm support vector machin random forest hidden markov el bayesian network gaussian network appli genom proteom system biolog numer domain proper perform convent machin learn algorithm reli heavili data represent call ture howev featur typic design human gineer extens domain expertis identifi featur appropri given task remain cult deep learn branch machin learn ha recent emerg base big data power parallel distribut comput sophist algorithm deep learn ha overcom previou limit academ interest ha increas rapidli sinc earli figur furthermor deep learn respons major advanc divers field seonwoo min candid depart electr comput engin seoul nation univers korea hi research area clude bioinformat machin learn biomed big data deep learn byunghan lee candid depart electr comput engin seoul nation univers korea hi research area includ bioinformat machin learn biomed big data data mine sungroh yoon associ professor depart electr comput engin seoul nation univers seoul korea receiv hi postdoctor train stanford univers stanford usa hi research interest includ machin learn deep learn informat bioinformat submit march receiv revis form june v c author publish oxford univers press right reserv permiss pleas email brief bioinformat doi advanc access public date juli paper download http guest march artifici intellig ai commun ha struggl mani year one import advanc thu far ha imag speech recognit though promis result dissemin natur languag process languag translat certainli bioinformat also benefit deep learn figur splice junction discov dna quenc finger joint recogn imag laps detect electroencephalographi eeg nal previou review address machin learn informat fundament deep learn addit although recent publish review leung et al mamoshina et al greenspan et al cuss deep learn applic bioinformat research former two limit applic genom medicin latter medic imag thi articl provid comprehens review deep learn bioinformat research exampl categor bioinformat domain omic biomed imag biomed signal process deep learn architectur deep neural network volut neural network recurr neural network gent architectur goal thi articl provid valuabl insight serv start point facilit tion deep learn bioinformat studi best knowledg one first group review deep learn applic bioinformat deep learn brief overview effort creat ai system long histori figur trate relationship schemat differ disciplin earli approach attempt explicitli program requir knowledg given task howev face difficulti deal complex problem caus design detail requir ai system complish satisfactori result hand demand job machin learn provid viabl solut capabl improv experi data although machin learn extract pattern data tation raw data process highli depend featur advanc featur represent learn particularli deep learn ha shown great promis represent learn discov effect featur well map data given task furthermor deep learn learn complex featur combin simpler featur learn data word artifici neural network multipl ear layer refer deep learn architectur ical represent data discov increas level abstract key element deep learn success deep learn built foundat nific algorithm detail gener understood two part construct train deep learn ture deep learn architectur basic artifici neural network multipl layer sever type propos accord input data characterist search object tabl categor deep learn architectur four group deep neural network dnn convolut neural network cnn recurr neural network rnn emerg architectur explain group detail tabl paper use dnn encompass deep learn architectur howev thi review use dnn refer specif multilay perceptron mlp stack sae deep belief network dbn use ceptron ae restrict boltzmann machin rbm build block neural work respect cnn architectur ceed particularli imag recognit consist convolut layer layer pool layer rnn design util sequenti inform input data cyclic connect among build block like perceptron long memori unit lstm gate rent unit gru addit mani emerg deep learn architectur suggest deep neural network dimension recurr neural network convolut cae goal train deep learn architectur tion weight paramet layer gradual figur approxim number publish deep learn articl year number articl base search result http two queri deep learn deep learn bio min et al download http guest march combin simpler featur complex featur suitabl hierarch represent learn data singl cycl optim process organ follow first given train dataset forward pass quential comput output layer propag function signal forward network final output layer object loss function measur error inferenc output given label minim train error backward pass use chain rule propag error signal comput gradient respect weight throughout neural network final weight paramet updat use optim algorithm base stochast gradient descent sgd wherea batch gradient descent perform paramet updat figur applic deep learn bioinformat research overview diagram input data research object b research exampl omic domain predict splice junction dna sequenc data deep neural network c research exampl biomed imag finger joint detect imag convolut neural network research exampl biomed signal process laps detect eeg signal recurr neural network figur relationship schemat artiﬁci intellig machin learn represent learn deep learn deep learn bioinformat download http guest march complet dataset sgd provid stochast approxim perform updat small set data exampl sever optim algorithm stem sgd exampl adagrad adam perform sgd adapt ifi learn rate base updat frequenc moment gradient paramet respect anoth core element train deep learn tectur regular refer strategi intend avoid overfit thu achiev good gener anc exampl weight decay tional approach add penalti term object loss function weight paramet converg smaller lute valu current wide use regular proach dropout dropout randomli remov hidden unit neural network dure train consid ensembl possibl subnetwork enhanc iti dropout new activ function maxout variant dropout rnn call rnndrop pose furthermor recent propos batch normal provid new regular method normal scalar featur activ within learn mean varianc paramet deep learn librari actual implement deep learn algorithm great deal attent algorithm detail requir fortun mani open sourc deep learn librari avail onlin tabl still clear librari ha strength accord benchmark test result cnn specif alexnet implement baharampour et al neon show great advantag process speed c þþ base caff torch offer great advantag term train model function extension respect theano provid librari fine optim mathemat express moreov ou wrapper kera lasagn block develop top theano vide intuit interfac googl recent releas c þþ base tensorflow python interfac thi librari current show limit perform undergo tinuou improv heterogen distribut comput support addit tensorflow also take tage kera provid addit interfac deep neural network basic structur dnn consist input layer multipl hidden layer output layer figur onc input data given dnn output valu comput sequenti along layer network layer input vector compris output valu unit layer multipli weight vector unit current layer produc weight sum function sigmoid hyperbol tangent rectifi linear unit relu appli weight sum comput output ue layer comput layer transform represent layer slightli abstract represent base type layer use dnn correspond learn method dnn classifi mlp sae dbn mlp ha similar structur usual neural network includ stack layer train pure supervis manner use onli label data sinc train method process optim paramet space mlp typic use larg number label data avail sae dbn use ae rbm build block architectur respect main differ mlp train execut two phase vise supervis first vise figur layer stack sequenti train manner ae rbm use label data afterward supervis output classifi layer stack whole neural network mize retrain label data sinc sae dbn exploit unlabel data help avoid overfit searcher abl obtain fairli regular result even label data insuffici common real world dnn renown suitabl analyz dimension data given bioinformat data typic complex dnn great promis bioinformat research believ dnn hierarch represent learn method discov previous known highli abstract pattern correl provid sight better understand natur data howev ha occur us capabl dnn yet fulli exploit although key characterist dnn hierarch featur learn sole data design featur often given input instead raw data form expect futur progress dnn bioinformat come investig proper way encod raw data learn suitabl featur tabl abbrevi alphabet order abbrevi full word ae ai artiﬁci intellig auc oper characterist curv curv brnn bidirect recurr neural network cae convolut cnn convolut neural network dbn deep belief network dnn deep neural network deep neural network ecg electrocardiographi ecog electrocorticographi eeg electroencephalographi emg electromyographi eog electrooculographi gru gate recurr unit lstm long memori recurr neural network mlp multilay perceptron mri magnet reson imag pca princip compon analysi pet positron emiss tomographi pssm posit speciﬁc score matrix rbm restrict boltzmann machin relu rectiﬁ linear unit rnn recurr neural network sae stack sgd stochast gradient descent min et al download http guest march convolut neural network cnn design process multipl data type especi imag directli inspir visual cortex brain visual cortex hierarchi two basic cell type simpl cell complex cell simpl cell react primit pattern visual stimuli complex cell synthes inform simpl cell identifi intric form sinc visual cortex power natur visual process system cnn appli imit three key idea local connect invari locat invari local transit basic structur cnn consist convolut layer layer pool layer figur use highli correl data group local weight sum call featur map obtain convolut layer comput convolut local patch weight tor call filter furthermor sinc ident pattern pear regardless locat data filter appli repeatedli across entir dataset also improv ing effici reduc number paramet learn layer increas properti featur map pool layer maximum averag sampl region featur map form thi subsampl enabl cnn handl somewhat differ semant similar featur thu aggreg local featur identifi complex featur current cnn one success deep ing architectur owe outstand capac analyz spatial inform thank develop field object recognit believ primari research ment bioinformat come biomed imag domain despit differ data characterist mal biomed imag cnn nonetheless offer straightforward applic compar domain inde cnn also great potenti omic biomed tabl categor deep learn appli research bioinformat omic biomed imag biomed signal process research topic refer research topic refer research topic refer deep neural network protein structur anomali classiﬁc brain decod gene express regul segment anomali classiﬁc protein classiﬁc recognit anomali classiﬁc brain decod convolut neural network gene express regul anomali classiﬁc brain decod segment anomali classiﬁc recognit recurr neural network protein structur brain decod gene express regul anomali classiﬁc protein classiﬁc emerg architectur protein structur segment brain decod tabl comparison deep learn librari core speed batch ms distribut strength caff c þþ x model support neon python x speed tensorflow c þþ heterogen distribut comput theano python x x eas use wrapper torch lua x function extension note speed batch base averag process time alexnet batch size singl gpu caff neon theano torch wa util cudnn tensorflow wa util cudnn figur basic structur dnn input unit x three hidden unit layer output unit layer weight sum function input comput hierarch resent obtain deep learn bioinformat download http guest march signal process three key idea cnn appli onli grid discov meaning recur pattern small varianc genom quenc motif also grid action within omic data matric biomed signal thu believ popular promis cnn bioinformat applic continu year ahead recurr neural network rnn design util sequenti inform basic structur cyclic connect figur sinc input data process sequenti recurr comput perform hidden unit cyclic connect exist therefor past inform implicitli store hidden unit call state vector output current input comput consid previou input use state tor sinc mani case past futur input affect output current input speech tion bidirect recurr neural network brnn also design use wide figur although rnn seem deep dnn cnn term number layer regard even deeper structur unrol time figur therefor long time research struggl vanish gradient problem train rnn learn enci among data difficult fortun substitut simpl perceptron hidden unit complex unit lstm gru function memori cell significantli help prevent problem recent rnn use success mani area includ ural languag process languag translat even though rnn explor less dnn cnn still provid veri power analysi method quential inform sinc omic data biomed signal typic sequenti often consid languag ture capabl rnn map put sequenc anoth sequenc predict promis bioinformat research regard ical imag rnn current first choic mani searcher nevertheless believ dissemin dynam ct mri would lead incorpor rnn cnn elev import long term furthermor expect success natur languag process lead rnn appli biomed text lysi employ attent mechan improv perform extract relev tion bioinformat data emerg architectur emerg architectur refer deep learn architectur side dnn cnn rnn thi review introduc three emerg architectur cae applic bioinformat design learn put target progress refin basic structur consist hidden layer figur key aspect structur progress refin sider local correl perform via input featur figur unsupervis process sae dbn first weight vector train input unit x hidden unit ﬁrst den layer rbm ae train anoth hidden layer stack obtain represent use train hidden unit anoth rbm ae process repeat desir number layer figur basic structur cnn consist convolut layer layer pool layer convolut layer cnn use multipl learn ter obtain multipl ﬁlter map detect ﬁlter pool layer combin featur min et al download http guest march composit layer spatial featur tempor ture spatial featur refer origin input whole use ident everi layer howev poral featur gradual alter progress upper layer except first layer comput hidden unit current layer onli adjac hidden unit coordin layer use local ation reflect progress design appli capabl rnn data treat group sequenti data instanc data treat group horizont vertic sequenc data similar brnn use context direct dimension data use context possibl tion data figur exampl dataset four context vari order data process reflect comput four hidden unit posit hidden layer hidden unit connect singl output layer final sult comput consider possibl context cae design util advantag ae cnn learn good hierarch tion data reflect spatial inform well ize unsupervis train figur train ae reconstruct error minim use encod decod extract featur vector input data creat data featur vector respect cnn convolut pool layer regard type coder therefor cnn encod decod consist deconvolut unpool layer integr form cae train manner ae deep learn rapidli grow research area plethora new deep learn architectur propos await wide applic bioinformat newli propos architectur differ advantag exist ture expect produc promis result ou research area exampl progress refin fit dynam fold process protein effect util protein structur predict capabl suitabl segment medic imag sinc segment requir interpret local global context unsupervis represent learn consider spatial inform cae provid great advantag discov recur pattern limit imbalanc bioinformat data omic omic research genet inform genom tome proteom data use approach problem matic common input data omic raw biolog sequenc dna rna amino acid sequenc becom rel afford easi obtain gener sequenc technolog addit extract featur sequenc posit specif score matric pssm physicochem properti atchley factor structur properti often use put deep learn algorithm allevi difficulti plex biolog data improv result addit protein contact map present distanc amino acid pair structur microarray gene express data also use accord characterist interest goriz topic interest omic four group tabl one research problem protein structur tion aim predict secondari structur contact map protein gene express regul includ splice junction rna bind protein protein classif figur basic structur rnn input unit x hidden unit h output unit cyclic connect exist comput den unit receiv input hidden unit previou time step input unit current time step recurr comput express explicitli rnn unrol time index symbol repres time step thi way ht receiv input xt propag comput result yt ht þ figur basic structur brnn unrol time two hidden unit h h time step h receiv input xt h reﬂect past inform h receiv input xt h reﬂect futur tion inform hidden unit propag yt figur basic structur notat hk j repres hidden unit j coordin kth hidden layer conduct progress ment neighborhood unit hk j input unit x use tion j deep learn bioinformat download http guest march includ super famili subcellular local also activ investig furthermor anomali classif approach use omic data detect cancer deep neural network dnn wide appli protein structur predict research sinc complet predict space complex challeng sever studi use simpler approach predict secondari ture torsion angl protein instanc heffernan et al appli sae protein amino acid sequenc solv diction problem secondari structur torsion angl cessibl surfac area anoth studi spencer et al appli dbn amino acid sequenc along pssm atchley factor predict protein secondari structur dnn also shown great capabl area gene express regul exampl lee et al lize dbn splice junction predict major research enu understand gene express propos new dbn train method call boost contrast genc imbalanc data new regular term sparsiti dna sequenc work show onli cantli improv perform also abil detect tle splice signal moreov chen et al appli mlp microarray express data infer express target gene onli landmark gene term protein classif asgari et al adopt model wide known method natur languag process consid variant mlp show could effect learn distribut represent biolog sequenc gener use mani omic applic includ protein famili tion anomali classif fakoor et al use figur basic structur data four group hidden unit reﬂect differ context ampl j hidden unit context receiv input j hidden unit context j unit input layer inform reﬂect hidden unit four context propag comput j unit output layer figur basic structur cae consist convolut layer pool layer work encod deconvolut layer unpool layer ing decod basic idea similar ae learn hierarch represent reconstruct input data cae addit util spatial inform integr convolut min et al download http guest march princip compon analysi pca reduc sional microarray gene express data appli sae classifi variou cancer includ acut myeloid leukemia breast cancer ovarian cancer convolut neural network rel studi use cnn solv problem involv biolog sequenc specif gene express regul problem nevertheless duce strong advantag cnn show great promis futur research first initi convolut layer power captur local sequenc pattern sider motif detector pssm sole learn data instead depth cnn enabl learn complex pattern captur longer motif integr cumul effect observ motif eventu learn sophist regulatori code moreov cnn suit exploit benefit multitask joint learn train cnn simultan predict close relat factor featur predict strength effici learn share across differ task exampl earli approach dena et al cess data matrix row transcript factor activ profil gene exploit cnn similar use imag process recent studi focus directli use cnn biolog sequenc data alipanahi et al kelley et al propos approach transcript factor bind site predict dna access multitask predict ive group present downstream applic genet variant identif furthermor zeng et al perform systemat explor cnn architectur transcript site predict show number convolut filter import number layer task zhou et al develop algorithm framework deepsea perform multitask joint learn chromatin factor transcript factor bind dnase sensit profil priorit express quantit trait loci genet variant base predict tabl deep learn appli bioinformat research avenu input data input data research avenu omic sequenc data featur genom sequenc posit speciﬁc score matrix pssm physicochem properti steric paramet volum atchley factor fac structur properti contact map distanc amino acid pair structur microarray gene express protein structur predict structur properti contact map structur model qualiti assess gene express regul splice junction genet variant affect splice sequenc speciﬁc protein classiﬁc super famili subcellular local anomali classiﬁc cancer biomed imag magnet reson imag mri radiograph imag positron emiss tomographi pet histopatholog imag volumetr electron microscopi imag retin imag situ hybrid ish imag anomali classiﬁc gene express pattern cancer alzheim diseas schizophrenia segment cell structur neuron structur vessel map brain tumor recognit cell nuclei finger joint anatom structur brain decod behavior biomed signal process ecog ecg emg eog eeg raw wavelet frequenc differenti entropi extract featur eeg normal decay peak variat brain decod behavior emot anomali classiﬁc alzheim diseas seizur sleep stage deep learn bioinformat download http guest march recurr neural network rnn expect appropri deep learn ture becaus biolog sequenc variabl length sequenti inform ha great import sever studi appli rnn protein structur predict gene express regul protein tion earli studi baldi et al use brnn perceptron hidden unit protein secondari structur tion thereaft improv perform lstm hidden unit becam wide recogn sønderbi et al appli brnn lstm hidden unit lution layer learn represent amino acid sequenc classifi subcellular locat protein furthermor park et al lee et al exploit rnn lstm hidden unit microrna identif target predict obtain significantli improv accuraci rel approach demonstr high capac rnn analyz biolog sequenc emerg architectur emerg architectur use protein structur diction research specif contact map predict di lena et al appli use spatial featur ing protein secondari structur orient probabl align probabl addit baldi et al appli rnn amino acid sequenc correl profil protein secondari structur biomed imag biomed imag anoth activ research main wide applic deep learn gener relat task biomed imag use clinic treatment reson imag mri graphic imag positron emiss tomographi pet histopatholog imag use input data deep learn algorithm categor research avenu biomed imag four group tabl one research problem anomali classif diagnos diseas cancer schizophrenia eral task segment partit specif structur cellular structur brain tumor recognit detect cell nuclei finger joint studi frequent biomed imag studi popular high content screen involv quantifi microscop imag cell biolog cover former group addit cranial mri use brain decod interpret human behavior emot deep neural network term biomed imag dnn appli eral research area includ anomali classif segment recognit brain decod pli et al classifi schizophrenia patient brain mri use dbn xu et al use sae detect cell nuclei histopatholog imag interestingli similar handwritten digit imag recognit van gerven et al classifi handwritten digit imag dbn analyz imag themselv indirectli analyz indirectli function mri particip look digit imag convolut neural network largest number studi ha conduct ical imag sinc avenu similar gener relat task anomali classif roth et al appli cnn three differ ct imag dataset sifi sclerot metastas lymph node colon polyp addit ciresan et al use cnn detect mitosi breast cancer histopatholog imag crucial approach cancer diagnosi assess pet imag esophag cancer use ypsilanti et al predict respons neoadjuv chemotherapi applic cnn found segment recognit exampl ning et al studi segment pattern cell wall cytoplasm nuclear membran nucleu outsid media use microscop imag havaei et al propos cascad cnn architectur exploit local global contextu featur perform brain tumor segment mri recognit cho et al search anatom structur recognit among ct imag lee et al propos finger joint detect system fingernet crucial step medic ation bone age growth disord rheumatoid arthriti recurr neural network tradit imag consid data involv intern correl spatial inform rather sequenti mation treat biomed imag data studi biomed imag chosen approach involv dnn cnn instead rnn emerg architectur attempt appli uniqu capabl rnn imag data use augment rnn structur continu rnn appli beyond imag imag exampl stollenga et al appli electron microscopi imag mri segment neuron structur biomed signal process biomed signal process domain searcher use record electr activ human bodi solv problem bioinformat variou data eeg electrocorticographi ecog electrocardiographi ecg electromyographi emg phi eog use studi focus eeg activ far becaus record signal usual noisi includ mani artifact raw signal often pose wavelet frequenc compon befor use input deep learn algorithm addit design featur like normal decay peak variat use studi improv result categor research avenu biomed signal process two group tabl brain decod use eeg signal anomali classif diagnos diseas deep neural network sinc biomed signal usual contain nois artifact decompos featur frequent use raw nal brain decod et al appli dbn min et al download http guest march frequenc compon eeg signal classifi motor imageri skill moreov jia et al jirayucharoensak et al use dbn sae respect emot classif anomali classif huanhuan et al publish one studi appli dbn ecg signal classifi beat either normal abnorm beat studi use raw eeg signal wulsin et al analyz individu waveform abnorm use dbn raw eeg signal tract featur input wherea zhao et al use onli raw eeg signal input dbn diagnos alzheim diseas convolut neural network raw eeg signal analyz brain decod anomali classif via cnn perform convolut instanc stober et al classifi rhythm type genr music particip listen cecotti et al classifi charact particip view anoth approach appli cnn medic signal process wa report mirowski et al extract featur synchroni wavelet coher code pixel color formul pattern ordinari cnn like one use biomed imag use predict seizur recurr neural network sinc biomed signal repres natur sequenti data rnn appropri deep learn architectur analyz data expect produc promis result present studi brain decod anomali ficat petrosian et al appli perceptron rnn raw eeg signal correspond wavelet decompos ture predict seizur addit davidson et al use lstm rnn eeg spectra featur detect laps emerg architectur cae ha appli brain decod studi wang et al perform finger flex extend tion use raw ecog signal addit stober et al sifi music rhythm particip listen raw eeg signal discuss limit imbalanc data consid necess optim tremend number weight paramet neural network deep learn algorithm assum suffici balanc data unfortun howev thi usual true problem bioinformat complex expens data acquisit ess limit size bioinformat dataset addit process often show significantli unequ class distribut instanc one class significantli higher stanc class exampl clinic case inevit less data ment group normal control group former also rare disclos public due privaci restrict ethic requir creat imbal abl data assess metric use clearli observ limit imbalanc data might compromis formanc deep learn accuraci often give mislead result harmon mean sion recal provid insight perform score measur perform differ class distribut oper characterist curv auc curv commonli use two measur strongli correl curv domin one measur onli domin nevertheless contrast auc might present optimist view perform sinc fals posit rate receiv oper characterist curv fail captur larg chang fals posit class neg skew solut limit imbalanc data divid three major group data preprocess learn algorithm modif data preprocess ical provid better dataset sampl basic ture extract sampl method balanc distribut imbalanc data sever approach propos includ inform undersampl synthet minor oversampl techniqu sampl exampl li et al roth et al perform ment analys ct imag spatial deform random shift rotat although basic featur tion method deviat concept deep learn occasion use lessen difficulti learn limit imbalanc data research bioinformat use human design featur input data pssm omic sequenc wavelet energi eeg signal understood context learn method defin differ cost misclassifi data exampl individu class solv limit imbalanc data problem cost sensit appli object loss function neural network ther explicitli implicitli exampl explicitli replac object loss function reflect class imbal implicitli modifi learn rate accord data instanc class dure train algorithm modif method accommod learn rithm increas suitabl limit imbalanc data simpl effect approach adopt unsupervis great help learn tion class produc regular result addit transfer learn consist ficient data similar differ domain real data ha great advantag instanc lee et al propos microrna target predict method exploit unsupervis rnn base ae achiev increas compar exist altern bar et al perform transfer learn use ural imag imagenet databas data chest imag identifi chest gie classifi healthi abnorm imag addit sophist train method also cute lee et al suggest dbn boost categor rbm havaei et al suggest cnn train combin idea undersampl chang main critic deep learn use even though produc outstand result deep learn bioinformat download http guest march know veri littl result deriv intern bioinformat particularli biomed domain enough simpli produc good outcom sinc mani studi connect patient health crucial chang provid logic reason clinician medic treatment transform deep learn still earli stage one wide use approach interpret visual train deep learn model term imag input deconvolut network ha propos reconstruct visual archic represent specif input cnn addit visual gener class repres imag rather depend particular input gradient ascent optim input space cf ha provid anoth effect methodolog regard genom sequenc input sever approach propos infer pssm train model visual correspond motif heat map sequenc logo exampl lee et al extract motif choos class discrimin weight vector among first layer dbn deepbind demo extract motif train cnn count nucleotid frequenc posit input subsequ high activ valu featur map respect specif transcript factor bind site predict alipanahi et al develop visual method tion map illustr effect genet variant ing score predict cnn mutat map consist heat map show much mutat alter bind score input sequenc logo height base scale maximum decreas bind score among possibl mutat moreov kelley et al ther complement mutat map line plot show maximum increas well maximum decreas predict score addit interpret izat attent mechan design focu citli salient point mathemat rational behind deep learn studi select appropri deep learn architectur hyperparamet choos appropri deep learn architectur crucial proper applic deep learn obtain robust liabl result awar capabl deep ing architectur select accord capabl addit input data characterist research object essenti howev date advantag ture onli roughli understood exampl dnn abl analysi intern correl data cnn suitabl analysi spatial inform rnn suitabl analysi sequenti inform inde detail methodolog select ate best fit deep learn architectur remain challeng studi futur even onc deep learn architectur select mani number layer number hidden unit weight initi valu learn iter even learn research set influenc result remark mani year hyperparamet tune wa rare systemat left human machin learn expert nevertheless autom machin learn research aim automat mize hyperparamet grow constantli rithm propos includ sequenti model base global optim bayesian optim gaussian process prior random search approach multimod deep learn multimod deep learn exploit inform multipl input sourc promis avenu ture deep learn research particular bioinformat expect benefit greatli field variou type data assimil natur exampl onli omic data imag signal drug respons electron medic record avail input data ct mri pet form also avail singl imag bioinformat studi alreadi begun use multimod deep learn exampl suk et al studi alzheim diseas classif use cerebrospin fluid brain imag form mri pet scan soleymani et al conduct emot detect studi eeg signal face imag data acceler deep learn deep learn model paramet train data come avail better learn perform achiev howev time thi inevit lead drastic creas train time emphas necess ate deep learn approach acceler deep learn divid three group advanc optim algorithm parallel distribut comput special hardwar sinc main reason long train time paramet tion plain sgd take long sever studi focus advanc optim algorithm thi end wide employ algorithm includ adagrad adam batch normal optim parallel distribut comput significantli erat time complet enabl mani deep learn studi approach exploit method use graphic process unit method use cluster machin tribut environ deep learn framework ing recent releas deepspark tensorflow provid parallel distribut comput abil although develop special hardwar deep learn still infanc provid major acceler becom far import long term current field mabl gate processor develop neuromorph chip model brain greatli pate promis technolog futur trend deep learn incorpor tradit deep learn architectur promis futur trend instanc joint network cnn rnn integr attent model appli imag caption video summar imag question answer studi toward augment structur rnn conduct well neural ture machin memori network adopt dressabl extern memori rnn shown great result task requir intric infer algorithm learn complex question answer recent adversari min et al download http guest march exampl degrad perform small impercept perturb receiv increas attent machin learn commun sinc sarial train neural network result regular provid higher perform expect addit studi thi area includ involv adversari gener work manifold regular network term learn methodolog learn reinforc learn also receiv attent supervis learn exploit unlabel label data algorithm propos exampl ladder network add skip connect mlp cnn taneous minim sum supervis unsupervis cost function denois represent everi level model reinforc learn leverag reward outcom nal result action rather correctli label data sinc reinforc learn close resembl human actual learn thi approach ha great promis ficial gener intellig current applic mainli focus game play robot conclus enter major era big data deep learn take center stage intern academ busi interest bioinformat great advanc made convent machin learn deep learn anticip produc promis result thi review provid tensiv review bioinformat research appli deep ing term input data research object characterist establish deep learn architectur discuss limit approach promis direct futur research although deep learn hold promis silver bullet provid great result ad hoc bioinformat cation remain mani potenti challeng includ limit imbalanc data interpret deep learn sult select appropri architectur paramet furthermor fulli exploit capabl deep learn multimod acceler deep learn requir studi thu confid prudent arat regard issu discuss herein key success futur deep learn approach bioinformat believ thi review provid valuabl insight serv start point applic deep learn vanc bioinformat futur research key point great deal biomed data ha late variou machin algorithm wide appli bioinformat extract knowledg big data deep learn ha evolv acquisit big data power parallel distribut comput sophist train algorithm ha facilit major advanc numer domain imag recognit speech recognit natur languag process review deep learn bioinformat sent research categor bioinformat domain omic biomed imag biomed signal cess deep learn architectur deep neural network convolut neural network current neural network emerg architectur furthermor discuss theoret practic issu plagu applic deep learn bioinformat includ imbalanc data pretat hyperparamet optim multimod deep learn train acceler comprehens review exist work liev thi paper provid valuabl insight serv launch point research appli deep learn approach bioinformat studi acknowledg author would like thank russ altman tsachi weissman stanford univers honglak lee univers michigan narri kim daehyun baek seoul nation univers kim univers california san diego help discuss appli artiﬁci intellig machin learn bioinformat fund thi research wa support nation research foundat nrf korea grant fund korean govern ministri scienc ict futur plan korea health technolog r project korea health industri develop institut khidi fund ministri health welfar snu ece brain korea project refer manyika j chui brown b et al big data next frontier innov competit product technic report mckinsey global institut ferrucci brown e j et al build watson overview deepqa project ai magazin ibm watson oncolog ibm http silver huang maddison cj et al master game go deep neural network tree search natur deepmind health googl deepmind http naga p calvo b santana r et al machin learn bioinformat brief bioinformat goodfellow bengio courvil deep learn book prepar mit press lecun bengio hinton deep learn natur farabet c coupri c najman l et al learn hierarch featur scene label ieee tran pattern anal mach intel szegedi c liu w jia et al go deeper tion arxiv preprint tompson jj jain lecun et al joint train tional network graphic model human pose deep learn bioinformat download http guest march estim advanc neural inform process system liu n han j zhang et al predict eye ﬁxation use convolut neural network proceed ieee confer comput vision pattern recognit hinton g deng l yu et al deep neural network acoust model speech recognit share view four research group ieee signal process mag sainath tn moham kingsburi b et al deep tional neural network lvcsr ieee intern confer acoust speech signal process icassp ieee new york chorowski jk bahdanau serdyuk et al model speech recognit adv neural inf process syst kiro r zhu salakhutdinov rr et al vector advanc neural inform process system li j luong jurafski hierarch neural coder paragraph document arxiv preprint luong pham h man cd effect approach neural machin translat arxiv preprint cho k van enboer b gulcehr c et al learn phrase represent use rnn statist machin translat arxiv preprint libbrecht mw nobl ws machin learn applic genet genom nat rev genet schmidhub deep learn neural network view neural network leung mk delong alipanahi b et al machin learn genom medicin review comput problem data set proc ieee mamoshina p vieira putin e et al applic deep learn biomedicin mol pharm greenspan h van ginneken b summer rm guest editori deep learn medic imag overview futur promis excit new techniqu ieee tran med imag lecun ranzato deep learn tutori tutori intern confer machin learn icml cites svozil kvasnicka v pospich introduct layer neural network chemometr intel lab syst vincent p larochel h bengio et al extract pose robust featur denois autoencod proceed intern confer machin learn acm new york vincent p larochel h lajoi et al stack denois autoencod learn use represent deep work local denois criterion j mach learn hinton g osindero teh fast learn algorithm deep belief net neural comput hinton g salakhutdinov rr reduc dimension data neural network scienc lecun boser b denker js et al handwritten digit tion network advanc neural inform process system cites lawrenc gile cl tsoi ac et al face recognit volut approach ieee tran neural netw krizhevski sutskev hinton imagenet classiﬁc deep convolut neural network advanc neural inform process system william rj zipser learn algorithm continu run fulli recurr neural network neural comput bengio simard p frasconi learn enci gradient descent difﬁcult ieee tran neural netw hochreit schmidhub long memori neural comput ger fa schmidhub j cummin learn forget tinual predict lstm neural comput lena pd nagata k baldi pf deep ture learn protein structur predict advanc neural inform process system grave schmidhub ofﬂin handwrit recognit multidimension recurr neural network advanc neural inform process system hadsel r sermanet p ben j et al learn vision autonom drive j field robot masci j meier u cire et al stack convolut hierarch featur extract artiﬁci neural network machin learn icann springer berlin heidelberg minski papert perceptron introduct tional geometri mit press cambridg expand edit fukushima cognitron multilay neural network biol cybern hinton g sejnowski tj learn releam boltzmann machin parallel distrib process explor microstruct cogn hinton practic guid train restrict boltzmann machin momentum theori backpropag neural work intern joint confer neural network ijcnn ieee washington dc bottou stochast gradient learn neural network proc duchi j hazan e singer adapt subgradi method onlin learn stochast optim j mach learn kingma ba adam method stochast optim arxiv preprint moodi j hanson krogh et al simpl weight decay improv gener adv neural inf process syst srivastava n hinton g krizhevski et al dropout simpl way prevent neural network overﬁt j mach learn baldi p sadowski pj understand dropout advanc neural inform process system goodfellow ij mirza et al maxout work arxiv preprint moon choi h lee h et al rnndrop novel dropout rnn asr automat speech recognit understand asru scottsdal az min et al download http guest march ioff szegedi batch normal acceler deep network train reduc intern covari shift arxiv preprint develop team sourc distribut deep learn jvm apach softwar foundat licens http bahrampour ramakrishnan n schott l et al compar studi deep learn softwar framework arxiv preprint nervana system neon http jia caff open sourc convolut architectur fast featur embed acm intern confer multimedia acm washington dc collobert r kavukcuoglu k farabet environ machin learn biglearn nip workshop bergstra j breuleux bastien f et al theano cpu gpu math express compil proceed python scientiﬁc comput confer scipi austin tx bastien f lamblin p pascanu r et al theano new featur speed improv arxiv preprint chollet kera deep learn librari code http document http dieleman heilman kelli j et al lasagn first releas van enboer b bahdanau dumoulin v et al block fuel framework deep learn arxiv preprint abadi agarw barham p et al tensorflow machin learn heterogen distribut system arxiv preprint nair v hinton rectiﬁ linear unit improv strict boltzmann machin proceed intern confer machin learn erhan bengio courvil et al whi doe unsupervis help deep learn j mach learn hubel dh wiesel tn recept ﬁeld function tectur monkey striat cortex j physiol schuster paliw kk bidirect recurr neural work ieee tran signal process cenic nabavi dg craen ra et al dynam ct ment cerebr blood ﬂow valid studi j neuroradiol tsao j boesig p pruessmann kp blast sens dynam mri high frame rate exploit ral correl magn reson med cohen hersh wr survey current work ical text mine brief bioinformat bahdanau cho k bengio neural machin translat jointli learn align translat arxiv preprint xu k ba j kiro r et al show attend tell neural imag caption gener visual attent arxiv preprint cho k courvil bengio describ multimedia content use network ieee tran multim mnih v heess n grave recurr model visual tention advanc neural inform process system jone dt protein secondari structur predict base score matric j mol biol ponomarenko jv ponomarenko mp frolov et al conform physicochem dna featur speciﬁc transcript factor bind site bioinformat cai lin sl support vector machin predict protein amino acid sequenc biochim biophi acta bba protein proteom atchley wr zhao j fernand ad et al solv protein sequenc metric problem proc natl acad sci usa branden ci introduct protein structur garland scienc new york richardson js anatomi taxonomi protein ture adv protein chem lyon j dehzangi heffernan r et al predict backbon ca angl dihedr protein sequenc stack spars deep neural network j comput chem heffernan r paliw k lyon j et al improv predict secondari structur local backbon angl solvent cessibl surfac area protein iter deep learn sci rep spencer eickholt j cheng deep learn network proach ab initio protein secondari structur predict tran comput biol bioinformat nguyen sp shang xu novel deep learn method protein model qualiti assess intern joint confer neural network ijcnn ieee new york baldi p brunak frasconi p et al exploit past futur protein secondari structur predict bioinformat baldi p pollastri g andersen ca et al match protein partner feedforward recurr neural network proceed confer intellig system molecular biolog la jolla ca sønderbi sk winther protein secondari structur diction long short term memori network arxiv preprint lena pd nagata k baldi deep architectur protein contact map predict bioinformat baldi p pollastri principl design cursiv neural network architectur protein structur predict problem j mach learn leung mk xiong hy lee lj et al deep learn splice code bioinformat lee yoon boost categor restrict boltzmann chine comput predict splice junction intern confer machin learn lill franc zhang zhou j hu h et al deep learn framework model structur featur protein target nucleic acid chen li narayan r et al gene express infer deep learn bioinformat deep learn bioinformat download http guest march li shi w wasserman ww predict region use supervis deep learn od biorxiv liu f ren c li h et al de novo identiﬁc time domain human genom deep learn bioinformat dena taylor deep model gene express tion erythropoiesi model intern confer machin learn workshop represent learn atlanta georgia usa b delong weirauch mt et al predict quenc speciﬁc protein deep learn nat biotechnol j singh r lin z et al deep motif visual genom sequenc classiﬁc arxiv preprint arxiv h edward md liu g et al convolut neural work architectur predict bind bioinformat dr snoek j rinn basset learn regulatori code access genom deep convolut ral network biorxiv j troyanskaya og predict effect noncod variant deep sequenc model nat method min choi et al deepmirgen deep neural work base precursor microrna predict arxiv preprint b lee na b et al splice junction predict use deep recurr neural network arxiv preprint b baek j park et al deeptarget learn framework microrna target predict use deep rent neural network arxiv preprint e mofrad continu distribut represent biolog sequenc deep proteom genom plo one heusel obermay fast tein homolog detect without align bioinformat sk sønderbi ck nielsen h et al convolut lstm network subcellular local protein arxiv preprint r ladhak f nazi et al use deep learn hanc cancer diagnosi classiﬁc proceed intern confer machin learn tw graveley br expans eukaryot ome altern splice natur princip compon analysi wiley onlin librari kelli deep learn regulatori genom nat biotechnol k splinter biomed signal imag process crc press new york rr warach magnet reson imag n engl j med lee kay ar et al brain magnet reson imag contrast depend blood oxygen proc natl acad sci comput tomographi principl design artifact recent advanc spie bellingham wa thomlinson w johnston r et al diffract enhanc imag phi med biol dl townsend dw valk pe et al positron emiss tomographi springer london mn boucheron le et al histopatholog imag analysi review biom eng ieee rev sm hjelm dr salakhutdinov r et al deep learn neuroimag valid studi front neurosci hsu hidayati sc et al ﬁcation lung nodul comput tomographi imag via deep learn techniqu onco target ther shen deep featur represent classiﬁc medic imag comput intervent miccai springer new york hr lu l liu j et al improv tion use convolut neural network random view aggreg arxiv preprint hr yao j lu l et al detect sclerot spine stase via random aggreg deep convolut neural network classiﬁc recent advanc comput method clinic applic spine imag springer heidelberg q cai w wang x et al medic imag classiﬁc convolut neural network intern confer control autom robot vision icarcv ieee singapor dc giusti gambardella lm et al mitosi tion breast cancer histolog imag deep neural work medic imag comput intervent miccai springer heidelberg siddiqu sohn et al predict spons neoadjuv chemotherapi pet imag use convolut neural network plo one li r mukkamala r et al deep convolut neural network annot gene express pattern mous brain bmc bioinformat aa oval jea madabhushi et al deep ing architectur imag represent visual abil autom carcinoma cancer detect medic imag comput intervent miccai springer heidelberg diamant wolf l et al deep learn medic train use chest patholog identiﬁc spie medic imag intern societi optic photon q feng b xie l et al learn approach vessel segment retin imag ieee tran med imag f delhomm lecun et al toward automat notyp develop embryo video ieee tran imag process sc murray jf jain v et al convolut network learn gener afﬁniti graph imag tion neural comput briggman kl turaga sc et al connectom reconstruct inner plexiform layer mous retina natur giusti gambardella lm et al deep neural work segment neuron membran electron copi imag advanc neural inform process system min et al download http guest march petersen k igel c et al deep featur learn knee cartilag segment use triplanar convolut neural network medic imag comput assist intervent miccai springer heidelberg davi et al brain tumor mentat deep neural network arxiv preprint hr lu l farag et al deeporgan deep convolut network autom pancrea tion medic imag comput intervent miccai springer heidelberg mf byeon w liwicki et al parallel dimension lstm applic fast biomed metric imag segment arxiv preprint j xiang l liu q et al stack spars autoencod ssae nuclei detect breast cancer histopatholog imag ieee tran med imag cl mahjoubfar tai et al deep learn free cell classiﬁc sci rep j lee k shin e et al medic imag deep learn hospit pac dataset arxiv preprint choi choi et al fingernet deep base robust ﬁnger joint detect radiograph biomed circuit system confer bioca ieee ieee new york hr lee ct shin et al tion medic imag use deep convolut net arxiv preprint hr lu l seff et al new represent lymph node detect use random set deep tional neural network observ medic imag comput intervent miccai springer heidelberg oz frey bj comput vision high content ing crit rev biochem mol biol mav de lang fp hesk neural decod hierarch gener model neural comput shikauchi naka k et al deep learn fmri big data novel approach ing arxiv preprint j jiang countryman p et al autom algorithm identiﬁc joint space phalanx margin cation digit hand radiograph med phi e da silva fl electroencephalographi basic principl clinic applic relat field lippincott william wilkin new york aki g anastassi ca koch origin lar ﬁeld current eeg ecog lfp spike nat rev neurosci hjl wagner gs practic electrocardiographi william wilkin baltimor luca cj use surfac electromyographi mechan j appl biomech lr sheena measur niqu psychol r boquet l mazo et al system assist iti use eye movement base electrooculographi ieee tran neural syst rehabil eng zv ramsey nf wronkeiwicz et al time naiv learn neural correl ecog physiolog int j mach learn comput x kuang guo x et al deep learn method siﬁcat eeg data base motor imageri intellig comput bioinformat springer heidelberg k li x zhang et al affect state recognit eeg deep belief network ieee intern confer bioinformat biomedicin bibm ieee new york x li k li x et al novel deep learn framework affect state recognit eeg signal ieee intern confer bioinformat bioengin bibe ieee new york guo lu reveal critic channel frequenc band emot recognit eeg deep belief network intern confer neural engin ner ieee new york israsena emot recognit use deep learn network cipal compon base covari shift adapt sci world j cameron dj grahn ja classifi eeg record rhythm percept intern societi music inform retriev confer ismir cameron dj grahn ja use lution neural network recogn rhythm advanc neural inform process system h graeser convolut neural network embed fourier transform eeg classiﬁc intern confer pattern recognit icpr ieee new york h aser convolut neural network detect applic interfac ieee tran pattern anal mach intel pantic et al continu emot detect use eeg signal facial express ieee intern confer multimedia expo icm ieee new york z lyu schalk g et al deep featur learn use target prior applic ecog signal decod bci proceed intern joint confer artiﬁci intellig aaai press palo alto sternin owen et al deep featur learn eeg record arxiv preprint yue classiﬁc electrocardiogram nal deep belief network ieee intern confer comput scienc engin cse ieee new york gupta j mani r et al model raphi waveform deep belief net fast classiﬁc anomali measur j neural eng j page mohsenin et al deep belief network use high resolut multichannel raphi data seizur detect aaai spring symposium seri deep learn eeg diagnosi alzheim diseas comput workshop springer new york deep learn bioinformat download http guest march angkvist karlsson l loutﬁa sleep stage classiﬁc use unsupervis featur learn adv artif neural syst p madhavan lecun et al classiﬁc tern eeg synchron seizur predict clin neurophysiol prokhorov homan r et al recurr neural network base predict epilept seizur extracrani eeg neurocomput pr jone rd peiri mt laps detect high tempor resolut ieee tran biom eng lee ms zhang ensembl learn activ ampl select imbalanc biomed data tion tran comput biol bioinformat tcbb ba el emam k keef cm biomed data privaci problem perspect recent advanc j med inform assoc h garcia ea learn imbalanc data ieee tran knowledg data eng j goadrich relationship roc curv proceed intern confer machin learn acm new york opez v andez ıa et al insight cation imbalanc data empir result current trend use data intrins characterist inform sci wu j zhou exploratori undersampl learn ieee tran syst man cybern part b cybern nv bowyer kw hall lo et al smote synthet noriti techniqu j artif intel japkowicz class imbal versu small disjunct acm sigkdd explor newslett kononenko learn neural network ecai cites sj yang survey transfer learn ieee tran knowl data eng j dong w socher r et al imagenet archic imag databas cvpr ieee confer comput vision pattern recognit ieee md fergu visual understand lution network comput springer bengio courvil et al visual layer featur deep network univers montreal k vedaldi zisserman deep insid tional network visualis imag classiﬁc model salienc map arxiv preprint henaff mathieu et al loss surfac multilay network arxiv preprint yn pascanu r gulcehr c et al identifi tack saddl point problem convex optim advanc neural inform process system practic recommend train deep architectur neural network trick trade springer heidelberg j bardenet r bengio et al algorithm paramet optim advanc neural inform process system f hoo hh sequenti base optim gener algorithm conﬁgur learn intellig optim springer berlin j larochel h adam rp practic bayesian mizat machin learn algorithm advanc neural inform process system j bengio random search optim j mach learn j khosla kim et al multimod deep learn proceed intern confer machin learn steffey j et al medic imag retriev modal approach cancer inform suppl j coat lahiri et al optim thod deep learn proceed intern confer machin learn deep learn via optim proceed intern confer machin learn r madhavan ng ay deep unsupervis learn use graphic processor proceed annual intern confer machin learn acm q cipar j cui h et al effect distribut ml via stale synchron parallel paramet server advanc neural inform process system schwenk h sene et al neural probabilist languag model innov machin learn springer berlin andersen dg park jw et al scale distribut chine learn paramet server usenix symposium oper system design implement osdi j corrado g monga r et al larg scale distribut deep network advanc neural inform process system h park j jang j et al deepspark deep ing support asynchron updat caff iti arxiv preprint agarw barham p et al tensorflow scale machin learn heterogen system softwar avail tensorﬂow org think silicon mit technolog review k ruwas kim et al acceler deep convolut neural network use special hardwar microsoft whitepap c poulet c han jy et al cnp sor convolut network fpl intern confer field programm logic applic ieee new york rd neuromorph chip mit technolog review l torabi cho k et al describ video exploit tempor structur proceed ieee intern confer comput vision h seo ph han imag question answer use volut neural network dynam paramet tion arxiv preprint wayn g danihelka neural turn machin arxiv preprint j chopra bord memori network arxiv preprint min et al download http guest march c zaremba w sutskev et al intrigu erti neural network arxiv preprint ij shlen j szegedi explain ing adversari exampl arxiv preprint j mirza et al gener versari net advanc neural inform process system choi yoon manifold regular deep neural work use adversari exampl arxiv preprint arxiv berglund honkala et al learn ladder network advanc neural inform process system deep reinforc learn foundat cial gener intellig theoret foundat artiﬁci gener intellig springer berlin jp efﬁcient reinforc learn robot use inform simul prior ieee intern confer robot autom icra ieee new york deep learn bioinformat download http guest march