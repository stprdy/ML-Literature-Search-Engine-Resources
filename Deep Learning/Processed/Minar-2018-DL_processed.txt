jul recent advanc deep learn overview matiur rahman minar jibon naher depart comput scienc engin chittagong univers engin technolog bangladesh editor abstract deep learn one newest trend machin learn artiﬁci intellig research also one popular scientiﬁc research trend deep learn method brought revolutionari advanc comput vision machin learn everi new new deep learn techniqu born outperform machin learn even exist deep learn techniqu recent year world ha seen mani major breakthrough thi ﬁeld sinc deep learn evolv huge speed kind hard keep track regular advanc especi new research thi paper go brieﬂi discuss recent advanc deep learn past year keyword neural network machin learn deep learn recent advanc overview introduct term deep learn dl wa ﬁrst introduc machin learn ml later use artiﬁci neural network ann schmidhub deep learn method compos multipl layer learn featur data multipl level abstract lecun et dl approach allow comput learn cate concept build simpler one goodfellow et cial neural network ann deep learn dl aka hierarch learn deng yu assign credit mani comput stage accur transform aggreg activ network schmidhub learn complic function deep architectur use multipl level abstract oper ann mani hidden layer bengio sum accur deep learn machin learn use mani level inform cess abstract supervis unsupervis featur learn represent classiﬁc pattern recognit deng yu deep learn represent learn class machin learn recent deep learn method mostli said develop sinc deng thi paper overview recent techniqu deep learn mainli recommend upcom research thi ﬁeld thi articl includ basic idea dl major approach method recent breakthrough applic overview paper found veri beneﬁci especi new research particular ﬁeld often hard keep track contemporari advanc research area provid ﬁeld ha great valu near futur relat applic scientiﬁc research attract profess sinc knowledg educ share avail ever technolog research trend onli normal assum numer advanc improv variou way overview particular ﬁeld coupl year back may turn obsolet today consid popular expans deep learn recent year present brief overview deep learn well neural network nn major advanc critic breakthrough past year hope thi paper help mani novic research thi ﬁeld get overal pictur recent deep learn research techniqu guid right way start also hope pay tribut thi work top dl ann research thi era geoﬀrey ton hinton juergen schmidhub schmidhub yann lecun lecun yoshua bengio bengio mani work meticul shape modern artiﬁci ligenc ai also import follow work stay updat dl ml research thi paper ﬁrstli provid short descript past overview paper deep learn model approach start describ recent advanc thi ﬁeld go discuss deep learn dl approach deep architectur deep neural network dnn deep gener model dgm follow import regular optim method also two brief section dl framework signiﬁc dl applic final discuss current statu futur deep learn last two section discuss conclus relat work mani overview paper deep learn dl past year describ dl method approach great way well applic direct futur research go brief outstand overview paper deep learn young et al talk dl model architectur mainli use natur languag process nlp show dl applic variou nlp ﬁeld compar dl model discuss possibl futur trend zhang et al discuss deep learn techniqu speech recognit system zhu et al present overview dl remot sens also discuss dl framework technic detail deep learn wang et al describ evolut deep learn model ner brief model graphic along breakthrough dl research thi paper would good read know origin deep learn evolutionari manner also mention optim futur research neural network goodfellow et al discuss deep network gener model detail start machin learn ml basic pro con deep architectur conclud recent dl research applic thoroughli lecun et al publish overview deep learn dl model lution neural network cnn recurr neural network rnn describ dl perspect represent learn show dl techniqu work get use success variou applic predict futur learn base unsupervis learn ul also point articl major advanc dl bibliographi schmidhub gener histor overview deep learn along cnn rnn deep reinforc learn rl emphas rnn point limit fundament dl nn trick improv nielsen describ neural network detail along code exampl also discuss deep neural network deep learn extent schmidhub cover histori evolut neural network base time progress categor machin learn approach use deep learn neural network deng yu describ deep learn class techniqu applic dl sever area bengio quick overview dl algorithm supervis unsupervis network optim train model perspect represent learn focus mani challeng deep learn scale algorithm larger model data reduc optim diﬃculti design eﬃcient scale method etc along optimist dl research bengio et al discuss represent featur learn aka deep ing explor variou method model perspect applic techniqu challeng deng gave overview deep structur learn architectur perspect inform process relat ﬁeld arel et al provid short overview recent dl techniqu bengio discuss deep architectur neural network gener model ai recent overview paper deep learn dl discuss import thing sever perspect necessari go dl research howev dl highli ﬂourish ﬁeld right mani new techniqu architectur invent even recent publish overview paper dl also previou paper focu diﬀer perspect paper mainli new learner novic research new thi ﬁeld purpos tri give basic clear idea deep learn new research anyon interest thi ﬁeld recent advanc thi section discuss main recent deep learn dl approach deriv machin learn brief evolut artiﬁci neural network ann common form use deep learn evolut deep architectur artiﬁci neural network ann come long way well deep model first gener ann wa compos simpl neural layer perceptron limit simpl comput second gener use backpropag updat weight neuron accord error rate support vector machin svm surfac surpass ann overcom limit backpropag restrict boltzmann machin wa propos make learn easier techniqu neural network came well feedforward neural network fnn convolut neural netowrk cnn recurr neural network rnn etc along deep belief network autoencod hinton next gener neural network point ann got improv design variou way variou purpos schmidhub bengio deng yu goodfellow et al wang et al etc provid detail overview evolut histori deep neural network dnn well deep learn dl deep architectur multilay repetit simpl architectur case help obtain highli complex function input lecun et deep learn approach deep neural network dnn gain huge success supervis learn sl also deep learn dl model immens success unsupervis hybrid reinforc learn well lecun et deep supervis learn supervis learn appli data label classiﬁ use class numer predict lecun et al provid brief yet veri good explan supervis learn approach deep architectur form deng yu mention mani deep network supervis hybrid learn explain deep stack network dsn variant schmidhub cover neural network start earli neural network recent success convolut neural network cnn recurr neural network rnn long short term memori lstm improv deep unsupervis learn input data label unsupervis learn approach appli extract ture data classifi label lecun et al predict futur deep learn unsupervis learn schmidhub describ neural network pervis learn well deng yu brief deep architectur unsupervis learn explain deep autoencod detail deep reinforc learn reinforc learn use reward punish system next move gener learn model thi mostli use game robot solv usual decis make problem li schmidhub describ advanc deep learn ment learn rl use deep feedforward neural netowrk fnn recurr neural network rnn rl li discuss deep reinforc learn drl architectur deep dqn applic variou ﬁeld mnih et al propos drl framework use asynchron gradient descent dnn optim van hasselt et al propos drl architectur use deep neural network dnn deep neural network thi section brieﬂi discuss deep neural network dnn recent improv breakthrough neural network work function lar human brain compos neuron connect mainli say deep neural network assum quit number hidden layer use extract featur input comput complex function bengio explain neural network deep architectur convolut neural network cnn ae etc variant deng yu tail neural network architectur ae variant goodfellow et al wrote skill explain deep feedforward network convolut network recurr recurs network improv schmidhub mention full histori neural network earli neural network recent success techniqu deep autoencod autoencod ae neural network nn output input ae take origin input encod compress represent decod reconstruct input wang deep ae lower hidden layer use encod higher one decod error use train deng yu goodfellow et al variat autoencod variat vae count decod wang vae built upon standard neural network train stochast gradient descent doersch stack denois autoencod earli ae encod layer smaller dimens input layer stack denois sdae encod layer wider input layer deng yu transform autoencod deep dae extract featur multilay process could chang due learner ing tae work input vector target output vector appli properti lead code toward desir way deng yu deep convolut neural network four basic idea make convolut neural network cnn local connect share weight pool use mani layer first part cnn made tional pool layer latter part mainli fulli connect layer convolut layer detect local conjunct featur pool layer merg similar featur one lecun et cnn use convolut instead matrix multipl convolut layer goodfellow et krizhevski et al present deep convolut neural network cnn tectur also known alexnet wa major breakthrough deep learn dl network compos ﬁve convolut layer three fulli connect layer architectur use graphic process unit gpu convolut oper rectiﬁ linear unit relu activ function dropout srivastava et reduc overﬁt iandola et al propos small cnn architectur call squeezenet szegedi et al propos deep cnn architectur name incept ment propos dai et al redmon et al propos cnn architectur name yolo onli look onc uniﬁ object detect zeiler fergu propos method visual activ within cnn gehr et al propos cnn architectur learn bansal et al propos pixelnet use pixel represent goodfellow et al explain basic cnn architecur idea gu et al present nice overview recent advanc cnn multipl variant cnn architectur regular method function applic variou ﬁeld deep convolut neural network convolut neural network mpcnn oper mainli convolut especi use digit imag process mpcnn gener consist three type layer input layer convolut layer take input imag gener map appli activ function layer sampl imag keep maximum valu layer doe linear multipl masci et deep mpcnn convolut layer use period input layer follow layer giusti et veri deep convolut neural network simonyan zisserman propos veri deep convolut neural network cnn architectur also known vgg net vgg net use veri small convolut ﬁlter depth weight layer conneau et al propos anoth vdcnn architectur text classiﬁc use small convolut pool claim thi architectur ﬁrst vdcnn use text process work charact level thi architectur compos convolut layer network network lin et al propos network network nin nin replac convolut layer tradit convolut neural network cnn micro neural network complex structur use perceptron mlpconv micro neural network global averag pool layer instead fulli connect layer deep nin architectur made thi propos nin structur lin et convolut neural network girshick et al propos convolut neural network use region recognit use region local segment object thi chitectur consist three modul categori independ region propos deﬁn set candid region larg convolut neural network cnn extract ture region set class speciﬁc linear support vector machin svm girshick et fast girshick propos fast convolut network fast thi method exploit girshick et architectur produc fast result fast consist convolut pool layer propos region sequenc fulli connect layer girshick faster ren et al propos faster convolut neural network faster cnn use region propos network rpn object detect rpn fulli convolut network gener region propos accur eﬃcient ren et mask et al propos mask convolut network mask stanc object segment mask extend faster ren et tectur use extra branch object mask et lee et al propos convolut neural network exploit fast girshick architectur gener region interest roi select exhaust search also use expert network instead singl network expert architectur fulli connect layer fast lee et deep residu network et al propos residu network resnet consist layer resnet lower error easili train residu learn deeper resnet achiev better perform resnet consid import advanc ﬁeld deep learn resnet resnet targ et al propos resnet resnet rir combin resnet et standard convolut neural network cnn deep dual stream ture targ et resnext xie et al propos resnext architectur resnext exploit resnet et repeat layer strategi xie et capsul network sabour et al propos capsul network capsnet architectur two volut layer one fulli connect layer capsnet usual contain sever lution layer capsul layer end xi et capsnet consid one recent breakthrough deep learn xi et sinc thi said build upon limit convolut neural network hinton use er capsul instead layer neuron capsul set neuron activ lower level capsul make predict upon agre multipl predict higher level capsul becom activ mechan use capsul er improv capsnet propos em rout anonym use em algorithm recurr neural network recurr neural network rnn better suit sequenti input like speech text gener sequenc recurr hidden unit consid veri deep feedforward network weight unfold time rnn use diﬃcult train becaus gradient vanish explod problem lecun et mani improv propos later solv thi problem goodfellow et al provid detail recurr recurs neural network architectur variant along relat gate memori network karpathi et al use languag model analyz ing predict represent train dynam error type rnn variant lstm ozefowicz et al explor rnn model limit languag model peng yao propos recurr neural network extern memori em improv memori capac rnn claim achiev languag understand better rnn chung et al propos gate feedback recurr neural network extend standard rnn stack multipl recurr layer global gate unit zheng et al propos condit random field recurr neural network combin convolut neural network cnn condit random field crf probabilist graphic model bradburi et al propos quasi recurr neural network qrnn neural quenc model appl parallel across timestep memori network weston et al propos memori network question answer qa memori network compos memori input featur map gener output featur map respons weston et dynam memori network kumar et al propos dynam memori network dmn qa task dmn ha four modul input question episod memori output kumar et augment neural network olah carter gave nice present attent augment recurr neural network neural ture machin ntm attent interfac neural grammer adapt comput time augment neural network usual made use extra properti like logic function along standard neural network ture olah carter neural ture machin grave et al propos neural ture machin ntm architectur consist neural network control memori bank ntm usual combin rnn extern memori bank olah carter neural gpu kaiser sutskev propos neural gpu solv parallel problem ntm grave et neural machin kurach et al propos neural random access machin use extern memori neural programm neelakantan et al propos neural programm augment neural network arithmet logic function neural reed de freita propos neural npi learn npi consist recurr core program memori encod reed de freita long short term memori network hochreit schmidhub propos long memori lstm overcom error problem recurr neural network rnn lstm base recurr network along learn algorithm hochreit schmidhub lstm introduc produc path gradient ﬂow goodfellow et greﬀet al provid analysi vanilla lstm eight lstm ant three use speech recognit handwrit recognit polyphon music model claim eight variant lstm fail perform signiﬁc ment onli vanilla lstm perform well greﬀet shi et al propos deep long memori dlstm stack lstm unit featur map learn represent shi et lstm cooijman et al propos lstm use normal hidden state recurr neural network pixel rnn van den oord et al propos pixel recurr neural network pixelrnn made twelv lstm layer bidirect lstm ollmer et al propos bidirect lstm blstm recurr network use dynam bayesian network dbn keyword detect variat shabanian et al propos variat variant bidirect lstm architectur variat creat channel inform exchang tween lstm use variat vae learn better represent shabanian et googl neural machin translat wu et al propos googl neural machin translat gnmt system tomat translat incorpor encod network decod network attent network follow common learn framework fader network lampl et al propos fader network new type architectur gener realist variat input imag chang attribut valu hyper network ha et al propos hypernetwork gener weight neural work static hypernetwork convolut network dynam hypernetwork recurr network deutsch use hyper network gener neural network highway network srivastava et al propos highway network use gate unit learn ulat inform inform ﬂow across sever layer call inform highway srivastava et recurr highway network zilli et al propos recurr highway network rhn extend long term memori lstm architectur rhn use highway layer insid recurr tion zilli et highway lstm rnn zhang et al propos highway long memori hlstm rnn extend deep lstm network gate direct connect highway memori cell adjac layer recurr cnn donahu et al propos recurr convolut network lrcn use cnn input lstm recurr sequenc model gener predict deep neural svm zhang et al propos deep neural support vector machin dnsvm use support vector machin svm top layer classiﬁc deep neural network dnn convolut residu memori network moniz pal propos convolut residu memori network rate memori mechan convolut neural network cnn augment volut residu network long short term memori mechan moniz pal fractal network larsson et al propos fractal network fractalnet altern residu net claim train ultra deep neural network without residu learn fractal repeat architectur gener simpl expans rule larsson et wavenet van den oord et al propos wavenet deep neural network gener raw audio wavenet compos stack convolut layer softmax distribut layer output van den oord et rethag et al propos wavenet model speech denois pointer network vinyal et al propos pointer network solv problem resent variabl dictionari use softmax probabl distribut call pointer deep gener model thi section brieﬂi discuss deep architecur use multipl level abstract represent similar deep neural network also known deep gener model dgm bengio explain deep architectur boltzmann machin bm restrict boltzmann machin rbm etc variant goodfellow et al explain deep gener model detail restrict unrestrict boltzmann machin variant deep boltzmann machin deep belief network dbn direct gener net gener stochast network etc maalø et al propos auxiliari deep gener model extend deep gener model auxiliari variabl auxiliari variabl make variat distribut stochast layer skip connect maalø et rezend et al develop class gener deep gener model boltzmann machin boltzmann machin connectionist approach learn arbitrari probabl tion use maximum likelihood principl learn goodfellow et restrict boltzmann machin restrict boltzmann machin rbm special type markov random ﬁeld contain one layer stochast hidden unit latent variabl one layer observ variabl deng yu goodfellow et al hinton salakhutdinov propos deep gener model use restrict boltzmann machin rbm document process deep belief network deep belief network dbn gener model sever layer latent binari real variabl goodfellow et ranzato et al built deep gener model use deep belief network dbn imag recognit deep lambertian network tang et al propos deep lambertian network dln multilay ativ model latent variabl albedo surfac normal light sourc dln combin lambertian reﬂect gaussian restrict boltzmann machin deep belief network tang et gener adversari network goodfellow et al propos gener adversari net gan estim er model adversari process gan architectur compos gener model pit adversari discrimin model learn model data bution goodfellow et improv propos gan mao et al kim et al etc saliman et al present sever method train gan laplacian gener adversari network denton et al propos deep gener model dgm call laplacian tive adversari network lapgan use gener adversari network gan proach model also use convolut network within laplacian pyramid framework denton et recurr support vector machin shi et al propos recurr support vector machin rsvm use current neural network rnn extract featur input sequenc standard support vector machin svm object discrimin train optim techniqu thi section provid short overview major techniqu regular optim deep neural network dnn dropout srivastava et al propos dropout prevent neural network overﬁt dropout neural network regular method ad nois hidden unit drop unit neural network along connect randomli dure train dropout use ani kind neural network even graphic model like rbm srivastava et veri recent propos improv dropout fratern dropout anonym recurr neural network rnn maxout goodfellow et al propos maxout new activ function use dropout srivastava et maxout output maximum set input beneﬁci dropout model averag goodfellow et zoneout krueger et al propos zoneout regular method recurr neural work rnn zoneout use nois randomli train similar dropout srivastava et preserv hidden unit instead drop krueger et deep residu learn et al propos deep residu learn framework deep neural network dnn call resnet lower train error batch normal ioﬀ szegedi propos batch normal method acceler deep neural network train reduc intern covari shift ioﬀ propos batch renorm extend previou approach distil hinton et al propos distil transfer knowledg ensembl highli regular model neural network compress smaller model layer normal ba et al propos layer normal train deep neural work especi rnn solv limit batch normal ioﬀ szegedi deep learn framework good number librari framework avail deep learn built python program languag theano bergstra et tensorﬂow abadi et pytorch pybrain schaul et caﬀe jia et block fuel van enboer et cudnn chetlur et honk tang lin chainercv niitani et chainer torch neon etc bahrampour et al compar studi sever deep learn framework applic deep learn thi section brieﬂi discuss recent outstand applic deep learn architectur sinc begin deep learn dl dl method use variou ﬁeld form supervis unsupervis reinforc learn start classiﬁc detect task dl applic spread rapidli everi ﬁeld imag classiﬁc recognit simonyan zisserman krizhevski et al et al video classiﬁc karpathi et sequenc gener grave defect classiﬁc masci et text speech imag video process lecun et text classiﬁc conneau et speech process arel et speech recognit spoken languag understand hinton et al zhang et al zhang et al zhang et al zhang et al shi et al mesnil et al peng yao amodei et al gener wang et al arik et al queri classiﬁc shi et sentenc classiﬁc kim sentenc model kalchbrenn et word process mikolov et premis select alemi et document sentenc process le mikolov mikolov et al gener imag caption vinyal et al xu et al photograph style transfer luan et natur imag manifold zhu et imag color zhang et imag question answer yang et gener textur styliz imag ulyanov et visual textual question answer xiong et al dblp visual recognit descript donahu et al razavian et al oquab et al object detect lee et al ranzato et al redmon et al liu et al document process hinton salakhutdinov charact motion synthesi edit holden et sing synthesi blaauw bonada person identiﬁc li et face recognit veriﬁc taigman et action recognit video simonyan zisserman human action recognit ji et action recognit sharma et classifi visual motion captur sequenc cho chen handwrit gener predict carter et autom machin translat wu et al cho et al bahdanau et al hermann et al luong et al name entiti recognit lampl et mobil vision howard et convers agent ghazvininejad et call genet variant poplin et cancer detect et ct reconstruct kang et epilept seizur predict mirowski et hardwar acceler han et robot lenz et name deng yu provid detail list dl applic variou categori speech audio process inform retriev object recognit comput vision multimod learn etc use deep reinforc learn drl master game ha becom hot topic everi ai bot creat dnn drl beat man world champion grandmast strateg game onli hour train exampl alphago alphago zero game go silver et al silver et al dong et al batsford atari mnih et al mnih et al van hasselt et al chess shougi silver et discuss though deep learn ha achiev tremend success mani area still ha long way go mani room left improv limit list quit long well exampl nguyen et al show deep neural network dnn easili fool recogn imag issu like transfer featur learn yosinski et huang et al propos architectur adersari attack neural network think futur work need defens attack zhang et al present experiment framework understand deep learn model think understand deep learn requir rethink gener marcu gave import review deep learn dl doe limit natur strongli point limit dl method requir data limit capac inabl deal hierarch structur struggl infer suﬃcient transpar well integr prior knowledg inabl distinguish causat correl marcu also mention dl assum stabl world work approxim diﬃcult engin ha potenti risk excess hype marcu think dl need reconceptu look possibl unsupervis learn symbol manipul hybrid model insight cognit scienc psycholog take bolder challeng conclus although deep learn dl ha advanc world faster ever still way go still away fulli understand deep learn work get machin smarter close smarter human learn exactli like human dl ha solv mani problem take technolog anoth dimens howev mani diﬃcult problem human deal exampl peopl still die hunger food crisi cancer lethal diseas etc hope deep learn ai much devot better human carri hardest scientiﬁc research last least make world better place everi singl human acknowledg would like thank moham moshiul hoqu professor depart cse cuet introduc us amaz world deep learn refer ın abadi ashish agarw paul barham eugen brevdo zhifeng chen craig citro gregori corrado andi davi jeﬀrey dean matthieu devin sanjay ghemawat ian goodfellow andrew harp geoﬀrey irv michael isard yangq jia rafal ozefowicz lukasz kaiser manjunath kudlur josh levenberg dan e rajat monga sherri moor derek gordon murray chri olah mike schuster jonathon shlen benoit steiner ilya sutskev kunal talwar paul tucker vincent vanhouck vijay vasudevan fernanda ega oriol vinyal pete warden martin wattenberg tin wick yuan yu xiaoqiang zheng tensorﬂow machin learn heterogen distribut system corr alexand alemi coi chollet geoﬀrey irv christian szegedi josef urban deepmath deep sequenc model premis select corr dario amodei rishita anubhai eric battenberg carl case jare casper bryan zaro jingdong chen mike chrzanowski adam coat greg diamo erich elsen jess engel linxi fan christoph fougner toni han awni hannun billi jun patrick legresley libbi lin sharan narang andrew ng sherjil ozair ryan prenger jonathan raiman sanjeev satheesh david seetapun shubho sengupta yi wang zhiqian wang chong wang bo xiao dani yogatama jun zhan zhenyao zhu deep speech speech recognit english mandarin corr anonym fratern dropout intern confer learn represent url http anonym matrix capsul em rout intern confer learn resent url http itamar arel derek rose tom karnowski deep learn architectur compris homogen cortic circuit scalabl spatiotempor pattern infer proc nip workshop deep learn speech page itamar arel derek rose thoma karnowski research frontier deep chine new frontier artiﬁci intellig research comp intel novemb issn doi url http sercan omer arik mike chrzanowski adam coat greg diamo andrew gibianski yongguo kang xian li john miller jonathan raiman shubho sengupta hammad shoeybi deep voic neural corr lei jimmi ba ryan kiro geoﬀrey hinton layer normal corr dzmitri bahdanau kyunghyun cho yoshua bengio neural machin translat jointli learn align translat corr soheil bahrampour naveen ramakrishnan luka schott mohak shah compar studi caﬀe neon theano torch deep learn corr aayush bansal xinlei chen bryan russel abhinav gupta deva ramanan net represent pixel pixel pixel corr tom batsford calcul optim jungl rout use neural network genet algorithm game behaviour url http yoshua bengio url http mila univers montreal quebec canada yoshua bengio learn deep architectur ai found trend mach januari issn doi url http yoshua bengio deep learn represent look forward corr yoshua bengio aaron courvil pascal vincent represent learn review new perspect ieee tran pattern anal mach august issn doi url http jame bergstra olivi breuleux eric bastien pascal lamblin razvan pascanu laum desjardin joseph turian david yoshua bengio theano cpu gpu math compil python merlijn blaauw jordi bonada neural parametr sing synthes corr jame bradburi stephen meriti caim xiong richard socher neural network corr carter david ha ian johnson chri olah experi ing neural network distil doi url http sharan chetlur cliﬀwoolley philipp vandermersch jonathan cohen john tran bryan catanzaro evan shelham cudnn eﬃcient primit deep learn corr kyunghyun cho xi chen classifi visual motion captur sequenc use deep neural network corr kyunghyun cho bart van merrienbo c cehr fethi bougar holger schwenk yoshua bengio learn phrase represent use rnn statist machin translat corr junyoung chung caglar gulcehr kyunghyun cho yoshua bengio gate feedback recurr neural network proceed intern confer ternat confer machin learn volum icml page url http alexi conneau holger schwenk ıc barrault yann lecun veri deep convolut network text classiﬁc corr tim cooijman nicola balla esar laurent aaron courvil recurr batch normal corr angel alfonso john edison arevalo oval anant madabhushi fabio gusto alez osorio deep learn architectur imag represent visual interpret autom carcinoma cancer detect page springer berlin heidelberg berlin heidelberg isbn doi url http jifeng dai haozhi qi yuwen xiong yi li guodong zhang han hu yichen wei deform convolut network corr li deng overview learn inform process li deng dong yu deep learn method applic found trend signal june issn doi url http emili denton soumith chintala arthur szlam robert fergu deep gener imag model use laplacian pyramid adversari network corr lior deutsch gener neural network neural network corr url http carl doersch tutori variat autoencod corr url http jeﬀdonahu lisa ann hendrick sergio guadarrama marcu rohrbach subhashini venugopalan kate saenko trevor darrel recurr convolut work visual recognit descript corr xiao dong jiasong wu ling zhou demystifi alphago zero alphago gan corr jona gehr michael auli david grangier deni yarat yann dauphin volut sequenc sequenc learn corr marjan ghazvininejad chri brockett chang bill dolan jianfeng gao tau yih michel galley neural convers model corr ross girshick jeﬀdonahu trevor darrel jitendra malik rich featur hierarchi accur object detect semant segment proceed ieee confer comput vision pattern recognit cvpr ross girshick fast corr alessandro giusti dan ciresan jonathan masci luca maria gambardella urgen schmidhub fast imag scan deep convolut neural network ieee intern confer imag process icip melbourn australia septemb page doi url http ian goodfellow david mehdi mirza aaron courvil yoshua bengio maxout network sanjoy dasgupta david mcallest editor proceed intern confer machin learn volum proceed machin learn research page atlanta georgia usa jun pmlr url http ian goodfellow jean mehdi mirza bing xu david farley sherjil ozair aaron courvil yoshua bengio gener versari net ghahramani well cort lawrenc weinberg editor advanc neural inform ing system page curran associ url http ian goodfellow yoshua bengio aaron courvil deep learn mit press http alex grave gener sequenc recurr neural network corr alex grave greg wayn ivo danihelka neural ture machin corr klau greﬀ rupesh kumar srivastava jan ık ba steunebrink urgen schmidhub lstm search space odyssey corr klau greﬀ rupesh kumar srivastava jan ık ba steunebrink urgen schmidhub lstm search space odyssey ieee tran neural netw ing doi url http jiuxiang gu zhenhua wang jason kuen lianyang amir shahroudi bing shuai ting liu xingx wang gang wang recent advanc convolut neural network corr david ha andrew dai quoc le hypernetwork corr song han xingyu liu huizi mao jing pu ardavan pedram mark horowitz william dalli eie eﬃcient infer engin compress deep neural network corr kaim url http facebook ai research fair kaim xiangyu zhang shaoq ren jian sun deep residu learn imag recognit corr kaim georgia gkioxari piotr ar ross girshick mask corr karl moritz hermann edward grefenstett lass espeholt kay mustafa suleyman phil blunsom teach machin read comprehend corr geoﬀrey hinton url http univers toronto u ontario canada googl brain team geoﬀrey hinton ruslan salakhutdinov discov binari code ment learn deep gener model topic cognit scienc issn doi url http geoﬀrey hinton li deng dong yu georg dahl abdel rahman moham navdeep jaitli andrew senior vincent vanhouck patrick nguyen tara sainath brian kingsburi deep neural network acoust model speech recognit signal process magazin geoﬀrey hinton oriol vinyal jeﬀrey dean distil knowledg neural network nip deep learn represent learn workshop url http sepp hochreit urgen schmidhub long memori neural novemb issn doi url http daniel holden jun saito taku komura deep learn framework charact motion synthesi edit acm tran juli issn doi url http andrew howard menglong zhu bo chen dmitri kalenichenko weijun wang bia weyand marco andreetto hartwig adam mobilenet eﬃcient convolut neural network mobil vision applic corr sandi huang nicola papernot ian goodfellow yan duan pieter abbeel adversari attack neural network polici corr forrest iandola matthew moskewicz khalid ashraf song han william dalli kurt keutzer squeezenet accuraci fewer paramet model size corr sergey ioﬀ batch renorm toward reduc minibatch depend normal model corr sergey ioﬀ christian szegedi batch normal acceler deep network ing reduc intern covari shift franci bach david blei editor ing intern confer machin learn volum proceed machin learn research page lill franc jul pmlr url http shuiwang ji wei xu ming yang kai yu convolut neural network human action recognit ieee tran pattern anal mach januari issn doi url http yangq jia evan shelham jeﬀdonahu sergey karayev jonathan long ross girshick sergio guadarrama trevor darrel caﬀe convolut architectur fast featur embed corr rafal ozefowicz oriol vinyal mike schuster noam shazeer yonghui wu explor limit languag model corr lukasz kaiser ilya sutskev neural gpu learn algorithm corr nal kalchbrenn edward grefenstett phil blunsom convolut neural network model sentenc corr eunhe kang junhong min jong chul ye wavenet deep convolut ral network use direct wavelet ct reconstruct corr andrej karpathi georg toderici sanketh shetti thoma leung rahul sukthankar li video classiﬁc convolut neural network proceed ieee confer comput vision pattern nition cvpr page washington dc usa ieee puter societi isbn doi url http andrej karpathi justin johnson li visual understand recurr network corr taeksoo kim moonsu cha hyunsoo kim jung kwon lee jiwon kim ing discov relat gener adversari network corr yoon kim convolut neural network sentenc classiﬁc corr alex krizhevski ilya sutskev geoﬀrey hinton imagenet cation deep convolut neural network proceed intern confer neural inform process system volum nip page usa curran associ url http david krueger tegan maharaj ano ar mohammad pezeshki nicola balla nan rosemari ke anirudh goyal yoshua bengio hugo larochel aaron courvil chri pal zoneout regular rnn randomli preserv hidden activ corr ankit kumar ozan irsoy jonathan su jame bradburi robert english brian pierc peter ondruska ishaan gulrajani richard socher ask anyth dynam memori network natur languag process corr karol kurach marcin andrychowicz ilya sutskev neural machin corr guillaum lampl miguel ballestero sandeep subramanian kazuya kawakami chri dyer neural architectur name entiti recognit corr guillaum lampl neil zeghidour nicola usuni antoin bord ludov denoy marc aurelio ranzato fader network manipul imag slide attribut corr url http gustav larsson michael mair gregori shakhnarovich fractalnet neural network without residu corr quoc le toma mikolov distribut represent sentenc document corr yann lecun url http new york univers nyu ny usa facebook ai research fair yann lecun yoshua bengio geoﬀrey hinton deep learn natur ep url http hyungta lee sungmin eum heesung kwon cnn object detect corr ian lenz honglak lee ashutosh saxena deep learn detect robot grasp corr wei li rui zhao tong xiao xiaogang wang deepreid deep ﬁlter pair ral network person ieee confer comput vision pattern recognit cvpr columbu usa june yuxi li deep reinforc learn overview corr min lin qiang chen shuicheng yan network network corr wei liu dragomir anguelov dumitru erhan christian szegedi scott reed yang fu alexand berg ssd singl shot multibox detector corr fujun luan sylvain pari eli shechtman kavita bala deep photo style transfer corr luong hieu pham christoph man eﬀect approach neural machin translat corr lar maalø casper kaae sønderbi søren kaae sønderbi ole winther auxiliari deep gener model proceed intern confer ternat confer machin learn volum icml page url http xudong mao qing li haoran xie raymond lau zhen wang gener adversari network loss function corr gari marcu deep learn critic apprais corr url http jonathan masci alessandro giusti dan ciresan gabriel fricout urgen huber fast learn algorithm imag segment convolut network ieee intern confer imag process icip bourn australia septemb page doi url http jonathan masci ueli meier gabriel fricout urgen schmidhub pyramid pool network gener steel defect classiﬁc ternat joint confer neural network ijcnn dalla tx usa august page doi url http egoir mesnil yann dauphin kaisheng yao yoshua bengio li deng dilek ur xiaodong larri heck okhan ur dong yu geoﬀrey zweig use recurr neural network slot ﬁlling spoken languag understand tran audio speech languag process toma mikolov kai chen greg corrado jeﬀrey dean eﬃcient estim word represent vector space corr toma mikolov ilya sutskev kai chen greg corrado jeﬀrey dean distribut represent word phrase composition corr piotr mirowski yann lecun deepak madhavan ruben kuzniecki compar svm convolut network epilept seizur predict intracrani eeg proc machin learn signal process mlsp ieee volodymyr mnih koray kavukcuoglu david silver alex grave ioanni antonogl daan wierstra martin riedmil play atari deep reinforc learn corr volodymyr mnih koray kavukcuoglu david silver andrei rusu joel veness marc bellemar alex grave martin riedmil andrea fidjeland georg ostrovski stig petersen charl beatti amir sadik ioanni antonogl helen king kumaran daan wierstra shane legg demi hassabi trol deep reinforc learn natur ep url http volodymyr mnih adri puigdom enech badia mehdi mirza alex grave timothi lillicrap tim harley david silver koray kavukcuoglu asynchron method deep reinforc learn corr joel moniz christoph pal convolut residu memori network corr arvind neelakantan quoc le ilya sutskev neural programm induc latent program gradient descent corr anh mai nguyen jason yosinski jeﬀclun deep neural network easili fool high conﬁdenc predict unrecogniz imag corr michael nielsen neural network deep learn determin press http yusuk niitani toru ogawa shunta saito masaki saito chainercv librari deep learn comput vision corr chri olah carter attent augment recurr neural network distil doi url http maxim oquab leon bottou ivan laptev josef sivic learn transfer level imag represent use convolut neural network proceed ieee confer comput vision pattern recognit cvpr page washington dc usa ieee comput societi isbn doi url http baolin peng kaisheng yao recurr neural network extern memori languag understand volum ryan poplin dan newburg jojo dijamco nam nguyen dion loy sam gross cori mclean mark depristo creat univers snp small indel variant caller deep neural network biorxiv url http ranzato susskind mnih hinton deep gener model cation recognit proceed ieee confer comput vision pattern recognit cvpr page washington dc usa ieee comput societi isbn doi url http ali sharif razavian hossein azizpour josephin sullivan stefan carlsson cnn featur astound baselin recognit corr joseph redmon santosh kumar divvala ross girshick ali farhadi onli look onc uniﬁ object detect corr scott reed nando de freita neural corr shaoq ren kaim ross girshick jian sun faster toward time object detect region propos network neural inform process system nip dario rethag jordi pon xavier serra wavenet speech denois corr danilo rezend shakir ivo danihelka karol gregor daan wierstra shot gener deep gener model maria florina balcan kilian weinberg editor proceed intern confer machin learn volum proceed machin learn research page new york new york usa jun pmlr url http sara sabour nichola frosst geoﬀrey hinton dynam rout capsul advanc neural inform process system annual confer neural inform process system decemb long beach ca usa page url http tim saliman ian goodfellow wojciech zaremba vicki cheung alec radford xi chen improv techniqu train gan corr tom schaul justin bayer daan wierstra yi sun martin felder frank sehnk thoma uckstieß urgen schmidhub pybrain mach learn march issn url http schmidhub deep learn scholarpedia doi url http vision juergen schmidhub url http idsia usi dall moll institut artiﬁci intellig switzerland urgen schmidhub deep learn neural network overview volum url http samira shabanian devansh arpit adam trischler yoshua bengio variat lstm corr url http shikhar sharma ryan kiro ruslan salakhutdinov action recognit use visual attent corr yangyang shi kaisheng yao hu chen dong yu pan hwang recurr support vector machin slot tag spoken languag understand page associ comput linguist yangyang shi kaisheng yao le tian daxin jiang deep lstm base featur ping queri classiﬁc page associ comput linguist david silver aja huang chri maddison arthur guez laurent sifr georg van den driessch julian schrittwies ioanni antonogl veda panneershelvam marc tot sander dieleman dominik grew john nham nal kalchbrenn ilya sutskev timothi lillicrap madelein leach koray kavukcuoglu thore graepel demi hassabi master game go deep neural network tree search natur ep url http david silver thoma hubert julian schrittwies ioanni antonogl matthew lai arthur guez marc lanctot laurent sifr dharshan kumaran thore graepel othi lillicrap karen simonyan demi hassabi master chess shogi gener reinforc learn algorithm corr url http david silver julian schrittwies karen simonyan ioanni antonogl aja huang arthur guez thoma hubert luca baker matthew lai adrian bolton yutian chen timothi lillicrap fan hui laurent sifr georg van den driessch thore graepel demi hassabi master game go without human knowledg natur ep url http karen simonyan andrew zisserman convolut network action recognit video corr karen simonyan andrew zisserman veri deep convolut network imag recognit corr nitish srivastava geoﬀrey hinton alex krizhevski ilya sutskev ruslan salakhutdinov dropout simpl way prevent neural network ﬁtting journal machin learn research url http rupesh kumar srivastava klau greﬀ urgen schmidhub highway network corr url http christian szegedi wei liu yangq jia pierr sermanet scott reed dragomir anguelov dumitru erhan vincent vanhouck andrew rabinovich go deeper convolut corr yaniv taigman ming yang marc aurelio ranzato lior wolf deepfac close gap perform face veriﬁc proceed ieee confer comput vision pattern recognit cvpr page washington dc usa ieee comput societi isbn doi url http raphael tang jimmi lin honk pytorch reimplement convolut neural network keyword spot corr yichuan tang ruslan salakhutdinov geoﬀrey hinton deep lambertian network sasha targ diogo almeida kevin lyman resnet resnet gener residu architectur corr dmitri ulyanov vadim lebedev andrea vedaldi victor lempitski textur work synthesi textur styliz imag corr aron van den oord sander dieleman heiga zen karen simonyan oriol vinyal alex grave nal kalchbrenn andrew senior koray kavukcuoglu wavenet gener model raw audio corr aron van den oord nal kalchbrenn koray kavukcuoglu pixel recurr neural network corr hado van hasselt arthur guez david silver deep reinforc learn doubl corr bart van enboer dzmitri bahdanau vincent dumoulin dmitriy serdyuk david jan chorowski yoshua bengio block fuel framework deep learn corr oriol vinyal alexand toshev sami bengio dumitru erhan show tell neural imag caption gener corr oriol vinyal meir fortunato navdeep jaitli pointer network corr url http haohan wang bhiksha raj eric xing origin deep learn corr shenlong wang url http univers toronto u ontario canada yuxuan wang daisi stanton yonghui wu ron weiss navdeep jaitli zongheng yang ying xiao zhifeng chen sami bengio quoc le yanni agiomyrgiannaki rob clark rif saurou tacotron fulli synthesi model corr jason weston sumit chopra antoin bord memori network corr martin ollmer florian eyben alex grave orn schuller gerhard rigol rection lstm network keyword detect cognit virtual agent framework cognit comput sep issn doi url http yonghui wu mike schuster zhifeng chen quoc le mohammad norouzi wolfgang macherey maxim krikun yuan cao qin gao klau macherey jeﬀklingn apurva shah melvin johnson xiaob liu lukasz kaiser stephan gouw yoshikiyo kato taku kudo hideto kazawa keith steven georg kurian nishant patil wei wang cliﬀyoung jason smith jason riesa alex rudnick oriol vinyal greg corrado macduﬀhugh jeﬀrey dean googl neural machin translat system bridg gap human machin translat corr edgar xi selina bing yang jin capsul network perform complex data corr url http sain xie ross girshick piotr ar zhuowen tu kaim aggreg residu transform deep neural network corr caim xiong stephen meriti richard socher dynam memori network visual textual question answer corr kelvin xu jimmi ba ryan kiro kyunghyun cho aaron courvil ruslan dinov richard zemel yoshua bengio show attend tell neural imag caption gener visual attent corr zichao yang xiaodong jianfeng gao li deng alexand smola stack attent network imag question answer corr jason yosinski jeﬀclun yoshua bengio hod lipson transfer featur deep neural network proceed intern confer neural inform process system volum nip page cambridg usa mit press url http tom young devamanyu hazarika soujanya poria erik cambria recent trend deep learn base natur languag process corr matthew zeiler rob fergu visual understand convolut network corr chiyuan zhang sami bengio moritz hardt benjamin recht oriol vinyal stand deep learn requir rethink gener corr richard zhang phillip isola alexei efro color imag color corr zhang chaojun liu kaisheng yao yifan gong deep neural support vector machin speech recognit icassp page ieee yu zhang guoguo chen dong yu kaisheng yao sanjeev khudanpur jame glass highway long memori rnn distant speech recognit corr yu zhang guoguo chen dong yu kaisheng yao sanjeev khudanpur jame glass highway long memori rnn distant speech recognit icassp page ieee zix zhang urgen geiger jouni pohjalainen amr mousa orn schuller deep learn environment robust speech recognit overview recent develop corr shuai zheng sadeep jayasumana bernardino vibhav vineet zhizhong su dalong du chang huang philip torr condit random ﬁeld recurr neural network corr zhu philipp uhl eli shechtman alexei efro gener visual manipul natur imag manifold corr xiao xiang zhu devi tuia lichao mou xia liangpei zhang feng xu friedrich fraundorf deep learn remot sens review corr julian georg zilli rupesh kumar srivastava jan ık urgen schmidhub recurr highway network proceed intern confer machin learn icml sydney nsw australia august page url http