citation paramasivam sindha balakrishnan machine learning classiﬁer used deep learned spatial motion feature human action recognition entropy 2023 25 academic editor andrea prati luis javier garcía villalba vincent cicirello received 30 march 2023 revised 4 may 2023 accepted 9 may 2023 published 25 may 2023 copyright 2023 author licensee mdpi basel switzerland article open access article distributed term condition creative common attribution cc license http entropy article machine learning classiﬁer used deep learned spatial motion feature human action recognition kalaivani paramasivam 1 mohamed mansoor roomi sindha 2 sathya bama balakrishnan 2 1 department electronics communication engineering government college engineering bodinayakanur 625582 tamilnadu india 2 department electronics communication engineering thiagarajar college engineering madurai 625015 tamilnadu india smmroomi sbece correspondence pkalaivaniecegcebn abstract human action recognition essential process surveillance video analysis used understand behavior people ensure safety existing method har use computationally heavy network cnn network alleviate challenge implementation training deep learning network parameter customized lightweight directed acyclic residual cnn fewer parameter wa designed scratch named harnet novel pipeline construction spatial motion data raw video input presented latent representation learning human action constructed input fed network simultaneous operation spatial motion information single stream latent representation learned fully connected layer extracted fed conventional machine learning classiﬁers action recognition proposed work wa empirically veriﬁed experimental result compared existing method result show proposed method outperforms sota method percentage improvement kth dataset keywords spatial motion cue directed acyclic residual cnn deep learned feature knn classiﬁer introduction recognizing human action vital process computer vision application violence detection surveillance video analysis 3 anomaly detection 4 video retrieval video summarization 3 elder care monitoring emergency rescue erations 5 human action recognition also applicable surgical method surgical method support augmented ity ar wa proposed rong wen 6 approach preoperative intraoperative information wa directly shown patient ar environment mobile surgical robot system executed predeﬁned rf needle insertion plan oriented region proposal network wa presented visual tracking application 7 augmented surgical planning approach wa proposed image real patient body direct augmented interactivity projection correction registration surgical model system wa presented create surgical environment spatial augmented reality directly patient body 8 joint similarity measure adjustable algorithm proposed 9 method enhance matching cost computation better ﬁt color image heart soft tissue approach simultaneously enhances adaptive weight using concept graph cutting recent year human action recognition ha increased attention ﬁeld computer vision due efﬁciency understanding context based imitation visual cortex entropy 2023 25 entropy 2023 25 844 2 15 method use approach lstm network method har although performed well temporal stream video ha limitation due intensive computational complexity prompted researcher develop method complexity still exists approach traversing twice network fore novel single stream directed acyclic residual cnn also known harnet ha proposed proposed work motivated information bottleneck theory 14 argues objective any supervised learning strategy extract competently represent signiﬁcant information content input data correspond output label according interpretation information theory minimally sufﬁcient statistic input data need mapped maximally compressed format output label preserving information content much possible proposed work introduces novel learning framework called harlearning prediction human action proposed method exploit capability cnn learning maximally compressed informative representation designing customized shallow layered graph residual cnn shallow network architecture wa chosen guarantee optimal performance model even training sample lesser quality helpful recognize abnormal action surveillance video amount abnormal action data le comparable normal action alternative reason shallow network easily deployed edge device structural simplicity number convolution layer used shallow network reduced lead reduced number parameter diminishing computational complexity training time term layered cnn architecture mean layer multiple input multiple output effectively mean information one layer directly landing next layer exception regular ﬂow achieved providing residual connection learned feature used train ml classiﬁers support vector machine svm decision tree dt linear discriminant analysis lda naïve bayes nb ensemble neighbor knn recognizing human action human action recognition information important spatial temporal information combined construct novel spatial motion cue spatial information preserved frame combined optical ﬂow motion vector band axis including temporal aspect major contribution follows fusion spatial temporal cue represented intensity optical ﬂow vector respectively proposal shallow ing deep learned action feature proposal machine learning framework classifying 101 human action experimentation comparison sota technique mark dataset organization paper follows section 2 give literature related proposed work section 3 describes proposed spatial motion feature learning framework section 4 depicts experimental detail network learning setup result discussion section 5 give conclusion future direction related work recently deep learning network widely used analyzing event video one model wa designed using extract important feature frame input followed recurrent neural network convlstm detecting any abnormal event 2 method using combination cnn long memory lstm classifying video smaller dataset wa proposed 15 three different variant input evaluated using encoding decoding entropy 2023 25 844 3 15 based lstm ﬁrst input wa rgb frame second wa optical ﬂow third wa combination rgb frame optical ﬂow hybrid deep learning network hdln proposed 16 ha used extract feature complex smartphone inertial data deep learning model also used automatically recognize activity single worker method integrating cnn svm wa proposed 17 extracted action feature trained using gaussian mixture model aigmm information wa analyzed resemblance preserved statistic aigmm mean posterior covariance utilized create kernel ﬁnding similarity 18 pedestrian attribute recognition par important computer vision niques applicable video surveillance system method mented provide comparison deep learning conventional algorithm 19 order recognize group activity individual interaction relevant object method based skeletal information wa proposed 20 method used group interaction relational network girn ﬁnd relationship among multiple module ﬁnd interaction among recognize human action random view view action generation method built auxiliary conditional gan wa posed 21 using approach action sample generated arbitrary view human action view range action sequence enlarged training set method based framework wa implemented recognize track activity ndas wa achieved mapping driver gaze identiﬁcation model using deep learning algorithm 22 furthermore human interaction recognition requires spatial temporal interactive feature dyadic relational graph convolutional network method wa posed interaction recognition 23 recent work transformer used action recognition video comprehensive survey approach using vision former action recognition given 24 action transformer act straightforward fully architecture outperforms complex network tion convolutional recurrent attentive layer wa presented 25 approach took advantage posture representation shorter temporal window reduce computing energy demand proposed spatial motion feature learning framework proposed spatial motion feature learning framework comprises three step namely preprocessing design neural network representation learning har depicted figure preprocessing involves fusion spatial information motion information performed concatenating form video frame motion vector obtained optical ﬂow computation band axis preprocessing input video data segmented frame subsampled reduce redundancy motion vector computed ﬁnding optical ﬂow frame using horn schunk approach 26 intensity image obtained rgb frame concatenated horizontal vertical vector optical ﬂow constructed input contains spatial motion information named spatial motion fusion data design proposed network model proposed network constructed stacking ﬁve stage convolution layer shown figure ﬁrst stage convolution layer kernel size 3 single stride padding used convolution layer followed batch normalization layer provide normalization across data relu layer used retain zero positive value feature alone entropy 2023 25 844 4 15 figure proposed framework learning deep spatial motion feature figure architecture proposed harnet convolution layer following stage network increasing number channel scaling factor 2 size kernel ﬁxed 3 similarly stride padding convolution layer output feature map relu layer ﬁrst stage added output feature map batch normalization layer second stage via 1 1 convolution operation skip connection 2 2 max pooling layer used size feature map half value retain only dominant feature relu layer used second stage network output feature map layer added combined feature output layer feature relu added batch normalization output max pooling layer used downsize dimension feature relu layer included followed ﬁnal convolution batch normalization layer output feature map relu fourth stage connected output feature map batch normalization ﬁfth stage followed average pooling layer fully connected layer fully connected layer receives input size 8 8 128 8192 number output node chosen number action class used train network fully connected layer used entropy 2023 25 844 5 15 extract representation data condensed form ﬁnal layer softmax layer used only learning kernel weight proposed network training phase categorical cross entropy used loss function training network model learning harnet kernel weight feature learned fully connected layer extracted representation feature used train neighbor classiﬁer inferring action characterized learned representation information bottleneck principle information bottleneck principle based information theory used extract signiﬁcant content contained random input variable x v denotes preprocessed video data random output variable l denotes label output action category given transition probability p x joint probability distribution computed p x p x p x 1 signiﬁcant average information given mutual information x p x p x p 2 statistical dependency x assumed shown figure 2 layer network operates input obtained previous layer cause neural network form markov chain hence data processing inequality dpi result fact information lost one layer not regained succeeding layer according information theoretic learning principle deep neural network dnns layer dnn process only input previous layer loss information consecutive layer n compared preceding layer depicted equation any succeeding layer n given x rm rn ˆ 3 rn representation higher layer rm representation lower layer ˆ predicted label true label equality expression achieved only layer give sufﬁcient statistic input hence necessary obtain not only pertinent representation layer also compact representation input hence massive layered network may result information bottleneck limitation overcome designing shallow network layer need try enhance rn diminishing rn much possible achieved help convolution neural network layer classiﬁcation feature learned fully connected layer extracted train machine learning classiﬁers efﬁcacy proposed network latent representation learning ha analyzed various ml classiﬁers support vector machine svm decision tree dt neighbor knn linear discriminant analysis lda naïve bayes nb ensemble neighbor classiﬁer practically applicable recognizing pattern human action mean doe not assume distribution data hence work well proposed approach nn classiﬁer store case training data try classify test data based similarity measure euclidean distance considered similarity measure ﬁnding neighbor experiment number neighbor included classifying test sample one entropy 2023 25 844 6 15 support vector machine complex data transformation performed svm based chosen kernel function help transformation separation boundary data maximized decision tree decision tree systematic approach used siﬁcation problem set query relation feature dataset posed dt visualized using binary tree data root node split two different record different attribute leaf represent class dataset naïve bayes bayes theorem basis naïve bayes classification method naïve bayes method used assumption independence every pair feature data linear discriminant analysis linear discriminant analysis lda classiﬁcation method used experiment assumes data different class based different gaussian distribution lda us estimated probability piece test data belongs particular class classifying class highest probability predicted output class given sample ensemble adaptive boosting classiﬁcation method used ensemble aggregation approach experimentation number learning cycle used experiment 100 learning rate shrinkage order train classiﬁers latent representation retrieved training dataset class representation learned test dataset predicted using trained model hyperparameters classiﬁer tuned training machine learning classiﬁer model kth shown table 1 result hyperparameter tuning experiment also listed table tuning hyperparameters ml classiﬁers model hyper parameter tuning accuracy tuning accuracy tuning hyperparameter k distance metric tuning range euclidean cityblock minkowski chebychev hamming spearman cosine mahalanobis tuned value 1 euclidean svm hyperparameter box constraint coding kernel scale tuning range tuned value 1 1 dt hyperparameter minimum leaf size tuning range tuned value 1 lda hyperparameter delta gamma tuning range 1 1 103 tuned value 0 nb hyperparameter distribution width tuning range normal kernel tuned value normal ensemble hyperparameter number learning cycle learning rate tuning range tuned value 100 1 entropy 2023 25 844 7 15 experimental detail network learning setup overall training regime harnet described section video sequence preprocessed obtain fusion spatial motion information input network downsized 64 64 convolution layer come input layer ha weight initialized using glorot initializer help stabilize training phase shorten training time kernel weight size 3 3 updated stochastic gradient descent ﬁrst convolution layer ha eight channel number doubled following convolution layer kernel move along input single stride convolution layer network size max pooling layer model 2 2 stride hyperparameters proposed harnet tuned experimentation changing linear range shown table following tuning process initial learning rate momentum size set 32 respectively approach comprising training testing validation used prevent network overﬁtting data split ratio used implementing approach wa experimentation wa performed data split wa carried basis provide sufﬁcient amount video sample training training set video data wa used train network model learning kernel weight validation data used training improve performance network testing set video data wa passed trained model predict action category unseen data table tuning hyperparameters harnet model hyperparameter tuning harnet hyperparameter momentum initial learning rate size tuning range tuned 32 datasets har three standard har datasets considered experimentally evaluating mance proposed work kth various feature datasets number video clip frame rate number action category challenge variation data capture listed table table various feature datasets dataset feature number video clip frame rate frame per second number action category challenge variation data capturing 6849 30 51 camera movement camera view point different video quality 13320 25 101 cluttered background camera movement pose appearance object varying scale different illumination condition view point kth 2391 25 6 presence shadow video scale variation subject different clothes indoors outdoors 27 human motion database containing 6849 video 51 action class action categorized ﬁve major group common body movement action common facial action body movement action object facial action object human interaction body movement 28 dataset comprises 13320 video 101 action category enormous diversity action large variation pose appearance object different scale view point illumination condition potentially camera motion different cluttered background kth dataset 29 contains 2391 video clip captured uniform entropy 2023 25 844 8 15 background using static camera frame rate 25 frame per second dataset includes six action namely boxing running jogging walking hand clapping hand waving video captured four different scenario indoors outdoors outdoors different scale outdoors different clothes result discussion quantitatively ass performance proposed network model standard evaluation metric assessing accuracy human action recognition calculated overall model using equation 4 accuracymodel tp tn tp tn fp fn 4 performance evaluation metric precision recall speciﬁcity evaluated order compare performance different classiﬁcation model well analyze performance model varying different parameter 30 performance evaluation metric precision recall speciﬁcity deﬁned action recognition problem average metric per class evaluation metric per class deﬁned assuming binary classiﬁcation problem class consideration taken positive case class negative case formulated using equation 5 8 precisionperclass tp tp fp 5 recallperclass tp tp fn 6 speci f icityperclass tn tn fp 7 2 2 fp fn 8 taking macro average arithmetic mean performance metric class evaluation metric computed multiple class evaluation proposed network model wa trained preprocessed video clip categorizing 101 action class learning weight latent representation data feature extracted fully connected layer proposed network extracted feature used train conventional ml classiﬁers evaluating efﬁcacy network learning latent representation human action test data predicted trained ml model average classiﬁcation accuracy lda nb ensemble dt svm knn detailed classiﬁcation report listing standard performance metric given table knn yield maximum value precision recall unity speciﬁcity value observed table 3 inferred proposed method work well data classifying action value metric precision recall speciﬁcity also high irrespective ml classiﬁer entropy 2023 25 844 9 15 table comparison inﬂuence ml classiﬁers ml classiﬁer accuracy precision recall speciﬁcity lda nb ensemble dt 1 svm 1 knn 1 evaluation standard metric accuracy precision recall speciﬁcity dataset listed table proposed method recognizes human action accuracy lda nb ensemble classiﬁer svm classiﬁer dt knn classiﬁers value listed table 4 reveals knn classiﬁer yield maximum value various metric precision recall speciﬁcity table comparison inﬂuence ml classiﬁers ml classiﬁer accuracy precision recall speciﬁcity lda nb ensemble svm dt knn evaluation kth dataset performance proposed approach experimentally evaluated untrimmed kth dataset ha six action class dataset contains frame without human foreground preprocessing step detecting people gaussian mixture model wa used detecting human foreground frame wa converted spatial motion cue wa processed network model learning latent representation learned representation wa used train ml classiﬁer model test dataset wa used ass prediction accuracy precision recall speciﬁcity table 6 list value performance metric computed kth dataset proposed work yield average classiﬁcation accuracy lda nb ensemble dt svm maximum performance knn classiﬁer knn result precision recall value speciﬁcity table comparison inﬂuence ml classiﬁers kth ml classiﬁer accuracy precision recall speciﬁcity lda nb ensemble dt svm knn result shown table indicate proposed method yield high precision value irrespective classiﬁer implies positive prediction made proposed methodology correct show efﬁciency proposed work learning representation human action high recall value reveal positive prediction made model correct actual positive entropy 2023 25 844 10 15 sample high speciﬁcity value ml classiﬁers suggest trained model classify negative sample test data correctly harmonic mean precision recall high demonstrates classiﬁers predict test sample correctly considering result high value metric depict strong robustness proposed representation learning har result ablation study ablation study wa conducted determine importance layer inﬂuencing performance proposed network model wa implemented removing certain layer proposed model experimental result listed table ﬁrst study understand importance residual connection skip connection via 1 1 convolution addition layer removed result named residual outcome demonstrate removal residual connection drop maximum performance original model knn classiﬁer 1 kth second study max pooling layer alone removed original referred maxpooling keeping residual connection addition operation understand contribution observed removal max pooling layer reduces performance proposed network model learning representation kth shown figure result conﬁrm residual connection max pooling layer signiﬁcant learning representation human action recognition table performance ablation study model ml classiﬁer kth harnet knn svm dt lda nb ensemble residual knn 1 svm dt lda nb ensemble maxpooling knn svm dt lda nb ensemble entropy 2023 25 844 11 15 figure comparison ablation study six classiﬁers three datasets comparison method efficacy proposed network representation learning ha analyzed compared existing method three benchmark datasets kth since sota method often employ data split proposed method also us split order compare sota technique result action recognition experiment using proposed network feature classified compared earlier study listed table inferred table 8 proposed methodology increase performance existing approach 31 twostream table 9 compare performance proposed work existing work dataset show mean prediction accuracy proposed method hmmdb 51 improved compared existing work 32 result kth dataset entropy 2023 25 844 12 15 compared existing work table result suggest proposed approach yield improvement performance compared existing method 33 proposed harnet feature also trained two latest variant centroid displacement based neighbor 34 ensemble neighbor based centroid displacement ecdnn 35 experimentation show minimal improvement accuracy cdnn ecdd considerable improvement accuracy cdnn ecdnn kth whereas relatively lower accuracy le cdnn le ecdnn wa found total number learnable parameter proposed existing deep neural network listed table proposed network ha only five 3 3 convolutional layer three 1 1 convolution layer fully connected layer number action class time 8192 weight count bias term proposed harnet model includes kernel weight bias term weight added along 496 offset scale parameter five stage batch normalization layer resulting total parameter compared best existing method 36 lower table comparison existing work author method year accuracy simonyan zisserman 37 fusion svm 2014 du et al 38 fine tuned 2015 wang et al 36 tsn 2016 qiu et al 39 pseudo 2017 zhou et al 40 mixed conv tube mict 2018 tran et al 31 r 2 1 kinetics 2018 tran et al 31 r 2 1 kinetics 2018 tu et al 41 2019 li et al 42 danet 2020 perrett et al 43 trx 2021 yongmei zhang 5 stfusionnet 2022 chen 44 2023 proposed harnet knn table comparison existing work author method year accuracy simonyan zisserman 37 two stream fusion svm 2014 wang et al 36 tsn 2016 zhou et al 40 mixed conv tube mict 2018 tran et al 31 r 2 1 kinetics 2018 tran et al 31 r 2 1 kinetics 2018 tu et al 41 2019 li et al 42 2020 rehman inzamam 32 2021 perrett et al 43 trx 2021 omi et al 45 2022 chen 44 2023 proposed harnet knn table comparison existing work kth author method year accuracy bregonzio et al 46 appearance distribution fusion 2012 shuiwang et al 47 2013 cho 48 local motion full motion 2014 yao 49 stb pool 2016 zhang et al 50 sift bow svm 2018 zhang et al 33 deconvolution 2020 mishra 51 fea 2022 proposed harnet knn entropy 2023 25 844 13 15 table comparison existing work parameter author method pretraining dataset year parameter simonyan zisserman 37 two stream imagenet 2014 25 du et al 38 2015 wang et al 36 tsn imagenet 2016 qiu et al 39 pseudo imagenet 2017 zhou et al 40 mixed conv tube mict 2018 li et al 42 danet 2020 wang 52 tdn imagenet 2021 omi et al 45 2022 chen 44 2023 proposed harnet datasets used experiment different comparison given information only conclusion future direction work representation learning model harlearning based tion bottleneck principle proposed wa implemented designing novel directed acyclic residual cnn named harnet wa built stacking convolution layer followed batch normalization layer relu max pooling layer residual connection via 1 1 convolution network wa trained learning latent representation input recognizing human action fusion spatial motion information wa performed concatenating form frame optical ﬂow tor using advantage batch normalization residual connection network wa able better understand distinct feature human action efﬁciency network learning feature recognize action fewer parameter wa achieved use max pooling layer 1 1 convolution learned feature used train ml classiﬁers harnet feature knn classiﬁer yielded improvement performance term accuracy kth compared sota method metric demonstrate robustness proposed method har far fewer network parameter aid implementing proposed model edge device proposed work extended unsupervised model har enable classify unseen data surveillance model trained large new dataset kinetics 700 order include action author contribution conceptualization data curation formal analysis investigation methodology project tration resource software supervision validation visualization draft editing author read agreed published version manuscript funding research received no external funding institutional review board statement not applicable informed consent statement not applicable data availability statement data available publicly accessible repository data presented study openly available reference number 28 reference number 27 kth reference number 29 acknowledgment author express sincere gratitude thiagarajar college ing tce support implementing research conﬂicts interest author declare no conﬂict interest entropy 2023 25 844 14 15 reference roshan srivathsan deepak violence detection automated video surveillance recent trend comparative study intelligent system academic press cambridge usa 2020 pp vosta yow combined structure violence detection surveillance camera appl sci 2022 12 1021 crossref elharrouss almaadeed bouridane beghdadi combined multiple action recognition summarization surveillance video sequence appl intell 2021 51 crossref berroukham housni lahraichi boulfriﬁ deep method anomaly detection video surveillance review bull electr eng inform 2023 12 crossref zhang guo du wu human action recognition dynamic scene emergency rescue based temporal fusion network electronics 2023 12 538 crossref wen tay nguyen chng chui hand gesture guided surgery based direct augmented reality interface comput method program biomed 2014 116 crossref zhu xue wang yuan li fast visual tracking siamese oriented region proposal network ieee signal process lett 2022 29 crossref wen nguyen chng chui situ spatial ar surgical planning using system proceeding symposium information communication technology da nang vietnam december 2013 lai yang liu yin yin zheng improved stereo matching algorithm based joint similarity measure adaptive weight appl sci 2023 13 514 crossref yang lu zhou motion network action recognition based spatial attention entropy 2022 24 368 crossref tasnim baek dynamic edge convolutional neural network human action recognition sensor 2023 23 778 crossref joefrie aono video action recognition using motion excitation temporal aggregation entropy 2022 24 1663 crossref ahn kim hong ko cross attention transformer human action recognition proceeding winter conference application computer vision wacv waikoloa hi usa january 2023 pp tishby zaslavsky deep learning information bottleneck principle proceeding information theory workshop itw jerusalem israel 26 may 2015 cikel arzamendia lopez gregor gutiérrez toral evaluation cnn lstm system classiﬁcation step proceeding xix conference spanish association artiﬁcial intelligence caepia malaga spain september 2021 cao xu li user authentication gait data smartphone sensor using hybrid deep learning network mathematics 2022 10 2283 crossref halikowski deep model automated assessment activity single worker sensor 2020 20 2571 crossref mohan action recognition using dynamic kernel pattern recognit 2022 122 108282 wang zheng yang zheng chen tang luo pedestrian attribute recognition survey pattern recognit 2022 121 108220 crossref perez liu kot relational reasoning group activity analysis pattern recognit 2022 122 108360 crossref gedamu ji yang gao shen human action recognition via action generation pattern recognit 2021 118 108043 crossref yang dong ding brighton zhan zhao recognition activity using monitoring system pattern recognit 2021 116 107955 crossref zhu wan li tian hou yuan dyadic relational graph convolutional network human interaction recognition pattern recognit 2021 115 107920 crossref ulhaq akhtar pogrebna mian vision transformer action recognition survey arxiv 2022 mazzia angarano salvetti angelini chiaberge action transformer model human action recognition pattern recognit 2022 124 108487 crossref horn schunk determining optical flow artif intell 1981 17 crossref kuehne jhuang stiefelhagen serre thomas large video database human motion recognition transaction high performance computing center stuttgart hlrs springer germany 2013 crossref soomro zamir shah dataset 101 human action class video wild arxiv 2012 crossref kthactiondataset available online accessed 26 march 2023 grandini bagli visani metric classiﬁcation overview arxiv 2020 entropy 2023 25 844 15 15 tran wang torresani ray le cun paluri closer look spatiotemporal convolution action recognition proceeding conference computer vision pattern recognition cvpr salt lake city ut usa june 2018 nasir raza shah khan rehman human action recognition using machine learning uncontrolled environment proceeding international conference artiﬁcial intelligence data analytics riyadh saudi arabia april 2021 zhang xiao lin chen liu tong deconvolutional network unsupervised representation learning human motion ieee trans cybern 2020 52 crossref wang chukova nguyen implementation analysis centroid neighbor advanced data mining application proceeding international 2022 brisbane qld australia november 2022 springer germany 2022 crossref wang chukova nguyen ensemble neighbor based centroid displacement inf sci 2023 629 crossref wang xiong wang qiao lin tang van gool temporal segment network towards good practice deep action recognition proceeding european conference computer vision eccv amsterdam netherlands october 2016 pp simonyan zisserman convolutional network action recognition video proceeding conference neural information processing system nip montreal ca usa december 2014 pp du bourdev fergus torresani paluri learning spatiotemporal feature convolutional network proceeding international conference computer vision santiago chile december 2015 pp qiu yao mei venice learning representation residual network proceeding international conference computer vision iccv venice italy october 2017 pp zhou sun zha zeng mict mixed convolutional tube human action recognition proceeding conference computer vision pattern recognition cvpr salt lake city ut usa june 2018 pp tu li zhang dauwels li emphasized spatiotemporal vlad video action recognition ieee trans image process 2019 28 crossref li xie zhang ding tong dual attention convolutional network action recognition iet image process 2020 14 crossref perrett masullo burghardt mirmehdi damen crosstransformers action recognition proceeding conference computer vision pattern recognition virtual june 2021 pp chen meng tang tong attention module based residual network human action recognition sensor 2023 23 1707 crossref omi kimata tamaki learning adapter action recognition ieice trans inf syst 2022 105 crossref bregonzio xiang gong fusing appearance distribution information interest point action recognition pattern recognit 2012 45 crossref ji xu yang yu convolutional neural network human action recognition ieee trans pattern anal mach intell 2013 crossref cho lee chang robust action recognition using local motion group sparsity pattern recognit 2014 47 crossref yao liu huang information human action recognition image video proc 2016 39 crossref zhang tian guo daal deep activationbased computer attribute learning action recognition depth video vi image underst 2018 167 crossref mishra kavimandan kapoor modal frequency based human action recognition using silhouette simplicial element ije trans basic 2022 35 wang tong ji wu tdn temporal difference network efﬁcient action recognition proceeding conference computer vision pattern recognition cvpr virtual june 2021 pp note statement opinion data contained publication solely individual author contributor not mdpi editor mdpi editor disclaim responsibility any injury people property resulting any idea method instruction product referred content