21 jul 2018 recent advance deep learning overview matiur rahman minar jibon naher department computer science engineering chittagong university engineering technology bangladesh editor abstract deep learning one newest trend machine learning artiﬁcial intelligence research also one popular scientiﬁc research trend deep learning method brought revolutionary advance computer vision machine learning every new new deep learning technique born outperforming machine learning even existing deep learning technique recent year world ha seen many major breakthrough ﬁeld since deep learning evolving huge speed kind hard keep track regular advance especially new researcher paper going brieﬂy discus recent advance deep learning past year keywords neural network machine learning deep learning recent advance overview introduction term deep learning dl wa ﬁrst introduced machine learning ml 1986 later used artiﬁcial neural network ann 2000 schmidhuber 2015 deep learning method composed multiple layer learn feature data multiple level abstraction lecun et 2015 dl approach allow computer learn cated concept building simpler one goodfellow et 2016 cial neural network ann deep learning dl aka hierarchical learning deng yu 2014 assigning credit many computational stage accurately transform aggregate activation network schmidhuber 2014 learn complicated function deep architecture used multiple level abstraction operation anns many hidden layer bengio 2009 sum accurately deep learning machine learning us many level information cessing abstraction supervised unsupervised feature learning representation classiﬁcation pattern recognition deng yu 2014 deep learning representation learning class machine learning recent deep learning method mostly said developed since 2006 deng 2011 paper overview recent technique deep learning mainly recommended upcoming researcher ﬁeld article includes basic idea dl major approach method recent breakthrough application 1 overview paper found beneﬁcial especially new researcher particular ﬁeld often hard keep track contemporary advance research area provided ﬁeld ha great value near future related application scientiﬁc research attractive profession since knowledge education shared available ever technological research trend only normal assume numerous advance improvement various way overview particular ﬁeld couple year back may turn obsolete today considering popularity expansion deep learning recent year present brief overview deep learning well neural network nn major advance critical breakthrough past year hope paper help many novice researcher ﬁeld getting overall picture recent deep learning research technique guiding right way start also hope pay some tribute work top dl ann researcher era geoﬀrey ton hinton juergen schmidhuber schmidhuber yann lecun lecun yoshua bengio bengio many others worked meticulously shape modern artiﬁcial ligence ai also important follow work stay updated dl ml research paper ﬁrstly provide short description past overview paper deep learning model approach start describing recent advance ﬁeld going discus deep learning dl approach deep architecture deep neural network dnn deep generative model dgm followed important regularization optimization method also two brief section dl framework signiﬁcant dl application finally discus current status future deep learning last two section discussion conclusion related work many overview paper deep learning dl past year described dl method approach great way well application direction future research going brief some outstanding overview paper deep learning young et al 2017 talked dl model architecture mainly used natural language processing nlp showed dl application various nlp ﬁelds compared dl model discussed possible future trend zhang et al 2017 discussed deep learning technique speech recognition system zhu et al 2017 presented overview dl remote sensing also discussed dl framework technical detail deep learning wang et al described evolution deep learning model ner briefed model graphically along breakthrough dl research paper would good read know origin deep learning evolutionary manner also mentioned optimization future research neural network goodfellow et al 2016 discussed deep network generative model detail starting machine learning ml basic pro con deep architecture concluded recent dl research application thoroughly 2 lecun et al 2015 published overview deep learning dl model lutional neural network cnn recurrent neural network rnn described dl perspective representation learning showing dl technique work getting used successfully various application predicting future learning based unsupervised learning ul also pointed article major advance dl bibliography schmidhuber 2015 generic historical overview deep learning along cnn rnn deep reinforcement learning rl emphasized rnns pointing limitation fundamental dl nns trick improve nielsen 2015 described neural network detail along code example also discussed deep neural network deep learning some extent schmidhuber 2014 covered history evolution neural network based time progression categorized machine learning approach us deep learning neural network deng yu 2014 described deep learning class technique application dl several area bengio 2013 quick overview dl algorithm supervised unsupervised network optimization training model perspective representation learning focused many challenge deep learning scaling algorithm larger model data reducing optimization diﬃculties designing eﬃcient scaling method etc along optimistic dl research bengio et al 2013 discussed representation feature learning aka deep ing explored various method model perspective application technique challenge deng 2011 gave overview deep structured learning architecture perspective information processing related ﬁelds arel et al 2010 provided short overview recent dl technique bengio 2009 discussed deep architecture neural network generative model ai recent overview paper deep learning dl discussed important thing several perspective necessary go dl researcher however dl highly ﬂourishing ﬁeld right many new technique architecture invented even recently published overview paper dl also previous paper focus diﬀerent perspective paper mainly new learner novice researcher new ﬁeld purpose try give basic clear idea deep learning new researcher anyone interested ﬁeld recent advance section discus main recent deep learning dl approach derived machine learning brief evolution artiﬁcial neural network ann common form used deep learning 3 evolution deep architecture artiﬁcial neural network ann come long way well deep model first generation anns wa composed simple neural layer perceptron limited simple computation second generation used backpropagation update weight neuron according error rate support vector machine svm surfaced surpassed anns overcome limitation backpropagation restricted boltzmann machine wa proposed making learning easier technique neural network came well feedforward neural network fnn convolutional neural netowrks cnn recurrent neural network rnn etc along deep belief network autoencoders hinton next generation neural network point anns got improved designed various way various purpose schmidhuber 2014 bengio 2009 deng yu 2014 goodfellow et al 2016 wang et al etc provided detailed overview evolution history deep neural network dnn well deep learning dl deep architecture multilayer repetition simple architecture case help obtain highly complex function input lecun et 2015 deep learning approach deep neural network dnn gained huge success supervised learning sl also deep learning dl model immensely successful unsupervised hybrid reinforcement learning well lecun et 2015 deep supervised learning supervised learning applied data labeled classiﬁer used class numeric prediction lecun et al 2015 provided brief yet good explanation supervised learning approach deep architecture formed deng yu 2014 mentioned many deep network supervised hybrid learning explained deep stacking network dsn variant schmidhuber 2014 covered neural network starting early neural network recently successful convolutional neural network cnn recurrent neural network rnn long short term memory lstm improvement deep unsupervised learning input data not labeled unsupervised learning approach applied extract tures data classify label lecun et al 2015 predicted future deep learning unsupervised learning schmidhuber 2014 described neural network pervised learning well deng yu 2014 briefed deep architecture unsupervised learning explained deep autoencoders detail deep reinforcement learning reinforcement learning us reward punishment system next move generated learning model mostly used game robot solves usually decision making 4 problem li 2017 schmidhuber 2014 described advance deep learning ment learning rl us deep feedforward neural netowrk fnn recurrent neural network rnn rl li 2017 discussed deep reinforcement learning drl architecture deep dqn application various ﬁelds mnih et al 2016 proposed drl framework using asynchronous gradient descent dnn optimization van hasselt et al 2015 proposed drl architecture using deep neural network dnn deep neural network section brieﬂy discus deep neural network dnn recent improvement breakthrough neural network work functionality lar human brain composed neuron connection mainly saying deep neural network assume quite number hidden layer used extract feature input compute complex function bengio 2009 explained neural network deep architecture convolutional neural network cnn ae etc variant deng yu 2014 tailed some neural network architecture ae variant goodfellow et al 2016 wrote skillfully explained deep feedforward network convolutional network recurrent recursive network improvement schmidhuber 2014 mentioned full history neural network early neural network recent successful technique deep autoencoders autoencoders ae neural network nn output input ae take original input encodes compressed representation decodes reconstruct input wang deep ae lower hidden layer used encoding higher one decoding error used training deng yu 2014 goodfellow et al 2016 variational autoencoders variational vae counted decoder wang vaes built upon standard neural network trained stochastic gradient descent doersch 2016 stacked denoising autoencoders early ae encoding layer smaller dimension input layer stacked denoising sdae encoding layer wider input layer deng yu 2014 transforming autoencoders deep dae extracted feature multilayers processing could changed due learner ing tae work input vector target output vector apply 5 property lead code towards desired way deng yu 2014 deep convolutional neural network four basic idea make convolutional neural network cnn local connection shared weight pooling using many layer first part cnn made tional pooling layer latter part mainly fully connected layer convolutional layer detect local conjunction feature pooling layer merge similar feature one lecun et 2015 cnns use convolution instead matrix multiplication convolutional layer goodfellow et 2016 krizhevsky et al 2012 presented deep convolutional neural network cnn tecture also known alexnet wa major breakthrough deep learning dl network composed ﬁve convolutional layer three fully connected layer architecture used graphic processing unit gpu convolution operation rectiﬁed linear unit relu activation function dropout srivastava et 2014 reduce overﬁtting iandola et al 2016 proposed small cnn architecture called squeezenet szegedy et al 2014 proposed deep cnn architecture named inception ment proposed dai et al 2017 redmon et al 2015 proposed cnn architecture named yolo only look uniﬁed object detection zeiler fergus 2013 proposed method visualizing activity within cnn gehring et al 2017 proposed cnn architecture learning bansal et al 2017 proposed pixelnet using pixel representation goodfellow et al 2016 explained basic cnn architecures idea gu et al 2015 presented nice overview recent advance cnns multiple variant cnn architecture regularization method functionality application various ﬁelds deep convolutional neural network convolutional neural network mpcnn operate mainly convolution especially used digital image processing mpcnn generally consists three type layer input layer convolutional layer take input image generate map apply activation function layer sample image keep maximum value layer doe linear multiplication masci et deep mpcnn convolutional layer used periodically input layer followed layer giusti et 2013 deep convolutional neural network simonyan zisserman proposed deep convolutional neural network cnn architecture also known vgg net vgg net use small convolution ﬁlters depth weight layer conneau et al 2016 proposed another vdcnn architecture text classiﬁcation us small convolution pooling claimed architecture ﬁrst 6 vdcnn used text processing work character level architecture composed 29 convolution layer network network lin et al 2013 proposed network network nin nin replaces convolution layer traditional convolutional neural network cnn micro neural network complex structure us perceptron mlpconv micro neural network global average pooling layer instead fully connected layer deep nin architecture made proposed nin structure lin et 2013 convolutional neural network girshick et al 2014 proposed convolutional neural network us region recognition us region localize segment object chitecture consists three module category independent region proposal deﬁnes set candidate region large convolutional neural network cnn extracting tures region set class speciﬁc linear support vector machine svm girshick et 2014 fast girshick 2015 proposed fast convolutional network fast method exploit girshick et 2014 architecture produce fast result fast consists convolutional pooling layer proposal region sequence fully connected layer girshick 2015 faster ren et al 2015 proposed faster convolutional neural network faster cnn us region proposal network rpn object detection rpn fully convolutional network generates region proposal accurately eﬃciently ren et 2015 mask et al 2017 proposed mask convolutional network mask stance object segmentation mask extends faster ren et 2015 tecture us extra branch object mask et 2017 lee et al 2017 proposed convolutional neural network exploit fast girshick 2015 architecture generates region interest roi selective exhaustive search also us expert network instead single network expert architecture fully connected layer fast lee et 2017 7 deep residual network et al 2015 proposed residual network resnets consists 152 layer resnets lower error easily trained residual learning deeper resnets achieve better performance resnets considered important advance ﬁeld deep learning resnet resnet targ et al 2016 proposed resnet resnet rir combine resnets et 2015 standard convolutional neural network cnn deep dual stream ture targ et 2016 resnext xie et al 2016 proposed resnext architecture resnext exploit resnets et 2015 repeating layer strategy xie et 2016 capsule network sabour et al 2017 proposed capsule network capsnet architecture two volutional layer one fully connected layer capsnet usually contains several lution layer capsule layer end xi et 2017 capsnet considered one recent breakthrough deep learning xi et 2017 since said build upon limitation convolutional neural network hinton us er capsule instead layer neuron capsule set neuron active lower level capsule make prediction upon agreeing multiple prediction higher level capsule becomes active mechanism used capsule er improvement capsnet proposed em routing anonymous using em algorithm recurrent neural network recurrent neural network rnn better suited sequential input like speech text generating sequence recurrent hidden unit considered deep feedforward network weight unfolded time rnns used diﬃcult train gradient vanishing exploding problem lecun et 2015 many improvement proposed later solve problem goodfellow et al 2016 provided detail recurrent recursive neural network architecture variant along related gated memory network karpathy et al 2015 used language model analyzing ing prediction representation training dynamic error type rnn variant lstms ozefowicz et al 2016 explored rnn model limitation language modelling 8 peng yao 2015 proposed recurrent neural network external memory em improve memory capacity rnns claimed achieve language understanding better rnns chung et al 2015 proposed gated feedback recurrent neural network extends standard rnn stacking multiple recurrent layer global gating unit zheng et al 2015 proposed conditional random field recurrent neural network combine convolutional neural network cnns conditional random field crfs probabilistic graphical modelling bradbury et al 2016 proposed quasi recurrent neural network qrnn neural quence modelling appling parallel across timesteps memory network weston et al 2014 proposed memory network question answering qa memory network composed memory input feature map generalization output feature map response weston et 2014 dynamic memory network kumar et al 2015 proposed dynamic memory network dmn qa task dmn ha four module input question episodic memory output kumar et 2015 augmented neural network olah carter 2016 gave nice presentation attentional augmented recurrent neural network neural turing machine ntm attentional interface neural grammer adaptive computation time augmented neural network usually made using extra property like logic function along standard neural network ture olah carter 2016 neural turing machine graf et al 2014 proposed neural turing machine ntm architecture consisting neural network controller memory bank ntms usually combine rnns external memory bank olah carter 2016 9 neural gpu kaiser sutskever 2015 proposed neural gpu solves parallel problem ntm graf et 2014 neural machine kurach et al 2015 proposed neural random access machine us external memory neural programmer neelakantan et al 2015 proposed neural programmer augmented neural network arithmetic logic function neural reed de freitas 2015 proposed neural npi learn npi consists recurrent core program memory encoders reed de freitas 2015 long short term memory network hochreiter schmidhuber 1997 proposed long memory lstm overcomes error problem recurrent neural network rnn lstm based recurrent network along learning algorithm hochreiter schmidhuber 1997 lstm introduced produce path gradient ﬂow goodfellow et 2016 greﬀet al 2017 provided analysis vanilla lstm eight lstm ant three us speech recognition handwriting recognition polyphonic music modeling claimed eight variant lstm failed perform signiﬁcant ment only vanilla lstm performs well greﬀet 2015 shi et al proposed deep long memory dlstm stack lstm unit feature mapping learn representation shi et lstm cooijmans et al 2016 proposed lstm us normalizing hidden state recurrent neural network pixel rnn van den oord et al proposed pixel recurrent neural network pixelrnn made twelve lstm layer bidirectional lstm ollmer et al 2010 proposed bidirection lstm blstm recurrent network used dynamic bayesian network dbn keyword detection 10 variational shabanian et al 2017 proposed variational variant bidirectional lstm architecture variational creates channel information exchange tween lstms using variational vae learning better representation shabanian et 2017 google neural machine translation wu et al 2016 proposed google neural machine translation gnmt system tomated translation incorporates encoder network decoder network attention network following common learning framework fader network lample et al 2017 proposed fader network new type architecture generate realistic variation input image changing attribute value hyper network ha et al 2016 proposed hypernetworks generates weight neural work static hypernetworks convolutional network dynamic hypernetworks recurrent network deutsch 2018 used hyper network generating neural network highway network srivastava et al 2015 proposed highway network us gating unit learn ulating information information ﬂow across several layer called information highway srivastava et 2015 recurrent highway network zilly et al 2017 proposed recurrent highway network rhn extend long term memory lstm architecture rhns use highway layer inside recurrent tion zilly et 2017 highway lstm rnn zhang et al proposed highway long memory hlstm rnn extends deep lstm network gated direction connection highway memory cell adjacent layer recurrent cnn donahue et al 2014 proposed recurrent convolutional network lrcn us cnn input lstm recurrent sequence modeling generating prediction 11 deep neural svm zhang et al proposed deep neural support vector machine dnsvm us support vector machine svm top layer classiﬁcation deep neural network dnn convolutional residual memory network moniz pal 2016 proposed convolutional residual memory network rate memory mechanism convolutional neural network cnn augments volutional residual network long short term memory mechanism moniz pal 2016 fractal network larsson et al 2016 proposed fractal network fractalnet alternative residual net claimed train ultra deep neural network without residual learning fractal repeated architecture generated simple expansion rule larsson et 2016 wavenet van den oord et al proposed wavenet deep neural network generating raw audio wavenet composed stack convolutional layer softmax distribution layer output van den oord et rethage et al 2017 proposed wavenet model speech denoising pointer network vinyals et al 2017 proposed pointer network solves problem resenting variable dictionary using softmax probability distribution called pointer deep generative model section brieﬂy discus deep architecures us multiple level abstraction representation similar deep neural network also known deep generative model dgm bengio 2009 explained deep architecture boltzmann machine bm restricted boltzmann machine rbm etc variant goodfellow et al 2016 explained deep generative model detail restricted unrestricted boltzmann machine variant deep boltzmann machine deep belief network dbn directed generative net generative stochastic network etc maaløe et al 2016 proposed auxiliary deep generative model extended deep generative model auxiliary variable auxiliary variable make variational distribution stochastic layer skip connection maaløe et 2016 rezende et al 2016 developed class generalization deep generative model 12 boltzmann machine boltzmann machine connectionist approach learning arbitrary probability tions use maximum likelihood principle learning goodfellow et 2016 restricted boltzmann machine restricted boltzmann machine rbm special type markov random ﬁeld containing one layer stochastic hidden unit latent variable one layer observable variable deng yu 2014 goodfellow et al 2016 hinton salakhutdinov 2011 proposed deep generative model using restricted boltzmann machine rbm document processing deep belief network deep belief network dbn generative model several layer latent binary real variable goodfellow et 2016 ranzato et al 2011 built deep generative model using deep belief network dbn image recognition deep lambertian network tang et al 2012 proposed deep lambertian network dln multilayer ative model latent variable albedo surface normal light source dln combination lambertian reﬂectance gaussian restricted boltzmann machine deep belief network tang et 2012 generative adversarial network goodfellow et al 2014 proposed generative adversarial net gan estimating erative model adversarial process gan architecture composed generative model pitted adversary discriminative model learn model data bution goodfellow et 2014 some improvement proposed gan mao et al 2016 kim et al 2017 etc salimans et al 2016 presented several method training gans laplacian generative adversarial network denton et al 2015 proposed deep generative model dgm called laplacian tive adversarial network lapgan using generative adversarial network gan proach model also us convolutional network within laplacian pyramid framework denton et 2015 recurrent support vector machine shi et al proposed recurrent support vector machine rsvm us current neural network rnn extracting feature input sequence standard support vector machine svm objective discrimination 13 training optimization technique section provide short overview some major technique regularization optimization deep neural network dnn dropout srivastava et al 2014 proposed dropout prevent neural network overﬁtting dropout neural network regularization method adding noise hidden unit drop unit neural network along connection randomly training dropout used any kind neural network even graphical model like rbm srivastava et 2014 recent proposed improvement dropout fraternal dropout anonymous recurrent neural network rnn maxout goodfellow et al 2013 proposed maxout new activation function used dropout srivastava et 2014 maxout output maximum set input beneﬁcial dropout model averaging goodfellow et 2013 zoneout krueger et al 2016 proposed zoneout regularization method recurrent neural work rnn zoneout us noise randomly training similar dropout srivastava et 2014 preserve hidden unit instead dropping krueger et 2016 deep residual learning et al 2015 proposed deep residual learning framework deep neural network dnn called resnets lower training error batch normalization ioﬀe szegedy 2015 proposed batch normalization method accelerating deep neural network training reducing internal covariate shift ioﬀe 2017 proposed batch renormalization extending previous approach distillation hinton et al 2015 proposed distillation transferring knowledge ensemble highly regularized model neural network compressed smaller model layer normalization ba et al 2016 proposed layer normalization training deep neural work especially rnns solves limitation batch normalization ioﬀe szegedy 2015 14 deep learning framework good number library framework available deep learning built python programming language theano bergstra et 2011 tensorﬂow abadi et 2016 pytorch pybrain schaul et 2010 caﬀe jia et 2014 block fuel van enboer et 2015 cudnn chetlur et 2014 honk tang lin 2017 chainercv niitani et 2017 chainer torch neon etc bahrampour et al 2015 comparative study several deep learning framework application deep learning section brieﬂy discus some recent outstanding application deep learning architecture since beginning deep learning dl dl method used various ﬁelds form supervised unsupervised reinforcement learning starting classiﬁcation detection task dl application spreading rapidly every ﬁelds image classiﬁcation recognition simonyan zisserman krizhevsky et al 2012 et al 2015 video classiﬁcation karpathy et 2014 sequence generation graf 2013 defect classiﬁcation masci et text speech image video processing lecun et 2015 text classiﬁcation conneau et 2016 speech processing arel et 2009 speech recognition spoken language understanding hinton et al 2012 zhang et al zhang et al zhang et al zhang et al shi et al mesnil et al 2015 peng yao 2015 amodei et al 2015 generation wang et al arik et al 2017 query classiﬁcation shi et sentence classiﬁcation kim 2014 sentence modelling kalchbrenner et 2014 word processing mikolov et premise selection alemi et 2016 document sentence processing le mikolov 2014 mikolov et al generating image caption vinyals et al 2014 xu et al 2015 15 photographic style transfer luan et 2017 natural image manifold zhu et 2016 image colorization zhang et image question answering yang et 2015 generating texture stylized image ulyanov et 2016 visual textual question answering xiong et al 2016 dblp visual recognition description donahue et al 2014 razavian et al 2014 oquab et al 2014 object detection lee et al 2017 ranzato et al 2011 redmon et al 2015 liu et al 2015 document processing hinton salakhutdinov 2011 character motion synthesis editing holden et 2016 singing synthesis blaauw bonada 2017 person identiﬁcation li et 2014 face recognition veriﬁcation taigman et 2014 action recognition video simonyan zisserman human action recognition ji et 2013 action recognition sharma et 2015 classifying visualizing motion capture sequence cho chen 2013 handwriting generation prediction carter et 2016 automated machine translation wu et al 2016 cho et al 2014 bahdanau et al 2014 hermann et al 2015 luong et al 2015 named entity recognition lample et 2016 mobile vision howard et 2017 conversational agent ghazvininejad et 2017 calling genetic variant poplin et 2016 cancer detection et 2013 ct reconstruction kang et 2016 epileptic seizure prediction mirowski et 2008 16 hardware acceleration han et 2016 robotics lenz et 2013 name deng yu 2014 provided detailed list dl application various category speech audio processing information retrieval object recognition computer vision multimodal learning etc using deep reinforcement learning drl mastering game ha become hot topic every ai bot created dnn drl beating man world champion grandmaster strategical game only hour training example alphago alphago zero game go silver et al silver et al 2016 dong et al 2017 batsford 2014 atari mnih et al 2013 mnih et al 2015 van hasselt et al 2015 chess shougi silver et discussion though deep learning ha achieved tremendous success many area still ha long way go many room left improvement limitation list quite long well example nguyen et al 2014 showed deep neural network dnn easily fooled recognizing image issue like transferability feature learned yosinski et 2014 huang et al 2017 proposed architecture adersarial attack neural network think future work needed defense attack zhang et al presented experimental framework understanding deep learning model think understanding deep learning requires rethinking generalization marcus 2018 gave important review deep learning dl doe limit nature strongly pointed limitation dl method requiring data limited capacity inability deal hierarchical structure struggling inference not suﬃciently transparent not well integrated prior knowledge inability distinguish causation correlation marcus 2018 also mentioned dl assumes stable world work approximation diﬃcult engineer ha potential risk excessive hype marcus 2018 think dl need reconceptualized look possibility unsupervised learning symbol manipulation hybrid model insight cognitive science psychology taking bolder challenge conclusion although deep learning dl ha advanced world faster ever still way go still away fully understanding deep learning work get machine smarter close smarter human learning exactly like human dl ha solving many problem taking technology another dimension however many diﬃcult problem humanity deal example people still dying hunger food crisis cancer lethal disease etc hope deep learning ai much devoted betterment humanity carry 17 hardest scientiﬁc research last not least make world better place every single human acknowledgment would like thank mohammed moshiul hoque professor department cse cuet introducing u amazing world deep learning reference ın abadi ashish agarwal paul barham eugene brevdo zhifeng chen craig citro gregory corrado andy davis jeﬀrey dean matthieu devin sanjay ghemawat ian goodfellow andrew harp geoﬀrey irving michael isard yangqing jia rafal ozefowicz lukasz kaiser manjunath kudlur josh levenberg dan e rajat monga sherry moore derek gordon murray chris olah mike schuster jonathon shlens benoit steiner ilya sutskever kunal talwar paul tucker vincent vanhoucke vijay vasudevan fernanda egas oriol vinyals pete warden martin wattenberg tin wicke yuan yu xiaoqiang zheng tensorﬂow machine learning heterogeneous distributed system corr alexander alemi cois chollet geoﬀrey irving christian szegedy josef urban deepmath deep sequence model premise selection corr dario amodei rishita anubhai eric battenberg carl case jared casper bryan zaro jingdong chen mike chrzanowski adam coates greg diamos erich elsen jesse engel linxi fan christopher fougner tony han awni hannun billy jun patrick legresley libby lin sharan narang andrew ng sherjil ozair ryan prenger jonathan raiman sanjeev satheesh david seetapun shubho sengupta yi wang zhiqian wang chong wang bo xiao dani yogatama jun zhan zhenyao zhu deep speech 2 speech recognition english mandarin corr anonymous fraternal dropout international conference learning representation url anonymous matrix capsule em routing international conference learning resentations url itamar arel derek rose tom karnowski deep learning architecture comprising homogeneous cortical circuit scalable spatiotemporal pattern inference proc nip workshop deep learn speech page itamar arel derek rose thomas karnowski research frontier deep chine new frontier artiﬁcial intelligence research comp intell 5 4 november issn doi url 18 sercan omer arik mike chrzanowski adam coates greg diamos andrew gibiansky yongguo kang xian li john miller jonathan raiman shubho sengupta hammad shoeybi deep voice neural corr lei jimmy ba ryan kiros geoﬀrey hinton layer normalization corr dzmitry bahdanau kyunghyun cho yoshua bengio neural machine translation jointly learning align translate corr soheil bahrampour naveen ramakrishnan lukas schott mohak shah comparative study caﬀe neon theano torch deep learning corr aayush bansal xinlei chen bryan russell abhinav gupta deva ramanan net representation pixel pixel pixel corr tom batsford calculating optimal jungling route using neural network genetic algorithm game behaviour 1 1 url yoshua bengio url mila university montreal quebec canada yoshua bengio learning deep architecture ai found trend mach 2 1 january issn doi url yoshua bengio deep learning representation looking forward corr yoshua bengio aaron courville pascal vincent representation learning review new perspective ieee trans pattern anal mach 35 8 august issn doi url james bergstra olivier breuleux eric bastien pascal lamblin razvan pascanu laume desjardins joseph turian david yoshua bengio theano cpu gpu math compiler python merlijn blaauw jordi bonada neural parametric singing synthesizer corr james bradbury stephen merity caiming xiong richard socher neural network corr carter david ha ian johnson chris olah experiment ing neural network distill doi url 19 sharan chetlur cliﬀwoolley philippe vandermersch jonathan cohen john tran bryan catanzaro evan shelhamer cudnn eﬃcient primitive deep learning corr kyunghyun cho xi chen classifying visualizing motion capture sequence using deep neural network corr kyunghyun cho bart van merrienboer c cehre fethi bougares holger schwenk yoshua bengio learning phrase representation using rnn statistical machine translation corr junyoung chung caglar gulcehre kyunghyun cho yoshua bengio gated feedback recurrent neural network proceeding international conference ternational conference machine learning volume 37 icml 15 page url alexis conneau holger schwenk ıc barrault yann lecun deep convolutional network text classiﬁcation corr tim cooijmans nicolas ballas esar laurent aaron courville recurrent batch normalization corr angel alfonso john edison arevalo ovalle anant madabhushi fabio gusto alez osorio deep learning architecture image representation visual interpretability automated carcinoma cancer detection page springer berlin heidelberg berlin heidelberg isbn doi 10 url jifeng dai haozhi qi yuwen xiong yi li guodong zhang han hu yichen wei deformable convolutional network corr li deng overview learning information processing 01 li deng dong yu deep learning method application found trend signal 7 3 8211 4 june issn doi url emily denton soumith chintala arthur szlam robert fergus deep generative image model using laplacian pyramid adversarial network corr lior deutsch generating neural network neural network corr url carl doersch tutorial variational autoencoders corr url jeﬀdonahue lisa anne hendricks sergio guadarrama marcus rohrbach subhashini venugopalan kate saenko trevor darrell recurrent convolutional work visual recognition description corr 2014 20 xiao dong jiasong wu ling zhou demystifying alphago zero alphago gan corr jonas gehring michael auli david grangier denis yarats yann dauphin volutional sequence sequence learning corr marjan ghazvininejad chris brockett chang bill dolan jianfeng gao tau yih michel galley neural conversation model corr ross girshick jeﬀdonahue trevor darrell jitendra malik rich feature hierarchy accurate object detection semantic segmentation proceeding ieee conference computer vision pattern recognition cvpr ross girshick fast corr alessandro giusti dan ciresan jonathan masci luca maria gambardella urgen schmidhuber fast image scanning deep convolutional neural network ieee international conference image processing icip 2013 melbourne australia september 2013 page doi url ian goodfellow david mehdi mirza aaron courville yoshua bengio maxout network sanjoy dasgupta david mcallester editor proceeding international conference machine learning volume 28 proceeding machine learning research page atlanta georgia usa jun pmlr url ian goodfellow jean mehdi mirza bing xu david farley sherjil ozair aaron courville yoshua bengio generative versarial net ghahramani welling cortes lawrence weinberger editor advance neural information ing system 27 page curran associate url ian goodfellow yoshua bengio aaron courville deep learning mit press alex graf generating sequence recurrent neural network corr alex graf greg wayne ivo danihelka neural turing machine corr klaus greﬀ rupesh kumar srivastava jan ık ba steunebrink urgen schmidhuber lstm search space odyssey corr klaus greﬀ rupesh kumar srivastava jan ık ba steunebrink urgen schmidhuber lstm search space odyssey ieee trans neural netw ing 28 10 doi url 21 jiuxiang gu zhenhua wang jason kuen lianyang amir shahroudy bing shuai ting liu xingxing wang gang wang recent advance convolutional neural network corr david ha andrew dai quoc le hypernetworks corr song han xingyu liu huizi mao jing pu ardavan pedram mark horowitz william dally eie eﬃcient inference engine compressed deep neural network corr kaiming url facebook ai research fair kaiming xiangyu zhang shaoqing ren jian sun deep residual learning image recognition corr kaiming georgia gkioxari piotr ar ross girshick mask corr karl moritz hermann edward grefenstette lasse espeholt kay mustafa suleyman phil blunsom teaching machine read comprehend corr geoﬀrey hinton url university toronto u ontario canada google brain team geoﬀrey hinton ruslan salakhutdinov discovering binary code ments learning deep generative model topic cognitive science 3 1 issn doi url geoﬀrey hinton li deng dong yu george dahl abdel rahman mohamed navdeep jaitly andrew senior vincent vanhoucke patrick nguyen tara sainath brian kingsbury deep neural network acoustic modeling speech recognition signal processing magazine geoﬀrey hinton oriol vinyals jeﬀrey dean distilling knowledge neural network nip deep learning representation learning workshop url sepp hochreiter urgen schmidhuber long memory neural 9 8 november issn doi url daniel holden jun saito taku komura deep learning framework character motion synthesis editing acm trans 35 4 july issn doi url andrew howard menglong zhu bo chen dmitry kalenichenko weijun wang bias weyand marco andreetto hartwig adam mobilenets eﬃcient convolutional neural network mobile vision application corr 2017 22 sandy huang nicolas papernot ian goodfellow yan duan pieter abbeel adversarial attack neural network policy corr forrest iandola matthew moskewicz khalid ashraf song han william dally kurt keutzer squeezenet accuracy fewer parameter model size corr sergey ioﬀe batch renormalization towards reducing minibatch dependence normalized model corr sergey ioﬀe christian szegedy batch normalization accelerating deep network ing reducing internal covariate shift francis bach david blei editor ings international conference machine learning volume 37 proceeding machine learning research page lille france jul pmlr url shuiwang ji wei xu ming yang kai yu convolutional neural network human action recognition ieee trans pattern anal mach 35 1 january issn doi url yangqing jia evan shelhamer jeﬀdonahue sergey karayev jonathan long ross girshick sergio guadarrama trevor darrell caﬀe convolutional architecture fast feature embedding corr rafal ozefowicz oriol vinyals mike schuster noam shazeer yonghui wu exploring limit language modeling corr lukasz kaiser ilya sutskever neural gpus learn algorithm corr nal kalchbrenner edward grefenstette phil blunsom convolutional neural network modelling sentence corr eunhee kang junhong min jong chul ye wavenet deep convolutional ral network using directional wavelet ct reconstruction corr andrej karpathy george toderici sanketh shetty thomas leung rahul sukthankar li video classiﬁcation convolutional neural network proceeding 2014 ieee conference computer vision pattern nition cvpr 14 page washington dc usa ieee puter society isbn doi url andrej karpathy justin johnson li visualizing understanding recurrent network corr 2015 23 taeksoo kim moonsu cha hyunsoo kim jung kwon lee jiwon kim ing discover relation generative adversarial network corr yoon kim convolutional neural network sentence classiﬁcation corr alex krizhevsky ilya sutskever geoﬀrey hinton imagenet cation deep convolutional neural network proceeding international conference neural information processing system volume 1 nip 12 page usa curran associate url david krueger tegan maharaj ano ar mohammad pezeshki nicolas ballas nan rosemary ke anirudh goyal yoshua bengio hugo larochelle aaron courville chris pal zoneout regularizing rnns randomly preserving hidden activation corr ankit kumar ozan irsoy jonathan su james bradbury robert english brian pierce peter ondruska ishaan gulrajani richard socher ask anything dynamic memory network natural language processing corr karol kurach marcin andrychowicz ilya sutskever neural machine corr guillaume lample miguel ballesteros sandeep subramanian kazuya kawakami chris dyer neural architecture named entity recognition corr guillaume lample neil zeghidour nicolas usunier antoine bordes ludovic denoyer marc aurelio ranzato fader network manipulating image sliding attribute corr url gustav larsson michael maire gregory shakhnarovich fractalnet neural network without residual corr quoc le tomas mikolov distributed representation sentence document corr yann lecun url new york university nyu ny usa facebook ai research fair yann lecun yoshua bengio geoﬀrey hinton deep learning nature ep 05 url hyungtae lee sungmin eum heesung kwon cnn object detection corr ian lenz honglak lee ashutosh saxena deep learning detecting robotic grasp corr 2013 24 wei li rui zhao tong xiao xiaogang wang deepreid deep ﬁlter pairing ral network person ieee conference computer vision pattern recognition cvpr columbus usa june yuxi li deep reinforcement learning overview corr min lin qiang chen shuicheng yan network network corr wei liu dragomir anguelov dumitru erhan christian szegedy scott reed yang fu alexander berg ssd single shot multibox detector corr fujun luan sylvain paris eli shechtman kavita bala deep photo style transfer corr luong hieu pham christopher manning eﬀective approach neural machine translation corr lars maaløe casper kaae sønderby søren kaae sønderby ole winther auxiliary deep generative model proceeding international conference ternational conference machine learning volume 48 icml 16 page url xudong mao qing li haoran xie raymond lau zhen wang generative adversarial network loss function corr gary marcus deep learning critical appraisal corr url jonathan masci alessandro giusti dan ciresan gabriel fricout urgen huber fast learning algorithm image segmentation convolutional network ieee international conference image processing icip 2013 bourne australia september 2013 page doi url jonathan masci ueli meier gabriel fricout urgen schmidhuber pyramidal pooling network generic steel defect classiﬁcation 2013 ternational joint conference neural network ijcnn 2013 dallas tx usa august 2013 page doi url egoire mesnil yann dauphin kaisheng yao yoshua bengio li deng dilek ur xiaodong larry heck okhan ur dong yu geoﬀrey zweig using recurrent neural network slot ﬁlling spoken language understanding trans audio speech language processing 23 3 tomas mikolov kai chen greg corrado jeﬀrey dean eﬃcient estimation word representation vector space corr 25 tomas mikolov ilya sutskever kai chen greg corrado jeﬀrey dean distributed representation word phrase compositionality corr piotr mirowski yann lecun deepak madhavan ruben kuzniecky comparing svm convolutional network epileptic seizure prediction intracranial eeg proc machine learning signal processing mlsp 08 ieee volodymyr mnih koray kavukcuoglu david silver alex graf ioannis antonoglou daan wierstra martin riedmiller playing atari deep reinforcement learning corr volodymyr mnih koray kavukcuoglu david silver andrei rusu joel veness marc bellemare alex graf martin riedmiller andreas fidjeland georg ostrovski stig petersen charles beattie amir sadik ioannis antonoglou helen king kumaran daan wierstra shane legg demis hassabis trol deep reinforcement learning nature ep 02 url volodymyr mnih adri puigdom enech badia mehdi mirza alex graf timothy lillicrap tim harley david silver koray kavukcuoglu asynchronous method deep reinforcement learning corr joel moniz christopher pal convolutional residual memory network corr arvind neelakantan quoc le ilya sutskever neural programmer inducing latent program gradient descent corr anh mai nguyen jason yosinski jeﬀclune deep neural network easily fooled high conﬁdence prediction unrecognizable image corr michael nielsen neural network deep learning determination press yusuke niitani toru ogawa shunta saito masaki saito chainercv library deep learning computer vision corr chris olah carter attention augmented recurrent neural network distill doi url maxime oquab leon bottou ivan laptev josef sivic learning transferring level image representation using convolutional neural network proceeding 2014 ieee conference computer vision pattern recognition cvpr 14 page washington dc usa ieee computer society isbn doi url baolin peng kaisheng yao recurrent neural network external memory language understanding volume 2015 26 ryan poplin dan newburger jojo dijamco nam nguyen dion loy sam gross cory mclean mark depristo creating universal snp small indel variant caller deep neural network biorxiv url ranzato susskind mnih hinton deep generative model cation recognition proceeding 2011 ieee conference computer vision pattern recognition cvpr 11 page washington dc usa ieee computer society isbn doi url ali sharif razavian hossein azizpour josephine sullivan stefan carlsson cnn feature astounding baseline recognition corr joseph redmon santosh kumar divvala ross girshick ali farhadi only look uniﬁed object detection corr scott reed nando de freitas neural corr shaoqing ren kaiming ross girshick jian sun faster towards time object detection region proposal network neural information processing system nip dario rethage jordi pons xavier serra wavenet speech denoising corr danilo rezende shakir ivo danihelka karol gregor daan wierstra shot generalization deep generative model maria florina balcan kilian weinberger editor proceeding international conference machine learning volume 48 proceeding machine learning research page new york new york usa jun pmlr url sara sabour nicholas frosst geoﬀrey hinton dynamic routing capsule advance neural information processing system 30 annual conference neural information processing system 2017 9 december 2017 long beach ca usa page url tim salimans ian goodfellow wojciech zaremba vicki cheung alec radford xi chen improved technique training gans corr tom schaul justin bayer daan wierstra yi sun martin felder frank sehnke thomas uckstieß urgen schmidhuber pybrain mach learn march issn url schmidhuber deep learning scholarpedia 10 11 doi url vision 152272 27 juergen schmidhuber url idsia usi dalle molle institute artiﬁcial intelligence switzerland urgen schmidhuber deep learning neural network overview volume url samira shabanian devansh arpit adam trischler yoshua bengio variational lstms corr url shikhar sharma ryan kiros ruslan salakhutdinov action recognition using visual attention corr yangyang shi kaisheng yao hu chen dong yu pan hwang recurrent support vector machine slot tagging spoken language understanding page association computational linguistics yangyang shi kaisheng yao le tian daxin jiang deep lstm based feature ping query classiﬁcation page association computational linguistics david silver aja huang chris maddison arthur guez laurent sifre george van den driessche julian schrittwieser ioannis antonoglou veda panneershelvam marc tot sander dieleman dominik grewe john nham nal kalchbrenner ilya sutskever timothy lillicrap madeleine leach koray kavukcuoglu thore graepel demis hassabis mastering game go deep neural network tree search nature ep 01 url david silver thomas hubert julian schrittwieser ioannis antonoglou matthew lai arthur guez marc lanctot laurent sifre dharshan kumaran thore graepel othy lillicrap karen simonyan demis hassabis mastering chess shogi general reinforcement learning algorithm corr url david silver julian schrittwieser karen simonyan ioannis antonoglou aja huang arthur guez thomas hubert lucas baker matthew lai adrian bolton yutian chen timothy lillicrap fan hui laurent sifre george van den driessche thore graepel demis hassabis mastering game go without human knowledge nature ep 10 url karen simonyan andrew zisserman convolutional network action recognition video corr karen simonyan andrew zisserman deep convolutional network image recognition corr nitish srivastava geoﬀrey hinton alex krizhevsky ilya sutskever ruslan salakhutdinov dropout simple way prevent neural network ﬁtting journal machine learning research url 28 rupesh kumar srivastava klaus greﬀ urgen schmidhuber highway network corr url christian szegedy wei liu yangqing jia pierre sermanet scott reed dragomir anguelov dumitru erhan vincent vanhoucke andrew rabinovich going deeper convolution corr yaniv taigman ming yang marc aurelio ranzato lior wolf deepface closing gap performance face veriﬁcation proceeding 2014 ieee conference computer vision pattern recognition cvpr 14 page washington dc usa ieee computer society isbn doi url raphael tang jimmy lin honk pytorch reimplementation convolutional neural network keyword spotting corr yichuan tang ruslan salakhutdinov geoﬀrey hinton deep lambertian network 2 06 sasha targ diogo almeida kevin lyman resnet resnet generalizing residual architecture corr dmitry ulyanov vadim lebedev andrea vedaldi victor lempitsky texture work synthesis texture stylized image corr aron van den oord sander dieleman heiga zen karen simonyan oriol vinyals alex graf nal kalchbrenner andrew senior koray kavukcuoglu wavenet generative model raw audio corr aron van den oord nal kalchbrenner koray kavukcuoglu pixel recurrent neural network corr hado van hasselt arthur guez david silver deep reinforcement learning double corr bart van enboer dzmitry bahdanau vincent dumoulin dmitriy serdyuk david jan chorowski yoshua bengio block fuel framework deep learning corr oriol vinyals alexander toshev samy bengio dumitru erhan show tell neural image caption generator corr oriol vinyals meire fortunato navdeep jaitly pointer network corr url haohan wang bhiksha raj eric xing origin deep learning corr shenlong wang url university toronto u ontario canada 29 yuxuan wang daisy stanton yonghui wu ron wei navdeep jaitly zongheng yang ying xiao zhifeng chen samy bengio quoc le yannis agiomyrgiannakis rob clark rif saurous tacotron fully synthesis model corr jason weston sumit chopra antoine bordes memory network corr martin ollmer florian eyben alex graf orn schuller gerhard rigoll rectional lstm network keyword detection cognitive virtual agent framework cognitive computation 2 3 sep issn doi url yonghui wu mike schuster zhifeng chen quoc le mohammad norouzi wolfgang macherey maxim krikun yuan cao qin gao klaus macherey jeﬀklingner apurva shah melvin johnson xiaobing liu lukasz kaiser stephan gouws yoshikiyo kato taku kudo hideto kazawa keith stevens george kurian nishant patil wei wang cliﬀyoung jason smith jason riesa alex rudnick oriol vinyals greg corrado macduﬀhughes jeﬀrey dean google neural machine translation system bridging gap human machine translation corr edgar xi selina bing yang jin capsule network performance complex data corr url saining xie ross girshick piotr ar zhuowen tu kaiming aggregated residual transformation deep neural network corr caiming xiong stephen merity richard socher dynamic memory network visual textual question answering corr kelvin xu jimmy ba ryan kiros kyunghyun cho aaron courville ruslan dinov richard zemel yoshua bengio show attend tell neural image caption generation visual attention corr zichao yang xiaodong jianfeng gao li deng alexander smola stacked attention network image question answering corr jason yosinski jeﬀclune yoshua bengio hod lipson transferable feature deep neural network proceeding international conference neural information processing system volume 2 nip 14 page cambridge usa mit press url tom young devamanyu hazarika soujanya poria erik cambria recent trend deep learning based natural language processing corr matthew zeiler rob fergus visualizing understanding convolutional network corr chiyuan zhang samy bengio moritz hardt benjamin recht oriol vinyals standing deep learning requires rethinking generalization corr 30 richard zhang phillip isola alexei efros colorful image colorization corr zhang chaojun liu kaisheng yao yifan gong deep neural support vector machine speech recognition icassp page ieee yu zhang guoguo chen dong yu kaisheng yao sanjeev khudanpur james glass highway long memory rnns distant speech recognition corr yu zhang guoguo chen dong yu kaisheng yao sanjeev khudanpur james glass highway long memory rnns distant speech recognition icassp page ieee zixing zhang urgen geiger jouni pohjalainen amr mousa orn schuller deep learning environmentally robust speech recognition overview recent development corr shuai zheng sadeep jayasumana bernardino vibhav vineet zhizhong su dalong du chang huang philip torr conditional random ﬁelds recurrent neural network corr zhu philipp uhl eli shechtman alexei efros generative visual manipulation natural image manifold corr xiao xiang zhu devi tuia lichao mou xia liangpei zhang feng xu friedrich fraundorfer deep learning remote sensing review corr julian georg zilly rupesh kumar srivastava jan ık urgen schmidhuber recurrent highway network proceeding international conference machine learning icml 2017 sydney nsw australia august 2017 page 4198 url 31