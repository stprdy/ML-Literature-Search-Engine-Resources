received april 20 2014 accepted may 13 2014 date publication may 16 2014 date current version may 28 digital object identifier big data deep learning challenge perspective senior member ieee xiaotong computer science wayne state university detroit mi 48404 usa computer science engineering oakland university rochester mi 48309 usa corresponding author chen abstract deep learning currently extremely active research area machine learning pattern recognition society ha gained huge success broad area application speech recognition computer vision natural language processing sheer size data available today big data brings big opportunity transformative potential various sector hand also present unprecedented challenge harnessing data information data keep getting bigger deep learning coming play key role providing big data predictive analytics solution paper provide brief overview deep learning highlight current research effort challenge big data well future trend index term classiﬁer design evaluation feature representation machine learning neural net model parallel processing introduction deep learning big data two hottest trend rapidly growing digital world big data ha deﬁned different way herein referred nential growth wide availability digital data difﬁcult even impossible managed analyzed using conventional software tool technology digital data shape size growing astonishing rate ple according national security agency internet processing petabyte data per day 1 2011 digital information ha grown nine time volume ﬁve year 2 2020 amount world reach 35 trillion gigabyte 3 explosion digital data brings big opportunity transformative potential various sector enterprise healthcare industry manufacturing educational service 4 also lead dramatic paradigm shift scientiﬁc research towards discovery big data offer great potential ing aspect society harvesting valuable edge big data not ordinary task large rapidly growing body information hidden dented volume data requires development advanced technology interdisciplinary team working close collaboration today machine ing technique together advance available tational power come play vital role big data analytics knowledge discovery see 5 8 employed widely leverage predictive power big data ﬁelds like search engine medicine astronomy extremely active subﬁeld machine learning deep learning considered together big data big deal base american innovation economic revolution 9 contrast conventional learning method considered using learning tures deep learning refers machine learning technique use supervised unsupervised strategy ically learn hierarchical representation deep architecture classiﬁcation 10 11 inspired biological tions human brain mechanism processing natural signal deep learning ha attracted much attention academic community recent year due performance many research domain speech nition 12 13 collaborative fultering 14 computer vision 15 16 deep learning ha also successfully applied industry product take advantage large volume digital data company like google apple facebook collect analyze massive amount data daily basis aggressively pushing forward deep learning related project example apple siri virtual personal assistant iphones offer wide variety service including weather report sport news answer user question reminder etc utilizing deep learning data collected apple service 17 google applies deep learning algorithm massive chunk messy data obtained internet google translator 514 2014 ieee translation content mining permitted academic research only personal use also permitted requires ieee permission see information volume 2 2014 chen lin big data deep learning android voice recognition google street view image search engine 18 industry giant not far behind either example microsoft language tion bing voice search 19 ibm computer 18 20 use technique like deep learning leverage big data competitive advantage data keep getting bigger deep learning coming play key role providing big data predictive analytics solution particularly increased processing power advance graphic processor paper goal not present comprehensive survey related work deep learning mainly discus important issue related learning massive amount data highlight current research effort challenge big data well future trend rest paper organized follows section 2 present brief review two commonly used deep learning architecture section 3 cuss strategy deep learning massive amount data finally discus challenge perspective deep learning big data section ii overview deep learning deep learning refers set machine learning technique learn multiple level representation deep tectures section present brief overview two deep architecture deep belief work dbns 21 23 convolutional neural network cnns 24 26 deep belief network conventional neural network prone get trapped local optimum objective function often lead poor performance 27 furthermore not take advantage unlabeled data often abundant cheap collect big data alleviate problem deep belief network dbn us deep architecture capable learning feature representation labeled unlabeled data presented 21 incorporates unsupervised supervised strategy construct model unsupervised stage intend learn data distribution without using label information supervised stage perform local search ﬁne tuning fig 1 show typical dbn architecture posed stack restricted boltzmann machine rbms one additional layer discrimination task rbms probabilistic generative model learn joint probability distribution observed training data without using data label 28 effectively utilize large amount unlabeled data exploiting complex data tures structure dbn determined goal training learn weight bias layer conducted ﬁrstly unsupervised learning rbms typical rbm consists two layer node one layer fully connected node layer no connection node layer see example input layer ﬁrst hidden layer form rbm 28 consequently node independent node layer given node layer characteristic allows u train generative weight w rbms using gibbs sampling 29 30 figure illustration deep belief network architecture particular dbn consists three hidden layer three neuron one input later five neuron one output layer also five neuron any two adjacent layer form rbm trained unlabeled data output current rbm h 1 first rbm marked red input next rbm h 2 second rbm marked green weight w labeled data rbms performed output rbm fed input next rbm process repeat rbms trained unsupervised learning critical dbn training practically help avoid local optimum alleviates problem observed million parameter used furthermore algorithm efﬁcient term time complexity linear number size rbms 21 feature different layer contain different information data structure feature constructed feature note number stacked rbms parameter determined user requires only unlabeled data good generalization simple rbm bernoulli distribution visible hidden layer sampling probability follows 21 p 1 v w σ x wijvi aj 1 p vi 1 h w σ j x wijhj bi 2 v h represents 1 visible unit vector j 1 hidden unit vector respectively w matrix weight wij connecting visible hidden layer aj bi bias term σ sigmoid function case volume 2 2014 515 chen lin big data deep learning visible unit conditional probability butions slightly different typically distribution assumed p vi h w gaussian 30 weight wij updated based approximate method called contrastive divergence cd approximation 31 example 1 weight wij updated follows 1 α 3 α learning rate c momentum factor expectation distribution deﬁned data model respectively expectation may calculated running gibbs sampling inﬁnitely many time practice cd often used performs well 31 model parameter bias updated similarly generative mode rbm training includes gibbs sampler sample hidden unit based visible unit vice versa eq 1 2 weight two layer updated using cd rule eq 3 process repeat convergence rbm model data tion using hidden unit without employing label information useful feature big data analysis dbn potentially leverage much data without knowing label improved performance information input data stored weight every adjacent layer dbn add ﬁnal layer representing desired output overall network ﬁne tuned using labeled data back propagation strategy better discrimination some implementation top stacked rbms another layer called associative memory determined supervised learning method variation instead using rbms example stacked denoising 32 33 stacked predictive sparse coding 34 also posed unsupervised feature learning furthermore recent result show large number training data able fully supervised training using random initial weight instead weight without using rbms practically work well 13 35 example discriminative model start network one single hidden layer shallow neural network trained back propagation method upon convergence new hidden layer inserted shallow nn ﬁrst hidden layer desired output layer full network discriminatively trained process continued predetermined criterion met number hidden neuron summary dbns use greedy efﬁcient layer approach learn latent variable weight hidden layer back propagation method tuning hybrid training strategy thus improves generative performance discriminative power network convolutional neural network typical cnn composed many layer hierarchy some layer feature representation feature map others type conventional neural network classiﬁcation 24 often start two altering type layer called convolutional subsampling layer lutional layer perform convolution operation several ﬁlter map equal size subsampling layer reduce size proceeding layer averaging pixel within small neighborhood 36 37 fig 2 show typical architecture cnns input ﬁrst convoluted set ﬁlters c layer fig 2 ﬁltered data called feature map nonlinear transformation subsampling performed reduce dimensionality layer fig 2 sequence repeated many time determined user figure illustration typical convolutional neural network architecture input image convolves four different filter h 1 1 4 followed nonlinear activation form four feature map second layer feature map factor 2 create feature map layer sequence repeated many time example form feature map layer use eight different filter h 2 1 8 first third fourth sixth feature map layer defined one corresponding feature map layer convoluting different filter second fifth map layer formed two map convoluting two different filter last layer output layer form fully connected neural network output last subsampling later concatenated one long input vector neuron fully connected neuron next layer hidden layer figure illustrated fig 2 lowest level architecture input layer n n image input local receptive ﬁelds upper layer neuron extract some elementary complex visual feature convolutional layer labeled cx fig 2 composed multiple feature map constructed convolving input ferent ﬁlters weight vector word value unit feature map result depending local receptive ﬁeld previous layer ﬁlter 516 volume 2 2014 chen lin big data deep learning followed nonlinear activation l j f x kij x bj 4 l j output convolution layer cl f nonlinear function recent implementation use scaled hyperbolic tangent function nonlinear activation function 38 f x tanh kij trainable ﬁlter kernel ﬁlter bank convolves feature map x previous layer produce new feature map current layer symbol n sent discrete convolution operator bj bias note ﬁlter kij connect portion feature map previous layer fig 2 show partially connected feature map layer labeled sx fig 2 reduces spatial resolution ture map thus providing some level distortion invariance general unit layer constructed averaging 2 2 area feature map max pooling small region key parameter decided weight layer normally trained standard tion procedure gradient descent algorithm mean loss function alternatively training deep cnn architecture unsupervised herein review particular method unsupervised training cnns tive sparse decomposition psd 39 idea imate input xwith linear combination some basic sparse function arg 2 λ α tanh kx 2 5 w matrix linear basis set z sparse coefﬁcient matrix diagonal gain matrix k ﬁlter bank predictor parameter goal ﬁnd optimal basis function set w ﬁlter bank kthat minimize reconstruction error ﬁrst term eq 5 sparse representation second term code prediction error simultaneously third term eq 5 suring difference predicted code actual code preserve invariance certain distortion psd trained encoder learn ﬁlter bank also pooling together 39 summary inspired biological process 40 cnn algorithm learn hierarchical feature representation lizing strategy like local receptive ﬁelds size ﬁlter normally small shared weight using weight construct feature map level signiﬁcantly reduces number parameter pling reduce dimensionality ﬁlter bank trained either supervised unsupervised od cnn capable learning good feature hierarchy automatically providing some degree translational distortional invariance iii deep learning massive amount data deep learning ha shown impressive result many application training not trivial task big data learning due fact iterative computation inherent deep learning algorithm often extremely difﬁcult parallelized thus unprecedented growth commercial academic data set recent year surge interest effective scalable parallel algorithm training deep model 12 13 15 41 44 contrast shallow architecture parameter preferable avoid overﬁtting problem deep learning algorithm enjoy success large number den neuron often resulting million free parameter thus deep learning often involves large umes data large model some algorithmic approach explored learning example locally connected network 24 39 improved optimizers 42 new structure implemented parallel 44 recently deng et al 44 proposed modiﬁed deep architecture called deep stacking network dsn effectively parallelized dsn consists several specialized neural network called module single hidden layer stacked module input composed raw data vector put previous module form dsn recently new deep architecture called tensor deep stacking network based dsn implemented using cpu cluster scalable parallel computing 45 use great computing power speed training process ha shown signiﬁcant potential big data deep learning example one way scale dbns use multiple cpu core core dealing subset training data scheme vanhoucke et al 46 discussed some aspect technical detail including fully designing data layout batching computation using instruction leveraging instruction implementation mentation enhance performance modern cpu deep learning another recent work aim parallelize gibbs sampling hidden visible unit splitting hidden unit visible unit n machine responsible unit 47 order make work data transfer machine required sampling hidden unit machine data visible unit vice verse method efﬁcient hidden visible unit binary also sample size modest communication cost however rise quickly data set used method deep learning also explore implementation 48 custom architecture control unit implemented cpu grid multiple processing tile fast memory survey focus some recently developed deep learning framework take advantage great puting power available today take graphic processor unit volume 2 2014 517 chen lin big data deep learning gpus example august 2013 nvidia single precision gpus exceeded memory bandwidth near 300 49 particularly suited massively parallel computing transistor devoted data proceeding need newly developed deep learning framework shown signiﬁcant advance making deep learning practical fig 3 show schematic typical gpu four mp consists several streaming multiprocessor sm form building block fig 3 show two sm block sm ha multiple stream processor sps share control logic memory furthermore gpu ha global memory high bandwidth high latency accessed cpu host architecture allows two level parallelism instruction memory level mp thread level sps simt single instruction multiple thread architecture allows thousand ten thousand thread run concurrently best suited operation large number arithmetic operation small access time memory level parallelism also effectively utilized special attention data ﬂow developing gpu parallel computing application one consideration example reduce data transfer ram gpu global memory 50 transferring data large chunk achieved uploading large set unlabeled data possible storing free parameter well intermediate computation global memory addition data parallelism learning update implemented leveraging two level parallelism input example assigned across mp individual node treated thread sps deep belief network raina et al 41 proposed framework sively parallelizing unsupervised learning model including dbns paper refer algorithm stacked rbms sparse coding 21 previous model tend use one four million free parameter hinton salakhutdinov 21 used million parameter free image ranzato szummer used three million ters text processing 51 proposed approach train 100 million free parameter million unlabeled training data 41 transferring data host gpu global memory time consuming one need minimize device transfer take advantage shared memory achieve one strategy store parameter large chunk training example global memory training 41 reduce data transfer time host globa memory also allow parameter update carried fully inside gpus addition utilize level parallelism unlabeled training data global memory selected time pute update concurrently across block data parallelism figure illustrative architecture gpu highly threaded streaming processor sps example gpu ha 64 stream processor sps organized four multiprocessor mp two stream multiprocessor sm sm ha eight sps share control unit instruction cache four mp building block also share global memory graphic double data rate dram often function memory memory bandwidth data exchange rate global memory typically ha high latency accessible cpu host typical processing flow includes input data first copied host memory gpu memory followed loading executing gpu program result sent back gpu memory host memory practically one need pay careful consideration data transfer host gpu memory may take considerable amount time fig 3 meanwhile component input example handled sps implementing dbn learning gibbs sampling 52 53 repeated using eq mented ﬁrst generating two sampling matrix p p j element p ity hidden node given input example p respectively 41 sampling matrix implemented parallel gpu block take example thread work element example similarly weight update operation eq 3 performed parallel using linear algebra package gpu new example generated experimental result show 45 million parameter rbm one million example mentation increase speed dbn learning factor 70 compared cpu implementation around 29 minute implementation versus one day implementation 41 convolutional neural network cnn type locally connected deep learning method cnn learning often implemented gpus several hundred parallel processing core cnn ing involves forward backward propagation parallelizing forward propagation one block assigned feature map depending size map 36 thread block devoted single neuron 518 volume 2 2014 chen lin big data deep learning map consequently computation neuron includes convolution shared weight kernel neuron previous layer activation summation performed sp output stored global memory weight updated error δk error signal δ k neuron k previous layer l 1 depends error signal δ l j some neuron local ﬁeld current layer parallelizing backward propagation implemented either pulling pushing 36 pulling error signal refers process ing delta signal neuron previous layer pulling error signal current layer not straightforward subsampling convolution operation example neuron previous layer may connect different number neuron previous layer due border effect 54 illustration plot dimensional convolution subsampling fig seen ﬁrst six unit different number connection need ﬁrst identify list neuron current layer contribute error signal neuron previous layer contrary unit current layer exactly number incoming connection consequently pushing error signal current layer previous layer efﬁcient unit current layer update related unit previous layer figure illustration operation involved convolution subsampling convolution filter size six consequently unit convolution layer defined six input unit subsampling involves averaging two adjacent unit convolution layer implementing data parallelism one need consider size global memory feature map size typically any given stage limited number training example processed parallel furthermore within block comvolution operation performed only portion feature map maintained any given time due extremely limited amount shared memory convolution operation scherer et al suggested use limited shared memory circular buffer 37 only hold small portion feature map loaded global memory time convolution performed thread parallel result written back global memory overcome gpu memory limitation author mented modiﬁed architecture convolution subsampling operation combined one step 37 modiﬁcation allows storing activity error value reduced memory usage running backpropagation speedup krizhevsky et al proposed use two gpus training cnns ﬁve convolutional layer three fully connected classiﬁcation layer cnn us rectiﬁed linear unit relus nonlinear function f x max 0 x ha shown run several time faster commonly used function 55 some layer half network computed single gpu portion calculated gpu two gpus communicated some layer tecture take full advantage parallelization allows two gpus communicate transfer data without using host memory combination scheme distbelief software framework recently designed tributed training learning deep network large model billion parameter data set leverage cluster machine manage data model parallelism via multithreading message passing synchronization well communication machine 56 data high dimensionality deep ing often involves many densely connected layer large number free parameter large model deal large model learning distbelief ﬁrst implement model parallelism allowing user partition large network tectures several smaller structure called block whose node assigned calculated several machine collectively call partitioned model block assigned one machine see fig 5 boundary node node whose edge belong one partition require data transfer machine apparently connected network boundary node often demand higher communication cost structure thus le performance beneﬁts nevertheless many 144 partition reported large model distbelief 56 lead signiﬁcant improvement training speed distbelief also implement data parallelism employ two separate distributed optimization procedure downpour stochastic gradient descent sgd sandblaster 56 perform online batch optimization respectively herein discus downpour detail mation sandblaster found reference 56 first multiple replica partitioned model created training inference like deep learning model large data set partitioned many subset lief run multiple replica partitioned model compute gradient descent via downpour sgd different subset training data speciﬁcally distbelief employ centralized parameter server storing applying update volume 2 2014 519 chen lin big data deep learning figure distbelief model partitioned four block consequently assigned four machine 56 information node belong two partition transferred machine line marked yellow color model effective le densely connected network parameter model parameter grouped server shard any given time machine tioned model need only communicate parameter server shard hold relevant parameter munication asynchronous machine partitioned model run independently parameter server shard act independently well one advantage using chronous communication standard synchronous sgd fault tolerance event failure one machine model copy model replica continue nicating central parameter server process data update shared weight practice adagrad adaptive learning rate dure 57 integrated downpour sgd ter performance distbelief implemented two deep learning model fully connected network 42 million model parameter billion example connected convolutional neural network 16 million image 100 100 pixel category many billion parameter experimental result show locally connected learning model beneﬁt distbelief indeed 81 machine billion parameter method faster using single machine demonstrated 56 signiﬁcant advantage distbelief ability scale single machine thousand machine key big data analysis recently distbelief framework wa used train deep architecture sparse deep autoencoder local tive ﬁelds pooling local contrast normalization 50 deep learning architecture consists three stacked layer sublayers local ﬁltering local pooling local contrast normalization ﬁltering sublayers not lutional ﬁlter weight optimization architecture involves overall objective function summation objective function three layer aiming minimizing reconstruction error maintaining sparsity connection sublayers distbelief framework able scale dataset model resource together model partitioned 169 machine 16 cpu core multiple core allow another level parallelism subset core perform different task asynchronous sgd implemented several replica core model training example framework wa able train many 14 million image size 200 200 pixel 20 thousand category three day cluster machine core model capable learning feature detect object without using labeled data cot hpc system distbelief learn large model one billion parameter training requires cpu core not commonly available researcher recently coates et al presented native approach train comparable deep network el 11 billion free parameter using three machine 58 commodity high performance computing cot hpc system comprised cluster 16 gpu server inﬁniband adapter interconnects mpi data exchange cluster server equipped four nvidia gpus memory number gpus cpu cot hpc capable running deep learning implementation includes carefully designed cuda kernel effective usage memory efﬁcient tation example efﬁciently compute matrix tiplication wx w ﬁlter matrix x input matrix coates et al 58 fully take advantage matrix sparseness local receptive ﬁeld extracting zero column w neuron share identical receptive ﬁelds multiplied corresponding row strategy successfully avoids situation requested memory larger shared memory gpu addition matrix operation performed using highly optimized tool called magma blas multiply kernel 59 furthermore gpus utilized implement model parallel scheme gpu only used different part model optimization input example collectively communication occurs mpi large scale deep learning system capable training 11 billion parameter largest model reported far much le machine table 1 summarizes current progress deep learning ha observed several group see 41 single cpu impractical deep learning large model multiple machine running time may not big concern any see 56 however 520 volume 2 2014 chen lin big data deep learning signiﬁcant computational resource needed achieve goal consequently major research effort towards experiment gpus table summary recent research progress deep learning iv remaining challenge perspective deep learning big data recent year big data ha taken center stage government society large 2012 obama administration announced big data research development tive help solve some nation pressing challenge 60 consequently six federal department agency nsf dod doe darpa usgs committed 200 million support project transform ability harness novel way huge volume digital data may year state massachusetts announced massachusetts big data initiative fund variety research institution 61 april 2013 president barack obama announced another federal project new brain mapping initiative called brain brain research advancing innovative neurotechnologies 62 aiming develop new tool help map human brain function understand complex link function behavior treat cure brain order initiative might test extend current limit technology big data collection analysis nih director francis collins stated collection storage processing yottabyte billion petabyte data would eventually required initiative potential big data undoubtedly signiﬁcant fully achieving potential requires new way thinking novel algorithm address many technical challenge example traditional machine learning algorithm designed data would completely loaded memory arrival big data age however assumption doe not hold any therefore algorithm learn massive amount data needed spite recent achievement deep learning discussed section 3 ﬁeld still infancy much need done address many niﬁcant challenge posted big data often characterized three v model volume variety velocity 63 refers large scale data different type data speed streaming data respectively deep learning high volume data first foremost high volume data present great challenging issue deep learning big data often posse large number example input large variety class type output high dimensionality attribute property directly lead complexity model complexity sheer volume data make often impossible train deep learning algorithm central processor storage instead distributed framework parallelized machine preferred recently impressive progress made mitigate challenge related high volume novel model utilize cluster cpu gpus increasing training speed without scarifying accuracy deep learning algorithm strategy data allelism model parallelism developed example data model divided block ﬁt data forward backward propagation implemented effectively parallel 56 58 although deep learning algorithm not trivially parallel recent deep learning framework handle signiﬁcantly large number sample parameter also possible scale gpus used le clear however deep learning system continue scaling signiﬁcantly beyond current framework expect continuous growth computer memory computational power mainly parallel tributed computing environment research effort addressing issue associated computation munication management copying data parameter gradient value different machine needed large data set ultimately build future deep learning system scalable big data one need develop high performance computing system together theoretically sound parallel learning algorithm novel architecture another challenge associated high volume data incompleteness noisy label unlike tional datasets used machine learning highly curated noise free big data often incomplete ing disparate origin make thing even complicated majority data may not labeled labeled exist noisy label take 80 million tiny volume 2 2014 521 chen lin big data deep learning image database example ha 80 million resolution color image search term 64 image database wa created searching web every english noun wordnet several search engine google flickr used collect data span six month some manual curation wa conducted remove duplicate image still image label extremely unreliable search technology one unique characteristic deep learning algorithm posse ability utility unlabeled data ing learning data distribution without using label tion thus availability large unlabeled data present ample opportunity deep learning method data incompleteness noisy label part big data package believe using vastly data preferable using smaller number exact clean carefully curated data advanced deep learning method required deal noisy data able tolerate some messiness example efﬁcient cost function novel training strategy may needed alleviate effect noisy label strategy used learning 65 68 may also help alleviate problem related noisy label deep learning high variety data second dimension big data variety data today come type format variety source probably different distribution example rapidly growing multimedia data coming web mobile device include huge collection still image video audio stream graphic animation unstructured text different characteristic key deal high variety data integration clearly one unique advantage deep learning ability representation learning either supervised unsupervised method combination deep learning used learn good feature representation classiﬁcation able discover mediate abstract representation carried using unsupervised learning hierarchy fashion one level time feature deﬁned feature thus natural solution address data integration lem learn data representation individual data source using deep learning method integrate learned feature different level deep learning ha shown effective integrating data different source example ngiam et al 69 developed novel application deep learning algorithm learn representation integrating audio video data demonstrated deep learning erally effective 1 learning single modality tions multiple modality unlabeled data 2 learning shared representation capable capturing relation across multiple modality recently tava salakhutdinov 70 developed multimodal deep boltzmann machine dbm fuse two different data modality dense image data text data sparse word frequency together learn uniﬁed sentation dbm generative model without ﬁrst build multiple modality form multimodal dbm additional layer binary hidden unit added top rbms joint representation learns joint distribution multimodal input space allows learning even missing modality current experiment demonstrated deep learning able utilize heterogeneous source niﬁcant gain system performance numerous question remain open example given different source may offer conﬂicting information resolve ﬂicts fuse data different source effectively efﬁciently current deep learning method mainly tested upon data two source system performance beneﬁts signiﬁcantly enlarged modality furthermore level deep learning architecture appropriate feature fusion geneous data deep learning seems well suited gration heterogeneous data multiple modality due capability learning abstract representation underlying factor data variation deep learning high velocity data emerging challenge big data learning also arose high velocity data generating extremely high speed need processed timely manner one solution learning high velocity data online learning approach online learning learns one instance time true label instance soon available used reﬁning model 71 76 sequential learning strategy particularly work big data current machine not hold entire dataset memory conventional neural network explored online learning 77 87 only limited progress online deep learning ha made recent year interestingly deep learning often trained stochastic gradient descent approach 88 89 one training example known label used time update model parameter strategy may adapted online learning well speed learning instead proceeding sequentially one example time update performed batch basis 37 practically example independent possible provide good balance computer memory running time another challenging problem associated high velocity data often data tribution changing time practically data normally separated chunk data small time interval assumption data close time stationary may characterized signiﬁcant degree correlation therefore follow distribution 90 97 thus important feature deep learning algorithm big data ability learn data stream one area need explored deep online learning online learning often scale naturally 522 volume 2 2014 chen lin big data deep learning memory bounded readily parallelizable theoretically guaranteed 98 algorithm capable learning data crucial big data learning deep learning also leverage high variety velocity big data transfer learning domain adaption training test data may sampled different distribution 99 107 recently glorot et al implemented stacked denoising based deep architecture domain adaption one train unsupervised sentation large number unlabeled data set domain applied train classiﬁer labeled example only one domain 100 empirical result demonstrated deep learning able extract ful representation shared across different domain intermediate abstraction general enough uncover underlying factor domain tions transferable across domain recently bengio also applied deep learning multiple level sentations transfer learning training example may not well represent test data 99 showed abstract feature discovered deep learning approach likely generic training test data thus deep learning top candidate transfer learning ability identify shared factor present input although preliminary experiment shown much potential deep learning transfer learning applying deep learning ﬁeld relatively new much need done improved performance course big question whether beneﬁt big data deep architecture transfer learning conclusion big data present signiﬁcant challenge deep learning including large scale heterogeneity noisy label distribution among many others order realize full potential big data need address technical challenge new way thinking transformative solution believe research challenge posed big data not only timely also bring ample opportunity deep learning together provide major advance science medicine business reference 1 national security agency national security agency mission authority oversight partnership online available http 2 gantz reinsel extracting value chaos hopkinton usa emc jun 2011 3 gantz reinsel digital universe ready hopkinton usa emc may 2010 4 2011 may big data next frontier innovation competition productivity mckinsey global institute online available 5 lin kolcz machine learning twitter proc acm sigmod scottsdale arizona usa 2012 pp 6 smola narayanamurthy architecture parallel topic model proc vldb endowment vol 3 no 1 pp 2010 7 ng et machine learning multicore proc adv neural inf procees vol 19 2006 pp 8 panda herbach basu bayardo mapreduce application massively parallel learning decision tree ensemble scaling machine learning parallel distributed approach cambridge cambridge univ press 2012 9 crego munoz islam 2013 8 big data deep learning big deal big delusion business online available 10 bengio bengio modeling discrete data neural network proc adv neural inf process vol 12 2000 pp 11 marc aurelio ranzato boureau lecun sparse feature learning deep belief network proc adv neural inf process vol 20 2007 pp 12 dahl yu deng acero trained deep neural network speech recognition ieee trans audio speech lang vol 20 no 1 pp 2012 13 hinton et deep neural network acoustic modeling speech recognition shared view four research group ieee signal process vol 29 no 6 pp 2012 14 salakhutdinov mnih hinton restricted boltzmann machine collaborative ﬁltering proc int conf mach 2007 pp 15 cireşan meler cambardella schmidhuber deep big simple neural net handwritten digit recognition neural vol 22 no 12 pp 2010 16 zeiler taylor fergus adaptive deconvolutional network mid high level feature learning proc ieee int conf comput 2011 pp 17 efrati 2013 11 deep learning work apple beyond information online available 18 jones computer science learning machine nature vol 505 no 7482 pp 2014 19 wang yu ju acero voice search language standing system extracting semantic information speech tur de mori ed new york ny usa wiley 2011 ch 5 20 kirk 2013 1 university ibm join force build computer pcworld online available 21 hinton salakhutdinov reducing dimensionality data neural network science vol 313 no 5786 pp 2006 22 bengio learning deep architecture ai found trend mach vol 2 no 1 pp 2009 23 nair hinton object recongition deep belief net proc adv nip vol 22 2009 pp 24 lecun bottou bengio haffner ing applied document recognition proc ieee vol 86 no 11 pp 1998 25 collobert weston bottou karlen kavukcuoglu kuksa natural language processing almost scratch mach learn vol 12 pp 2011 26 le callet barba convolutional neural network approach objective video quality assessment ieee trans neural vol 17 no 5 pp 2006 27 rumelhart hinton williams learning representation error nature vol 323 pp 1986 28 hinton practical guide training restricted boltzmann machine dept comput univ toronto toronto canada tech utml tr 2010 29 hinton osindero teh fast learning algorithm deep belief net neural vol 18 no 7 pp 2006 30 bengio lamblin popovici larochelle greedy wise training deep network proc neural inf process 2006 pp 31 hinton training product expert minimizing contrastive gence neural vol 14 no 8 pp 2002 32 vincent larochelle bengio manzagol extracting composing robust feature denoising autoencoders proc int conf mach 2008 pp volume 2 2014 523 chen lin big data deep learning 33 larochelle bengio louradour lamblin exploring strategy training deep neural network mach learn vol 10 pp 2009 34 lee battle raina ng efﬁcient sparse coding rithms proc neural inf procees 2006 pp 35 seide li yu conversational speech transcription using deep neural network proc interspeech 2011 pp 36 cireşan meier masci gambardella schmidhuber flexible high performance convolutional neural network image classiﬁcation proc int conf artif 2011 pp 37 scherer müller behnke evaluation pooling operation convolutional architecture object recognition proc int conf artif neural 2010 pp 38 lecun bottou orr muller efﬁcient backprop ral network trick trade orr muller ed new york ny usa 1998 39 kavukcuoglu ranzato fergus lecun learning invariant feature topographic ﬁlter map proc int conf cvpr 2009 pp 40 hubel wiesel receptive ﬁelds functional architecture monkey striate cortex j vol 195 pp mar 1968 41 raina madhavan ng deep unsupervised learning using graphic processor proc int conf mach montreal qc canada 2009 pp 42 marten deep learning via optimization proc int conf mach 2010 43 zhang chen deep belief net mapreduce ieee access vol 2 pp apr 2014 44 deng yu platt scalable stacking learning building deep architecture proc ieee icassp mar 2012 pp 45 hutchinson deng yu tensor deep stacking network ieee trans pattern anal mach vol 35 no 8 pp 2013 46 vanhoucke senior mao improving speed neural network cpu proc deep learn unsupervised feature learn workshop 2011 47 krizhevsky learning multiple layer feature tiny image dept comput univ toronto toronto canada tech 2009 48 farabet et convolutional network machine learning large data set bekkerman bilenko langford ed cambridge cambridge univ press 2011 49 cuda c programming guide nvidia corporation santa clara ca usa jul 2013 50 le et building feature using large scale unsupervised learning proc int conf mach 2012 51 ranzato szummer learning compact document representation deep network proc int conf mach 2008 pp 52 geman geman stochastic relaxation gibbs distribution bayesian restoration image ieee trans pattern anal mach vol 6 no 6 pp 1984 53 casella george explaining gibbs sampler amer vol 46 no 3 pp 1992 54 simard steinkraus platt best practice convolutional neural network applied visual document analysis proc icdar 2003 pp 55 krizhevsky sutskever hinton imagenet classiﬁcation deep convolutional neural network proc adv nip 2012 pp 56 dean et large scale distributed deep network proc adv nip 2012 pp 57 duchi hazan singer adaptive subgradient method online learning stochastic optimization mach learn vol 12 pp jul 2011 58 coat huval wng wu wu deep ing cot hp system mach learn vol 28 no 3 pp 2013 59 tomov nath du dongarra 2011 magma user guide icl univ tennessee knoxville tn usa online available 60 2012 obama administration unveils big data initiative announces 200 million new r investment ofﬁce science nology policy executive ofﬁce president washington dc usa online available 61 haberlin mcgilpin ouellette governor patrick announces new initiative strengthen massachusetts position world leader big data commonwealth massachusetts online available 62 fact sheet brain initiative ofﬁce press secretary white house washington dc usa 2013 63 laney importance big data deﬁnition stamford ct usa gartner 2012 64 torralba fergus freeman 80 million tiny image large data set nonparametric object scene recognition ieee trans softw vol 30 no 11 pp 2008 65 wang shen large margin learning mach learn vol 8 no 8 pp 2007 66 weston ratle collobert deep learning via embedding proc int conf mach helsinki finland 2008 67 sinha belkin learning using sparse function base proc adv nip 2009 pp 68 fergus wei torralba learning gigantic image collection proc adv nip 2009 pp 69 ngiam khosla kim nam lee ng multimodal deep learning proc int conf mach bellevue wa usa 2011 70 srivastava salakhutdinov multimodal learning deep boltzmann machine proc adv nip 2012 71 bottou online algorithm stochastic approximation learning neural network saad ed cambridge cambridge univ press 1998 72 blum burch learning metrical task system problem proc annu conf comput learn theory 1997 pp 73 freund helmbold warmuth prediction conversation strategy proc conf comput learn theory eurocolt vol oxford 1994 pp 74 freund schapire game theory prediction ing proc annu conf comput learn theory 1996 pp 75 littlestone long warmuth ing linear function proc symp theory 1991 pp 76 online learning online convex optimization found trend mach vol 4 no 2 pp 2012 77 heskes kappen learning process artiﬁcial neural network math library vol 51 pp 1993 78 marti multilayer neural network experimental evaluation training method comput operat vol 31 no 9 pp 2004 79 lim harrison online pattern classiﬁcation multiple neural network system experimental study ieee trans man cybern c appl vol 33 no 2 pp may 2003 80 rattray saad globally optimal learning rule neural network phys math general vol 30 no 22 pp 1997 81 riegler biehl backpropagation neural network phys vol 28 no 20 pp 1995 82 saad solla exact solution learning multilayer neural network phys rev vol 74 no 21 pp 1995 83 west saad learning adaptive network phys rev e vol 56 no 3 pp 1997 84 campolucci uncini piazza rao learning algorithm locally recurrent neural network ieee trans neural vol 10 no 2 pp mar 1999 85 liang huang saratchandran sundararajan fast accurate online sequential learning algorithm feedforward network ieee trans neural vol 17 no 6 pp 2006 86 ruiz de angulo torras learning minimal dation feedforward network ieee trans neural vol 6 no 3 pp may 1995 524 volume 2 2014 chen lin big data deep learning 87 choy srinivasan cheu neural network continuous online learning control ieee trans neural vol 17 no 6 pp 2006 88 bottou bousequet stochastic gradient learning neural network proc 1991 89 singer srebro pegasos primal estimated solver svm proc int conf mach 2007 90 chien hsieh nonstationary source separation using sequential variational bayesian learning ieee trans neural netw learn vol 24 no 5 pp may 2013 91 sugiyama kawanabe machine learning environment introduction covariate shift adaptation cambridge usa mit press mar 2012 92 elwell polikar incremental learning nonstationary ments controlled forgetting proc int joint conf neural 2009 pp 93 elwell polikar incremental learning concept drift stationary environment ieee trans neural vol 22 no 10 pp 2011 94 alippi roveru adaptive detecting nonstationary change ieee trans neural vol 19 no 7 pp jul 2008 95 alippi roveru adaptive ii designing classiﬁer ieee trans neural vol 19 no 12 pp 2008 96 rutkowski adaptive probabilistic neural network pattern ﬁcation environment ieee trans neural vol 15 no 4 pp jul 2004 97 de oliveira rosenblatt bayesian algorithm learning stationary environment ieee trans neural vol 18 no 2 pp mar 2007 98 bartlett optimal online prediction adversarial environment proc int conf 2010 371 99 bengio deep learning representation unsupervised fer learning mach learn vol 27 pp 2012 100 glorot bordes bengio domain adaptation sentiment classiﬁcation deep learning approach proc int conf mach bellevue wa usa 2011 101 mesnil et unsupervised transfer learning challenge deep learning approach mach learn vol 7 pp 2011 102 pan yang survey transfer learning ieee trans knowl data vol 22 no 10 pp 2010 103 gutstein fuentes freudenthal knowledge transfer deep convolutional neural net int artif intell tool vol 17 no 3 pp 2008 104 blum mitchell combining labeled unlabeled data proc annu conf comput learn theory 1998 pp 105 raina battle lee packer ng learning transfer learning unlabeled data proc icml 2007 106 pan tsang kwok yang domain adaptation via transfer component analysis ieee trans neural vol 22 no 2 pp 2011 107 mesnil rifai bordes glorot bengio vincent unsupervised transfer learning uncertainty object detection scene categorization proc icpram 2013 pp chen 03 currently professor chair department computer science wayne state university detroit mi usa received degree carnegie mellon university pittsburgh pa usa currently serving ciate editor editorial board member eral international journal including ieee access bmc system biology ieee transaction information technology biomedicine served conference chair program chair number conference acm conference information knowledge agement 2012 ieee international conference machine learning application senior member ieee computer society xiaotong lin currently visiting assistant professor ment computer science engineering oakland university rochester mi usa received degree university kansa lawrence k usa 2012 degree university pittsburgh pittsburgh pa usa research interest include large scale machine learning data mining computing bioinformatics volume 2 2014 525