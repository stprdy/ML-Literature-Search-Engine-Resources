received april 1 2019 accepted april 15 2019 date publication april 22 2019 date current version may 1 digital object identifier review deep learning algorithm architecture ajay shrestha ausif mahmood senior member ieee department computer science engineering university bridgeport bridgeport ct 06604 usa corresponding author ajay shrestha shrestha abstract deep learning dl playing increasingly important role life ha already made huge impact area cancer diagnosis precision medicine car predictive forecasting speech recognition painstakingly handcrafted feature extractor used traditional learning classiﬁcation pattern recognition system not scalable data set many case depending problem complexity dl also overcome limitation earlier shallow network prevented efﬁcient training abstraction hierarchical representation training data deep neural network dnn us multiple deep layer unit highly optimized algorithm architecture paper review several optimization method improve accuracy training reduce training time delve math behind training algorithm used recent deep network describe current shortcoming enhancement implementation review also cover different type deep architecture deep convolution network deep residual network recurrent neural network reinforcement learning variational autoencoders others index term machine learning algorithm optimization artiﬁcial intelligence deep neural network architecture convolution neural network backpropagation supervised unsupervised learning introduction neural network machine learning ml technique inspired resembles human nervous system structure brain consists processing unit organized input hidden output layer node unit layer connected node adjacent layer connection ha weight value input multiplied respective weight summed unit sum undergoes transformation based tion function case sigmoid function tan hyperbolic rectiﬁed linear unit relu tions used mathematically favorable derivative making easier compute partial derivative error delta respect individual weight sigmoid tanh function also squash input narrow output range option respectively ment saturated nonlinearity output plateau rate respective threshold relu hand exhibit saturating behavior f x max 0 x output function fed input subsequent unit next layer result ﬁnal output layer used solution problem associate editor coordinating review manuscript approving publication wa jiang neural network used variety lem including pattern recognition classiﬁcation clustering dimensionality reduction computer vision natural language processing nlp regression predictive analysis etc example image recognition figure 1 show deep neural network called lution neural network cnn learn hierarchical level representation input vector fully identify object red square ﬁgure simply gross generalization pixel value highlighted section ﬁgure cnns progressively extract higher representation image layer ﬁnally recognize image implementation neural network consists following step acquire training testing data set train network make prediction test data paper organized following section introduction machine learning background motivation classiﬁcations neural network dnn architecture training algorithm 53040 2019 ieee translation content mining permitted academic research only personal use also permitted requires ieee permission see information volume 7 2019 shrestha mahmood review dl algorithm architecture figure image recognition cnn shortcoming training algorithm optimization training algorithm architecture algorithm implementation conclusion background 1957 frank rosenblatt created perceptron ﬁrst prototype know neural network 1 two layer processing unit could recognize simple pattern instead undergoing research development neural network entered dark phase history 1969 professor mit demonstrated even learn simple xor function 2 addition wa another ﬁnding particularly dampened motivation dnn universal mation theorem showed single hidden layer wa able solve any continuous problem 3 wa mathematically proven well 4 questioned validity dnn single hidden layer could used learn wa not efﬁcient wa far cry convenience capability afforded hierarchical abstraction multiple hidden layer dnn know wa not universal approximation theorem held back progress dnn back way train dnn either factor prolonged ai winter phase history artiﬁcial intelligence get much funding interest result advance much either breakthrough dnn occurred advent backpropagation learning algorithm wa proposed 5 6 wa fully understood applied neural network learning wa made possible deeper understanding application backpropagation algorithm tion feature extractor differentiates dnns earlier generation machine learning technique dnn type neural network modeled multilayer perceptron mlp trained algorithm learn representation data set without any manual design feature extractor name deep learning suggests consists higher deeper number processing er contrast shallow learning model fewer layer unit shift shallow deep learning ha allowed complex function mapped not efﬁciently mapped shallow architecture improvement ha complemented proliferation cheaper processing unit graphic processing unit gpgpu large volume data set big data train gpgpus le powerful cpu number parallel processing core outnumber cpu core order magnitude make gpgpus better implementing dnns tion backpropagation algorithm gpu adoption advancement ml particularly deep learning attributed explosion data bigdata last 10 year ml continue impact disrupt area life education ﬁnance governance healthcare manufacturing marketing others 7 motivation deep learning perhaps signiﬁcant development ﬁeld computer science recent time impact ha felt nearly scientiﬁc ﬁelds already disrupting transforming business industry race among world leading economy technology ny advance deep learning already many area deep learning ha exceeded human level capability performance predicting movie rating decision approve loan application time taken car delivery etc 8 march 27 2019 three deep learning pioneer yoshua bengio geoffrey hinton yann lecun awarded turing award also referred nobel prize computing 9 lot ha accomplished advance deep learning deep learning ha potential improve human life accurate diagnosis disease like cancer 10 discovery new drug prediction natural disaster 11 12 reported deep learning network wa able learn image disease wa able diagnose level 21 board certiﬁed dermatologist google ai 10 wa able beat average accuracy u board certiﬁed general pathologist grading prostate cancer 70 61 goal review cover vast subject deep learning present holistic survey dispersed tion one article present novel work collating work leading author wide scope breadth deep learning review paper 13 16 focus speciﬁc area implementation without encompass full scope ﬁeld review cover different type volume 7 2019 53041 shrestha mahmood review dl algorithm architecture figure 2 feedforward neural network 6 b unrolling rnn time 6 deep learning network architecture deep learning rithms shortcoming optimization method latest implementation application ii classification neural network neural network classiﬁed following different type feedforward neural network recurrent neural network rnn radial basis function neural network kohonen self organizing neural network modular neural network feedforward neural network information ﬂows one direction input output layer via hidden node any not form any circle loopbacks figure show particular type implementation multilayer feedforward neural network value tions computed along forward pas path z weighed sum input represents activation function f z layer w represents weight two unit adjoining layer indicated subscript letter b represents bias value unit unlike feedforward neural network processing unit rnn form cycle output layer becomes input next layer typically only layer network thus output layer becomes input forming feedback loop allows network memory previous state use inﬂuence current output one signiﬁcant outcome difference unlike feedforward neural network rnn take sequence input generate sequence output value well rendering useful application require processing sequence time phased input data like speech recognition video classiﬁcation etc figure demonstrates unrolling rnn time sequence sentence constitutes input word would correspond layer thus network would unfolded unrolled 3 time rnn mathematical explanation diagram xt represents input time u v w learned parameter shared step ot output time st represents state time computed follows f activation function relu st f uxt 1 radial basis function neural network used cation function approximation time series prediction lem etc consists input hidden output layer hidden layer includes radial basis function implemented gaussian function node represents cluster center network learns designate input center output layer combine output radial basis function weight parameter perform classiﬁcation inference 17 kohonen neural network self organizes network model input data using unsupervised ing consists two fully connected layer input layer output layer output layer organized dimensional grid no activation function weight represent attribute position output layer node euclidian distance input data output layer node respect weight calculated weight closest node neighbor input data updated bring closer input data formula 18 wi 1 wi α x 2 x input data time wi ith weight time neighborhood function ith jth node modular neural network break large network smaller independent neural network module smaller network perform speciﬁc task later combined part single output entire network 19 53042 volume 7 2019 shrestha mahmood review dl algorithm architecture dnns implemented following popular way sparse autoencoders convolution neural network cnns convnets restricted boltzmann machine rbms long memory lstm autoencoders neural network learn tures encoding given dataset order perform dimensionality reduction sparse autoencoder variation autoencoders some unit output value close zero inactive not ﬁre deep cnn us multiple layer unit collection interact input pixel value case image result desired feature extraction cnn ﬁnds application image recognition recommender system nlp rbm used learn probability distribution within data set network use backpropagation training backpropagation us gradient descent error reduction adjusting weight based partial derivative error respect weight neural network model also divided lowing two distinct category discriminative generative discriminative model approach data ﬂows input layer via hidden layer output layer used supervised training problem like classiﬁcation regression generative model hand data ﬂows opposite direction used unsupervised probabilistic distribution problem input x corresponding label given discriminative model learns probability tribution p probability given x directly whereas generative model learns joint probability p x p predicted 20 general whenever labeled data available discriminative approach undertaken provide effective training labeled data not available generative approach taken 21 training broadly categorized three type supervised unsupervised supervised learning consists labeled data used train network whereas unsupervised learning no labeled data set thus no learning based back unsupervised learning neural network trained using generating model rbms later could using standard supervised learning rithms used test data set determine tern classiﬁcations big data ha pushed envelope even deep learning sheer volume variety data contrary intuitive inclination no clear consensus whether supervised learning better unsupervised learning merit use case reference 22 demonstrated enhance result unsupervised learning using unstructured video sequence camera motion estimation monocular depth ﬁed neural network deep belief network dbm described chen lin 23 us labeled unlabeled data supervised unsupervised learning respectively improve performance developing way automatically extract meaningful feature labeled unlabeled high dimensional data space challenging yann lecun et al asserts one way could achieve would utilize integrate unsupervised vised learning 24 complementing unsupervised learning data supervised learning labeled data referred learning dnn training algorithm overcome two major challenge premature convergence overﬁtting ture convergence occurs weight bias dnn settle state only optimal local level miss global minimum entire dimensional space overﬁtting hand describes state dnns become highly tailored given training data set ﬁne grain level becomes unﬁt rigid le adaptable any test data set along different type training algorithm architecture also different machine learning work table 1 library made training model easier framework make complex mathematical tions training algorithm statistically modeling available without write some provide distributed parallel processing capability nient development deployment feature figure 3 show graph various deep learning library along github star github largest hosting service provider source code world 25 github star indicative popular project github tensorflow popular dl library iii dnn architecture deep neural network consists several layer node ferent architecture developed solve problem different domain cnn used time computer vision image recognition rnn commonly used time series hand no clear winner general problem like classiﬁcation choice architecture could depend multiple factor nonetheless 27 evaluated 179 classiﬁers concluded parallel random forest essentially parallel implementation variation decision tree performed best three common architecture deep neural network convolution neural network autoencoder restricted boltzmann machine rbm long memory lstm convolution neural network cnn based human visual cortex neural network choice computer vision image recognition volume 7 2019 53043 shrestha mahmood review dl algorithm architecture figure github star deep learning library 26 table popular deep learning framework library video recognition also used area nlp drug discovery etc shown figure 4 cnn consists series convolution er followed fully connected layer normalizing softmax function layer figure 4 illustrates known 7 layered cnn architecture devised lecun et al 28 digit recognition series tiple convolution layer perform progressively reﬁned feature extraction every layer moving input output layer fully connected layer perform tion follow convolution layer pooling layer often inserted convolution layer cnn take n n pixelated image input layer consists group neuron called ﬁlters nels unlike neural network neuron feature extraction layer cnn not connected neuron adjacent layer instead only connected spatially mapped ﬁxed sized partially overlapping ron previous layer input image feature map region input called local receptive ﬁeld lowered number connection reduces training time chance overﬁtting neuron ﬁlter connected number neuron previous input layer feature map constrained sequence weight bias factor speed learning reduces memory requirement network thus neuron speciﬁc ﬁlter look pattern different part input image layer reduce size network addition along local receptive ﬁelds shared weight within ﬁlter effectively reduces network susceptibility shift scale distortion image 29 pooling local averaging ﬁlters used often achieve ﬁnal layer cnn responsible actual classiﬁcations neuron layer fully connected deep cnn implemented multiple series convolution layer layer deep nature cnn result high quality representation maintaining locality reduced parameter invariance minor variation input image 30 case backpropagation used solely training parameter weight bias cnn brief description algorithm cost function respect individual training example x hidden layer 53044 volume 7 2019 shrestha mahmood review dl algorithm architecture figure 4 architecture cnn character recognition 28 deﬁned 31 j w b x 1 b x 3 equation error term δ layer l given 31 δ l w l δ z l 4 δ error l 1 th layer network whose cost function j w b x f z l represents derivate activation function l j w b x δ 5 l j w b x δ 6 input 1 input layer actual input image l input l layer error layer calculated 31 δ l k upsample w l k δ k f z l k 7 k represent ﬁlter number layer sampling layer error ha cascaded opposite direction mean pooling used upsample evenly distributes error previous input unit ﬁnally gradient feature map 31 l k j w b x x l δ k 2 8 l k j w b x x b δ k b 9 l k represents convolution error input l layer respect k ﬁlter algorithm 1 represents description ﬂow backpropagation algorithm used cnn go multiple epoch either maximum iteration reached cost function target met addition discriminative model image nition cnn also used generative model deconvolving image make blurry image sharper algorithm 1 cnn backpropagation algorithm pseudo code 1 initialization weight randomly generated value small 2 set learning rate small value positive 3 iteration n 1 begin 4 n max iteration cost function criterion met 5 image xi 6 forward propagate convolution pooling fully conﬂected layer 7 derive cost fuction value image 8 error term δ l respect weight type layer 9 note error get propagated layer layer following sequence 10 connected layer 11 layer 12 layer 13 gradient l k l k weight l k bias respectively layer 14 gradient calculated following sequence 15 layer 16 layer 17 connected layer 18 weight 19 w l ji l ji l ji 20 bias 21 b l j l j l j reference 32 achieves leveraging fourier formation regularize inversion blurred image denoising different implementation cnn ha shown continuous improvement accuracy computer vision improvement tested benchmark imagenet ensure unbiased result variation implementation cnn architecture alexnet cnn developed run nvidia parallel ing platform support gpus volume 7 2019 53045 shrestha mahmood review dl algorithm architecture figure linear representation data input using pca inception deep cnn developed google resnet deep residual network developed microsoft place ilsvrc 2015 competition imagenet dataset vgg deep cnn developed large scale image recognition dcgan deep convolutional generative adversarial work proposed 33 used unsupervised learning hierarchy feature representation input object autoencoder autoencoder neural network us unsupervised rithm learns representation input data set dimensionality reduction recreate original data set learning algorithm based implementation backpropagation autoencoders extend idea principal component analysis pca shown figure 5 pca form data linear representation figure 5 demonstrates input data reduced linear vector using pca autoencoders hand go produce nonlinear representation pca mine set linear variable direction largest variance p dimensional input data point represented orthogonal direction constitutes lower le dimensional space original data point projected principal direction thus ting information corresponding orthogonal direction pca focus variance rather covariance correlation look linear function variance 34 goal determine direction figure training stage autoencoder 36 least mean square error would least reconstruction error autoencoders use encoder decoder block hidden layer generalize pca perform dimensionality reduction eventual reconstruction original data us greedy layer layer unsupervised training backpropagation 35 despite using backpropagation mostly used supervised training autoencoders considered unsupervised dnn regenerate input x instead different set target value x hinton et al able achieve near perfect reconstruction image using autoencoder proving far better pca 36 performing dimensionality reduction autoencoders come interesting representation input vector hidden layer often attributed smaller number node hidden layer every second layer layer block even higher number node hidden layer sparsity constraint enforced hidden unit retain interesting lower dimension representation input achieve sparsity some node restricted ﬁring output set value close zero figure 6 show single layer feature detector block rbms used followed 53046 volume 7 2019 shrestha mahmood review dl algorithm architecture figure autoencoder node unrolling 36 unrolling combine stack rbms create encoder block revers encoder block create decoder section ﬁnally network tuned backpropagation 36 figure 7 illustrates simpliﬁed representation autoencoders reduce dimension input data learn recreate output layer wang et al 37 successfully implemented deep autoencoder stack rbm block similar figure 6 achieve better eling accuracy efﬁciency proper orthogonal decomposition pod method dimensionality reduction distributed parameter system dp equation describes average activation function 2 j jth unit layer xth input activates neuron 38 ˆ ρj 1 xm aj 2 x 10 10 sparsity parameter ρ introduced ρ close zero ˆ ρ ensure ˆ ρ ρ penalty term kl ˆ ρj introduced kl divergence term kl ˆ ρj 0 ˆ ρ else becomes large monotonically difference two value diverges 38 updated cost function 38 jsparse w b j w b β x kl ˆ ρj 11 equal number unit layer β parameter control sparsity penalty term weight restricted boltzmann machine rbm restricted boltzmann machine artiﬁcial neural work apply unsupervised learning algorithm figure restricted boltzmann machine build generative model unlabeled data 39 goal train network increase function product log probability vector visible unit probabilistically reconstruct input learns probability distribution input shown figure 8 rbm made network called visible layer hidden layer unit visible layer connected unit hidden layer no connection unit layer energy e function conﬁguration visible hidden unit v h expressed following way 40 e v h x iεvisible aivi x jεhidden bjhj x j vihjwij 12 vi hj vector state visible unit hidden unit ai bj represents bias visible hidden unit wij denotes weight respective visible hidden unit partition function z represented sum possible pair visible hidden vector 40 z x v h v h 13 probability every pair visible hidden vector given following 40 p v h 1 z v h 14 probability particular visible layer vector vided following 40 p v 1 z x h v h 15 see equation partition function becomes higher lower energy function value thus training process weight bias network adjusted arrive lower energy thus maximize probability assigned training vector mathematically convenient compute derivative log probability training vector p v 16 volume 7 2019 53047 shrestha mahmood review dl algorithm architecture figure lstm block memory cell gate equation 40 sent expectation respective distribution thus adjustment weight denoted follows 40 ϵ learning rate ϵ 17 long memory lstm lstm implementation recurrent neural network wa ﬁrst proposed hochreiter et al 1997 41 unlike earlier described feed forward network tures lstm retain knowledge earlier state trained work requires memory state ness lstm partly address major limitation rnn problem vanishing gradient letting gradient pas unaltered shown illustration figure 9 lstm consists block memory cell state signal ﬂows regulated input forget output gate gate control stored read written cell lstm used google apple amazon voice recognition platform 42 ﬁgure 9 c x h represent cell input output value subscript denotes time step value previous lstm block time denotes current block value symbol σ sigmoid function tanh hyperbolic tangent function operator wise summation x multiplication computation gate described equation 41 43 ft σ wf xt wf bf 18 σ wixt bi 19 ot σ woxt bo 20 ct ft wcxt bc 21 ht ot ct 21 22 f forget input output gate vector respectively w w b weight input weight recurrent output bias cation respectively smaller variation lstm known gated recurrent unit gru grus smaller size lstm include output gate perform better lstm only some simpler datasets 44 45 lstms recurrent neural network keep track term dependency therefore great learning sequence input data building model rely context earlier state cell block lstm retains pertinent information previous state input forget output gate dictate new data going cell remains cell cell value used calculation output lstm block respectively 41 43 naul et al demonstrated lstm gru based autoencoders automatic feature extraction 46 comparison dnn network table 2 provides compact summary comparison different dnn architecture example mentation application datasets dl software work presented table not implied exhaustive addition some categorization network tectures could implemented hybrid fashion even though rbms generative model training considered unsupervised element inative model training ﬁnetuned supervised learning table also provides example common cation using different architecture iv training algorithm learning algorithm constitutes main part deep learning number layer differentiates deep neural network shallow one higher number layer deeper becomes layer specialized detect speciﬁc aspect feature indicated najafabadi et al 47 case image face recognition ﬁrst layer detect edge second detect higher feature various part face ear eye third layer go complexity order even learning facial shape various person even though layer might learn detect deﬁned feature sequence not always designed especially unsupervised learning feature tor layer manually programmed prior development training algorithm gradient descent classiﬁers scale lager dataset adapt variation dataset message wa echoed 1998 paper 28 yann lecun et demonstrate system automatic learning reduced manually designed heuristic yield far better pattern recognition backpropagation provides representation learning ology raw data fed without need manually massage classiﬁers automatically ﬁnd representation needed classiﬁcation recognition 6 53048 volume 7 2019 shrestha mahmood review dl algorithm architecture table dnn network comparison table goal learning algorithm ﬁnd optimal value weight vector solve class problem domain some training algorithm gradient descent stochastic gradient descent momentum algorithm backpropagation time gradient descent gradient descent gd underlying idea machine learning deep learning algorithm based concept newton algorithm ﬁnding root zero value function achieve randomly pick point curve slide right left along based negative positive value tive slope function chosen point value function f x becomes zero idea used gradient descent traverse descend along certain path weight space cost function keep decreasing stop error rate cease decrease newton method prone getting stuck local minimum derivative function current point zero likewise risk also present using gradient descent function fact impact ampliﬁed dimension sent weight variable landscape dnn result set weight cost function volume 7 2019 53049 shrestha mahmood review dl algorithm architecture figure error calculation multilayer neural network 6 one half square difference desired output minus current output shown c 1 2 23 backpropagation methodology us gradient descent backpropagation chain rule partial derivative employed determine error delta any change value weight individual weight adjusted reduce cost function every learning iteration training data set resulting ﬁnal weight landscape weight value 6 process sample training dataset applying update weight process repeated objective aka cost function reduce any figure 10 show error derivative relation output hidden layer weighted summation error derivates relation input unit layer calculated partial error derivative respect wjk equal stochastic gradient descent stochastic gradient descent sgd common variation implementation gradient descent gradient descent process sample training dataset applying update weight sgd update applied running batch n number sample since updating weight frequently sgd gd converge towards global minimum much faster momentum standard sgd learning rate used ﬁxed multiplier gradient compute step size update weight cause update overshoot potential minimum gradient steep delay convergence gradient noisy using concept momentum physic momentum algorithm present velocity v variable conﬁgured exponentially decreasing average gradient 48 help prevent costly descent wrong direction equation α 0 1 momentum parameter ϵ learning rate velocity update v 24 actual update θ v 25 algorithm algorithm lma primarily used solving least square problem curve ting least square problem try ﬁt given data point function least amount sum square error actual data point point function lma us combination gradient descent method gradient descent employed reduce sum squared error updating parameter function direction descent method minimizes error assuming function locally quadratic ﬁnds minimum quadratic 49 ﬁtting function denoted ˆ p data point denoted ti yi squared error written 49 p xm ti ti p σyi 26 p w p 27 yt wy w ˆ ˆ yt w ˆ 28 measurement error ti σyi inverse weighting matrix wii gradient descent squared error function relation n parameter denoted 49 2 p w p 29 2 p w p 30 2 yˆ wj 31 hgd αjt w 32 j jacobian matrix size n used place hgd update direction steepest gradient descent equation method update hgn follows 49 h jt wj hgn jt w 33 53050 volume 7 2019 shrestha mahmood review dl algorithm architecture marquardt update hlm generated combining gradient descent method resulting equation 49 h jt wj λ diag jt wj hlm jt w 34 backpropagation time backpropagation time bptt standard method train recurrent neural network shown figure unrolling rnn time make appears like feedforward network unlike feedforward work unrolled rnn ha exact set weight ues layer represents training process time domain backward pas time domain work calculates gradient respect speciﬁc weight layer average update weight different time increment layer change ensure value weight layer continues stay uniform comparison deep learning algorithm table 3 provides summary comparison common deep learning algorithm advantage disadvantage presented along technique address disadvantage gradient training common type training backpropagation time tion tailored recurrent neural network contrastive gence ﬁnds use probabilistic model rbms evolutionary algorithm applied hyperparameter optimization training model optimizing weight reinforcement learning could used game theory agent system problem exploitation exploration need optimized shortcoming training algorithm several shortcoming standard use training algorithm dnns common one described vanishing exploding gradient deep neural network prone vanishing ing gradient due inherent way gradient derivates computed layer layer ing manner layer contributing exponentially decreasing increasing derivative weight increased decreased based gradient reduce cost tion error small gradient cause network take long time train whereas large gradient cause training overshoot diverge made worse activation function like sigmoid tanh function squash output small range since change weight nominal effect output ing could take much longer problem mitigated using linear activation function like relu proper weight initialization table deep learning algorithm comparison table local minimum local minimum always global minimum convex function make gradient descent based optimization fool proof whereas nonconvex function tion based gradient descent particularly vulnerable issue premature convergence local minimum local minimum shown figure 11 easily mistaken global absolute minimum flat region like local minimum ﬂat region saddle point figure 12 also pose similar challenge gradient descent based optimization nonconvex tions training algorithm could potentially mislead area gradient come halt point steep edge steep edge another section optimization face area steep gradient could cause gradient volume 7 2019 53051 shrestha mahmood review dl algorithm architecture figure gradient descent figure flat saddle point marked black dot region nonconvex function weight update overshoot miss tial global minimum training time training time important factor gauge efﬁciency algorithm not uncommon graduate student train model day week computer lab model require exorbitant amount time large datasets train often time many sample datasets not add value training process some case introduce noise adversely affect training overfitting add neuron dnn undoubtedly model network complex problem dnn lend high conformability training data also high risk overﬁtting outlier noise training data shown figure result delayed training testing time result lower quality prediction actual test data classiﬁcation cluster problem overﬁtting create high order polynomial output separate decision boundary training set take longer result degraded result test figure overfitting classification data set one way overcome overﬁtting choose number neuron hidden layer wisely match problem size type some algorithm used approximate appropriate number neuron no magic bullet best bet experiment use case get optimal value vi optimization training algorithm goal dnn improve accuracy model test data training algorithm aim achieve end goal reducing cost function common root cause three ﬁve shortcoming mentioned primarily due fact training algorithm assume problem area convex function problem high number node sheer possible combination weight value weight learned training dataset additional crucial parameter referred hyperparameters directly learnt training dataset hyperparameters take range value add complexity ﬁnding optimal architecture model signiﬁcant room improvement standard training algorithm some popular way enhance accuracy dnns parameter initialization technique since solution space huge initial parameter outsized inﬂuence fast slow ing converges prematurely converges suboptimal point initialization strategy tend heuristic nature reference 50 proposed normalized initialization weight initialized following manner w 6 6 35 reference 51 proposed another technique called sparse initialization number incoming weight capped certain limit causing retain high diversity reduce chance saturation 53052 volume 7 2019 shrestha mahmood review dl algorithm architecture hyperparameter optimization learning rate regularization parameter constitutes commonly used hyperparameters dnn learning rate determines rate weight updated purpose regularization prevent overﬁtting ularization parameter affect degree inﬂuence loss function cnn additional hyperparameters number ﬁlters ﬁlter shape number dropout max pooling shape convolution layer number node fully connected layer parameter important training modeling dnn coming optimal set parameter value ing feat exhaustively iterating combination hyperparameter value computationally expensive example training evaluating dnn full dataset take ten minute seven hyperparameters eight potential value take 87 10 min minute almost 40 year exhaustively train evaluate network combination rameter value hyperparameter optimized ent metaheuristics metaheuristics nature inspired guiding principle help traversing search space intelligently yet much faster exhaustive method particle swarm optimization pso another type metaheuristic used hyperparameter tion pso modeled around bird ﬂy around search food migration velocity location bird particle adjusted steer swarm towards better solution vast search space escalante et al used pso hyperparameter optimization build competitive model ranked among top relative comparable method 52 genetic algorithm ga metaheuristic monly used solve combinatorial optimization problem mimic selection crossover process specie reproduction contributes evolution improvement specie prospect survival figure show diagram figure illustrates crossover process part respective genetic sequence merged parent form new genetic sequence child goal ﬁnd ulation member sequence number resembling dna nucleotide meet ﬁtness requirement ulation member represents potential solution population member selected based different method elite roulette rank tournament elite method rank population member ﬁtness only us high ﬁtness member crossover process mutation process make random change number sequence entire process continues desired ﬁtness maximum number iteration reached reference 53 54 propose parallelization tion ga achieve better faster result parallelization provide speedup better result periodically exchange population member distributed parallel operation genetic algorithm different set figure 14 genetic algorithm 53 b crossover genetic algorithm population member hybridization process mixing primary algorithm ga case operation like local search shrestha mahmood 53 incorporated local search method ga improve search optimal solution reference 55 postulate correctly performed exchange ga breed innovation result creation solution hard problem like real life collaboration exchange viduals organization society additional ga variation metaheuristics also used evolve optimize deep learning architecture hyperparameters 56 proposed codeepneat framework based deep neuroevolution technique ﬁnding optimized architecture match task hand volume 7 2019 53053 shrestha mahmood review dl algorithm architecture adaptive learning rate learning rate huge impact training dnn speed training time help navigate ﬂat surface ter overcome pitfall function adaptive learning rate allow u change learning rate eters response gradient momentum several tive method proposed reference 48 describes following algorithm adagrad rmsprop adam algorithm learning rate eter increased partial derivative respect stay sign decreased sign change adagrad sophisticated 57 prescribes inversely proportional scaling learning rate square root cumulative squared gradient adagrad not effective dnn training since change learning rate function historical gradient adagrad becomes susceptible convergence rmsprop algorithm modiﬁcation adagrad rithm make effective nonconvex problem space rmsprod replaces summation squared gradient adagrad exponentially decaying moving average gradient effectively dropping impact historical ent 48 adam denotes adaptive moment estimation latest evolution adaptive learning algorithm integrates idea adagrad rmsprop tum 58 like adagrad rmsprod adam provides individual learning rate parameter adam includes beneﬁts earlier method doe better job handling objective noisy sparse gradient problem 58 adam us ﬁrst moment mean used rmsprop well second moment dients uncentered variance utilizing exponential moving average squared gradient 58 figure 15 show relative performance various adaptive learning rate mechanism adam outperform rest batch normalization network getting trained variation weight parameter distribution actual data input layer dnn change often making large small thus making difﬁcult train network especially activation function implement saturating nonlinearities sigmoid tanh function iofee szegedy 59 proposed idea batch ization ha made huge difference improving training time accuracy dnn update input unit variance zero mean supervised pretraining supervised pretraining constitutes breaking complex problem smaller part training simpler figure multilayer network training cost mnist dataset using different adaptive learning algorithm 58 figure dnn without dropout model later combining solve larger model greedy algorithm commonly used supervised training dnn dropout commonly used method lower risk overﬁtting dropout technique randomly choose unit nullify weight output not inﬂuence forward pas backpropagation figure 16 show fully connected dnn left dnn dropout right method include use regularization simply enlarging training dataset using label preserving technique dropout work better regularization reduces risk overﬁtting also speed training process reference 60 53054 volume 7 2019 shrestha mahmood review dl algorithm architecture proposed dropout technique demonstrated signiﬁcant improvement supervised learning based dnn puter vision computational biology speech recognition document classiﬁcation problem training speed cloud gpu processing training time one key performance indicator machine learning cloud computing gpus lend self well speeding training process cloud provides massive amount compute power major cloud vendor include gpu powered server easily provisioned used training dnns demand competitive price cloud vendor amazon web service aws instance provides 40 thousand parallel gpu core gpu instance optimized machine learning 61 summary dl algorithm shortcoming resolution technique table 4 provides summary deep learning algorithm coming resolution technique table also list cause effect shortcoming vii architecture algorithm implementation section describes different implementation neural network using variety training method network tectures model also includes model idea incorporated machine learning general deep residual learning ability add layer dnn ha allowed u solve harder problem microsoft research asia msra applied layer deep residual network resnet dataset place ilsvrc 2015 tion dnn imagenet dataset 62 figure 17 demonstrates simpliﬁed version microsoft winning deep residual learning model despite depth network simply adding layer dnn doe not improve guarantee result contrary degrades quality solution make training dnn not straight forward msra team wa able overcome degradation making hoping stacked layer match residual mapping instead desired mapping following function 62 f x h x 36 f x residual mapping h x desired mapping recasting desired mapping end 62 according msra team much easier optimize residual mapping oddball stochastic gradient descent training data not created equal some higher training error others yet assume table dl algorithm shortcoming resolution technique figure deep residual learning model msra microsoft thus use training example number time simpson 63 argues assumption invalid make case paper number time training example used proportional respective training error training example ha higher error rate used train network higher number time volume 7 2019 53055 shrestha mahmood review dl algorithm architecture training example simpson 63 prof methodology termed oddball stochastic gradient descent training set 1000 video frame simpson 63 ated training selection probability distribution training example based error value pegged frequency using training example based distribution deep belief network chen lin 23 highlight fact conventional neural network easily get stuck local minimum tion propose dnn architecture called large scale deep belief network dbn us labeled unlabeled learn feature representation dbn made layer rbm stacked together learn probability distribution input vector employ unsupervised supervised algorithm niques mitigate risk getting trapped local minimum equation 23 change weight c momentum factor α learning rate v h visible hidden unit respectively 1 α 37 equation 23 probability distribution hidden visible input p hj w σ x wijvi aj 38 p vi w σ j x wijhj bi 39 big data big data provides tremendous opportunity challenge deep learning big data known 4 v volume ity veracity variety unlike shallow network huge volume variety data handled dnns signiﬁcantly improve training process ability ﬁt complex model ﬂip side sheer ity data generated daunting process jajafabadi et al 47 raise similar challenge learning streaming data credit card usage monitor fraud detection propose using parallel distributed processing thousand cpu core addition also use cloud provider support based usage workload not data represent quality case computer vision image constrained source studio much easier recognize one unconstrained source like surveillance camera reference 64 proposes method utilize multiple image unconstrained source enhance recognition process deep learning help mine extract useful pattern big data build model inference prediction business decision making massive volume structured unstructured data medium ﬁles getting figure learning multiple layer representation generated today making information retrieval lenging deep learning help semantic indexing enable information readily accessible search engine 14 65 involves building model provide relationship document keywords contain make information retrieval effective generative top connection generative model much training usually implemented approach discriminatory recognition model developed using backpropagation model one take vector representation input object computes higher level feature representation subsequent layer ﬁnal discrimination recognition pattern output layer one shortcoming backpropagation requires labeled data train geoffrey hinton proposed novel way overcoming limitation 2007 66 proposed dnn used generative connection opposed connection mimic way generate visual imagery dream without actual sensory input generative connection data representation put network used generate raw vector representation original input one layer time layer feature representation learned approach perfected either generative model even standard recognition model 66 generative model figure 18 since correct upstream cause event layer known parison actual cause prediction made approximate inference procedure made recognition weight rij adjusted increase probability correct prediction 53056 volume 7 2019 shrestha mahmood review dl algorithm architecture figure dbn deep boltzmann machine equation 66 adjusting recognition weight rij α hi hj x hirij 40 unsupervised deep boltzmann machine vast majority dnn training based supervised ing real life learning based supervised unsupervised learning fact learning pervised unsupervised learning relevant today age big data analytics raw data unlabeled 47 one way overcome limitation backpropagation get stuck local minimum incorporate supervised unsupervised training quite evident generative unsupervised learning good generalization essentially adjusting weight trying match recreate input data layer time 67 effective unsupervised training always some labeled data geoffrey hinton ruslan salakhutdinov describe multiple layer rbms stacked together trained layer layer greedy unsupervised way essentially creating called deep belief network modify stack make model symmetric weight thus creating deep boltzmann machine dbm four layered deep belief network deep boltzmann machine shown figure 67 dbm layer trained one time using unsupervised method tweaked using supervised backpropagation mnist norb datasets shown figure 67 received favorable result validating beneﬁts combining supervised unsupervised learning method equation showing probability distribution visible two hidden unit dbm unsupervised figure pretraining stacked altered rbm create dbm 67 figure dbm getting initialized deterministic neural network supervised 67 67 p vi σ j w 1 ijhj 41 p σ j w 2 j 42 p j σ x w 1 x w 2 43 post unsupervised dbm converted deterministic neural network tuning network supervised learning using labeled data demonstrated figure approximate posterior distribution q generated input tor marginals q j added tional input network shown ﬁgure subsequently backpropagation used network 67 volume 7 2019 53057 shrestha mahmood review dl algorithm architecture extreme learning machine elm variation learning methodology layer allow u extract complex feature pattern some problem might solved faster ter le number layer reference 68 proposed cnn termed deepbox outperformed larger network speed accuracy evaluating objectness elm another type neural network one den layer linear model learnt dataset single iteration adjusting weight den layer output whereas weight input hidden layer randomly initialized ﬁxed 69 elm obviously converge much faster agation only applied simpler problem classiﬁcations regression since proposing elm 2006 huang et al came multilayer version elm 2016 70 take complex problem combined unsupervised multilayer encoding random initialization weight demonstrate faster convergence lower training time state art multilayer perceptron training algorithm multiobjective sparse feature learning model gong et al 71 developed sparse feature learning model based auto encoder used evolutionary algorithm optimize two competing objective sparsity hidden unit reconstruction error input vendor ae fair better model sparsity determined human intervention le optimal method since time complexity evolutionary algorithm high 71 utilize tial evolution de based decomposition cut time demonstrate ha better result standard ae auto encoder sparse response rmb sesm sparse encoding symmetric machine testing mnist dataset compare result implementation learning procedure ously iterates evolutionary optimization step stochastic gradient descent optimize reconstruction error 71 step 1 optimization select optimal point pareto frontier objective step 2 optimize parameter θ θ stochastic gradient descent following reconstruction error function auto encoder training data set l x loss function x representing input representing output reconstructed input x l x f θ x 44 figure 22 show pareto frontier function used achieve compromise two competing objective function figure pareto frontier figure spectral clustering representation multiclass learning based kernel spectral clustering mehrkanoon et al 72 proposed multiclass learning rithm based kernel spectral clustering ksc using labeled unlabeled data novelty proposal introduction regularization term added cost function ksc allow label membership applied unlabeled data example achieved following way 72 unsupervised learning based kernel spectral ing ksc used core model regularization term introduced label labeled data added model figure 23 illustrates data point spectral clustering representation spectral clustering sc algorithm divide data point graph using laplacian double derivative operation whereas ksc simply extension sc us least square support vector machine methodology 73 53058 volume 7 2019 shrestha mahmood review dl algorithm architecture since unlabeled data abundantly available relative labeled data would beneﬁcial make unsupervised case learning deep convolutional network natural language processing deep cnn mostly used computer vision effective conneau et al 74 used ﬁrst time nlp 29 convolution layer goal analyze extract layer hierarchical representation word sentence syntactic semantic textual level one major setback lack earlier deep cnn nlp deeper network tend cause saturation degradation accuracy addition processing overhead layer et al 62 state degradation not caused overﬁtting deeper system difﬁcult optimize reference 62 addressed issue shortcut connection convolution block let gradient propagate freely along 74 able validate beneﬁts shortcut 49 layer respectively conneau et al 74 architecture sists series convolution block separated pooling halved resolution followed pooling classiﬁcation end metaheuristics metaheuristics used train neural network overcome limitation learning implementing metaheuristics training algorithm weight neural network connection represented dimension solution search space problem trying solve goal come near possible optimal value weight location search space represents global best solution particle swarm optimization pso type metaheuristic inspired movement bird sky consists particle candidate solution move search space reach near optimal solution paper 75 krpan jakobovic ran parallel mentation using backpropagation pso result demonstrate parallelization improves efﬁcacy algorithm parallel backpropagation efﬁcient only large network whereas parallel pso ha wider inﬂuence various size problem similarly dong zhou 76 complemented pso supervised learning control module guide search global minimum optimization problem supervised learning module provided feedback back fusion bd retain diversity social attractor renewal overcome stagnation 76 metaheuristics provide high level guidance inspired nature applies solve mathematical problem similar way 77 proposes porating concept intelligent teacher privileged information essentially extra information available training not evaluation testing dnn training process genetic algorithm genetic algorithm metaheuristic effectively used training dnn ga mimic evolutionary process selection crossover mutation population ber represents possible solution set weight unlike pso includes only one operator adjusting tion evolutionary algorithm like ga includes various step selection crossover mutation method 52 lation member undergo several iteration selection crossover based known strategy achieve better solution next iteration generation ga ha undergone decade improvement reﬁnements since wa ﬁrst proposed 1976 78 several way perform tions elite roulette rank tournament 79 dozen way perform crossover larrañaga et al alone 80 selection methodology represent exploration solution space crossover represent exploitation selected solution candidate goal get better tion wider exploration deeper exploitation additional tweaking introduced mutation parallel cluster ga executed independently island member exchanged island every often 81 addition also utilize local search greedy algorithm nearest neighbor algorithm improve quality solution lin et al 82 demonstrated successful incorporation ga resulted better classiﬁcation accuracy performance polynomial neural network standard ga operation including selection crossover mutation used parameter included partial description pd input ﬁrst layer bias input feature 82 ga wa enhanced incorporation concept mitochondrial dna mtdna evolution quite evident casual observation simple reason crossover population member much similarity doe not yield much variance offspring likewise infer ga selection crossover solution similar would not result high degree exploration solution space fact might run risk getting pigeonholed restricted pattern diversity key overcoming risk getting stuck local minimum risk mitigated exploiting idea mtdna mtdna represents one percent human chromosome 83 concept incorporating drial dna ga wa introduced shrestha mood 53 describe way restrict crossover population member solution candidate based proximity mtdna value 53 unlike rest 99 dna mtdna only inherited female thus continuous marker lineage genetic proximity premise behind offspring population member similar genetic makeup help overcoming volume 7 2019 53059 shrestha mahmood review dl algorithm architecture figure continental model mtdna 53 local minimum figure 24 describes parallel tributed nature full implementation 53 along ga operator selection mutation mtdna rated crossover training process enhanced 53 implementation continental model distributed server run multiple thread running instance ga mtdna population member exchanged server ﬁxed number iteration shown figure neural machine translation nmt neural machine translation turnkey solution used translation sentence provides some improvement traditional statistical machine translation smt not scalable large model datasets also requires lot computational power training translation ha difﬁcult rare word reason large tech company like google microsoft improved nmt implementation nmt labeled google neural machine translation gnmt skype translator respectively gmnt shown figure 257 sists encoder decoder lstm block organized layer wa presented 2016 84 overcomes shortcoming nmt enhanced deep lstm neural network includes 8 encoder 8 decoder layer method break rare difﬁcult word infer meaning conference machine translation 2014 gnmt received result par language benchmark 84 learning image real life include multiple instance object need multiple label describe ture ofﬁce space could include laptop computer desk cubicle person typing computer zhou et al 85 proposed miml learning framework corresponding mimlboost mimlsvm algorithm efﬁcient learning individual object label complex high level concept like ofﬁce space goal learn f dataset xm ym xi represents set instance xi ni xij j 1 2 ni yi represents set instance yi li yik k 1 2 li ni number instance xi li number label yi 85 mimlboost us decomposition ditional single instance single label supervised learning whereas mimlsvn utilizes feature mation instead trying learn idea complex entity ofﬁce space 85 took alternate route learned lower level individual object inferred higher level concept adversarial training machine learning training deployment used done isolated computer increasing done highly interconnected commercial production environment take face recognition system network could trained ﬂeet server training dataset imported external data source trained model could deployed another server accepts apis call real time input image people entering building responds match interconnected architecture expose machine learning wide attack surface input training dataset manipulated 53060 volume 7 2019 shrestha mahmood review dl algorithm architecture figure gnmt architecture 84 encoder neural network left decoder neural network right adversary compromise output image match network entire model respectively adversarial machine learning relatively new ﬁeld research take new threat machine learning according 86 adversary email spammer exploit lack stationary data distribution ulate input actual spam email normal email reference 86 demonstrates vulnerability discus application domain feature data distribution used reduce risk impact adversarial attack gaussian mixture model gaussian mixture model gmm statistical probabilistic model used represent multiple normal gaussian tions within larger distribution using em estimation maximization algorithm unsupervised setting gmm could used represent height distribution large population group two gaussian distribution male female figure 26 demonstrates gmm three gaussian distribution within gmm ha used primarily speech recognition tracking object video sequence gmm tive extracting speech feature modeling ability density function desired level accuracy long sufﬁcient component tion maximization make easy ﬁt model 87 probability density function gmm given following 87 p x xm cmn x µm cm 0 45 figure gmm example three component number number gaussian component cm weight gaussian x µm represents random variable x following mean vector µm siamese network purpose siamese network determine degree similarity two image shown ﬁgure 27 siamese network consists two identical cnn network identical weight parameter two image compared passed separately two twin cnns respective vector representation output ated using contrastive divergence loss function function deﬁned following 88 l w 1 1 2 dw 2 1 2 max 0 2 46 volume 7 2019 53061 shrestha mahmood review dl algorithm architecture figure siamese network dw represents euclidean distance two output vector shown ﬁgure output contrastive divergence loss function either 1 indicates image not 0 indicates image represents margin value greater idea siamese network ha extended come triplet network includes three identical network used ass similarity given image two image since softmax layer output must match number class standard cnn becomes impractical problem large number class issue apply siamese network number output softmax twin network requirement match number class 89 ability scale many class classiﬁcation extends use siamese network beyond traditional cnn used siamese network used handwritten check recognition signature veriﬁcation text similarity etc variational autoencoders name suggests variational autoencoder vae type autoencoder consists encoder decoder part shown ﬁgure fall generative model class neural network used unsupervised learning vaes learn low dimensional representation latent variable model original high dimensional dataset gaussian distribution kl divergence method good way compare distribution therefore loss function vae combination cross entropy mean squared error minimize reconstruction error kl divergence make compressed latent variable follow gaussian distribution sample probability distribution generate new dataset sample tative original dataset ha found various application figure variational autoencoder including generating image video game picture ﬁgure 28 x input z encoded output latent variable p x represents distribution associated p z represents distribution associated goal infer p z based p follows certain distribution mathematical derivation vaes originally proposed 90 suppose wanted infer p based some q try minimize kl divergence two dkl q xq log q p z 47 e log q p 48 e log q 49 dkl kl divergence e represents expectation using baye rule p p p z p x 50 dkl q e log q p z p x 51 e log q p p z log p x 52 allow u easily sample p z generate new data set p z normal distribution n 0 1 q represented gaussian parameter µ x p x kl divergence q p z derived closed form dkl n µ x 6 x 0 1 x k exp 6 x x x 53 deep reinforcement learning primary idea reinforcement learning ing agent learn environment help random experimentation exploration deﬁned reward exploitation consists ﬁnite number state si resenting agent environment action ai agent probability pa moving one state another based action ai reward ra si associated moving next state action goal balance maximize current reward r future reward γ max q predicting best action deﬁned function q γ equation represent ﬁxed discount factor q represented summation 53062 volume 7 2019 shrestha mahmood review dl algorithm architecture current reward r future reward γ max q shown q r γ max q 54 reinforcement learning speciﬁcally suited problem consists reward game like chess go etc alphago google program beat human go champion also us reinforcement ing 91 combine deep network architecture reinforcement learning get deep reinforcement learning drl extend use reinforcement even complex game area robotics smart grid healthcare ﬁnance etc 92 drl problem intractable reinforcement learning solved higher number hidden layer deep network reinforcement learning based algorithm imizes reward action taken agent 13 generative adversarial network gan gans consists generative discriminative neural work generative network generates completely new fake data based input data unsupervised learning discriminative network attempt distinguish whether data real training set generated generative network trained increase probability deceiving discriminative network make generated data indistinguishable original gans proposed goodfellow et al 93 ha popular ha many application good bad 94 able successfully synthesize realistic image text method enhancing deep learning deep learning optimized different area cussed training algorithm enhancement parallel processing parameter optimization various architecture area simultaneously implemented framework get best result speciﬁc problem training rithms ﬁnetuned different level incorporating heuristic hyperparameter optimization time train deep learning network model major factor gauge performance algorithm network instead training network data set select smaller representative data set full training distribution set using instance selection method 95 monte carlo sampling 48 effective sampling method result preventing overﬁtting improving accuracy speeding learning process without compromising quality training dataset albelwi mahmood 96 designed framework combined dataset reduction deconvolution network correlation coefﬁcient updated objective function method wa used optimizing parameter objective function result comparable latest known result mnist dataset 96 thus combining optimization tiple level using multiple method promising ﬁeld research lead advancement machine learning viii conclusion tutorial provided thorough overview neural network deep neural network took deeper dive training algorithm architecture highlighted shortcoming getting stuck local minimum overﬁtting training time large lem set examined several way come challenge different optimization method investigated adaptive learning rate hyperparameter optimization effective method improve accuracy network surveyed reviewed several recent paper studied presented implementation improvement training process also included table summarize content concise manner table provide full view different aspect deep learning correlated deep learning still nascent stage tremendous opportunity exploitation current exploration optimization method solve complex problem training rently constrained overﬁtting training time highly susceptible getting stuck local minimum continue overcome challenge deep learning work accelerate breakthrough across application machine learning artiﬁcial intelligence conflict interest author declare no conﬂict interest founding sponsor no role design study lection analysis interpretation data writing manuscript decision publish result orcid ajay shrestha reference 1 rosenblatt perceptron probabilistic model information storage organization brain psychol vol 65 no 6 pp 1958 2 minsky papert perceptrons introduction tional geometry expanded edition cambridge usa mit press 1969 258 3 cybenko approximation superposition sigmoidal function math control signal vol 2 no 4 pp 1989 4 hornik approximation capability multilayer feedforward work neural vol 4 no 2 pp 1991 5 werbos beyond regression new tool prediction analysis behavioral science dissertation harvard cambridge usa 1975 6 lecun bengio hinton deep learning nature vol 521 no 7553 pp may 2015 7 jordan mitchell machine learning trend perspective prospect science vol 349 no 6245 pp 2015 8 ng machine learning yearning technical strategy ai engineer era deep learning tech 2019 9 metz turing award 3 pioneer artiﬁcial intelligence new york ny usa new york time 2019 volume 7 2019 53063 shrestha mahmood review dl algorithm architecture 10 nagpal et development validation deep learning algorithm improving gleason scoring prostate cancer corr 2018 11 nevo ml ﬂood forecasting scale corr 2019 12 esteva et classiﬁcation skin cancer deep neural network nature vol 542 no 7639 115 2017 13 arulkumaran deisenroth brundage bharath deep reinforcement learning brief survey ieee signal process vol 34 no 6 pp 2017 14 gheisari wang bhuiyan survey deep learning big data proc ieee int conf comput sci eng cse jul 2017 pp 15 pouyanfar survey deep learning algorithm technique application acm comput vol 51 no 5 92 2018 16 vargas mosavi ruiz deep learning review proc adv intell syst 2017 pp 17 buhmann radial basis function cambridge cambridge univ press 2003 270 18 akinduko mirkes gorban som tic initialization versus principal component inf vols pp 2016 19 chen deep modular neural network springer handbook computational intelligence kacprzyk pedrycz ed berlin germany springer 2015 pp 20 ng jordan discriminative generative classiﬁers comparison logistic regression naive bayes proc int conf neural inf process syst cambridge usa mit press 2001 pp 21 bishop lasserre generative discriminative getting best world bayesian vol 8 pp 2007 22 zhou brown snavely lowe unsupervised learning depth video corr apr 2017 23 chen lin big data deep learning challenge tives ieee access vol 2 pp 2014 24 lecun kavukcuoglu farabet convolutional network application vision proc ieee int symp circuit 2010 pp 25 gousios vasilescu serebrenik zaidman lean rent github data demand proc work conf mining softw repository hyderabad india 2014 pp 26 2019 top deep learning github repository online available 27 cernadas barro amorim need hundred classiﬁers solve real world classiﬁcation problem mach learn vol 15 no 1 pp 2014 28 lecun bottou bengio haffner ing applied document recognition proc ieee vol 86 no 11 pp 1998 29 lecun bengio convolutional network image speech time series handbook brain theory neural network michael ed cambridge usa mit press 1998 pp 30 taylor fergus lecun bregler convolutional ing feature computer vision berlin germany springer 2010 31 ng jul 21 2018 convolutional neural network ufldl online available 32 schuler burger harmeling schölkopf machine learning approach image deconvolution proc ieee conf comput vi pattern jun 2013 pp 33 radford metz chintala unsupervised representation learning deep convolutional generative adversarial network corr 2015 34 jolliffe principal component analysis mathematics tic ed new york ny usa springer 2002 487 35 noda multimodal integration learning object manipulation iors using deep neural network proc int conf intell robot 2013 pp 36 hinton salakhutdinov reducing dimensionality data neural network science vol 313 no 5786 pp 2006 37 wang li chen chen deep model reduction distributed parameter system ieee trans man vol 46 no 12 pp 2016 38 ng jul 21 2018 autoencoders ufldl online available 39 teh hinton restricted boltzmann machine face recognition proc adv neural inf process 2001 pp 40 hinton practical guide training restricted boltzmann machine neural network trick trade montavon orr müller ed berlin germany springer 2012 pp 41 hochreiter schmidhuber long memory neural vol 9 no 8 pp 1997 42 metz apple bringing ai revolution phone wired tech 2016 43 gers schmidhuber cummins learning forget continual prediction lstm neural vol 12 no 10 pp 2000 44 chung 2014 empirical evaluation gated recurrent neural work sequence online available 45 cho 2014 learning phrase representation using rnn decoder statistical machine online available http 46 naul bloom pérez van der walt recurrent neural network classiﬁcation unevenly sampled variable star nature vol 2 no 2 pp 2018 47 najafabadi villanustre khoshgoftaar seliya wald muharemagic deep learning application challenge big data analytics big data vol 2 no 1 1 2015 48 goodfellow bengio courville deep learning adaptive computation machine learning cambridge usa mit press 2016 775 49 gavin method nonlinear least square problem tech 2016 50 glorot bengio understanding difﬁculty training deep feedforward neural network proc int conf artif intell 2010 pp 51 marten deep learning via optimization proc int conf int conf mach learn haifa israel omnipress 2010 pp 52 escalante monte sucar particle swarm model selection mach learn vol 10 pp 2009 53 shrestha mahmood improving genetic algorithm tuned crossover scaled architecture j vol 2016 10 mar 2016 54 sastry goldberg kendall genetic algorithm 2005 55 goldberg design innovation lesson competent genetic algorithm boston usa springer 2013 56 miikkulainen evolving deep neural network corr mar 2017 57 duchi hazan singer adaptive subgradient method online learning stochastic optimization mach learn vol 12 pp jul 2011 58 kingma ba adam method stochastic optimization corr 2014 59 ioffe szegedy batch normalization accelerating deep network training reducing internal covariate shift corr 2015 60 srivastava hinton krizhevsky sutskever salakhutdinov dropout simple way prevent neural network overﬁtting mach learn vol 15 no 1 pp 2014 61 aw service jul 21 2018 amazon instance zon instance type online available 62 zhang ren sun deep residual learning image recognition proc ieee conf comput vi pattern recognit cvpr jun 2016 pp 63 simpson uniform learning deep neural network via oddball stochastic gradient descent corr 2015 64 han otto klare jain unconstrained face recognition identifying person interest medium collection ieee trans inf forensics security vol 9 no 12 pp 2014 65 letsche berry information retrieval latent semantic indexing inf vol 100 no pp 1997 53064 volume 7 2019 shrestha mahmood review dl algorithm architecture 66 hinton learning multiple layer representation trend cognit vol 11 no 10 pp 2007 67 salakhutdinov hinton deep boltzmann machine proc int conf artif intell van max ed 2009 pp 68 kuo hariharan malik deepbox learning objectness convolutional network corr may 2015 69 huang zhu siew extreme learning machine ory application neurocomputing vol 70 no pp 2006 70 tang deng huang extreme learning machine multilayer perceptron ieee trans neural netw learn vol 27 no 4 pp apr 2015 71 gong liu li cai su multiobjective sparse feature learning model deep neural network ieee trans neural netw learn vol 26 no 12 pp 2015 72 mehrkanoon alzate mall langone suykens multiclass semisupervised learning based upon kernel spectral ing ieee trans neural netw learn vol 26 no 4 pp apr 2015 73 langone mall alzate suykens kernel spectral clustering application corr may 2015 74 conneau schwenk barrault lecun deep lutional network text classiﬁcation corr jun 2016 75 krpan jakobovic parallel neural network training opencl proc int conv mipro may 2012 pp 76 dong zhou supervised learning control method improve particle swarm optimization algorithm ieee trans man cybern vol 47 no 7 pp jul 2017 77 vapnik izmailov learning using privileged information larity control knowledge transfer mach learn vol 16 no 1 pp 2015 78 sampson adaptation natural artiﬁcial system vol 18 no 3 holland ed philadelphia pa usa siam 1976 pp 79 razali geraghty genetic algorithm performance different selection strategy solving tsp proc world congr 2010 pp 80 larrañaga kuijpers murga inza dizdarevic genetic algorithm travelling salesman problem review resentations operator artif intell vol 13 no 2 pp apr 1999 81 whitley genetic algorithm tutorial statist vol 4 no 2 pp jun 1994 82 lin prasad saxena improved polynomial neural network classiﬁer using genetic algorithm ieee trans man vol 45 no 11 pp 2015 83 guo et use next generation sequencing technology study effect radiation therapy mitochondrial dna mutation mutation toxicol environ mutagenesis vol 744 no 2 pp 2012 84 wu google neural machine translation system bridging gap human machine translation corr 2016 85 zhou zhang huang li label learning artif vol 176 no 1 pp 2012 86 huang joseph nelson rubinstein tygar adversarial machine learning proc acm workshop secur artif chicago il usa 2011 pp 87 yu deng automatic speech recognition deep learning approach london springer 2015 88 hadsell chopra lecun dimensionality reduction ing invariant mapping proc ieee comput soc conf comput vi pattern recognit cvpr jun 2006 pp 89 shrestha mahmood enhancing siamese network training importance sampling proc int conf agent artif intell prague czech republic scitepress 2019 pp 90 kingma welling 2013 variational online available 91 silver et mastering game go deep neural network tree search nature vol 529 no 7587 484 2016 92 henderson islam bellemare pineau introduction deep reinforcement learning corr 2018 93 goodfellow et al 2014 generative adversarial online available 94 reed akata yan logeswaran schiele lee 2016 generative adversarial text image online available 95 brighton mellish advance instance selection based learning algorithm data mining knowl discovery vol 6 no 2 pp 2002 96 albelwi mahmood framework designing architecture deep convolutional neural network entropy vol 19 no 6 242 ajay shrestha received degree computer engineering degree puter science university bridgeport ct usa 2002 2006 respectively currently pursuing degree computer science engineering ha guest lectured pennsylvania state versity also adjunct faculty school engineering university bridgeport thermo fisher scientiﬁc branford ct usa manager technical operation research interest include machine learning metaheuristics ha served technical committee member international conference system computing science software engineering sc received academic excellence award graduate research assistantship graduate graduate study respectively ha serving chapter vice president ofﬁcers upsilon pi epsilon upe since 2014 received upe executive council award presented upe executive council ausif mahmood sm 82 received degree electrical computer neering washington state university usa currently chair person puter science engineering department professor computer science neering department electrical engineering department university bridgeport bridgeport ct usa research interest include parallel distributed computing computer vision deep learning computer architecture volume 7 2019 53065